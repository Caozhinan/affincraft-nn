[INFO] Job starting at Fri Nov  7 16:47:54 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä® (LMDBÊ†ºÂºè)
 ËäÇÁÇπ:        g0927
 ‰Ωú‰∏öID:      4512497
 GPUs:        0,1,2,3,4,5,6,7
 ÂêØÂä®Êó∂Èó¥:    Fri Nov  7 16:47:54 CST 2025
==========================================
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - Â§öGPUÂàÜÂ∏ÉÂºèÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           8 GPUs √ó 1 node(s)
DataLoader workers: 6 per GPU
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/valid_lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   112
-------------------------------------------------------------------
ÁõÆÊ†áËÆ≠ÁªÉËΩÆÊï∞:       100
‰º∞ÁÆóÊÄªÊõ¥Êñ∞Ê≠•Êï∞:     1250000
Â≠¶‰π†ÁéáÈ¢ÑÁÉ≠Ê≠•Êï∞:     50000
===================================================================
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:51:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 0
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 1
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 4
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 3
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 5
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 7
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 2
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2025-11-07 16:52:30 | INFO | fairseq.distributed.utils | initialized host g0927 as rank 6
2025-11-07 16:52:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 64, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 14, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 100, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 14, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 1250000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=64, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=14, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=14, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=1250000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[5e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=470, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=50000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1250000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 470, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/valid_lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 50000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 1250000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129





2025-11-07 16:52:31 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb





Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568






2025-11-07 16:52:31 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå80568 ‰∏™Ê†∑Êú¨
2025-11-07 16:52:31 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=64, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=14, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=14, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=1250000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[5e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=470, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=50000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1250000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-11-07 16:52:32 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-11-07 16:52:32 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-11-07 16:52:32 | INFO | fairseq_cli.train | model: GraphormerModel
2025-11-07 16:52:32 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-11-07 16:52:32 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-11-07 16:52:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-11-07 16:52:32 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 80568
2025-11-07 16:52:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   4: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   5: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   6: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | rank   7: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:52:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-11-07 16:52:33 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2025-11-07 16:52:33 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 14
2025-11-07 16:52:33 | INFO | fairseq.trainer | Preparing to load checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint_last.pt
2025-11-07 16:52:33 | INFO | fairseq.trainer | No existing checkpoint found /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint_last.pt
2025-11-07 16:52:33 | INFO | fairseq.trainer | loading train data for epoch 1
2025-11-07 16:52:33 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-11-07 16:52:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 13011
2025-11-07 16:52:37 | INFO | fairseq.trainer | begin training epoch 1
2025-11-07 16:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-07 16:52:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 16:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 16:53:59 | INFO | train_inner | epoch 001:     52 / 13011 loss=0.870537, wps=1425.9, ups=0.74, wpb=1916.5, bsz=112, num_updates=50, lr=5e-08, gnorm=154.33, clip=100, loss_scale=16, train_wall=77, gb_free=17.6, wall=86
2025-11-07 16:54:59 | INFO | train_inner | epoch 001:    102 / 13011 loss=0.812878, wps=1616.5, ups=0.84, wpb=1926.3, bsz=112, num_updates=100, lr=1e-07, gnorm=161.287, clip=100, loss_scale=16, train_wall=59, gb_free=17.7, wall=146
2025-11-07 16:55:55 | INFO | train_inner | epoch 001:    152 / 13011 loss=0.72373, wps=1681.1, ups=0.88, wpb=1913.7, bsz=112, num_updates=150, lr=1.5e-07, gnorm=136.076, clip=100, loss_scale=16, train_wall=57, gb_free=19.2, wall=203
2025-11-07 16:56:53 | INFO | train_inner | epoch 001:    202 / 13011 loss=0.688711, wps=1654.1, ups=0.87, wpb=1905.3, bsz=112, num_updates=200, lr=2e-07, gnorm=73.087, clip=100, loss_scale=16, train_wall=57, gb_free=16.9, wall=260
2025-11-07 16:57:51 | INFO | train_inner | epoch 001:    252 / 13011 loss=0.636599, wps=1656.7, ups=0.86, wpb=1925.7, bsz=112, num_updates=250, lr=2.5e-07, gnorm=85.771, clip=100, loss_scale=16, train_wall=58, gb_free=9.7, wall=319
2025-11-07 16:58:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 16:58:50 | INFO | train_inner | epoch 001:    303 / 13011 loss=0.66447, wps=1607, ups=0.84, wpb=1903.2, bsz=112, num_updates=300, lr=3e-07, gnorm=91.697, clip=100, loss_scale=16, train_wall=59, gb_free=16.5, wall=378
2025-11-07 16:59:47 | INFO | train_inner | epoch 001:    353 / 13011 loss=0.638707, wps=1683.3, ups=0.88, wpb=1919.9, bsz=112, num_updates=350, lr=3.5e-07, gnorm=92.056, clip=100, loss_scale=16, train_wall=57, gb_free=9.2, wall=435
2025-11-07 17:00:44 | INFO | train_inner | epoch 001:    403 / 13011 loss=0.606723, wps=1674.4, ups=0.89, wpb=1882.6, bsz=112, num_updates=400, lr=4e-07, gnorm=88.144, clip=100, loss_scale=16, train_wall=56, gb_free=16.7, wall=491
2025-11-07 17:01:41 | INFO | train_inner | epoch 001:    453 / 13011 loss=0.616286, wps=1676, ups=0.88, wpb=1914.4, bsz=112, num_updates=450, lr=4.5e-07, gnorm=116.661, clip=100, loss_scale=16, train_wall=57, gb_free=15.3, wall=548
2025-11-07 17:02:39 | INFO | train_inner | epoch 001:    503 / 13011 loss=0.595849, wps=1651.6, ups=0.86, wpb=1927.9, bsz=112, num_updates=500, lr=5e-07, gnorm=95.61, clip=100, loss_scale=16, train_wall=58, gb_free=12.6, wall=607
2025-11-07 17:03:36 | INFO | train_inner | epoch 001:    553 / 13011 loss=0.602843, wps=1680.1, ups=0.88, wpb=1915.1, bsz=112, num_updates=550, lr=5.5e-07, gnorm=91.277, clip=100, loss_scale=16, train_wall=57, gb_free=18.7, wall=664
2025-11-07 17:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 17:04:34 | INFO | train_inner | epoch 001:    604 / 13011 loss=0.549853, wps=1649.5, ups=0.87, wpb=1902, bsz=112, num_updates=600, lr=6e-07, gnorm=89.257, clip=100, loss_scale=16, train_wall=57, gb_free=18.8, wall=721
2025-11-07 17:05:31 | INFO | train_inner | epoch 001:    654 / 13011 loss=0.571792, wps=1689.8, ups=0.88, wpb=1919.5, bsz=112, num_updates=650, lr=6.5e-07, gnorm=96.41, clip=100, loss_scale=16, train_wall=57, gb_free=18.2, wall=778
2025-11-07 17:06:29 | INFO | train_inner | epoch 001:    704 / 13011 loss=0.569931, wps=1654.7, ups=0.86, wpb=1918.6, bsz=112, num_updates=700, lr=7e-07, gnorm=117.244, clip=100, loss_scale=16, train_wall=58, gb_free=17.4, wall=836
2025-11-07 17:07:26 | INFO | train_inner | epoch 001:    754 / 13011 loss=0.563707, wps=1664.2, ups=0.86, wpb=1924.3, bsz=112, num_updates=750, lr=7.5e-07, gnorm=123.436, clip=100, loss_scale=16, train_wall=58, gb_free=17.2, wall=894
2025-11-07 17:08:25 | INFO | train_inner | epoch 001:    804 / 13011 loss=0.519887, wps=1647.9, ups=0.85, wpb=1946.7, bsz=112, num_updates=800, lr=8e-07, gnorm=97.15, clip=100, loss_scale=16, train_wall=59, gb_free=14.3, wall=953
2025-11-07 17:10:59 | INFO | train_inner | epoch 001:    854 / 13011 loss=0.521401, wps=620.3, ups=0.33, wpb=1898.6, bsz=112, num_updates=850, lr=8.5e-07, gnorm=105.231, clip=100, loss_scale=32, train_wall=152, gb_free=18.1, wall=1106
2025-11-07 17:13:08 | INFO | train_inner | epoch 001:    904 / 13011 loss=0.510225, wps=743.3, ups=0.39, wpb=1917.6, bsz=112, num_updates=900, lr=9e-07, gnorm=114.321, clip=100, loss_scale=32, train_wall=95, gb_free=17.9, wall=1235
2025-11-07 17:13:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 17:14:23 | INFO | train_inner | epoch 001:    955 / 13011 loss=0.50753, wps=1249.7, ups=0.66, wpb=1884.4, bsz=112, num_updates=950, lr=9.5e-07, gnorm=108.628, clip=100, loss_scale=16, train_wall=61, gb_free=14.6, wall=1310
2025-11-07 17:15:28 | INFO | train_inner | epoch 001:   1005 / 13011 loss=0.522239, wps=1444.9, ups=0.77, wpb=1872.5, bsz=112, num_updates=1000, lr=1e-06, gnorm=144.871, clip=100, loss_scale=16, train_wall=65, gb_free=17.2, wall=1375
2025-11-07 17:16:27 | INFO | train_inner | epoch 001:   1055 / 13011 loss=0.502071, wps=1611, ups=0.84, wpb=1910.9, bsz=112, num_updates=1050, lr=1.05e-06, gnorm=109.919, clip=100, loss_scale=16, train_wall=59, gb_free=17.7, wall=1434
2025-11-07 17:17:39 | INFO | train_inner | epoch 001:   1105 / 13011 loss=0.511992, wps=1323.1, ups=0.69, wpb=1915.7, bsz=112, num_updates=1100, lr=1.1e-06, gnorm=126.207, clip=100, loss_scale=16, train_wall=63, gb_free=18, wall=1507
2025-11-07 17:18:45 | INFO | train_inner | epoch 001:   1155 / 13011 loss=0.511102, wps=1476.8, ups=0.77, wpb=1926.3, bsz=112, num_updates=1150, lr=1.15e-06, gnorm=111.991, clip=100, loss_scale=16, train_wall=65, gb_free=19.1, wall=1572
2025-11-07 17:19:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 17:19:56 | INFO | train_inner | epoch 001:   1206 / 13011 loss=0.497442, wps=1356.7, ups=0.71, wpb=1923.3, bsz=112, num_updates=1200, lr=1.2e-06, gnorm=117.553, clip=100, loss_scale=16, train_wall=71, gb_free=18.1, wall=1643
2025-11-07 17:21:05 | INFO | train_inner | epoch 001:   1256 / 13011 loss=0.483388, wps=1365.5, ups=0.72, wpb=1907.7, bsz=112, num_updates=1250, lr=1.25e-06, gnorm=96.904, clip=100, loss_scale=16, train_wall=63, gb_free=10.3, wall=1713
2025-11-07 17:22:12 | INFO | train_inner | epoch 001:   1306 / 13011 loss=0.506811, wps=1400.7, ups=0.75, wpb=1875.5, bsz=112, num_updates=1300, lr=1.3e-06, gnorm=99.76, clip=100, loss_scale=16, train_wall=67, gb_free=18, wall=1780
2025-11-07 17:23:24 | INFO | train_inner | epoch 001:   1356 / 13011 loss=0.476037, wps=1301.1, ups=0.7, wpb=1865.7, bsz=112, num_updates=1350, lr=1.35e-06, gnorm=93.221, clip=100, loss_scale=16, train_wall=64, gb_free=14.9, wall=1851
2025-11-07 17:24:57 | INFO | train_inner | epoch 001:   1406 / 13011 loss=0.490777, wps=1039.6, ups=0.54, wpb=1931, bsz=112, num_updates=1400, lr=1.4e-06, gnorm=96.115, clip=100, loss_scale=16, train_wall=93, gb_free=15.1, wall=1944
2025-11-07 17:26:40 | INFO | train_inner | epoch 001:   1456 / 13011 loss=0.488642, wps=933.6, ups=0.48, wpb=1932.5, bsz=112, num_updates=1450, lr=1.45e-06, gnorm=93.302, clip=100, loss_scale=32, train_wall=68, gb_free=17.4, wall=2048
2025-11-07 17:27:44 | INFO | train_inner | epoch 001:   1506 / 13011 loss=0.487532, wps=1508.2, ups=0.79, wpb=1903.8, bsz=112, num_updates=1500, lr=1.5e-06, gnorm=71.211, clip=100, loss_scale=32, train_wall=63, gb_free=18.3, wall=2111
2025-11-07 17:29:24 | INFO | train_inner | epoch 001:   1556 / 13011 loss=0.449529, wps=932.8, ups=0.5, wpb=1880.5, bsz=112, num_updates=1550, lr=1.55e-06, gnorm=67.164, clip=100, loss_scale=32, train_wall=60, gb_free=15.9, wall=2212
2025-11-07 17:31:05 | INFO | train_inner | epoch 001:   1606 / 13011 loss=0.455992, wps=951.7, ups=0.5, wpb=1917.9, bsz=112, num_updates=1600, lr=1.6e-06, gnorm=63.684, clip=100, loss_scale=32, train_wall=101, gb_free=18.2, wall=2312
2025-11-07 17:33:06 | INFO | train_inner | epoch 001:   1656 / 13011 loss=0.454214, wps=807.7, ups=0.41, wpb=1952.4, bsz=112, num_updates=1650, lr=1.65e-06, gnorm=71.793, clip=100, loss_scale=32, train_wall=116, gb_free=18.6, wall=2433
2025-11-07 17:34:26 | INFO | train_inner | epoch 001:   1706 / 13011 loss=0.462095, wps=1195.8, ups=0.63, wpb=1906.7, bsz=112, num_updates=1700, lr=1.7e-06, gnorm=57.104, clip=100, loss_scale=64, train_wall=61, gb_free=18.5, wall=2513
2025-11-07 17:35:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 17:35:31 | INFO | train_inner | epoch 001:   1757 / 13011 loss=0.4683, wps=1444.1, ups=0.76, wpb=1898.8, bsz=112, num_updates=1750, lr=1.75e-06, gnorm=58.259, clip=100, loss_scale=32, train_wall=64, gb_free=18.3, wall=2579
2025-11-07 17:37:40 | INFO | train_inner | epoch 001:   1807 / 13011 loss=0.443543, wps=762.4, ups=0.39, wpb=1953.7, bsz=112, num_updates=1800, lr=1.8e-06, gnorm=57.824, clip=100, loss_scale=32, train_wall=102, gb_free=14.3, wall=2707
2025-11-07 17:38:52 | INFO | train_inner | epoch 001:   1857 / 13011 loss=0.44793, wps=1320.1, ups=0.69, wpb=1907.4, bsz=112, num_updates=1850, lr=1.85e-06, gnorm=64.664, clip=100, loss_scale=32, train_wall=72, gb_free=17.8, wall=2779
2025-11-07 17:40:32 | INFO | train_inner | epoch 001:   1907 / 13011 loss=0.478023, wps=953.3, ups=0.5, wpb=1913.6, bsz=112, num_updates=1900, lr=1.9e-06, gnorm=61.918, clip=100, loss_scale=32, train_wall=100, gb_free=15.2, wall=2880
2025-11-07 17:41:33 | INFO | train_inner | epoch 001:   1957 / 13011 loss=0.46288, wps=1571.2, ups=0.83, wpb=1896.4, bsz=112, num_updates=1950, lr=1.95e-06, gnorm=57.793, clip=100, loss_scale=32, train_wall=60, gb_free=18, wall=2940
2025-11-07 17:43:13 | INFO | train_inner | epoch 001:   2007 / 13011 loss=0.446822, wps=965.8, ups=0.5, wpb=1939.2, bsz=112, num_updates=2000, lr=2e-06, gnorm=57.744, clip=100, loss_scale=64, train_wall=100, gb_free=17.9, wall=3040
2025-11-07 17:45:25 | INFO | train_inner | epoch 001:   2057 / 13011 loss=0.448126, wps=727.2, ups=0.38, wpb=1913.3, bsz=112, num_updates=2050, lr=2.05e-06, gnorm=51.859, clip=100, loss_scale=64, train_wall=131, gb_free=18.2, wall=3172
2025-11-07 17:47:37 | INFO | train_inner | epoch 001:   2107 / 13011 loss=0.452808, wps=709.8, ups=0.38, wpb=1884.3, bsz=112, num_updates=2100, lr=2.1e-06, gnorm=49.249, clip=100, loss_scale=64, train_wall=133, gb_free=18.4, wall=3305
2025-11-07 17:49:13 | INFO | train_inner | epoch 001:   2157 / 13011 loss=0.443159, wps=1017, ups=0.52, wpb=1939.4, bsz=112, num_updates=2150, lr=2.15e-06, gnorm=48.681, clip=100, loss_scale=64, train_wall=82, gb_free=14.6, wall=3400
2025-11-07 17:50:15 | INFO | train_inner | epoch 001:   2207 / 13011 loss=0.454308, wps=1529, ups=0.8, wpb=1913.7, bsz=112, num_updates=2200, lr=2.2e-06, gnorm=52.683, clip=100, loss_scale=64, train_wall=62, gb_free=9.1, wall=3463
2025-11-07 17:51:24 | INFO | train_inner | epoch 001:   2257 / 13011 loss=0.448227, wps=1404.2, ups=0.73, wpb=1936.3, bsz=112, num_updates=2250, lr=2.25e-06, gnorm=53.732, clip=100, loss_scale=64, train_wall=69, gb_free=17.8, wall=3532
2025-11-07 17:52:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 17:53:07 | INFO | train_inner | epoch 001:   2308 / 13011 loss=0.432381, wps=933.2, ups=0.49, wpb=1923, bsz=112, num_updates=2300, lr=2.3e-06, gnorm=49.996, clip=100, loss_scale=64, train_wall=102, gb_free=14, wall=3635
2025-11-07 17:54:20 | INFO | train_inner | epoch 001:   2358 / 13011 loss=0.444764, wps=1306.7, ups=0.68, wpb=1916.6, bsz=112, num_updates=2350, lr=2.35e-06, gnorm=45.402, clip=100, loss_scale=64, train_wall=64, gb_free=18.2, wall=3708
2025-11-07 17:56:01 | INFO | train_inner | epoch 001:   2408 / 13011 loss=0.458411, wps=966.4, ups=0.5, wpb=1950.5, bsz=112, num_updates=2400, lr=2.4e-06, gnorm=49.467, clip=100, loss_scale=64, train_wall=101, gb_free=18, wall=3809
2025-11-07 17:57:43 | INFO | train_inner | epoch 001:   2458 / 13011 loss=0.443314, wps=942.4, ups=0.49, wpb=1910.3, bsz=112, num_updates=2450, lr=2.45e-06, gnorm=45.548, clip=100, loss_scale=64, train_wall=101, gb_free=17.8, wall=3910
2025-11-07 17:59:07 | INFO | train_inner | epoch 001:   2508 / 13011 loss=0.443312, wps=1155.4, ups=0.59, wpb=1948.7, bsz=112, num_updates=2500, lr=2.5e-06, gnorm=44.285, clip=100, loss_scale=64, train_wall=84, gb_free=14, wall=3994
2025-11-07 18:00:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:00:26 | INFO | train_inner | epoch 001:   2559 / 13011 loss=0.427374, wps=1250.2, ups=0.64, wpb=1961.6, bsz=112, num_updates=2550, lr=2.55e-06, gnorm=46.348, clip=100, loss_scale=64, train_wall=74, gb_free=18.1, wall=4073
2025-11-07 18:01:28 | INFO | train_inner | epoch 001:   2609 / 13011 loss=0.456045, wps=1552.9, ups=0.8, wpb=1951.4, bsz=112, num_updates=2600, lr=2.6e-06, gnorm=43.119, clip=100, loss_scale=64, train_wall=63, gb_free=18.8, wall=4136
2025-11-07 18:03:12 | INFO | train_inner | epoch 001:   2659 / 13011 loss=0.438333, wps=928.4, ups=0.48, wpb=1916.1, bsz=112, num_updates=2650, lr=2.65e-06, gnorm=41.876, clip=100, loss_scale=64, train_wall=103, gb_free=18.5, wall=4239
2025-11-07 18:05:39 | INFO | train_inner | epoch 001:   2709 / 13011 loss=0.455339, wps=644.2, ups=0.34, wpb=1903.9, bsz=112, num_updates=2700, lr=2.7e-06, gnorm=41.633, clip=100, loss_scale=64, train_wall=148, gb_free=11.2, wall=4387
2025-11-07 18:06:50 | INFO | train_inner | epoch 001:   2759 / 13011 loss=0.433313, wps=1380.2, ups=0.71, wpb=1944, bsz=112, num_updates=2750, lr=2.75e-06, gnorm=35.613, clip=100, loss_scale=64, train_wall=70, gb_free=18, wall=4457
2025-11-07 18:08:03 | INFO | train_inner | epoch 001:   2809 / 13011 loss=0.442727, wps=1285.9, ups=0.68, wpb=1883.2, bsz=112, num_updates=2800, lr=2.8e-06, gnorm=41.014, clip=100, loss_scale=128, train_wall=73, gb_free=17.5, wall=4530
2025-11-07 18:09:28 | INFO | train_inner | epoch 001:   2859 / 13011 loss=0.411582, wps=1122.5, ups=0.59, wpb=1911.8, bsz=112, num_updates=2850, lr=2.85e-06, gnorm=34.029, clip=100, loss_scale=128, train_wall=85, gb_free=17.6, wall=4616
2025-11-07 18:09:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:11:02 | INFO | train_inner | epoch 001:   2910 / 13011 loss=0.451023, wps=1037.4, ups=0.53, wpb=1952.4, bsz=112, num_updates=2900, lr=2.9e-06, gnorm=42.822, clip=100, loss_scale=64, train_wall=94, gb_free=19.1, wall=4710
2025-11-07 18:12:05 | INFO | train_inner | epoch 001:   2960 / 13011 loss=0.436364, wps=1553.3, ups=0.8, wpb=1945.3, bsz=112, num_updates=2950, lr=2.95e-06, gnorm=41.93, clip=100, loss_scale=64, train_wall=62, gb_free=17.7, wall=4772
2025-11-07 18:13:41 | INFO | train_inner | epoch 001:   3010 / 13011 loss=0.451919, wps=990.3, ups=0.52, wpb=1904.9, bsz=112, num_updates=3000, lr=3e-06, gnorm=41.896, clip=100, loss_scale=64, train_wall=96, gb_free=18.2, wall=4869
2025-11-07 18:14:48 | INFO | train_inner | epoch 001:   3060 / 13011 loss=0.428615, wps=1419.5, ups=0.75, wpb=1892.8, bsz=112, num_updates=3050, lr=3.05e-06, gnorm=38.001, clip=100, loss_scale=64, train_wall=66, gb_free=16.4, wall=4935
2025-11-07 18:16:06 | INFO | train_inner | epoch 001:   3110 / 13011 loss=0.413482, wps=1216.5, ups=0.64, wpb=1911.5, bsz=112, num_updates=3100, lr=3.1e-06, gnorm=36.669, clip=100, loss_scale=64, train_wall=78, gb_free=18.9, wall=5014
2025-11-07 18:17:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:17:43 | INFO | train_inner | epoch 001:   3161 / 13011 loss=0.430135, wps=984.7, ups=0.52, wpb=1898.8, bsz=112, num_updates=3150, lr=3.15e-06, gnorm=39.451, clip=100, loss_scale=64, train_wall=96, gb_free=18.2, wall=5110
2025-11-07 18:19:59 | INFO | train_inner | epoch 001:   3211 / 13011 loss=0.426996, wps=716.8, ups=0.37, wpb=1956.5, bsz=112, num_updates=3200, lr=3.2e-06, gnorm=37.086, clip=100, loss_scale=64, train_wall=136, gb_free=17.7, wall=5247
2025-11-07 18:21:41 | INFO | train_inner | epoch 001:   3261 / 13011 loss=0.418059, wps=946.5, ups=0.49, wpb=1923, bsz=112, num_updates=3250, lr=3.25e-06, gnorm=38.071, clip=100, loss_scale=64, train_wall=69, gb_free=18.1, wall=5348
2025-11-07 18:22:45 | INFO | train_inner | epoch 001:   3311 / 13011 loss=0.427696, wps=1494.9, ups=0.78, wpb=1909.6, bsz=112, num_updates=3300, lr=3.3e-06, gnorm=35.071, clip=100, loss_scale=64, train_wall=64, gb_free=16.9, wall=5412
2025-11-07 18:25:37 | INFO | train_inner | epoch 001:   3361 / 13011 loss=0.417381, wps=561.2, ups=0.29, wpb=1938, bsz=112, num_updates=3350, lr=3.35e-06, gnorm=39.574, clip=100, loss_scale=64, train_wall=172, gb_free=15.2, wall=5585
2025-11-07 18:27:10 | INFO | train_inner | epoch 001:   3411 / 13011 loss=0.417927, wps=1024.2, ups=0.54, wpb=1889.2, bsz=112, num_updates=3400, lr=3.4e-06, gnorm=37.555, clip=100, loss_scale=128, train_wall=92, gb_free=18.6, wall=5677
2025-11-07 18:28:27 | INFO | train_inner | epoch 001:   3461 / 13011 loss=0.455863, wps=1226, ups=0.64, wpb=1903.7, bsz=112, num_updates=3450, lr=3.45e-06, gnorm=43.318, clip=100, loss_scale=128, train_wall=77, gb_free=18.6, wall=5755
2025-11-07 18:29:36 | INFO | train_inner | epoch 001:   3511 / 13011 loss=0.438696, wps=1376.7, ups=0.72, wpb=1903.6, bsz=112, num_updates=3500, lr=3.5e-06, gnorm=37.904, clip=100, loss_scale=128, train_wall=65, gb_free=18.2, wall=5824
2025-11-07 18:31:32 | INFO | train_inner | epoch 001:   3561 / 13011 loss=0.420524, wps=820.5, ups=0.43, wpb=1894.3, bsz=112, num_updates=3550, lr=3.55e-06, gnorm=36.643, clip=100, loss_scale=128, train_wall=115, gb_free=18, wall=5939
2025-11-07 18:32:58 | INFO | train_inner | epoch 001:   3611 / 13011 loss=0.40736, wps=1120.5, ups=0.58, wpb=1926.7, bsz=112, num_updates=3600, lr=3.6e-06, gnorm=39.168, clip=100, loss_scale=128, train_wall=85, gb_free=17.6, wall=6025
2025-11-07 18:34:00 | INFO | train_inner | epoch 001:   3661 / 13011 loss=0.40006, wps=1568, ups=0.81, wpb=1940.7, bsz=112, num_updates=3650, lr=3.65e-06, gnorm=33.585, clip=100, loss_scale=256, train_wall=62, gb_free=17.1, wall=6087
2025-11-07 18:34:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 18:35:53 | INFO | train_inner | epoch 001:   3712 / 13011 loss=0.432146, wps=830.3, ups=0.44, wpb=1875.7, bsz=112, num_updates=3700, lr=3.7e-06, gnorm=35.264, clip=100, loss_scale=128, train_wall=105, gb_free=16.8, wall=6200
2025-11-07 18:37:40 | INFO | train_inner | epoch 001:   3762 / 13011 loss=0.422908, wps=915.7, ups=0.47, wpb=1960.6, bsz=112, num_updates=3750, lr=3.75e-06, gnorm=32.261, clip=100, loss_scale=128, train_wall=107, gb_free=17.3, wall=6307
2025-11-07 18:39:24 | INFO | train_inner | epoch 001:   3812 / 13011 loss=0.414441, wps=944, ups=0.48, wpb=1960.6, bsz=112, num_updates=3800, lr=3.8e-06, gnorm=32.377, clip=100, loss_scale=128, train_wall=65, gb_free=14.9, wall=6411
2025-11-07 18:40:57 | INFO | train_inner | epoch 001:   3862 / 13011 loss=0.401404, wps=1011.4, ups=0.54, wpb=1890.5, bsz=112, num_updates=3850, lr=3.85e-06, gnorm=39.498, clip=100, loss_scale=128, train_wall=93, gb_free=18.8, wall=6504
2025-11-07 18:41:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:42:23 | INFO | train_inner | epoch 001:   3913 / 13011 loss=0.420446, wps=1104.6, ups=0.58, wpb=1894.3, bsz=112, num_updates=3900, lr=3.9e-06, gnorm=38.402, clip=100, loss_scale=64, train_wall=85, gb_free=16.9, wall=6590
2025-11-07 18:43:25 | INFO | train_inner | epoch 001:   3963 / 13011 loss=0.409511, wps=1529.5, ups=0.8, wpb=1903.9, bsz=112, num_updates=3950, lr=3.95e-06, gnorm=34.083, clip=100, loss_scale=64, train_wall=62, gb_free=16.6, wall=6652
2025-11-07 18:44:46 | INFO | train_inner | epoch 001:   4013 / 13011 loss=0.402037, wps=1173.3, ups=0.62, wpb=1906.3, bsz=112, num_updates=4000, lr=4e-06, gnorm=35.074, clip=100, loss_scale=64, train_wall=81, gb_free=18, wall=6734
2025-11-07 18:46:02 | INFO | train_inner | epoch 001:   4063 / 13011 loss=0.401208, wps=1256.1, ups=0.66, wpb=1900.9, bsz=112, num_updates=4050, lr=4.05e-06, gnorm=37.581, clip=100, loss_scale=64, train_wall=75, gb_free=18, wall=6809
2025-11-07 18:47:21 | INFO | train_inner | epoch 001:   4113 / 13011 loss=0.420651, wps=1202.5, ups=0.63, wpb=1904.4, bsz=112, num_updates=4100, lr=4.1e-06, gnorm=38.331, clip=100, loss_scale=64, train_wall=79, gb_free=19.1, wall=6888
2025-11-07 18:48:23 | INFO | train_inner | epoch 001:   4163 / 13011 loss=0.41553, wps=1549.9, ups=0.8, wpb=1933.8, bsz=112, num_updates=4150, lr=4.15e-06, gnorm=35.058, clip=100, loss_scale=128, train_wall=62, gb_free=17, wall=6951
2025-11-07 18:50:26 | INFO | train_inner | epoch 001:   4213 / 13011 loss=0.419173, wps=784.4, ups=0.41, wpb=1915.1, bsz=112, num_updates=4200, lr=4.2e-06, gnorm=41.593, clip=100, loss_scale=128, train_wall=95, gb_free=18.8, wall=7073
2025-11-07 18:51:50 | INFO | train_inner | epoch 001:   4263 / 13011 loss=0.396137, wps=1123.6, ups=0.59, wpb=1890.8, bsz=112, num_updates=4250, lr=4.25e-06, gnorm=35.666, clip=100, loss_scale=128, train_wall=63, gb_free=18.1, wall=7157
2025-11-07 18:54:43 | INFO | train_inner | epoch 001:   4313 / 13011 loss=0.41388, wps=563.1, ups=0.29, wpb=1946, bsz=112, num_updates=4300, lr=4.3e-06, gnorm=34.637, clip=100, loss_scale=128, train_wall=173, gb_free=14.4, wall=7330
2025-11-07 18:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:56:45 | INFO | train_inner | epoch 001:   4364 / 13011 loss=0.396414, wps=794.1, ups=0.41, wpb=1947.3, bsz=112, num_updates=4350, lr=4.35e-06, gnorm=39.906, clip=100, loss_scale=64, train_wall=122, gb_free=18.6, wall=7453
2025-11-07 18:57:47 | INFO | train_inner | epoch 001:   4414 / 13011 loss=0.4166, wps=1560.1, ups=0.8, wpb=1943.2, bsz=112, num_updates=4400, lr=4.4e-06, gnorm=35.818, clip=100, loss_scale=64, train_wall=62, gb_free=17, wall=7515
2025-11-07 18:59:40 | INFO | train_inner | epoch 001:   4464 / 13011 loss=0.400458, wps=853.6, ups=0.44, wpb=1919.2, bsz=112, num_updates=4450, lr=4.45e-06, gnorm=34.878, clip=100, loss_scale=64, train_wall=112, gb_free=16.9, wall=7627
2025-11-07 19:01:55 | INFO | train_inner | epoch 001:   4514 / 13011 loss=0.411283, wps=711.1, ups=0.37, wpb=1927, bsz=112, num_updates=4500, lr=4.5e-06, gnorm=37.469, clip=100, loss_scale=64, train_wall=135, gb_free=11.6, wall=7763
2025-11-07 19:03:11 | INFO | train_inner | epoch 001:   4564 / 13011 loss=0.40647, wps=1263.7, ups=0.66, wpb=1917.1, bsz=112, num_updates=4550, lr=4.55e-06, gnorm=40.288, clip=100, loss_scale=64, train_wall=76, gb_free=18.2, wall=7839
2025-11-07 19:04:27 | INFO | train_inner | epoch 001:   4614 / 13011 loss=0.407015, wps=1270.9, ups=0.66, wpb=1928.9, bsz=112, num_updates=4600, lr=4.6e-06, gnorm=32.652, clip=100, loss_scale=128, train_wall=76, gb_free=19, wall=7915
2025-11-07 19:05:28 | INFO | train_inner | epoch 001:   4664 / 13011 loss=0.391546, wps=1534.4, ups=0.82, wpb=1878.2, bsz=112, num_updates=4650, lr=4.65e-06, gnorm=37.658, clip=100, loss_scale=128, train_wall=61, gb_free=17.7, wall=7976
2025-11-07 19:06:45 | INFO | train_inner | epoch 001:   4714 / 13011 loss=0.410847, wps=1247, ups=0.66, wpb=1900, bsz=112, num_updates=4700, lr=4.7e-06, gnorm=43.045, clip=100, loss_scale=128, train_wall=63, gb_free=18.1, wall=8052
2025-11-07 19:08:08 | INFO | train_inner | epoch 001:   4764 / 13011 loss=0.381611, wps=1161.1, ups=0.6, wpb=1940, bsz=111.9, num_updates=4750, lr=4.75e-06, gnorm=35.673, clip=100, loss_scale=128, train_wall=70, gb_free=11.8, wall=8135
2025-11-07 19:09:40 | INFO | train_inner | epoch 001:   4814 / 13011 loss=0.400371, wps=1059.1, ups=0.55, wpb=1938.2, bsz=112, num_updates=4800, lr=4.8e-06, gnorm=37.88, clip=100, loss_scale=128, train_wall=63, gb_free=15.4, wall=8227
2025-11-07 19:11:40 | INFO | train_inner | epoch 001:   4864 / 13011 loss=0.391367, wps=782.9, ups=0.41, wpb=1892.6, bsz=112, num_updates=4850, lr=4.85e-06, gnorm=37.223, clip=100, loss_scale=256, train_wall=121, gb_free=17.1, wall=8348
2025-11-07 19:11:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:13:08 | INFO | train_inner | epoch 001:   4915 / 13011 loss=0.392185, wps=1089.5, ups=0.57, wpb=1915.1, bsz=112, num_updates=4900, lr=4.9e-06, gnorm=36.047, clip=100, loss_scale=128, train_wall=88, gb_free=18, wall=8436
2025-11-07 19:14:11 | INFO | train_inner | epoch 001:   4965 / 13011 loss=0.396232, wps=1523.3, ups=0.8, wpb=1913.7, bsz=112, num_updates=4950, lr=4.95e-06, gnorm=37.928, clip=100, loss_scale=128, train_wall=63, gb_free=19, wall=8499
2025-11-07 19:15:28 | INFO | train_inner | epoch 001:   5015 / 13011 loss=0.404657, wps=1269.9, ups=0.65, wpb=1948.4, bsz=112, num_updates=5000, lr=5e-06, gnorm=36.464, clip=100, loss_scale=128, train_wall=72, gb_free=18.7, wall=8575
2025-11-07 19:17:55 | INFO | train_inner | epoch 001:   5065 / 13011 loss=0.378556, wps=651.9, ups=0.34, wpb=1918.2, bsz=112, num_updates=5050, lr=5.05e-06, gnorm=39.743, clip=100, loss_scale=128, train_wall=111, gb_free=18.2, wall=8722
2025-11-07 19:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:19:07 | INFO | train_inner | epoch 001:   5116 / 13011 loss=0.397006, wps=1341.2, ups=0.7, wpb=1925.6, bsz=112, num_updates=5100, lr=5.1e-06, gnorm=43.087, clip=100, loss_scale=64, train_wall=63, gb_free=13.7, wall=8794
2025-11-07 19:20:19 | INFO | train_inner | epoch 001:   5166 / 13011 loss=0.384856, wps=1305.3, ups=0.69, wpb=1885.2, bsz=112, num_updates=5150, lr=5.15e-06, gnorm=35.912, clip=100, loss_scale=64, train_wall=70, gb_free=15.6, wall=8866
2025-11-07 19:21:45 | INFO | train_inner | epoch 001:   5216 / 13011 loss=0.390841, wps=1140.2, ups=0.58, wpb=1953.1, bsz=112, num_updates=5200, lr=5.2e-06, gnorm=37.775, clip=100, loss_scale=64, train_wall=65, gb_free=12.4, wall=8952
2025-11-07 19:22:47 | INFO | train_inner | epoch 001:   5266 / 13011 loss=0.38717, wps=1557.6, ups=0.8, wpb=1945.5, bsz=112, num_updates=5250, lr=5.25e-06, gnorm=36.656, clip=100, loss_scale=64, train_wall=62, gb_free=18.6, wall=9014
2025-11-07 19:24:23 | INFO | train_inner | epoch 001:   5316 / 13011 loss=0.396153, wps=997.3, ups=0.52, wpb=1919.3, bsz=112, num_updates=5300, lr=5.3e-06, gnorm=42.677, clip=100, loss_scale=64, train_wall=96, gb_free=17.5, wall=9111
2025-11-07 19:26:33 | INFO | train_inner | epoch 001:   5366 / 13011 loss=0.395532, wps=730.2, ups=0.38, wpb=1898.8, bsz=112, num_updates=5350, lr=5.35e-06, gnorm=42.206, clip=100, loss_scale=128, train_wall=130, gb_free=18.2, wall=9241
2025-11-07 19:29:00 | INFO | train_inner | epoch 001:   5416 / 13011 loss=0.385604, wps=658.8, ups=0.34, wpb=1934.3, bsz=112, num_updates=5400, lr=5.4e-06, gnorm=31.935, clip=100, loss_scale=128, train_wall=101, gb_free=18.3, wall=9388
2025-11-07 19:30:20 | INFO | train_inner | epoch 001:   5466 / 13011 loss=0.407355, wps=1211.9, ups=0.63, wpb=1929.7, bsz=112, num_updates=5450, lr=5.45e-06, gnorm=42.485, clip=100, loss_scale=128, train_wall=79, gb_free=17.4, wall=9467
2025-11-07 19:31:23 | INFO | train_inner | epoch 001:   5516 / 13011 loss=0.38853, wps=1514, ups=0.8, wpb=1901.9, bsz=112, num_updates=5500, lr=5.5e-06, gnorm=34.791, clip=100, loss_scale=128, train_wall=63, gb_free=15.4, wall=9530
2025-11-07 19:32:27 | INFO | train_inner | epoch 001:   5566 / 13011 loss=0.383432, wps=1462.5, ups=0.78, wpb=1880.4, bsz=112, num_updates=5550, lr=5.55e-06, gnorm=38.479, clip=100, loss_scale=128, train_wall=64, gb_free=18.8, wall=9594
2025-11-07 19:33:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:33:33 | INFO | train_inner | epoch 001:   5617 / 13011 loss=0.381252, wps=1434.5, ups=0.75, wpb=1905.6, bsz=112, num_updates=5600, lr=5.6e-06, gnorm=35.38, clip=100, loss_scale=128, train_wall=66, gb_free=15, wall=9661
2025-11-07 19:34:38 | INFO | train_inner | epoch 001:   5667 / 13011 loss=0.393788, wps=1483.1, ups=0.77, wpb=1930.4, bsz=112, num_updates=5650, lr=5.65e-06, gnorm=41.39, clip=100, loss_scale=128, train_wall=65, gb_free=16, wall=9726
2025-11-07 19:35:42 | INFO | train_inner | epoch 001:   5717 / 13011 loss=0.37713, wps=1521.2, ups=0.79, wpb=1926.1, bsz=112, num_updates=5700, lr=5.7e-06, gnorm=34.896, clip=100, loss_scale=128, train_wall=63, gb_free=17.5, wall=9789
2025-11-07 19:36:53 | INFO | train_inner | epoch 001:   5767 / 13011 loss=0.384117, wps=1365.3, ups=0.7, wpb=1958.6, bsz=112, num_updates=5750, lr=5.75e-06, gnorm=37.991, clip=100, loss_scale=128, train_wall=71, gb_free=16.9, wall=9861
2025-11-07 19:38:12 | INFO | train_inner | epoch 001:   5817 / 13011 loss=0.391559, wps=1227.5, ups=0.64, wpb=1932.1, bsz=112, num_updates=5800, lr=5.8e-06, gnorm=44.1, clip=100, loss_scale=128, train_wall=71, gb_free=19.1, wall=9939
2025-11-07 19:39:17 | INFO | train_inner | epoch 001:   5867 / 13011 loss=0.390878, wps=1476.6, ups=0.77, wpb=1922.5, bsz=112, num_updates=5850, lr=5.85e-06, gnorm=44.463, clip=100, loss_scale=128, train_wall=65, gb_free=17.4, wall=10005
2025-11-07 19:39:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:40:23 | INFO | train_inner | epoch 001:   5918 / 13011 loss=0.356275, wps=1442.2, ups=0.76, wpb=1899.3, bsz=112, num_updates=5900, lr=5.9e-06, gnorm=40.192, clip=100, loss_scale=128, train_wall=66, gb_free=16.1, wall=10070
2025-11-07 19:41:28 | INFO | train_inner | epoch 001:   5968 / 13011 loss=0.379584, wps=1477.6, ups=0.77, wpb=1928.3, bsz=112, num_updates=5950, lr=5.95e-06, gnorm=34.703, clip=100, loss_scale=128, train_wall=65, gb_free=17.8, wall=10136
2025-11-07 19:42:34 | INFO | train_inner | epoch 001:   6018 / 13011 loss=0.395979, wps=1468.2, ups=0.76, wpb=1935, bsz=112, num_updates=6000, lr=6e-06, gnorm=35.688, clip=100, loss_scale=128, train_wall=66, gb_free=15.6, wall=10202
2025-11-07 19:43:38 | INFO | train_inner | epoch 001:   6068 / 13011 loss=0.381607, wps=1467.6, ups=0.79, wpb=1862.2, bsz=112, num_updates=6050, lr=6.05e-06, gnorm=40.092, clip=100, loss_scale=128, train_wall=63, gb_free=12, wall=10265
2025-11-07 19:44:41 | INFO | train_inner | epoch 001:   6118 / 13011 loss=0.381305, wps=1496, ups=0.8, wpb=1881, bsz=112, num_updates=6100, lr=6.1e-06, gnorm=39.342, clip=100, loss_scale=128, train_wall=63, gb_free=16.2, wall=10328
2025-11-07 19:45:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:45:46 | INFO | train_inner | epoch 001:   6169 / 13011 loss=0.380236, wps=1445, ups=0.76, wpb=1889.5, bsz=112, num_updates=6150, lr=6.15e-06, gnorm=45.722, clip=100, loss_scale=128, train_wall=65, gb_free=16.4, wall=10393
2025-11-07 19:46:52 | INFO | train_inner | epoch 001:   6219 / 13011 loss=0.375864, wps=1440, ups=0.76, wpb=1897.1, bsz=112, num_updates=6200, lr=6.2e-06, gnorm=37.806, clip=100, loss_scale=128, train_wall=66, gb_free=17.6, wall=10459
2025-11-07 19:47:57 | INFO | train_inner | epoch 001:   6269 / 13011 loss=0.380008, wps=1470.6, ups=0.77, wpb=1911.3, bsz=112, num_updates=6250, lr=6.25e-06, gnorm=39.979, clip=100, loss_scale=128, train_wall=65, gb_free=19.4, wall=10524
2025-11-07 19:49:01 | INFO | train_inner | epoch 001:   6319 / 13011 loss=0.386678, wps=1512.9, ups=0.78, wpb=1936.4, bsz=112, num_updates=6300, lr=6.3e-06, gnorm=41.979, clip=100, loss_scale=128, train_wall=64, gb_free=16.7, wall=10588
2025-11-07 19:50:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:50:09 | INFO | train_inner | epoch 001:   6370 / 13011 loss=0.391531, wps=1415.1, ups=0.74, wpb=1918.1, bsz=112, num_updates=6350, lr=6.35e-06, gnorm=50.292, clip=100, loss_scale=64, train_wall=68, gb_free=17.8, wall=10656
2025-11-07 19:51:17 | INFO | train_inner | epoch 001:   6420 / 13011 loss=0.388159, wps=1421, ups=0.73, wpb=1939.2, bsz=112, num_updates=6400, lr=6.4e-06, gnorm=42.78, clip=100, loss_scale=64, train_wall=67, gb_free=18.2, wall=10724
2025-11-07 19:52:21 | INFO | train_inner | epoch 001:   6470 / 13011 loss=0.381825, wps=1487.8, ups=0.78, wpb=1912.3, bsz=112, num_updates=6450, lr=6.45e-06, gnorm=45.976, clip=100, loss_scale=64, train_wall=64, gb_free=15.3, wall=10788
2025-11-07 19:53:23 | INFO | train_inner | epoch 001:   6520 / 13011 loss=0.373141, wps=1513.7, ups=0.8, wpb=1888.3, bsz=112, num_updates=6500, lr=6.5e-06, gnorm=37.215, clip=100, loss_scale=64, train_wall=62, gb_free=18.2, wall=10851
2025-11-07 19:54:32 | INFO | train_inner | epoch 001:   6570 / 13011 loss=0.373173, wps=1398.6, ups=0.73, wpb=1923.3, bsz=112, num_updates=6550, lr=6.55e-06, gnorm=46.528, clip=100, loss_scale=64, train_wall=69, gb_free=19.1, wall=10920
2025-11-07 19:55:57 | INFO | train_inner | epoch 001:   6620 / 13011 loss=0.391712, wps=1147.2, ups=0.59, wpb=1941.4, bsz=112, num_updates=6600, lr=6.6e-06, gnorm=45.88, clip=100, loss_scale=128, train_wall=84, gb_free=15.3, wall=11004
2025-11-07 19:57:00 | INFO | train_inner | epoch 001:   6670 / 13011 loss=0.373288, wps=1516.1, ups=0.79, wpb=1917.1, bsz=112, num_updates=6650, lr=6.65e-06, gnorm=46.423, clip=100, loss_scale=128, train_wall=63, gb_free=18.1, wall=11067
2025-11-07 19:58:06 | INFO | train_inner | epoch 001:   6720 / 13011 loss=0.384635, wps=1436.5, ups=0.75, wpb=1903.7, bsz=112, num_updates=6700, lr=6.7e-06, gnorm=43.443, clip=100, loss_scale=128, train_wall=66, gb_free=15.9, wall=11134
2025-11-07 19:59:11 | INFO | train_inner | epoch 001:   6770 / 13011 loss=0.384233, wps=1494.1, ups=0.78, wpb=1918.8, bsz=112, num_updates=6750, lr=6.75e-06, gnorm=43.098, clip=100, loss_scale=128, train_wall=64, gb_free=17.1, wall=11198
2025-11-07 19:59:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:00:18 | INFO | train_inner | epoch 001:   6821 / 13011 loss=0.392998, wps=1419.3, ups=0.74, wpb=1922.4, bsz=112, num_updates=6800, lr=6.8e-06, gnorm=44.863, clip=100, loss_scale=64, train_wall=67, gb_free=17.7, wall=11266
2025-11-07 20:01:24 | INFO | train_inner | epoch 001:   6871 / 13011 loss=0.371604, wps=1451.8, ups=0.75, wpb=1923.6, bsz=112, num_updates=6850, lr=6.85e-06, gnorm=34.841, clip=100, loss_scale=64, train_wall=66, gb_free=18.1, wall=11332
2025-11-07 20:02:35 | INFO | train_inner | epoch 001:   6921 / 13011 loss=0.356489, wps=1377.1, ups=0.71, wpb=1934.7, bsz=112, num_updates=6900, lr=6.9e-06, gnorm=37.453, clip=100, loss_scale=64, train_wall=70, gb_free=16.6, wall=11402
2025-11-07 20:03:39 | INFO | train_inner | epoch 001:   6971 / 13011 loss=0.361733, wps=1489.7, ups=0.78, wpb=1909.3, bsz=112, num_updates=6950, lr=6.95e-06, gnorm=40.234, clip=100, loss_scale=64, train_wall=64, gb_free=17.5, wall=11466
2025-11-07 20:04:52 | INFO | train_inner | epoch 001:   7021 / 13011 loss=0.345066, wps=1322.8, ups=0.69, wpb=1928.1, bsz=112, num_updates=7000, lr=7e-06, gnorm=34.527, clip=100, loss_scale=64, train_wall=73, gb_free=16.8, wall=11539
2025-11-07 20:05:59 | INFO | train_inner | epoch 001:   7071 / 13011 loss=0.365244, wps=1430.4, ups=0.75, wpb=1917.9, bsz=112, num_updates=7050, lr=7.05e-06, gnorm=40.72, clip=100, loss_scale=128, train_wall=67, gb_free=18.4, wall=11606
2025-11-07 20:07:15 | INFO | train_inner | epoch 001:   7121 / 13011 loss=0.369879, wps=1263.9, ups=0.66, wpb=1916.1, bsz=112, num_updates=7100, lr=7.1e-06, gnorm=38.901, clip=100, loss_scale=128, train_wall=76, gb_free=19, wall=11682
2025-11-07 20:08:27 | INFO | train_inner | epoch 001:   7171 / 13011 loss=0.364747, wps=1324.2, ups=0.69, wpb=1911.6, bsz=112, num_updates=7150, lr=7.15e-06, gnorm=43.494, clip=100, loss_scale=128, train_wall=72, gb_free=17.7, wall=11754
2025-11-07 20:09:31 | INFO | train_inner | epoch 001:   7221 / 13011 loss=0.35596, wps=1495.3, ups=0.77, wpb=1930.4, bsz=112, num_updates=7200, lr=7.2e-06, gnorm=35.298, clip=100, loss_scale=128, train_wall=64, gb_free=15.6, wall=11819
2025-11-07 20:10:41 | INFO | train_inner | epoch 001:   7271 / 13011 loss=0.365728, wps=1387.1, ups=0.72, wpb=1922.9, bsz=112, num_updates=7250, lr=7.25e-06, gnorm=40.296, clip=100, loss_scale=128, train_wall=69, gb_free=18.4, wall=11888
2025-11-07 20:11:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:11:46 | INFO | train_inner | epoch 001:   7322 / 13011 loss=0.356757, wps=1505.1, ups=0.77, wpb=1956, bsz=112, num_updates=7300, lr=7.3e-06, gnorm=40.902, clip=100, loss_scale=64, train_wall=65, gb_free=18.4, wall=11953
2025-11-07 20:12:50 | INFO | train_inner | epoch 001:   7372 / 13011 loss=0.359773, wps=1484.2, ups=0.78, wpb=1907.2, bsz=112, num_updates=7350, lr=7.35e-06, gnorm=44.772, clip=100, loss_scale=64, train_wall=64, gb_free=14.4, wall=12017
2025-11-07 20:13:53 | INFO | train_inner | epoch 001:   7422 / 13011 loss=0.389762, wps=1513.4, ups=0.79, wpb=1925.3, bsz=112, num_updates=7400, lr=7.4e-06, gnorm=44.776, clip=100, loss_scale=64, train_wall=63, gb_free=16.6, wall=12081
2025-11-07 20:15:00 | INFO | train_inner | epoch 001:   7472 / 13011 loss=0.364576, wps=1450.7, ups=0.75, wpb=1943.4, bsz=112, num_updates=7450, lr=7.45e-06, gnorm=46.919, clip=100, loss_scale=64, train_wall=67, gb_free=18.4, wall=12148
2025-11-07 20:16:10 | INFO | train_inner | epoch 001:   7522 / 13011 loss=0.356211, wps=1378.7, ups=0.72, wpb=1918.7, bsz=112, num_updates=7500, lr=7.5e-06, gnorm=39.356, clip=100, loss_scale=64, train_wall=69, gb_free=11.3, wall=12217
2025-11-07 20:17:15 | INFO | train_inner | epoch 001:   7572 / 13011 loss=0.371654, wps=1470.2, ups=0.76, wpb=1924.1, bsz=112, num_updates=7550, lr=7.55e-06, gnorm=47.681, clip=100, loss_scale=128, train_wall=65, gb_free=17, wall=12283
2025-11-07 20:18:24 | INFO | train_inner | epoch 001:   7622 / 13011 loss=0.367886, wps=1385.4, ups=0.73, wpb=1894.4, bsz=112, num_updates=7600, lr=7.6e-06, gnorm=41.263, clip=100, loss_scale=128, train_wall=68, gb_free=18.2, wall=12351
2025-11-07 20:19:36 | INFO | train_inner | epoch 001:   7672 / 13011 loss=0.371834, wps=1318.8, ups=0.69, wpb=1903.8, bsz=112, num_updates=7650, lr=7.65e-06, gnorm=40.938, clip=100, loss_scale=128, train_wall=72, gb_free=15, wall=12423
2025-11-07 20:19:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:20:48 | INFO | train_inner | epoch 001:   7723 / 13011 loss=0.365031, wps=1318.2, ups=0.69, wpb=1910.4, bsz=112, num_updates=7700, lr=7.7e-06, gnorm=42.858, clip=100, loss_scale=64, train_wall=72, gb_free=15.5, wall=12496
2025-11-07 20:21:59 | INFO | train_inner | epoch 001:   7773 / 13011 loss=0.369029, wps=1343.6, ups=0.71, wpb=1896.8, bsz=112, num_updates=7750, lr=7.75e-06, gnorm=36.789, clip=100, loss_scale=64, train_wall=70, gb_free=15.3, wall=12566
2025-11-07 20:23:13 | INFO | train_inner | epoch 001:   7823 / 13011 loss=0.370008, wps=1307.6, ups=0.68, wpb=1931.2, bsz=112, num_updates=7800, lr=7.8e-06, gnorm=40.518, clip=100, loss_scale=64, train_wall=74, gb_free=17.5, wall=12640
2025-11-07 20:24:19 | INFO | train_inner | epoch 001:   7873 / 13011 loss=0.35911, wps=1429.6, ups=0.75, wpb=1899.1, bsz=112, num_updates=7850, lr=7.85e-06, gnorm=43.422, clip=100, loss_scale=64, train_wall=66, gb_free=17.9, wall=12707
2025-11-07 20:25:24 | INFO | train_inner | epoch 001:   7923 / 13011 loss=0.35863, wps=1464.9, ups=0.77, wpb=1894.4, bsz=112, num_updates=7900, lr=7.9e-06, gnorm=41.408, clip=100, loss_scale=64, train_wall=64, gb_free=19.3, wall=12771
2025-11-07 20:26:29 | INFO | train_inner | epoch 001:   7973 / 13011 loss=0.362931, wps=1457.4, ups=0.76, wpb=1907.7, bsz=112, num_updates=7950, lr=7.95e-06, gnorm=36.771, clip=100, loss_scale=128, train_wall=65, gb_free=12.4, wall=12837
2025-11-07 20:27:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:27:36 | INFO | train_inner | epoch 001:   8024 / 13011 loss=0.361447, wps=1455.1, ups=0.75, wpb=1942.4, bsz=112, num_updates=8000, lr=8e-06, gnorm=43.79, clip=100, loss_scale=64, train_wall=67, gb_free=14.5, wall=12904
2025-11-07 20:28:43 | INFO | train_inner | epoch 001:   8074 / 13011 loss=0.359462, wps=1424.1, ups=0.75, wpb=1898.6, bsz=112, num_updates=8050, lr=8.05e-06, gnorm=44.646, clip=100, loss_scale=64, train_wall=66, gb_free=15.5, wall=12970
2025-11-07 20:29:48 | INFO | train_inner | epoch 001:   8124 / 13011 loss=0.353933, wps=1483, ups=0.77, wpb=1935.9, bsz=112, num_updates=8100, lr=8.1e-06, gnorm=45.126, clip=100, loss_scale=64, train_wall=65, gb_free=19, wall=13036
2025-11-07 20:30:55 | INFO | train_inner | epoch 001:   8174 / 13011 loss=0.34332, wps=1422.1, ups=0.74, wpb=1912.8, bsz=112, num_updates=8150, lr=8.15e-06, gnorm=43.782, clip=100, loss_scale=64, train_wall=67, gb_free=17, wall=13103
2025-11-07 20:32:07 | INFO | train_inner | epoch 001:   8224 / 13011 loss=0.351246, wps=1314.5, ups=0.69, wpb=1893.1, bsz=112, num_updates=8200, lr=8.2e-06, gnorm=40.722, clip=100, loss_scale=64, train_wall=72, gb_free=17.4, wall=13175
2025-11-07 20:33:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:33:21 | INFO | train_inner | epoch 001:   8275 / 13011 loss=0.349154, wps=1290.8, ups=0.68, wpb=1893.5, bsz=112, num_updates=8250, lr=8.25e-06, gnorm=36.127, clip=100, loss_scale=64, train_wall=73, gb_free=15.2, wall=13248
2025-11-07 20:34:27 | INFO | train_inner | epoch 001:   8325 / 13011 loss=0.359391, wps=1462.4, ups=0.76, wpb=1929.9, bsz=112, num_updates=8300, lr=8.3e-06, gnorm=39.857, clip=100, loss_scale=64, train_wall=66, gb_free=19.1, wall=13314
2025-11-07 20:35:31 | INFO | train_inner | epoch 001:   8375 / 13011 loss=0.357354, wps=1492.7, ups=0.78, wpb=1924.8, bsz=112, num_updates=8350, lr=8.35e-06, gnorm=38.817, clip=100, loss_scale=64, train_wall=64, gb_free=15.4, wall=13379
2025-11-07 20:36:36 | INFO | train_inner | epoch 001:   8425 / 13011 loss=0.380014, wps=1468.7, ups=0.78, wpb=1893.5, bsz=112, num_updates=8400, lr=8.4e-06, gnorm=42.344, clip=100, loss_scale=64, train_wall=64, gb_free=15.1, wall=13443
2025-11-07 20:37:41 | INFO | train_inner | epoch 001:   8475 / 13011 loss=0.352473, wps=1468.9, ups=0.77, wpb=1904.6, bsz=112, num_updates=8450, lr=8.45e-06, gnorm=39.794, clip=100, loss_scale=64, train_wall=65, gb_free=18.8, wall=13508
2025-11-07 20:38:50 | INFO | train_inner | epoch 001:   8525 / 13011 loss=0.3494, wps=1381.7, ups=0.72, wpb=1913.6, bsz=112, num_updates=8500, lr=8.5e-06, gnorm=43.387, clip=100, loss_scale=128, train_wall=69, gb_free=17.7, wall=13577
2025-11-07 20:39:54 | INFO | train_inner | epoch 001:   8575 / 13011 loss=0.369207, wps=1502.2, ups=0.78, wpb=1923.2, bsz=112, num_updates=8550, lr=8.55e-06, gnorm=41.219, clip=100, loss_scale=128, train_wall=64, gb_free=18.5, wall=13641
2025-11-07 20:40:58 | INFO | train_inner | epoch 001:   8625 / 13011 loss=0.360923, wps=1477.6, ups=0.78, wpb=1906.5, bsz=112, num_updates=8600, lr=8.6e-06, gnorm=43.04, clip=100, loss_scale=128, train_wall=64, gb_free=18.9, wall=13706
2025-11-07 20:42:02 | INFO | train_inner | epoch 001:   8675 / 13011 loss=0.365358, wps=1501, ups=0.78, wpb=1918.1, bsz=112, num_updates=8650, lr=8.65e-06, gnorm=41.333, clip=100, loss_scale=128, train_wall=64, gb_free=16.2, wall=13770
2025-11-07 20:42:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:43:08 | INFO | train_inner | epoch 001:   8726 / 13011 loss=0.348461, wps=1444.8, ups=0.76, wpb=1902, bsz=112, num_updates=8700, lr=8.7e-06, gnorm=35.732, clip=100, loss_scale=64, train_wall=66, gb_free=18.7, wall=13835
2025-11-07 20:44:13 | INFO | train_inner | epoch 001:   8776 / 13011 loss=0.373632, wps=1480, ups=0.77, wpb=1921.1, bsz=112, num_updates=8750, lr=8.75e-06, gnorm=45.485, clip=100, loss_scale=64, train_wall=65, gb_free=17.4, wall=13900
2025-11-07 20:45:25 | INFO | train_inner | epoch 001:   8826 / 13011 loss=0.343077, wps=1329.5, ups=0.69, wpb=1919.9, bsz=112, num_updates=8800, lr=8.8e-06, gnorm=43.425, clip=100, loss_scale=64, train_wall=72, gb_free=19.1, wall=13973
2025-11-07 20:46:29 | INFO | train_inner | epoch 001:   8876 / 13011 loss=0.354685, wps=1487, ups=0.78, wpb=1911.9, bsz=112, num_updates=8850, lr=8.85e-06, gnorm=36.222, clip=100, loss_scale=64, train_wall=64, gb_free=17.5, wall=14037
2025-11-07 20:47:33 | INFO | train_inner | epoch 001:   8926 / 13011 loss=0.343104, wps=1527.1, ups=0.79, wpb=1932, bsz=112, num_updates=8900, lr=8.9e-06, gnorm=45.247, clip=100, loss_scale=64, train_wall=63, gb_free=16.1, wall=14100
2025-11-07 20:48:40 | INFO | train_inner | epoch 001:   8976 / 13011 loss=0.344261, wps=1423.7, ups=0.74, wpb=1919.9, bsz=112, num_updates=8950, lr=8.95e-06, gnorm=40.525, clip=100, loss_scale=128, train_wall=67, gb_free=17.6, wall=14168
2025-11-07 20:49:44 | INFO | train_inner | epoch 001:   9026 / 13011 loss=0.340941, wps=1523.5, ups=0.78, wpb=1943.4, bsz=112, num_updates=9000, lr=9e-06, gnorm=36.761, clip=100, loss_scale=128, train_wall=64, gb_free=18.5, wall=14231
2025-11-07 20:50:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 20:50:53 | INFO | train_inner | epoch 001:   9077 / 13011 loss=0.327377, wps=1390.1, ups=0.73, wpb=1911.3, bsz=112, num_updates=9050, lr=9.05e-06, gnorm=40.745, clip=100, loss_scale=64, train_wall=69, gb_free=18.3, wall=14300
2025-11-07 20:52:04 | INFO | train_inner | epoch 001:   9127 / 13011 loss=0.329722, wps=1347.9, ups=0.7, wpb=1929.9, bsz=112, num_updates=9100, lr=9.1e-06, gnorm=39.635, clip=100, loss_scale=64, train_wall=71, gb_free=18.3, wall=14372
2025-11-07 20:52:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 20:53:13 | INFO | train_inner | epoch 001:   9178 / 13011 loss=0.333118, wps=1434, ups=0.73, wpb=1967.7, bsz=112, num_updates=9150, lr=9.15e-06, gnorm=41.093, clip=100, loss_scale=32, train_wall=68, gb_free=18.6, wall=14440
2025-11-07 20:54:20 | INFO | train_inner | epoch 001:   9228 / 13011 loss=0.345974, wps=1423.9, ups=0.75, wpb=1906.7, bsz=112, num_updates=9200, lr=9.2e-06, gnorm=39.27, clip=100, loss_scale=32, train_wall=67, gb_free=19.2, wall=14507
2025-11-07 20:55:24 | INFO | train_inner | epoch 001:   9278 / 13011 loss=0.355782, wps=1506.8, ups=0.78, wpb=1938.7, bsz=112, num_updates=9250, lr=9.25e-06, gnorm=43.599, clip=100, loss_scale=32, train_wall=64, gb_free=17.9, wall=14572
2025-11-07 20:56:33 | INFO | train_inner | epoch 001:   9328 / 13011 loss=0.33612, wps=1394.4, ups=0.73, wpb=1910.8, bsz=112, num_updates=9300, lr=9.3e-06, gnorm=39.375, clip=100, loss_scale=32, train_wall=68, gb_free=16.7, wall=14640
2025-11-07 20:57:42 | INFO | train_inner | epoch 001:   9378 / 13011 loss=0.356915, wps=1384.1, ups=0.72, wpb=1917.8, bsz=112, num_updates=9350, lr=9.35e-06, gnorm=40.48, clip=100, loss_scale=32, train_wall=69, gb_free=16.6, wall=14709
2025-11-07 20:58:52 | INFO | train_inner | epoch 001:   9428 / 13011 loss=0.348693, wps=1325.9, ups=0.71, wpb=1867.2, bsz=112, num_updates=9400, lr=9.4e-06, gnorm=40.094, clip=100, loss_scale=64, train_wall=70, gb_free=17.7, wall=14780
2025-11-07 21:00:04 | INFO | train_inner | epoch 001:   9478 / 13011 loss=0.343743, wps=1340.3, ups=0.7, wpb=1924.7, bsz=112, num_updates=9450, lr=9.45e-06, gnorm=40.849, clip=100, loss_scale=64, train_wall=72, gb_free=17.8, wall=14852
2025-11-07 21:01:10 | INFO | train_inner | epoch 001:   9528 / 13011 loss=0.359975, wps=1444.7, ups=0.76, wpb=1904.8, bsz=112, num_updates=9500, lr=9.5e-06, gnorm=44.212, clip=100, loss_scale=64, train_wall=66, gb_free=17.1, wall=14917
2025-11-07 21:02:13 | INFO | train_inner | epoch 001:   9578 / 13011 loss=0.330217, wps=1523.9, ups=0.79, wpb=1917, bsz=112, num_updates=9550, lr=9.55e-06, gnorm=34.193, clip=100, loss_scale=64, train_wall=63, gb_free=18.4, wall=14980
2025-11-07 21:03:19 | INFO | train_inner | epoch 001:   9628 / 13011 loss=0.327091, wps=1466.2, ups=0.75, wpb=1947, bsz=112, num_updates=9600, lr=9.6e-06, gnorm=37.976, clip=100, loss_scale=64, train_wall=66, gb_free=18.7, wall=15047
2025-11-07 21:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:04:30 | INFO | train_inner | epoch 001:   9679 / 13011 loss=0.335848, wps=1355.4, ups=0.71, wpb=1920.5, bsz=112, num_updates=9650, lr=9.65e-06, gnorm=44.825, clip=100, loss_scale=64, train_wall=71, gb_free=17.9, wall=15118
2025-11-07 21:05:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 21:05:41 | INFO | train_inner | epoch 001:   9730 / 13011 loss=0.347052, wps=1384.3, ups=0.7, wpb=1965.9, bsz=112, num_updates=9700, lr=9.7e-06, gnorm=46.804, clip=100, loss_scale=32, train_wall=71, gb_free=14.9, wall=15189
2025-11-07 21:06:51 | INFO | train_inner | epoch 001:   9780 / 13011 loss=0.317716, wps=1379.5, ups=0.72, wpb=1925.2, bsz=112, num_updates=9750, lr=9.75e-06, gnorm=37.429, clip=100, loss_scale=32, train_wall=70, gb_free=17.1, wall=15258
2025-11-07 21:07:55 | INFO | train_inner | epoch 001:   9830 / 13011 loss=0.338841, wps=1492.4, ups=0.78, wpb=1916.8, bsz=112, num_updates=9800, lr=9.8e-06, gnorm=42.657, clip=100, loss_scale=32, train_wall=64, gb_free=18.8, wall=15323
2025-11-07 21:09:02 | INFO | train_inner | epoch 001:   9880 / 13011 loss=0.340888, wps=1418, ups=0.75, wpb=1895.3, bsz=112, num_updates=9850, lr=9.85e-06, gnorm=43.196, clip=100, loss_scale=32, train_wall=67, gb_free=16.5, wall=15389
2025-11-07 21:10:09 | INFO | train_inner | epoch 001:   9930 / 13011 loss=0.344827, wps=1429.5, ups=0.75, wpb=1914.5, bsz=112, num_updates=9900, lr=9.9e-06, gnorm=49.344, clip=100, loss_scale=32, train_wall=67, gb_free=16.5, wall=15456
2025-11-07 21:11:22 | INFO | train_inner | epoch 001:   9980 / 13011 loss=0.331644, wps=1347.4, ups=0.68, wpb=1976, bsz=112, num_updates=9950, lr=9.95e-06, gnorm=42.24, clip=100, loss_scale=64, train_wall=73, gb_free=18.6, wall=15530
2025-11-07 21:12:32 | INFO | train_inner | epoch 001:  10030 / 13011 loss=0.330723, wps=1345.9, ups=0.72, wpb=1877.7, bsz=112, num_updates=10000, lr=1e-05, gnorm=39.06, clip=100, loss_scale=64, train_wall=70, gb_free=14.8, wall=15600
2025-11-07 21:13:38 | INFO | train_inner | epoch 001:  10080 / 13011 loss=0.32703, wps=1454.6, ups=0.76, wpb=1904.5, bsz=112, num_updates=10050, lr=1.005e-05, gnorm=38.989, clip=100, loss_scale=64, train_wall=65, gb_free=18.3, wall=15665
2025-11-07 21:14:41 | INFO | train_inner | epoch 001:  10130 / 13011 loss=0.330558, wps=1495.4, ups=0.78, wpb=1908.2, bsz=112, num_updates=10100, lr=1.01e-05, gnorm=45.636, clip=100, loss_scale=64, train_wall=64, gb_free=12.8, wall=15729
2025-11-07 21:15:45 | INFO | train_inner | epoch 001:  10180 / 13011 loss=0.328815, wps=1479.1, ups=0.79, wpb=1869.7, bsz=112, num_updates=10150, lr=1.015e-05, gnorm=41.449, clip=100, loss_scale=64, train_wall=63, gb_free=14.5, wall=15792
2025-11-07 21:16:50 | INFO | train_inner | epoch 001:  10230 / 13011 loss=0.329824, wps=1498, ups=0.77, wpb=1951, bsz=112, num_updates=10200, lr=1.02e-05, gnorm=41.711, clip=100, loss_scale=128, train_wall=65, gb_free=18.8, wall=15857
2025-11-07 21:17:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:17:54 | INFO | train_inner | epoch 001:  10281 / 13011 loss=0.337091, wps=1451.2, ups=0.77, wpb=1873.1, bsz=112, num_updates=10250, lr=1.025e-05, gnorm=42.005, clip=100, loss_scale=64, train_wall=64, gb_free=15.8, wall=15922
2025-11-07 21:18:58 | INFO | train_inner | epoch 001:  10331 / 13011 loss=0.325348, wps=1505.2, ups=0.78, wpb=1922.3, bsz=112, num_updates=10300, lr=1.03e-05, gnorm=45.053, clip=100, loss_scale=64, train_wall=64, gb_free=18.6, wall=15986
2025-11-07 21:20:07 | INFO | train_inner | epoch 001:  10381 / 13011 loss=0.314535, wps=1376, ups=0.73, wpb=1885.7, bsz=112, num_updates=10350, lr=1.035e-05, gnorm=36.459, clip=100, loss_scale=64, train_wall=68, gb_free=17, wall=16054
2025-11-07 21:21:11 | INFO | train_inner | epoch 001:  10431 / 13011 loss=0.342333, wps=1491.7, ups=0.78, wpb=1906.5, bsz=112, num_updates=10400, lr=1.04e-05, gnorm=43.221, clip=100, loss_scale=64, train_wall=64, gb_free=17.9, wall=16118
2025-11-07 21:22:25 | INFO | train_inner | epoch 001:  10481 / 13011 loss=0.336837, wps=1283.8, ups=0.67, wpb=1920.8, bsz=112, num_updates=10450, lr=1.045e-05, gnorm=42.457, clip=100, loss_scale=64, train_wall=75, gb_free=8.1, wall=16193
2025-11-07 21:23:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:23:30 | INFO | train_inner | epoch 001:  10532 / 13011 loss=0.309208, wps=1501, ups=0.78, wpb=1926, bsz=112, num_updates=10500, lr=1.05e-05, gnorm=37.928, clip=100, loss_scale=64, train_wall=64, gb_free=18.8, wall=16257
2025-11-07 21:24:41 | INFO | train_inner | epoch 001:  10582 / 13011 loss=0.328929, wps=1340.1, ups=0.7, wpb=1912.5, bsz=112, num_updates=10550, lr=1.055e-05, gnorm=43.698, clip=100, loss_scale=64, train_wall=71, gb_free=18.3, wall=16328
2025-11-07 21:25:51 | INFO | train_inner | epoch 001:  10632 / 13011 loss=0.320086, wps=1361.1, ups=0.71, wpb=1911.4, bsz=112, num_updates=10600, lr=1.06e-05, gnorm=37.867, clip=100, loss_scale=64, train_wall=70, gb_free=19.2, wall=16399
2025-11-07 21:27:07 | INFO | train_inner | epoch 001:  10682 / 13011 loss=0.325794, wps=1267.2, ups=0.66, wpb=1930.1, bsz=112, num_updates=10650, lr=1.065e-05, gnorm=38.119, clip=100, loss_scale=64, train_wall=76, gb_free=18.2, wall=16475
2025-11-07 21:28:20 | INFO | train_inner | epoch 001:  10732 / 13011 loss=0.324154, wps=1319, ups=0.69, wpb=1917.2, bsz=112, num_updates=10700, lr=1.07e-05, gnorm=37.498, clip=100, loss_scale=64, train_wall=72, gb_free=17.1, wall=16547
2025-11-07 21:29:31 | INFO | train_inner | epoch 001:  10782 / 13011 loss=0.328891, wps=1366.7, ups=0.71, wpb=1928.1, bsz=112, num_updates=10750, lr=1.075e-05, gnorm=37.478, clip=100, loss_scale=128, train_wall=66, gb_free=17.6, wall=16618
2025-11-07 21:29:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:30:35 | INFO | train_inner | epoch 001:  10833 / 13011 loss=0.321602, wps=1468.7, ups=0.77, wpb=1904.1, bsz=112, num_updates=10800, lr=1.08e-05, gnorm=38.767, clip=100, loss_scale=64, train_wall=65, gb_free=18.8, wall=16683
2025-11-07 21:31:38 | INFO | train_inner | epoch 001:  10883 / 13011 loss=0.329989, wps=1479.8, ups=0.79, wpb=1861.5, bsz=112, num_updates=10850, lr=1.085e-05, gnorm=41.041, clip=100, loss_scale=64, train_wall=63, gb_free=18.3, wall=16746
2025-11-07 21:32:45 | INFO | train_inner | epoch 001:  10933 / 13011 loss=0.310505, wps=1403, ups=0.75, wpb=1876.8, bsz=112, num_updates=10900, lr=1.09e-05, gnorm=39.329, clip=100, loss_scale=64, train_wall=67, gb_free=17.4, wall=16813
2025-11-07 21:33:51 | INFO | train_inner | epoch 001:  10983 / 13011 loss=0.310468, wps=1444.1, ups=0.76, wpb=1912.5, bsz=112, num_updates=10950, lr=1.095e-05, gnorm=36.109, clip=100, loss_scale=64, train_wall=66, gb_free=16.6, wall=16879
2025-11-07 21:34:56 | INFO | train_inner | epoch 001:  11033 / 13011 loss=0.336121, wps=1492.3, ups=0.78, wpb=1916.3, bsz=112, num_updates=11000, lr=1.1e-05, gnorm=44.795, clip=100, loss_scale=64, train_wall=64, gb_free=17.2, wall=16943
2025-11-07 21:35:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:36:06 | INFO | train_inner | epoch 001:  11084 / 13011 loss=0.337284, wps=1372.4, ups=0.71, wpb=1922.3, bsz=112, num_updates=11050, lr=1.105e-05, gnorm=43.339, clip=100, loss_scale=64, train_wall=70, gb_free=17.6, wall=17013
2025-11-07 21:37:09 | INFO | train_inner | epoch 001:  11134 / 13011 loss=0.326574, wps=1533.7, ups=0.78, wpb=1956, bsz=112, num_updates=11100, lr=1.11e-05, gnorm=44.129, clip=100, loss_scale=64, train_wall=64, gb_free=17.5, wall=17077
2025-11-07 21:38:14 | INFO | train_inner | epoch 001:  11184 / 13011 loss=0.324997, wps=1500, ups=0.78, wpb=1923.9, bsz=112, num_updates=11150, lr=1.115e-05, gnorm=44.528, clip=100, loss_scale=64, train_wall=64, gb_free=18.5, wall=17141
2025-11-07 21:39:17 | INFO | train_inner | epoch 001:  11234 / 13011 loss=0.331345, wps=1481.7, ups=0.79, wpb=1885.2, bsz=112, num_updates=11200, lr=1.12e-05, gnorm=40.04, clip=100, loss_scale=64, train_wall=63, gb_free=18.4, wall=17205
2025-11-07 21:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 21:40:23 | INFO | train_inner | epoch 001:  11285 / 13011 loss=0.320801, wps=1458.1, ups=0.76, wpb=1926.4, bsz=112, num_updates=11250, lr=1.125e-05, gnorm=42.029, clip=100, loss_scale=32, train_wall=66, gb_free=14.4, wall=17271
2025-11-07 21:41:35 | INFO | train_inner | epoch 001:  11335 / 13011 loss=0.329022, wps=1330.1, ups=0.7, wpb=1912.6, bsz=112, num_updates=11300, lr=1.13e-05, gnorm=39.921, clip=100, loss_scale=32, train_wall=68, gb_free=19.6, wall=17342
2025-11-07 21:42:39 | INFO | train_inner | epoch 001:  11385 / 13011 loss=0.327107, wps=1460.6, ups=0.78, wpb=1870.2, bsz=112, num_updates=11350, lr=1.135e-05, gnorm=39.398, clip=100, loss_scale=32, train_wall=64, gb_free=16.2, wall=17407
2025-11-07 21:43:50 | INFO | train_inner | epoch 001:  11435 / 13011 loss=0.312978, wps=1376, ups=0.71, wpb=1943.6, bsz=112, num_updates=11400, lr=1.14e-05, gnorm=39.885, clip=100, loss_scale=32, train_wall=70, gb_free=12.5, wall=17477
2025-11-07 21:44:53 | INFO | train_inner | epoch 001:  11485 / 13011 loss=0.319986, wps=1491.1, ups=0.79, wpb=1880.3, bsz=112, num_updates=11450, lr=1.145e-05, gnorm=39.128, clip=100, loss_scale=32, train_wall=63, gb_free=17.5, wall=17540
2025-11-07 21:45:59 | INFO | train_inner | epoch 001:  11535 / 13011 loss=0.322189, wps=1462.4, ups=0.76, wpb=1922.7, bsz=112, num_updates=11500, lr=1.15e-05, gnorm=40.665, clip=100, loss_scale=32, train_wall=66, gb_free=9.9, wall=17606
2025-11-07 21:47:04 | INFO | train_inner | epoch 001:  11585 / 13011 loss=0.308876, wps=1443.6, ups=0.76, wpb=1891.6, bsz=112, num_updates=11550, lr=1.155e-05, gnorm=42.491, clip=100, loss_scale=64, train_wall=65, gb_free=17.3, wall=17671
2025-11-07 21:48:08 | INFO | train_inner | epoch 001:  11635 / 13011 loss=0.29842, wps=1516.6, ups=0.79, wpb=1925.6, bsz=112, num_updates=11600, lr=1.16e-05, gnorm=36.954, clip=100, loss_scale=64, train_wall=63, gb_free=18.1, wall=17735
2025-11-07 21:49:13 | INFO | train_inner | epoch 001:  11685 / 13011 loss=0.311709, wps=1476.1, ups=0.76, wpb=1930.2, bsz=112, num_updates=11650, lr=1.165e-05, gnorm=40.114, clip=100, loss_scale=64, train_wall=65, gb_free=17.8, wall=17800
2025-11-07 21:50:20 | INFO | train_inner | epoch 001:  11735 / 13011 loss=0.316657, wps=1435.1, ups=0.75, wpb=1917.6, bsz=112, num_updates=11700, lr=1.17e-05, gnorm=38.42, clip=100, loss_scale=64, train_wall=67, gb_free=10.1, wall=17867
2025-11-07 21:51:30 | INFO | train_inner | epoch 001:  11785 / 13011 loss=0.318754, wps=1341, ups=0.71, wpb=1881.4, bsz=112, num_updates=11750, lr=1.175e-05, gnorm=43.317, clip=100, loss_scale=64, train_wall=70, gb_free=18.7, wall=17937
2025-11-07 21:52:33 | INFO | train_inner | epoch 001:  11835 / 13011 loss=0.298598, wps=1533.6, ups=0.79, wpb=1950.2, bsz=112, num_updates=11800, lr=1.18e-05, gnorm=34.237, clip=100, loss_scale=128, train_wall=63, gb_free=17.1, wall=18001
2025-11-07 21:52:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:53:39 | INFO | train_inner | epoch 001:  11886 / 13011 loss=0.319591, wps=1501.8, ups=0.76, wpb=1963.3, bsz=112, num_updates=11850, lr=1.185e-05, gnorm=42.645, clip=100, loss_scale=64, train_wall=65, gb_free=9.7, wall=18066
2025-11-07 21:54:44 | INFO | train_inner | epoch 001:  11936 / 13011 loss=0.322078, wps=1474.4, ups=0.77, wpb=1917.9, bsz=112, num_updates=11900, lr=1.19e-05, gnorm=39.523, clip=100, loss_scale=64, train_wall=65, gb_free=17.4, wall=18131
2025-11-07 21:55:49 | INFO | train_inner | epoch 001:  11986 / 13011 loss=0.326522, wps=1469.9, ups=0.77, wpb=1916.7, bsz=112, num_updates=11950, lr=1.195e-05, gnorm=44.24, clip=100, loss_scale=64, train_wall=65, gb_free=17.6, wall=18197
2025-11-07 21:56:59 | INFO | train_inner | epoch 001:  12036 / 13011 loss=0.316273, wps=1381.1, ups=0.72, wpb=1917.2, bsz=112, num_updates=12000, lr=1.2e-05, gnorm=40.627, clip=100, loss_scale=64, train_wall=69, gb_free=12.3, wall=18266
2025-11-07 21:58:04 | INFO | train_inner | epoch 001:  12086 / 13011 loss=0.316765, wps=1490.6, ups=0.77, wpb=1938.7, bsz=112, num_updates=12050, lr=1.205e-05, gnorm=44.215, clip=100, loss_scale=64, train_wall=65, gb_free=13.3, wall=18331
2025-11-07 21:58:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 21:59:09 | INFO | train_inner | epoch 001:  12137 / 13011 loss=0.308213, wps=1485.5, ups=0.77, wpb=1934.1, bsz=112, num_updates=12100, lr=1.21e-05, gnorm=37.778, clip=100, loss_scale=64, train_wall=65, gb_free=18.6, wall=18396
2025-11-07 22:00:14 | INFO | train_inner | epoch 001:  12187 / 13011 loss=0.310298, wps=1466.3, ups=0.77, wpb=1916, bsz=112, num_updates=12150, lr=1.215e-05, gnorm=42.707, clip=100, loss_scale=64, train_wall=65, gb_free=18.3, wall=18461
2025-11-07 22:01:18 | INFO | train_inner | epoch 001:  12237 / 13011 loss=0.303608, wps=1518.4, ups=0.79, wpb=1931.6, bsz=112, num_updates=12200, lr=1.22e-05, gnorm=38.611, clip=100, loss_scale=64, train_wall=63, gb_free=14.3, wall=18525
2025-11-07 22:02:22 | INFO | train_inner | epoch 001:  12287 / 13011 loss=0.315548, wps=1489.4, ups=0.78, wpb=1921.1, bsz=112, num_updates=12250, lr=1.225e-05, gnorm=45.522, clip=100, loss_scale=64, train_wall=64, gb_free=18, wall=18589
2025-11-07 22:03:27 | INFO | train_inner | epoch 001:  12337 / 13011 loss=0.324229, wps=1497.6, ups=0.77, wpb=1948.7, bsz=112, num_updates=12300, lr=1.23e-05, gnorm=42.22, clip=100, loss_scale=64, train_wall=65, gb_free=17.6, wall=18655
2025-11-07 22:04:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 22:04:31 | INFO | train_inner | epoch 001:  12388 / 13011 loss=0.301683, wps=1478.6, ups=0.78, wpb=1900.3, bsz=112, num_updates=12350, lr=1.235e-05, gnorm=37.607, clip=100, loss_scale=64, train_wall=64, gb_free=18, wall=18719
2025-11-07 22:05:37 | INFO | train_inner | epoch 001:  12438 / 13011 loss=0.296888, wps=1469.9, ups=0.76, wpb=1931.3, bsz=112, num_updates=12400, lr=1.24e-05, gnorm=42.804, clip=100, loss_scale=64, train_wall=65, gb_free=18.8, wall=18785
2025-11-07 22:06:39 | INFO | train_inner | epoch 001:  12488 / 13011 loss=0.309614, wps=1519.9, ups=0.81, wpb=1874.2, bsz=112, num_updates=12450, lr=1.245e-05, gnorm=42.126, clip=100, loss_scale=64, train_wall=61, gb_free=18.4, wall=18846
2025-11-07 22:07:42 | INFO | train_inner | epoch 001:  12538 / 13011 loss=0.301221, wps=1524.5, ups=0.79, wpb=1925.2, bsz=112, num_updates=12500, lr=1.25e-05, gnorm=39.153, clip=100, loss_scale=64, train_wall=63, gb_free=17.7, wall=18909
2025-11-07 22:08:54 | INFO | train_inner | epoch 001:  12588 / 13011 loss=0.314443, wps=1370.6, ups=0.69, wpb=1976.5, bsz=112, num_updates=12550, lr=1.255e-05, gnorm=42.512, clip=100, loss_scale=64, train_wall=72, gb_free=17, wall=18981
2025-11-07 22:10:08 | INFO | train_inner | epoch 001:  12638 / 13011 loss=0.309634, wps=1292.8, ups=0.68, wpb=1914.1, bsz=112, num_updates=12600, lr=1.26e-05, gnorm=37.299, clip=100, loss_scale=128, train_wall=74, gb_free=18.6, wall=19055
2025-11-07 22:10:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 22:11:34 | INFO | train_inner | epoch 001:  12689 / 13011 loss=0.289729, wps=1110.6, ups=0.58, wpb=1906.5, bsz=112, num_updates=12650, lr=1.265e-05, gnorm=38.732, clip=100, loss_scale=64, train_wall=86, gb_free=17.1, wall=19141
2025-11-07 22:12:57 | INFO | train_inner | epoch 001:  12739 / 13011 loss=0.289608, wps=1167.4, ups=0.6, wpb=1938.6, bsz=112, num_updates=12700, lr=1.27e-05, gnorm=43.554, clip=100, loss_scale=64, train_wall=83, gb_free=16.4, wall=19224
2025-11-07 22:14:04 | INFO | train_inner | epoch 001:  12789 / 13011 loss=0.292938, wps=1437.8, ups=0.75, wpb=1915.9, bsz=112, num_updates=12750, lr=1.275e-05, gnorm=35.154, clip=100, loss_scale=64, train_wall=66, gb_free=18.1, wall=19291
2025-11-07 22:15:08 | INFO | train_inner | epoch 001:  12839 / 13011 loss=0.304601, wps=1487.7, ups=0.78, wpb=1909.6, bsz=112, num_updates=12800, lr=1.28e-05, gnorm=36.772, clip=100, loss_scale=64, train_wall=64, gb_free=18.3, wall=19355
2025-11-07 22:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 22:16:19 | INFO | train_inner | epoch 001:  12890 / 13011 loss=0.301412, wps=1346.7, ups=0.7, wpb=1928.4, bsz=112, num_updates=12850, lr=1.285e-05, gnorm=37.607, clip=100, loss_scale=32, train_wall=71, gb_free=14.3, wall=19427
2025-11-07 22:17:32 | INFO | train_inner | epoch 001:  12940 / 13011 loss=0.300148, wps=1320.7, ups=0.68, wpb=1930.7, bsz=112, num_updates=12900, lr=1.29e-05, gnorm=41.335, clip=100, loss_scale=32, train_wall=73, gb_free=16.9, wall=19500
2025-11-07 22:18:36 | INFO | train_inner | epoch 001:  12990 / 13011 loss=0.302707, wps=1530.6, ups=0.79, wpb=1935.1, bsz=112, num_updates=12950, lr=1.295e-05, gnorm=35.737, clip=100, loss_scale=32, train_wall=63, gb_free=18.4, wall=19563
2025-11-07 22:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-07 22:39:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.288845 | wps 1301.6 | wpb 1907.1 | bsz 111.9 | num_updates 12971
2025-11-07 22:39:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 12971 updates
2025-11-07 22:39:10 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint1.pt
2025-11-07 22:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint1.pt
2025-11-07 22:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint1.pt (epoch 1 @ 12971 updates, score 0.288845) (writing took 218.68483735300106 seconds)
2025-11-07 22:42:48 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2025-11-07 22:42:48 | INFO | train | epoch 001 | loss 0.39509 | wps 1184.2 | ups 0.62 | wpb 1916.9 | bsz 112 | num_updates 12971 | lr 1.2971e-05 | gnorm 48.96 | clip 100 | loss_scale 32 | train_wall 18969 | gb_free 13.7 | wall 21016
2025-11-07 22:42:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 13011
2025-11-07 22:42:50 | INFO | fairseq.trainer | begin training epoch 2
2025-11-07 22:42:50 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-07 22:44:05 | INFO | train_inner | epoch 002:     29 / 13011 loss=0.301278, wps=60.6, ups=0.03, wpb=1853.4, bsz=110, num_updates=13000, lr=1.3e-05, gnorm=39.533, clip=100, loss_scale=32, train_wall=94, gb_free=16.8, wall=21093
2025-11-07 22:46:35 | INFO | train_inner | epoch 002:     79 / 13011 loss=0.29386, wps=632.5, ups=0.33, wpb=1891.1, bsz=112, num_updates=13050, lr=1.305e-05, gnorm=37.381, clip=100, loss_scale=32, train_wall=149, gb_free=17.4, wall=21242
2025-11-07 22:47:36 | INFO | train_inner | epoch 002:    129 / 13011 loss=0.291999, wps=1562.9, ups=0.81, wpb=1921.7, bsz=112, num_updates=13100, lr=1.31e-05, gnorm=37.75, clip=100, loss_scale=64, train_wall=61, gb_free=15.9, wall=21304
2025-11-07 22:49:04 | INFO | train_inner | epoch 002:    179 / 13011 loss=0.292054, wps=1074.4, ups=0.57, wpb=1893.8, bsz=112, num_updates=13150, lr=1.315e-05, gnorm=47.316, clip=100, loss_scale=64, train_wall=88, gb_free=18.5, wall=21392
2025-11-07 22:51:08 | INFO | train_inner | epoch 002:    229 / 13011 loss=0.283678, wps=777.2, ups=0.4, wpb=1927.4, bsz=112, num_updates=13200, lr=1.32e-05, gnorm=37.792, clip=100, loss_scale=64, train_wall=124, gb_free=14.9, wall=21516
2025-11-07 22:52:40 | INFO | train_inner | epoch 002:    279 / 13011 loss=0.299113, wps=1053.2, ups=0.55, wpb=1932.1, bsz=112, num_updates=13250, lr=1.325e-05, gnorm=42.592, clip=100, loss_scale=64, train_wall=91, gb_free=18.6, wall=21607
2025-11-07 22:55:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 22:55:31 | INFO | train_inner | epoch 002:    330 / 13011 loss=0.288652, wps=563.5, ups=0.29, wpb=1928.6, bsz=112, num_updates=13300, lr=1.33e-05, gnorm=37.273, clip=100, loss_scale=32, train_wall=171, gb_free=18, wall=21779
2025-11-07 22:56:53 | INFO | train_inner | epoch 002:    380 / 13011 loss=0.290409, wps=1162.3, ups=0.61, wpb=1904, bsz=112, num_updates=13350, lr=1.335e-05, gnorm=41.681, clip=100, loss_scale=32, train_wall=82, gb_free=18.8, wall=21860
2025-11-07 22:59:10 | INFO | train_inner | epoch 002:    430 / 13011 loss=0.29254, wps=692, ups=0.36, wpb=1899.1, bsz=112, num_updates=13400, lr=1.34e-05, gnorm=43.671, clip=100, loss_scale=32, train_wall=137, gb_free=18.1, wall=21998
2025-11-07 23:01:18 | INFO | train_inner | epoch 002:    480 / 13011 loss=0.292178, wps=738.4, ups=0.39, wpb=1885.5, bsz=112, num_updates=13450, lr=1.345e-05, gnorm=43.409, clip=100, loss_scale=32, train_wall=108, gb_free=15.1, wall=22125
2025-11-07 23:03:24 | INFO | train_inner | epoch 002:    530 / 13011 loss=0.287593, wps=750.4, ups=0.4, wpb=1894.8, bsz=112, num_updates=13500, lr=1.35e-05, gnorm=42.127, clip=100, loss_scale=32, train_wall=110, gb_free=18, wall=22252
2025-11-07 23:04:52 | INFO | train_inner | epoch 002:    580 / 13011 loss=0.301357, wps=1094.1, ups=0.57, wpb=1924.6, bsz=112, num_updates=13550, lr=1.355e-05, gnorm=41.381, clip=100, loss_scale=32, train_wall=88, gb_free=19, wall=22340
2025-11-07 23:06:34 | INFO | train_inner | epoch 002:    630 / 13011 loss=0.279269, wps=931.5, ups=0.49, wpb=1901.9, bsz=112, num_updates=13600, lr=1.36e-05, gnorm=39.164, clip=100, loss_scale=64, train_wall=102, gb_free=11.2, wall=22442
2025-11-07 23:07:46 | INFO | train_inner | epoch 002:    680 / 13011 loss=0.282905, wps=1347.1, ups=0.7, wpb=1927.1, bsz=112, num_updates=13650, lr=1.365e-05, gnorm=39.679, clip=100, loss_scale=64, train_wall=71, gb_free=17.7, wall=22513
2025-11-07 23:09:31 | INFO | train_inner | epoch 002:    730 / 13011 loss=0.294013, wps=906.9, ups=0.48, wpb=1908.8, bsz=112, num_updates=13700, lr=1.37e-05, gnorm=40.166, clip=100, loss_scale=64, train_wall=96, gb_free=16.9, wall=22618
2025-11-07 23:11:47 | INFO | train_inner | epoch 002:    780 / 13011 loss=0.280129, wps=722.7, ups=0.37, wpb=1962.9, bsz=112, num_updates=13750, lr=1.375e-05, gnorm=36.806, clip=100, loss_scale=64, train_wall=86, gb_free=11, wall=22754
2025-11-07 23:14:44 | INFO | train_inner | epoch 002:    830 / 13011 loss=0.305589, wps=530.9, ups=0.28, wpb=1880.3, bsz=112, num_updates=13800, lr=1.38e-05, gnorm=43.639, clip=100, loss_scale=64, train_wall=177, gb_free=19, wall=22931
2025-11-07 23:17:27 | INFO | train_inner | epoch 002:    880 / 13011 loss=0.268661, wps=584.1, ups=0.31, wpb=1903.9, bsz=112, num_updates=13850, lr=1.385e-05, gnorm=38.469, clip=100, loss_scale=128, train_wall=163, gb_free=17.4, wall=23094
2025-11-07 23:17:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 23:19:01 | INFO | train_inner | epoch 002:    931 / 13011 loss=0.282721, wps=1006.5, ups=0.53, wpb=1896.2, bsz=112, num_updates=13900, lr=1.39e-05, gnorm=36.44, clip=100, loss_scale=64, train_wall=94, gb_free=19.7, wall=23188
2025-11-07 23:21:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 23:21:53 | INFO | train_inner | epoch 002:    982 / 13011 loss=0.291373, wps=559.9, ups=0.29, wpb=1927.8, bsz=112, num_updates=13950, lr=1.395e-05, gnorm=45.445, clip=100, loss_scale=32, train_wall=172, gb_free=12.9, wall=23361
2025-11-07 23:23:54 | INFO | train_inner | epoch 002:   1032 / 13011 loss=0.269819, wps=790.9, ups=0.42, wpb=1902.2, bsz=112, num_updates=14000, lr=1.4e-05, gnorm=40.618, clip=100, loss_scale=32, train_wall=120, gb_free=15, wall=23481
2025-11-07 23:25:44 | INFO | train_inner | epoch 002:   1082 / 13011 loss=0.275865, wps=870.2, ups=0.45, wpb=1916.3, bsz=112, num_updates=14050, lr=1.405e-05, gnorm=35.249, clip=100, loss_scale=32, train_wall=110, gb_free=18.7, wall=23591
2025-11-07 23:28:16 | INFO | train_inner | epoch 002:   1132 / 13011 loss=0.297221, wps=629.4, ups=0.33, wpb=1913.7, bsz=112, num_updates=14100, lr=1.41e-05, gnorm=43.843, clip=100, loss_scale=32, train_wall=111, gb_free=18.6, wall=23743
2025-11-07 23:30:14 | INFO | train_inner | epoch 002:   1182 / 13011 loss=0.291106, wps=814.7, ups=0.42, wpb=1931.7, bsz=112, num_updates=14150, lr=1.415e-05, gnorm=43.58, clip=100, loss_scale=32, train_wall=106, gb_free=18.6, wall=23862
2025-11-07 23:32:55 | INFO | train_inner | epoch 002:   1232 / 13011 loss=0.298637, wps=592.4, ups=0.31, wpb=1907, bsz=112, num_updates=14200, lr=1.42e-05, gnorm=42.817, clip=100, loss_scale=64, train_wall=161, gb_free=15.8, wall=24023
2025-11-07 23:34:29 | INFO | train_inner | epoch 002:   1282 / 13011 loss=0.283326, wps=1019.2, ups=0.53, wpb=1907.5, bsz=112, num_updates=14250, lr=1.425e-05, gnorm=41.595, clip=100, loss_scale=64, train_wall=93, gb_free=13.2, wall=24116
2025-11-07 23:36:49 | INFO | train_inner | epoch 002:   1332 / 13011 loss=0.277186, wps=672.2, ups=0.36, wpb=1891, bsz=112, num_updates=14300, lr=1.43e-05, gnorm=37.216, clip=100, loss_scale=64, train_wall=140, gb_free=18.4, wall=24257
2025-11-07 23:39:36 | INFO | train_inner | epoch 002:   1382 / 13011 loss=0.27417, wps=584.9, ups=0.3, wpb=1946.6, bsz=112, num_updates=14350, lr=1.435e-05, gnorm=40.237, clip=100, loss_scale=64, train_wall=144, gb_free=15.6, wall=24423
2025-11-07 23:42:12 | INFO | train_inner | epoch 002:   1432 / 13011 loss=0.275332, wps=619.3, ups=0.32, wpb=1937.8, bsz=112, num_updates=14400, lr=1.44e-05, gnorm=43.606, clip=100, loss_scale=64, train_wall=156, gb_free=15.3, wall=24580
2025-11-07 23:43:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 23:45:10 | INFO | train_inner | epoch 002:   1483 / 13011 loss=0.283545, wps=542.6, ups=0.28, wpb=1924.8, bsz=112, num_updates=14450, lr=1.445e-05, gnorm=41.038, clip=100, loss_scale=32, train_wall=97, gb_free=16.1, wall=24757
2025-11-07 23:45:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 23:46:35 | INFO | train_inner | epoch 002:   1534 / 13011 loss=0.283959, wps=1101, ups=0.58, wpb=1890.6, bsz=112, num_updates=14500, lr=1.45e-05, gnorm=40.125, clip=100, loss_scale=16, train_wall=86, gb_free=17.2, wall=24843
2025-11-07 23:48:38 | INFO | train_inner | epoch 002:   1584 / 13011 loss=0.270536, wps=774.7, ups=0.41, wpb=1906.5, bsz=112, num_updates=14550, lr=1.455e-05, gnorm=39.914, clip=100, loss_scale=16, train_wall=82, gb_free=17.4, wall=24966
2025-11-07 23:50:27 | INFO | train_inner | epoch 002:   1634 / 13011 loss=0.275086, wps=862.6, ups=0.46, wpb=1873.9, bsz=112, num_updates=14600, lr=1.46e-05, gnorm=37.908, clip=100, loss_scale=16, train_wall=108, gb_free=16.8, wall=25075
2025-11-07 23:53:14 | INFO | train_inner | epoch 002:   1684 / 13011 loss=0.27905, wps=568.4, ups=0.3, wpb=1895, bsz=112, num_updates=14650, lr=1.465e-05, gnorm=42.32, clip=100, loss_scale=16, train_wall=166, gb_free=19.2, wall=25241
2025-11-07 23:55:10 | INFO | train_inner | epoch 002:   1734 / 13011 loss=0.26517, wps=832.7, ups=0.43, wpb=1929.2, bsz=112, num_updates=14700, lr=1.47e-05, gnorm=37.176, clip=100, loss_scale=16, train_wall=116, gb_free=16.7, wall=25357
2025-11-07 23:58:04 | INFO | train_inner | epoch 002:   1784 / 13011 loss=0.282308, wps=551.4, ups=0.29, wpb=1926.2, bsz=112, num_updates=14750, lr=1.475e-05, gnorm=40.851, clip=100, loss_scale=32, train_wall=165, gb_free=18.1, wall=25532
2025-11-08 00:00:06 | INFO | train_inner | epoch 002:   1834 / 13011 loss=0.26306, wps=803.1, ups=0.41, wpb=1957.3, bsz=112, num_updates=14800, lr=1.48e-05, gnorm=39.891, clip=100, loss_scale=32, train_wall=122, gb_free=18.8, wall=25654
2025-11-08 00:02:32 | INFO | train_inner | epoch 002:   1884 / 13011 loss=0.259998, wps=666.7, ups=0.34, wpb=1938.2, bsz=112, num_updates=14850, lr=1.485e-05, gnorm=39.575, clip=100, loss_scale=32, train_wall=145, gb_free=17.9, wall=25799
2025-11-08 00:04:41 | INFO | train_inner | epoch 002:   1934 / 13011 loss=0.268369, wps=730.8, ups=0.39, wpb=1889.6, bsz=112, num_updates=14900, lr=1.49e-05, gnorm=40.618, clip=100, loss_scale=32, train_wall=129, gb_free=15.9, wall=25928
2025-11-08 00:07:16 | INFO | train_inner | epoch 002:   1984 / 13011 loss=0.272988, wps=618, ups=0.32, wpb=1915, bsz=112, num_updates=14950, lr=1.495e-05, gnorm=41.802, clip=100, loss_scale=32, train_wall=85, gb_free=17.9, wall=26083
2025-11-08 00:09:11 | INFO | train_inner | epoch 002:   2034 / 13011 loss=0.271776, wps=826.9, ups=0.43, wpb=1904.9, bsz=112, num_updates=15000, lr=1.5e-05, gnorm=39.068, clip=100, loss_scale=64, train_wall=115, gb_free=15.3, wall=26198
2025-11-08 00:12:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 00:12:08 | INFO | train_inner | epoch 002:   2085 / 13011 loss=0.276003, wps=535.3, ups=0.28, wpb=1892.8, bsz=112, num_updates=15050, lr=1.505e-05, gnorm=42.43, clip=100, loss_scale=32, train_wall=177, gb_free=17.5, wall=26376
2025-11-08 00:14:17 | INFO | train_inner | epoch 002:   2135 / 13011 loss=0.259123, wps=757.8, ups=0.39, wpb=1945.2, bsz=112, num_updates=15100, lr=1.51e-05, gnorm=39.037, clip=100, loss_scale=32, train_wall=128, gb_free=18.1, wall=26504
2025-11-08 00:17:37 | INFO | train_inner | epoch 002:   2185 / 13011 loss=0.269118, wps=479.9, ups=0.25, wpb=1926.5, bsz=112, num_updates=15150, lr=1.515e-05, gnorm=37.897, clip=100, loss_scale=32, train_wall=134, gb_free=16.7, wall=26705
2025-11-08 00:19:49 | INFO | train_inner | epoch 002:   2235 / 13011 loss=0.268986, wps=728, ups=0.38, wpb=1921.7, bsz=112, num_updates=15200, lr=1.52e-05, gnorm=38.496, clip=100, loss_scale=32, train_wall=132, gb_free=17.7, wall=26837
2025-11-08 00:22:12 | INFO | train_inner | epoch 002:   2285 / 13011 loss=0.258073, wps=672.5, ups=0.35, wpb=1920.9, bsz=112, num_updates=15250, lr=1.525e-05, gnorm=38.697, clip=100, loss_scale=32, train_wall=134, gb_free=16, wall=26980
2025-11-08 00:24:32 | INFO | train_inner | epoch 002:   2335 / 13011 loss=0.26626, wps=683.6, ups=0.36, wpb=1905.4, bsz=112, num_updates=15300, lr=1.53e-05, gnorm=37.737, clip=100, loss_scale=32, train_wall=87, gb_free=18.5, wall=27119
2025-11-08 00:26:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 00:26:48 | INFO | train_inner | epoch 002:   2386 / 13011 loss=0.262903, wps=701, ups=0.37, wpb=1913.4, bsz=112, num_updates=15350, lr=1.535e-05, gnorm=39.981, clip=100, loss_scale=32, train_wall=107, gb_free=18.3, wall=27256
2025-11-08 00:28:58 | INFO | train_inner | epoch 002:   2436 / 13011 loss=0.252174, wps=746.1, ups=0.39, wpb=1934.4, bsz=112, num_updates=15400, lr=1.54e-05, gnorm=39.683, clip=100, loss_scale=32, train_wall=121, gb_free=18.4, wall=27385
2025-11-08 00:30:20 | INFO | train_inner | epoch 002:   2486 / 13011 loss=0.254099, wps=1173.1, ups=0.61, wpb=1933.6, bsz=112, num_updates=15450, lr=1.545e-05, gnorm=40.929, clip=100, loss_scale=32, train_wall=82, gb_free=15.2, wall=27468
2025-11-08 00:32:55 | INFO | train_inner | epoch 002:   2536 / 13011 loss=0.269888, wps=626.3, ups=0.32, wpb=1935, bsz=112, num_updates=15500, lr=1.55e-05, gnorm=42.069, clip=100, loss_scale=32, train_wall=116, gb_free=16.1, wall=27622
2025-11-08 00:35:26 | INFO | train_inner | epoch 002:   2586 / 13011 loss=0.270729, wps=631.8, ups=0.33, wpb=1913.4, bsz=112, num_updates=15550, lr=1.555e-05, gnorm=37.553, clip=100, loss_scale=32, train_wall=88, gb_free=17.9, wall=27773
2025-11-08 00:37:35 | INFO | train_inner | epoch 002:   2636 / 13011 loss=0.281434, wps=746.4, ups=0.39, wpb=1921.2, bsz=112, num_updates=15600, lr=1.56e-05, gnorm=39.28, clip=100, loss_scale=32, train_wall=128, gb_free=19.1, wall=27902
2025-11-08 00:40:13 | INFO | train_inner | epoch 002:   2686 / 13011 loss=0.265709, wps=610.5, ups=0.32, wpb=1928.2, bsz=112, num_updates=15650, lr=1.565e-05, gnorm=39.676, clip=100, loss_scale=64, train_wall=158, gb_free=16.7, wall=28060
2025-11-08 00:40:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 00:42:22 | INFO | train_inner | epoch 002:   2737 / 13011 loss=0.266243, wps=739, ups=0.39, wpb=1912.8, bsz=112, num_updates=15700, lr=1.57e-05, gnorm=36.019, clip=100, loss_scale=32, train_wall=129, gb_free=17.2, wall=28189
2025-11-08 00:44:46 | INFO | train_inner | epoch 002:   2787 / 13011 loss=0.270162, wps=657.8, ups=0.35, wpb=1894.1, bsz=112, num_updates=15750, lr=1.575e-05, gnorm=39.973, clip=100, loss_scale=32, train_wall=121, gb_free=18.2, wall=28333
2025-11-08 00:46:12 | INFO | train_inner | epoch 002:   2837 / 13011 loss=0.254716, wps=1108.2, ups=0.58, wpb=1904.6, bsz=112, num_updates=15800, lr=1.58e-05, gnorm=40.79, clip=100, loss_scale=32, train_wall=86, gb_free=18.3, wall=28419
2025-11-08 00:46:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 00:48:16 | INFO | train_inner | epoch 002:   2888 / 13011 loss=0.26412, wps=782.1, ups=0.4, wpb=1935.4, bsz=112, num_updates=15850, lr=1.585e-05, gnorm=36.018, clip=100, loss_scale=16, train_wall=118, gb_free=18.8, wall=28543
2025-11-08 00:51:07 | INFO | train_inner | epoch 002:   2938 / 13011 loss=0.257861, wps=561.6, ups=0.29, wpb=1921.2, bsz=112, num_updates=15900, lr=1.59e-05, gnorm=38.083, clip=100, loss_scale=16, train_wall=101, gb_free=15.5, wall=28714
2025-11-08 00:53:35 | INFO | train_inner | epoch 002:   2988 / 13011 loss=0.256913, wps=650.7, ups=0.34, wpb=1926.5, bsz=112, num_updates=15950, lr=1.595e-05, gnorm=41.071, clip=100, loss_scale=16, train_wall=148, gb_free=15, wall=28862
2025-11-08 00:56:27 | INFO | train_inner | epoch 002:   3038 / 13011 loss=0.271142, wps=559.1, ups=0.29, wpb=1925.1, bsz=112, num_updates=16000, lr=1.6e-05, gnorm=43.225, clip=100, loss_scale=16, train_wall=149, gb_free=15.6, wall=29034
2025-11-08 00:58:12 | INFO | train_inner | epoch 002:   3088 / 13011 loss=0.256927, wps=931.4, ups=0.48, wpb=1952.6, bsz=112, num_updates=16050, lr=1.605e-05, gnorm=38.779, clip=100, loss_scale=16, train_wall=105, gb_free=17.2, wall=29139
2025-11-08 01:01:03 | INFO | train_inner | epoch 002:   3138 / 13011 loss=0.243179, wps=557.2, ups=0.29, wpb=1909.7, bsz=112, num_updates=16100, lr=1.61e-05, gnorm=38.65, clip=100, loss_scale=32, train_wall=125, gb_free=17.7, wall=29311
2025-11-08 01:04:24 | INFO | train_inner | epoch 002:   3188 / 13011 loss=0.253996, wps=468.2, ups=0.25, wpb=1877.9, bsz=112, num_updates=16150, lr=1.615e-05, gnorm=36.012, clip=100, loss_scale=32, train_wall=200, gb_free=16.4, wall=29511
2025-11-08 01:07:29 | INFO | train_inner | epoch 002:   3238 / 13011 loss=0.24614, wps=519.1, ups=0.27, wpb=1925.5, bsz=112, num_updates=16200, lr=1.62e-05, gnorm=36.014, clip=100, loss_scale=32, train_wall=185, gb_free=18.5, wall=29697
2025-11-08 01:08:41 | INFO | train_inner | epoch 002:   3288 / 13011 loss=0.247687, wps=1360.6, ups=0.7, wpb=1946.7, bsz=112, num_updates=16250, lr=1.625e-05, gnorm=37.741, clip=100, loss_scale=32, train_wall=71, gb_free=18.4, wall=29768
2025-11-08 01:11:01 | INFO | train_inner | epoch 002:   3338 / 13011 loss=0.252421, wps=688.2, ups=0.36, wpb=1931.8, bsz=112, num_updates=16300, lr=1.63e-05, gnorm=38.441, clip=100, loss_scale=32, train_wall=140, gb_free=16.3, wall=29908
2025-11-08 01:12:30 | INFO | train_inner | epoch 002:   3388 / 13011 loss=0.247718, wps=1077.7, ups=0.56, wpb=1927, bsz=112, num_updates=16350, lr=1.635e-05, gnorm=37.065, clip=100, loss_scale=64, train_wall=89, gb_free=15.4, wall=29998
2025-11-08 01:12:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 01:14:27 | INFO | train_inner | epoch 002:   3439 / 13011 loss=0.262257, wps=829.3, ups=0.43, wpb=1910.7, bsz=112, num_updates=16400, lr=1.64e-05, gnorm=39.693, clip=100, loss_scale=32, train_wall=115, gb_free=18.4, wall=30114
2025-11-08 01:16:06 | INFO | train_inner | epoch 002:   3489 / 13011 loss=0.252993, wps=971, ups=0.51, wpb=1920.1, bsz=112, num_updates=16450, lr=1.645e-05, gnorm=37.397, clip=100, loss_scale=32, train_wall=99, gb_free=6.1, wall=30213
2025-11-08 01:17:37 | INFO | train_inner | epoch 002:   3539 / 13011 loss=0.253684, wps=1052.2, ups=0.55, wpb=1926.6, bsz=112, num_updates=16500, lr=1.65e-05, gnorm=38.433, clip=100, loss_scale=32, train_wall=91, gb_free=18.7, wall=30305
2025-11-08 01:18:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 01:19:40 | INFO | train_inner | epoch 002:   3590 / 13011 loss=0.246302, wps=784.4, ups=0.41, wpb=1928.8, bsz=112, num_updates=16550, lr=1.655e-05, gnorm=39.107, clip=100, loss_scale=16, train_wall=122, gb_free=17.9, wall=30428
2025-11-08 01:22:19 | INFO | train_inner | epoch 002:   3640 / 13011 loss=0.261425, wps=601.8, ups=0.32, wpb=1909.3, bsz=112, num_updates=16600, lr=1.66e-05, gnorm=37.174, clip=100, loss_scale=16, train_wall=158, gb_free=18.9, wall=30586
2025-11-08 01:23:51 | INFO | train_inner | epoch 002:   3690 / 13011 loss=0.256933, wps=1047.5, ups=0.54, wpb=1934.5, bsz=112, num_updates=16650, lr=1.665e-05, gnorm=39.345, clip=100, loss_scale=16, train_wall=92, gb_free=18.3, wall=30679
2025-11-08 01:25:54 | INFO | train_inner | epoch 002:   3740 / 13011 loss=0.248272, wps=763.4, ups=0.41, wpb=1878.9, bsz=112, num_updates=16700, lr=1.67e-05, gnorm=39.11, clip=100, loss_scale=16, train_wall=123, gb_free=18.4, wall=30802
2025-11-08 01:27:47 | INFO | train_inner | epoch 002:   3790 / 13011 loss=0.239919, wps=853.2, ups=0.44, wpb=1918.9, bsz=112, num_updates=16750, lr=1.675e-05, gnorm=38.693, clip=100, loss_scale=16, train_wall=112, gb_free=9.9, wall=30914
2025-11-08 01:29:29 | INFO | train_inner | epoch 002:   3840 / 13011 loss=0.236125, wps=943.7, ups=0.49, wpb=1925.2, bsz=112, num_updates=16800, lr=1.68e-05, gnorm=36.264, clip=100, loss_scale=32, train_wall=102, gb_free=18.2, wall=31016
2025-11-08 01:30:56 | INFO | train_inner | epoch 002:   3890 / 13011 loss=0.253049, wps=1099.9, ups=0.57, wpb=1920.4, bsz=112, num_updates=16850, lr=1.685e-05, gnorm=39.17, clip=100, loss_scale=32, train_wall=87, gb_free=18.6, wall=31103
2025-11-08 01:33:00 | INFO | train_inner | epoch 002:   3940 / 13011 loss=0.236367, wps=765.1, ups=0.4, wpb=1894.9, bsz=112, num_updates=16900, lr=1.69e-05, gnorm=38.062, clip=100, loss_scale=32, train_wall=124, gb_free=16.1, wall=31227
2025-11-08 01:34:39 | INFO | train_inner | epoch 002:   3990 / 13011 loss=0.243938, wps=980.2, ups=0.5, wpb=1951.6, bsz=112, num_updates=16950, lr=1.695e-05, gnorm=35.857, clip=100, loss_scale=32, train_wall=99, gb_free=9.3, wall=31327
2025-11-08 01:36:28 | INFO | train_inner | epoch 002:   4040 / 13011 loss=0.234942, wps=887.1, ups=0.46, wpb=1932.4, bsz=112, num_updates=17000, lr=1.7e-05, gnorm=37.383, clip=100, loss_scale=32, train_wall=109, gb_free=18.5, wall=31436
2025-11-08 01:38:46 | INFO | train_inner | epoch 002:   4090 / 13011 loss=0.254354, wps=704.7, ups=0.36, wpb=1937.5, bsz=112, num_updates=17050, lr=1.705e-05, gnorm=39.376, clip=100, loss_scale=64, train_wall=137, gb_free=16.7, wall=31573
2025-11-08 01:40:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 01:40:20 | INFO | train_inner | epoch 002:   4141 / 13011 loss=0.243718, wps=1029.4, ups=0.53, wpb=1937.2, bsz=112, num_updates=17100, lr=1.71e-05, gnorm=38.678, clip=100, loss_scale=32, train_wall=94, gb_free=18, wall=31667
2025-11-08 01:42:27 | INFO | train_inner | epoch 002:   4191 / 13011 loss=0.246159, wps=751.1, ups=0.39, wpb=1914, bsz=112, num_updates=17150, lr=1.715e-05, gnorm=42.378, clip=100, loss_scale=32, train_wall=127, gb_free=16.8, wall=31795
2025-11-08 01:44:12 | INFO | train_inner | epoch 002:   4241 / 13011 loss=0.237672, wps=909.5, ups=0.48, wpb=1905.7, bsz=112, num_updates=17200, lr=1.72e-05, gnorm=40.735, clip=100, loss_scale=32, train_wall=105, gb_free=18.1, wall=31899
2025-11-08 01:46:03 | INFO | train_inner | epoch 002:   4291 / 13011 loss=0.241449, wps=860.2, ups=0.45, wpb=1905.6, bsz=112, num_updates=17250, lr=1.725e-05, gnorm=39.998, clip=100, loss_scale=32, train_wall=111, gb_free=18.2, wall=32010
2025-11-08 01:47:49 | INFO | train_inner | epoch 002:   4341 / 13011 loss=0.238649, wps=897.5, ups=0.47, wpb=1903.5, bsz=112, num_updates=17300, lr=1.73e-05, gnorm=35.701, clip=100, loss_scale=32, train_wall=106, gb_free=17.7, wall=32116
2025-11-08 01:49:21 | INFO | train_inner | epoch 002:   4391 / 13011 loss=0.246175, wps=1027.4, ups=0.54, wpb=1891.8, bsz=112, num_updates=17350, lr=1.735e-05, gnorm=39.42, clip=100, loss_scale=64, train_wall=92, gb_free=18.2, wall=32208
2025-11-08 01:50:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 01:51:07 | INFO | train_inner | epoch 002:   4442 / 13011 loss=0.253071, wps=906, ups=0.47, wpb=1913.6, bsz=112, num_updates=17400, lr=1.74e-05, gnorm=39.815, clip=100, loss_scale=32, train_wall=105, gb_free=15.5, wall=32314
2025-11-08 01:53:43 | INFO | train_inner | epoch 002:   4492 / 13011 loss=0.248986, wps=606, ups=0.32, wpb=1893.4, bsz=112, num_updates=17450, lr=1.745e-05, gnorm=39.311, clip=100, loss_scale=32, train_wall=156, gb_free=18, wall=32470
2025-11-08 01:55:01 | INFO | train_inner | epoch 002:   4542 / 13011 loss=0.235905, wps=1217.9, ups=0.64, wpb=1895.2, bsz=112, num_updates=17500, lr=1.75e-05, gnorm=36.207, clip=100, loss_scale=32, train_wall=78, gb_free=17.5, wall=32548
2025-11-08 01:56:43 | INFO | train_inner | epoch 002:   4592 / 13011 loss=0.24038, wps=933.9, ups=0.49, wpb=1910.6, bsz=112, num_updates=17550, lr=1.755e-05, gnorm=37.181, clip=100, loss_scale=32, train_wall=102, gb_free=16.7, wall=32650
2025-11-08 01:58:48 | INFO | train_inner | epoch 002:   4642 / 13011 loss=0.229918, wps=766.7, ups=0.4, wpb=1918, bsz=112, num_updates=17600, lr=1.76e-05, gnorm=39.797, clip=100, loss_scale=32, train_wall=125, gb_free=15.9, wall=32775
2025-11-08 02:00:02 | INFO | train_inner | epoch 002:   4692 / 13011 loss=0.233404, wps=1269, ups=0.67, wpb=1890.4, bsz=112, num_updates=17650, lr=1.765e-05, gnorm=33.955, clip=100, loss_scale=64, train_wall=74, gb_free=10.2, wall=32850
2025-11-08 02:01:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 02:01:38 | INFO | train_inner | epoch 002:   4743 / 13011 loss=0.227829, wps=989.9, ups=0.52, wpb=1895.4, bsz=112, num_updates=17700, lr=1.77e-05, gnorm=38.298, clip=100, loss_scale=32, train_wall=95, gb_free=17.4, wall=32946
2025-11-08 02:03:26 | INFO | train_inner | epoch 002:   4793 / 13011 loss=0.245692, wps=900.5, ups=0.46, wpb=1942.7, bsz=112, num_updates=17750, lr=1.775e-05, gnorm=36.272, clip=100, loss_scale=32, train_wall=108, gb_free=16.9, wall=33053
2025-11-08 02:05:25 | INFO | train_inner | epoch 002:   4843 / 13011 loss=0.223994, wps=804.4, ups=0.42, wpb=1917.9, bsz=112, num_updates=17800, lr=1.78e-05, gnorm=38.574, clip=100, loss_scale=32, train_wall=119, gb_free=12.1, wall=33173
2025-11-08 02:06:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 02:07:07 | INFO | train_inner | epoch 002:   4894 / 13011 loss=0.231669, wps=940.9, ups=0.49, wpb=1906.6, bsz=112, num_updates=17850, lr=1.785e-05, gnorm=38.676, clip=100, loss_scale=16, train_wall=101, gb_free=14.7, wall=33274
2025-11-08 02:09:37 | INFO | train_inner | epoch 002:   4944 / 13011 loss=0.234376, wps=643.4, ups=0.33, wpb=1937.5, bsz=112, num_updates=17900, lr=1.79e-05, gnorm=39.228, clip=100, loss_scale=16, train_wall=150, gb_free=16.4, wall=33425
2025-11-08 02:11:40 | INFO | train_inner | epoch 002:   4994 / 13011 loss=0.242597, wps=788.8, ups=0.41, wpb=1934.5, bsz=112, num_updates=17950, lr=1.795e-05, gnorm=37.416, clip=100, loss_scale=16, train_wall=122, gb_free=18.4, wall=33547
2025-11-08 02:14:19 | INFO | train_inner | epoch 002:   5044 / 13011 loss=0.231926, wps=603.2, ups=0.31, wpb=1915.9, bsz=112, num_updates=18000, lr=1.8e-05, gnorm=38.64, clip=100, loss_scale=16, train_wall=159, gb_free=18.3, wall=33706
2025-11-08 02:15:59 | INFO | train_inner | epoch 002:   5094 / 13011 loss=0.21648, wps=957.2, ups=0.5, wpb=1917.2, bsz=112, num_updates=18050, lr=1.805e-05, gnorm=39.908, clip=100, loss_scale=16, train_wall=100, gb_free=17.1, wall=33806
2025-11-08 02:16:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 02:17:24 | INFO | train_inner | epoch 002:   5145 / 13011 loss=0.228585, wps=1151.5, ups=0.59, wpb=1954.8, bsz=112, num_updates=18100, lr=1.81e-05, gnorm=35.961, clip=100, loss_scale=16, train_wall=85, gb_free=18.8, wall=33891
2025-11-08 02:19:08 | INFO | train_inner | epoch 002:   5195 / 13011 loss=0.226336, wps=915.3, ups=0.48, wpb=1914.6, bsz=112, num_updates=18150, lr=1.815e-05, gnorm=39.616, clip=100, loss_scale=16, train_wall=104, gb_free=11.7, wall=33996
2025-11-08 02:20:38 | INFO | train_inner | epoch 002:   5245 / 13011 loss=0.233449, wps=1049.6, ups=0.56, wpb=1887.5, bsz=112, num_updates=18200, lr=1.82e-05, gnorm=35.068, clip=100, loss_scale=16, train_wall=90, gb_free=15.1, wall=34086
2025-11-08 02:22:13 | INFO | train_inner | epoch 002:   5295 / 13011 loss=0.236339, wps=992.5, ups=0.53, wpb=1884.7, bsz=112, num_updates=18250, lr=1.825e-05, gnorm=37.885, clip=100, loss_scale=16, train_wall=95, gb_free=18.9, wall=34180
2025-11-08 02:23:41 | INFO | train_inner | epoch 002:   5345 / 13011 loss=0.224751, wps=1121.1, ups=0.57, wpb=1972.9, bsz=112, num_updates=18300, lr=1.83e-05, gnorm=37.873, clip=100, loss_scale=16, train_wall=88, gb_free=17.1, wall=34268
2025-11-08 02:25:11 | INFO | train_inner | epoch 002:   5395 / 13011 loss=0.230366, wps=1073.3, ups=0.56, wpb=1926, bsz=112, num_updates=18350, lr=1.835e-05, gnorm=42.179, clip=100, loss_scale=32, train_wall=90, gb_free=17.2, wall=34358
2025-11-08 02:26:52 | INFO | train_inner | epoch 002:   5445 / 13011 loss=0.229924, wps=953.8, ups=0.5, wpb=1923.6, bsz=112, num_updates=18400, lr=1.84e-05, gnorm=37.375, clip=100, loss_scale=32, train_wall=101, gb_free=18.1, wall=34459
2025-11-08 02:28:32 | INFO | train_inner | epoch 002:   5495 / 13011 loss=0.210957, wps=942.7, ups=0.5, wpb=1888.1, bsz=112, num_updates=18450, lr=1.845e-05, gnorm=35.094, clip=100, loss_scale=32, train_wall=100, gb_free=15.4, wall=34559
2025-11-08 02:30:39 | INFO | train_inner | epoch 002:   5545 / 13011 loss=0.224346, wps=744.5, ups=0.39, wpb=1892, bsz=112, num_updates=18500, lr=1.85e-05, gnorm=37.649, clip=100, loss_scale=32, train_wall=114, gb_free=10.6, wall=34686
2025-11-08 02:31:54 | INFO | train_inner | epoch 002:   5595 / 13011 loss=0.211991, wps=1278.2, ups=0.67, wpb=1921.4, bsz=112, num_updates=18550, lr=1.855e-05, gnorm=36.089, clip=100, loss_scale=32, train_wall=75, gb_free=16.5, wall=34761
2025-11-08 02:33:35 | INFO | train_inner | epoch 002:   5645 / 13011 loss=0.214542, wps=956.9, ups=0.5, wpb=1924.2, bsz=112, num_updates=18600, lr=1.86e-05, gnorm=39.934, clip=100, loss_scale=64, train_wall=100, gb_free=18.7, wall=34862
2025-11-08 02:35:32 | INFO | train_inner | epoch 002:   5695 / 13011 loss=0.219332, wps=834.3, ups=0.43, wpb=1957.4, bsz=112, num_updates=18650, lr=1.865e-05, gnorm=37.609, clip=100, loss_scale=64, train_wall=117, gb_free=15.4, wall=34979
2025-11-08 02:37:15 | INFO | train_inner | epoch 002:   5745 / 13011 loss=0.212597, wps=937.7, ups=0.48, wpb=1935.7, bsz=112, num_updates=18700, lr=1.87e-05, gnorm=34.577, clip=100, loss_scale=64, train_wall=103, gb_free=15.5, wall=35083
2025-11-08 02:39:08 | INFO | train_inner | epoch 002:   5795 / 13011 loss=0.220193, wps=856.5, ups=0.44, wpb=1926, bsz=112, num_updates=18750, lr=1.875e-05, gnorm=37.928, clip=100, loss_scale=64, train_wall=112, gb_free=17.5, wall=35195
2025-11-08 02:40:27 | INFO | train_inner | epoch 002:   5845 / 13011 loss=0.214063, wps=1174.2, ups=0.63, wpb=1862.5, bsz=112, num_updates=18800, lr=1.88e-05, gnorm=34.78, clip=100, loss_scale=64, train_wall=79, gb_free=18, wall=35274
2025-11-08 02:42:30 | INFO | train_inner | epoch 002:   5895 / 13011 loss=0.227403, wps=776.6, ups=0.41, wpb=1914.1, bsz=112, num_updates=18850, lr=1.885e-05, gnorm=35.202, clip=100, loss_scale=128, train_wall=123, gb_free=12.4, wall=35398
2025-11-08 02:43:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-08 02:44:38 | INFO | train_inner | epoch 002:   5946 / 13011 loss=0.224061, wps=750.1, ups=0.39, wpb=1911.5, bsz=112, num_updates=18900, lr=1.89e-05, gnorm=35.512, clip=100, loss_scale=64, train_wall=127, gb_free=17.9, wall=35525
2025-11-08 02:45:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 02:46:38 | INFO | train_inner | epoch 002:   5997 / 13011 loss=0.214591, wps=800.7, ups=0.42, wpb=1929, bsz=112, num_updates=18950, lr=1.895e-05, gnorm=34.458, clip=100, loss_scale=32, train_wall=113, gb_free=9.1, wall=35645
2025-11-08 02:48:09 | INFO | train_inner | epoch 002:   6047 / 13011 loss=0.220074, wps=1065.9, ups=0.55, wpb=1938.1, bsz=112, num_updates=19000, lr=1.9e-05, gnorm=36.87, clip=100, loss_scale=32, train_wall=91, gb_free=18.9, wall=35736
2025-11-08 02:49:55 | INFO | train_inner | epoch 002:   6097 / 13011 loss=0.205686, wps=906.2, ups=0.47, wpb=1928, bsz=112, num_updates=19050, lr=1.905e-05, gnorm=36.252, clip=100, loss_scale=32, train_wall=106, gb_free=15.5, wall=35843
2025-11-08 02:51:31 | INFO | train_inner | epoch 002:   6147 / 13011 loss=0.212641, wps=1003, ups=0.52, wpb=1917.9, bsz=112, num_updates=19100, lr=1.91e-05, gnorm=36.717, clip=100, loss_scale=32, train_wall=95, gb_free=14.9, wall=35938
2025-11-08 02:53:03 | INFO | train_inner | epoch 002:   6197 / 13011 loss=0.217044, wps=1040.8, ups=0.54, wpb=1913, bsz=112, num_updates=19150, lr=1.915e-05, gnorm=33.847, clip=100, loss_scale=32, train_wall=92, gb_free=17.5, wall=36030
2025-11-08 02:54:41 | INFO | train_inner | epoch 002:   6247 / 13011 loss=0.215202, wps=968, ups=0.51, wpb=1904.9, bsz=112, num_updates=19200, lr=1.92e-05, gnorm=36.664, clip=100, loss_scale=64, train_wall=98, gb_free=17.7, wall=36129
2025-11-08 02:56:15 | INFO | train_inner | epoch 002:   6297 / 13011 loss=0.209694, wps=1017.8, ups=0.53, wpb=1909.7, bsz=112, num_updates=19250, lr=1.925e-05, gnorm=36.505, clip=100, loss_scale=64, train_wall=94, gb_free=11.9, wall=36222
2025-11-08 02:57:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 02:58:01 | INFO | train_inner | epoch 002:   6348 / 13011 loss=0.224777, wps=922.6, ups=0.47, wpb=1957.1, bsz=112, num_updates=19300, lr=1.93e-05, gnorm=39.679, clip=100, loss_scale=32, train_wall=106, gb_free=18.6, wall=36328
2025-11-08 02:59:45 | INFO | train_inner | epoch 002:   6398 / 13011 loss=0.22784, wps=916.8, ups=0.48, wpb=1897, bsz=112, num_updates=19350, lr=1.935e-05, gnorm=40.304, clip=100, loss_scale=32, train_wall=103, gb_free=17.5, wall=36432
2025-11-08 03:01:21 | INFO | train_inner | epoch 002:   6448 / 13011 loss=0.211422, wps=993.8, ups=0.52, wpb=1923.4, bsz=112, num_updates=19400, lr=1.94e-05, gnorm=35.217, clip=100, loss_scale=32, train_wall=97, gb_free=13.6, wall=36529
2025-11-08 03:02:47 | INFO | train_inner | epoch 002:   6498 / 13011 loss=0.218158, wps=1117.2, ups=0.58, wpb=1919.8, bsz=112, num_updates=19450, lr=1.945e-05, gnorm=32.381, clip=100, loss_scale=32, train_wall=86, gb_free=18.5, wall=36615
2025-11-08 03:04:22 | INFO | train_inner | epoch 002:   6548 / 13011 loss=0.212585, wps=1003.3, ups=0.53, wpb=1910.6, bsz=112, num_updates=19500, lr=1.95e-05, gnorm=36.937, clip=100, loss_scale=32, train_wall=95, gb_free=17.4, wall=36710
2025-11-08 03:06:01 | INFO | train_inner | epoch 002:   6598 / 13011 loss=0.219222, wps=971.1, ups=0.51, wpb=1908.6, bsz=112, num_updates=19550, lr=1.955e-05, gnorm=35.568, clip=100, loss_scale=64, train_wall=98, gb_free=18.8, wall=36808
2025-11-08 03:08:04 | INFO | train_inner | epoch 002:   6648 / 13011 loss=0.210275, wps=784.7, ups=0.41, wpb=1936.9, bsz=112, num_updates=19600, lr=1.96e-05, gnorm=34.924, clip=100, loss_scale=64, train_wall=123, gb_free=17.3, wall=36932
2025-11-08 03:09:56 | INFO | train_inner | epoch 002:   6698 / 13011 loss=0.222429, wps=834.3, ups=0.45, wpb=1869.9, bsz=112, num_updates=19650, lr=1.965e-05, gnorm=34.853, clip=100, loss_scale=64, train_wall=112, gb_free=17, wall=37044
2025-11-08 03:11:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 03:11:37 | INFO | train_inner | epoch 002:   6749 / 13011 loss=0.213229, wps=965.6, ups=0.49, wpb=1954.8, bsz=112, num_updates=19700, lr=1.97e-05, gnorm=35.557, clip=100, loss_scale=32, train_wall=101, gb_free=17.9, wall=37145
2025-11-08 03:13:46 | INFO | train_inner | epoch 002:   6799 / 13011 loss=0.213636, wps=749.2, ups=0.39, wpb=1932.7, bsz=112, num_updates=19750, lr=1.975e-05, gnorm=42.891, clip=100, loss_scale=32, train_wall=129, gb_free=18.1, wall=37274
2025-11-08 03:15:21 | INFO | train_inner | epoch 002:   6849 / 13011 loss=0.198515, wps=1023.3, ups=0.53, wpb=1929.7, bsz=112, num_updates=19800, lr=1.98e-05, gnorm=35.483, clip=100, loss_scale=32, train_wall=92, gb_free=18.1, wall=37368
2025-11-08 03:17:32 | INFO | train_inner | epoch 002:   6899 / 13011 loss=0.207259, wps=721.5, ups=0.38, wpb=1888.8, bsz=112, num_updates=19850, lr=1.985e-05, gnorm=36.341, clip=100, loss_scale=32, train_wall=131, gb_free=17.7, wall=37499
2025-11-08 03:19:05 | INFO | train_inner | epoch 002:   6949 / 13011 loss=0.203875, wps=1028.5, ups=0.53, wpb=1930.3, bsz=112, num_updates=19900, lr=1.99e-05, gnorm=35.838, clip=100, loss_scale=32, train_wall=94, gb_free=17.5, wall=37593
2025-11-08 03:21:02 | INFO | train_inner | epoch 002:   6999 / 13011 loss=0.213245, wps=812.6, ups=0.43, wpb=1895.3, bsz=112, num_updates=19950, lr=1.995e-05, gnorm=36.741, clip=100, loss_scale=32, train_wall=116, gb_free=18.1, wall=37709
2025-11-08 03:21:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 03:22:47 | INFO | train_inner | epoch 002:   7050 / 13011 loss=0.212034, wps=919.6, ups=0.48, wpb=1929.2, bsz=112, num_updates=20000, lr=2e-05, gnorm=37.985, clip=100, loss_scale=32, train_wall=105, gb_free=18.2, wall=37814
2025-11-08 03:24:20 | INFO | train_inner | epoch 002:   7100 / 13011 loss=0.203876, wps=1035.6, ups=0.54, wpb=1926, bsz=112, num_updates=20050, lr=2.005e-05, gnorm=36.21, clip=100, loss_scale=32, train_wall=93, gb_free=18.2, wall=37907
2025-11-08 03:25:47 | INFO | train_inner | epoch 002:   7150 / 13011 loss=0.212497, wps=1099.6, ups=0.57, wpb=1919.2, bsz=112, num_updates=20100, lr=2.01e-05, gnorm=36.45, clip=100, loss_scale=32, train_wall=87, gb_free=18.1, wall=37995
2025-11-08 03:27:21 | INFO | train_inner | epoch 002:   7200 / 13011 loss=0.191543, wps=1028.9, ups=0.54, wpb=1922, bsz=112, num_updates=20150, lr=2.015e-05, gnorm=33.11, clip=100, loss_scale=32, train_wall=93, gb_free=16.1, wall=38088
2025-11-08 03:29:05 | INFO | train_inner | epoch 002:   7250 / 13011 loss=0.197753, wps=894.2, ups=0.48, wpb=1869.2, bsz=112, num_updates=20200, lr=2.02e-05, gnorm=35.433, clip=100, loss_scale=32, train_wall=104, gb_free=18.6, wall=38193
2025-11-08 03:31:04 | INFO | train_inner | epoch 002:   7300 / 13011 loss=0.210769, wps=810.1, ups=0.42, wpb=1932.8, bsz=112, num_updates=20250, lr=2.025e-05, gnorm=35.126, clip=100, loss_scale=64, train_wall=119, gb_free=17.6, wall=38312
2025-11-08 03:32:44 | INFO | train_inner | epoch 002:   7350 / 13011 loss=0.210757, wps=953, ups=0.5, wpb=1904.5, bsz=112, num_updates=20300, lr=2.03e-05, gnorm=35.852, clip=100, loss_scale=64, train_wall=100, gb_free=18.7, wall=38412
2025-11-08 03:34:21 | INFO | train_inner | epoch 002:   7400 / 13011 loss=0.199455, wps=1003.9, ups=0.52, wpb=1933, bsz=112, num_updates=20350, lr=2.035e-05, gnorm=34.972, clip=100, loss_scale=64, train_wall=96, gb_free=16.6, wall=38508
2025-11-08 03:35:41 | INFO | train_inner | epoch 002:   7450 / 13011 loss=0.204923, wps=1197.8, ups=0.62, wpb=1925.6, bsz=112, num_updates=20400, lr=2.04e-05, gnorm=37.527, clip=100, loss_scale=64, train_wall=80, gb_free=19.2, wall=38588
2025-11-08 03:37:37 | INFO | train_inner | epoch 002:   7500 / 13011 loss=0.19635, wps=819.1, ups=0.43, wpb=1902.4, bsz=112, num_updates=20450, lr=2.045e-05, gnorm=34.296, clip=100, loss_scale=64, train_wall=116, gb_free=16.3, wall=38705
2025-11-08 03:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-08 03:39:21 | INFO | train_inner | epoch 002:   7551 / 13011 loss=0.197255, wps=921.9, ups=0.48, wpb=1911.1, bsz=112, num_updates=20500, lr=2.05e-05, gnorm=35.539, clip=100, loss_scale=64, train_wall=103, gb_free=18.5, wall=38808
2025-11-08 03:39:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 03:41:09 | INFO | train_inner | epoch 002:   7602 / 13011 loss=0.200808, wps=884.8, ups=0.46, wpb=1922.8, bsz=112, num_updates=20550, lr=2.055e-05, gnorm=34.494, clip=100, loss_scale=32, train_wall=108, gb_free=17, wall=38917
2025-11-08 03:43:01 | INFO | train_inner | epoch 002:   7652 / 13011 loss=0.202924, wps=854.1, ups=0.45, wpb=1903.3, bsz=112, num_updates=20600, lr=2.06e-05, gnorm=36.903, clip=100, loss_scale=32, train_wall=111, gb_free=17.6, wall=39028
2025-11-08 03:45:02 | INFO | train_inner | epoch 002:   7702 / 13011 loss=0.205467, wps=786.8, ups=0.41, wpb=1912.3, bsz=112, num_updates=20650, lr=2.065e-05, gnorm=39.085, clip=100, loss_scale=32, train_wall=121, gb_free=17.9, wall=39150
2025-11-08 03:46:46 | INFO | train_inner | epoch 002:   7752 / 13011 loss=0.197079, wps=923.4, ups=0.48, wpb=1910.9, bsz=112, num_updates=20700, lr=2.07e-05, gnorm=33.672, clip=100, loss_scale=32, train_wall=103, gb_free=18.5, wall=39253
2025-11-08 03:49:07 | INFO | train_inner | epoch 002:   7802 / 13011 loss=0.195572, wps=667.5, ups=0.35, wpb=1883.2, bsz=112, num_updates=20750, lr=2.075e-05, gnorm=37.165, clip=100, loss_scale=32, train_wall=141, gb_free=13.2, wall=39394
2025-11-08 03:50:53 | INFO | train_inner | epoch 002:   7852 / 13011 loss=0.190368, wps=888.4, ups=0.47, wpb=1892.2, bsz=112, num_updates=20800, lr=2.08e-05, gnorm=34.489, clip=100, loss_scale=64, train_wall=106, gb_free=16.6, wall=39501
2025-11-08 03:52:33 | INFO | train_inner | epoch 002:   7902 / 13011 loss=0.19283, wps=982.6, ups=0.5, wpb=1950.9, bsz=112, num_updates=20850, lr=2.085e-05, gnorm=33.831, clip=100, loss_scale=64, train_wall=99, gb_free=16.6, wall=39600
2025-11-08 03:54:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 03:54:25 | INFO | train_inner | epoch 002:   7953 / 13011 loss=0.201983, wps=820.1, ups=0.45, wpb=1836.4, bsz=112, num_updates=20900, lr=2.09e-05, gnorm=35.328, clip=100, loss_scale=32, train_wall=112, gb_free=17.6, wall=39712
2025-11-08 03:55:58 | INFO | train_inner | epoch 002:   8003 / 13011 loss=0.191776, wps=1035.7, ups=0.54, wpb=1923, bsz=112, num_updates=20950, lr=2.095e-05, gnorm=36.913, clip=100, loss_scale=32, train_wall=93, gb_free=18.8, wall=39805
2025-11-08 03:57:20 | INFO | train_inner | epoch 002:   8053 / 13011 loss=0.19685, wps=1148.3, ups=0.6, wpb=1902.4, bsz=112, num_updates=21000, lr=2.1e-05, gnorm=34.543, clip=100, loss_scale=32, train_wall=83, gb_free=15.9, wall=39888
2025-11-08 03:58:42 | INFO | train_inner | epoch 002:   8103 / 13011 loss=0.197944, wps=1173.3, ups=0.62, wpb=1906.4, bsz=112, num_updates=21050, lr=2.105e-05, gnorm=35.205, clip=100, loss_scale=32, train_wall=81, gb_free=19.3, wall=39969
2025-11-08 04:00:20 | INFO | train_inner | epoch 002:   8153 / 13011 loss=0.198819, wps=960.8, ups=0.51, wpb=1889.1, bsz=112, num_updates=21100, lr=2.11e-05, gnorm=35.192, clip=100, loss_scale=32, train_wall=98, gb_free=18.6, wall=40067
2025-11-08 04:01:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 04:02:07 | INFO | train_inner | epoch 002:   8204 / 13011 loss=0.194293, wps=883.1, ups=0.47, wpb=1898.1, bsz=112, num_updates=21150, lr=2.115e-05, gnorm=37.44, clip=100, loss_scale=16, train_wall=107, gb_free=17.8, wall=40175
2025-11-08 04:03:50 | INFO | train_inner | epoch 002:   8254 / 13011 loss=0.200638, wps=939.6, ups=0.49, wpb=1922.8, bsz=112, num_updates=21200, lr=2.12e-05, gnorm=33.105, clip=100, loss_scale=16, train_wall=102, gb_free=12.8, wall=40277
2025-11-08 04:06:05 | INFO | train_inner | epoch 002:   8304 / 13011 loss=0.195463, wps=711.5, ups=0.37, wpb=1923.2, bsz=112, num_updates=21250, lr=2.125e-05, gnorm=32.54, clip=100, loss_scale=16, train_wall=135, gb_free=13.5, wall=40412
2025-11-08 04:07:34 | INFO | train_inner | epoch 002:   8354 / 13011 loss=0.192459, wps=1061.6, ups=0.56, wpb=1889.6, bsz=112, num_updates=21300, lr=2.13e-05, gnorm=35.901, clip=100, loss_scale=16, train_wall=84, gb_free=18.9, wall=40501
2025-11-08 04:09:15 | INFO | train_inner | epoch 002:   8404 / 13011 loss=0.195231, wps=942.2, ups=0.49, wpb=1907.3, bsz=112, num_updates=21350, lr=2.135e-05, gnorm=36.486, clip=100, loss_scale=16, train_wall=101, gb_free=18.3, wall=40602
2025-11-08 04:11:03 | INFO | train_inner | epoch 002:   8454 / 13011 loss=0.199754, wps=885.5, ups=0.46, wpb=1910, bsz=112, num_updates=21400, lr=2.14e-05, gnorm=36.854, clip=100, loss_scale=32, train_wall=108, gb_free=13.1, wall=40710
2025-11-08 04:12:27 | INFO | train_inner | epoch 002:   8504 / 13011 loss=0.183344, wps=1150.3, ups=0.59, wpb=1938.3, bsz=112, num_updates=21450, lr=2.145e-05, gnorm=34.121, clip=100, loss_scale=32, train_wall=84, gb_free=16.4, wall=40795
2025-11-08 04:14:32 | INFO | train_inner | epoch 002:   8554 / 13011 loss=0.191639, wps=769.9, ups=0.4, wpb=1921.9, bsz=112, num_updates=21500, lr=2.15e-05, gnorm=35.603, clip=100, loss_scale=32, train_wall=125, gb_free=17.6, wall=40919
2025-11-08 04:16:03 | INFO | train_inner | epoch 002:   8604 / 13011 loss=0.190855, wps=1057.7, ups=0.55, wpb=1935.5, bsz=112, num_updates=21550, lr=2.155e-05, gnorm=33.634, clip=100, loss_scale=32, train_wall=91, gb_free=17.6, wall=41011
2025-11-08 04:18:00 | INFO | train_inner | epoch 002:   8654 / 13011 loss=0.195766, wps=824.1, ups=0.43, wpb=1915.6, bsz=112, num_updates=21600, lr=2.16e-05, gnorm=34.535, clip=100, loss_scale=32, train_wall=116, gb_free=12.9, wall=41127
2025-11-08 04:19:41 | INFO | train_inner | epoch 002:   8704 / 13011 loss=0.189497, wps=928, ups=0.49, wpb=1887.7, bsz=112, num_updates=21650, lr=2.165e-05, gnorm=33.989, clip=100, loss_scale=32, train_wall=101, gb_free=12, wall=41229
2025-11-08 04:21:57 | INFO | train_inner | epoch 002:   8754 / 13011 loss=0.178593, wps=708.9, ups=0.37, wpb=1928.7, bsz=112, num_updates=21700, lr=2.17e-05, gnorm=34.151, clip=100, loss_scale=64, train_wall=136, gb_free=16.9, wall=41365
2025-11-08 04:23:49 | INFO | train_inner | epoch 002:   8804 / 13011 loss=0.194961, wps=874.7, ups=0.45, wpb=1949.1, bsz=112, num_updates=21750, lr=2.175e-05, gnorm=35.884, clip=100, loss_scale=64, train_wall=111, gb_free=9.4, wall=41476
2025-11-08 04:24:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 04:25:49 | INFO | train_inner | epoch 002:   8855 / 13011 loss=0.184757, wps=774.4, ups=0.42, wpb=1858.3, bsz=112, num_updates=21800, lr=2.18e-05, gnorm=32.873, clip=100, loss_scale=32, train_wall=120, gb_free=18.5, wall=41596
2025-11-08 04:27:14 | INFO | train_inner | epoch 002:   8905 / 13011 loss=0.192276, wps=1139.2, ups=0.59, wpb=1930.4, bsz=112, num_updates=21850, lr=2.185e-05, gnorm=34.401, clip=100, loss_scale=32, train_wall=84, gb_free=15, wall=41681
2025-11-08 04:28:46 | INFO | train_inner | epoch 002:   8955 / 13011 loss=0.174794, wps=1043.2, ups=0.54, wpb=1936.4, bsz=112, num_updates=21900, lr=2.19e-05, gnorm=33.971, clip=100, loss_scale=32, train_wall=93, gb_free=18.4, wall=41774
2025-11-08 04:30:14 | INFO | train_inner | epoch 002:   9005 / 13011 loss=0.182955, wps=1102.5, ups=0.57, wpb=1934.4, bsz=112, num_updates=21950, lr=2.195e-05, gnorm=32.624, clip=100, loss_scale=32, train_wall=87, gb_free=19, wall=41862
2025-11-08 04:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 04:32:12 | INFO | train_inner | epoch 002:   9056 / 13011 loss=0.191835, wps=815, ups=0.42, wpb=1927.7, bsz=112, num_updates=22000, lr=2.2e-05, gnorm=32.542, clip=100, loss_scale=16, train_wall=118, gb_free=13.7, wall=41980
2025-11-08 04:33:51 | INFO | train_inner | epoch 002:   9106 / 13011 loss=0.183555, wps=994.4, ups=0.5, wpb=1971.2, bsz=112, num_updates=22050, lr=2.205e-05, gnorm=35.269, clip=100, loss_scale=16, train_wall=99, gb_free=16.3, wall=42079
2025-11-08 04:35:17 | INFO | train_inner | epoch 002:   9156 / 13011 loss=0.190447, wps=1113.3, ups=0.58, wpb=1911.1, bsz=112, num_updates=22100, lr=2.21e-05, gnorm=35.818, clip=100, loss_scale=16, train_wall=86, gb_free=16.9, wall=42165
2025-11-08 04:36:58 | INFO | train_inner | epoch 002:   9206 / 13011 loss=0.190118, wps=938.6, ups=0.5, wpb=1888.2, bsz=112, num_updates=22150, lr=2.215e-05, gnorm=35.905, clip=100, loss_scale=16, train_wall=100, gb_free=15.4, wall=42265
2025-11-08 04:38:24 | INFO | train_inner | epoch 002:   9256 / 13011 loss=0.179076, wps=1106.4, ups=0.58, wpb=1915, bsz=112, num_updates=22200, lr=2.22e-05, gnorm=32.81, clip=100, loss_scale=16, train_wall=86, gb_free=18.2, wall=42352
2025-11-08 04:40:06 | INFO | train_inner | epoch 002:   9306 / 13011 loss=0.173925, wps=954.2, ups=0.49, wpb=1936.7, bsz=112, num_updates=22250, lr=2.225e-05, gnorm=33.339, clip=100, loss_scale=32, train_wall=101, gb_free=17.8, wall=42453
2025-11-08 04:41:48 | INFO | train_inner | epoch 002:   9356 / 13011 loss=0.176846, wps=936.7, ups=0.49, wpb=1909.9, bsz=112, num_updates=22300, lr=2.23e-05, gnorm=32.534, clip=100, loss_scale=32, train_wall=102, gb_free=16.2, wall=42555
2025-11-08 04:41:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 04:43:47 | INFO | train_inner | epoch 002:   9407 / 13011 loss=0.178206, wps=816.2, ups=0.42, wpb=1942.6, bsz=112, num_updates=22350, lr=2.235e-05, gnorm=32.924, clip=100, loss_scale=16, train_wall=119, gb_free=17.9, wall=42674
2025-11-08 04:45:49 | INFO | train_inner | epoch 002:   9457 / 13011 loss=0.179556, wps=793.9, ups=0.41, wpb=1940.5, bsz=112, num_updates=22400, lr=2.24e-05, gnorm=37.673, clip=100, loss_scale=16, train_wall=122, gb_free=17.3, wall=42797
2025-11-08 04:47:36 | INFO | train_inner | epoch 002:   9507 / 13011 loss=0.190785, wps=897.3, ups=0.47, wpb=1924.2, bsz=112, num_updates=22450, lr=2.245e-05, gnorm=34.625, clip=100, loss_scale=16, train_wall=107, gb_free=17.1, wall=42904
2025-11-08 04:49:50 | INFO | train_inner | epoch 002:   9557 / 13011 loss=0.169667, wps=711.1, ups=0.37, wpb=1902.2, bsz=112, num_updates=22500, lr=2.25e-05, gnorm=31.825, clip=100, loss_scale=16, train_wall=133, gb_free=19.1, wall=43037
2025-11-08 04:51:55 | INFO | train_inner | epoch 002:   9607 / 13011 loss=0.179653, wps=760.4, ups=0.4, wpb=1897.1, bsz=112, num_updates=22550, lr=2.255e-05, gnorm=32.078, clip=100, loss_scale=16, train_wall=124, gb_free=16, wall=43162
2025-11-08 04:53:46 | INFO | train_inner | epoch 002:   9657 / 13011 loss=0.173757, wps=876.5, ups=0.45, wpb=1940.4, bsz=112, num_updates=22600, lr=2.26e-05, gnorm=33.007, clip=100, loss_scale=32, train_wall=110, gb_free=13.4, wall=43273
2025-11-08 04:55:14 | INFO | train_inner | epoch 002:   9707 / 13011 loss=0.170719, wps=1109.1, ups=0.57, wpb=1953.4, bsz=112, num_updates=22650, lr=2.265e-05, gnorm=32.84, clip=100, loss_scale=32, train_wall=88, gb_free=16.5, wall=43361
2025-11-08 04:56:47 | INFO | train_inner | epoch 002:   9757 / 13011 loss=0.173471, wps=1005.7, ups=0.53, wpb=1887.9, bsz=112, num_updates=22700, lr=2.27e-05, gnorm=34.764, clip=100, loss_scale=32, train_wall=94, gb_free=13.6, wall=43455
2025-11-08 04:58:10 | INFO | train_inner | epoch 002:   9807 / 13011 loss=0.174907, wps=1149.7, ups=0.61, wpb=1893, bsz=112, num_updates=22750, lr=2.275e-05, gnorm=36.371, clip=100, loss_scale=32, train_wall=82, gb_free=18.5, wall=43537
2025-11-08 04:58:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 04:59:50 | INFO | train_inner | epoch 002:   9858 / 13011 loss=0.165063, wps=961.7, ups=0.5, wpb=1926.2, bsz=112, num_updates=22800, lr=2.28e-05, gnorm=29.132, clip=100, loss_scale=16, train_wall=100, gb_free=17.8, wall=43637
2025-11-08 05:01:32 | INFO | train_inner | epoch 002:   9908 / 13011 loss=0.190277, wps=963.2, ups=0.49, wpb=1958, bsz=112, num_updates=22850, lr=2.285e-05, gnorm=37.402, clip=100, loss_scale=16, train_wall=101, gb_free=17.8, wall=43739
2025-11-08 05:02:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 05:03:40 | INFO | train_inner | epoch 002:   9959 / 13011 loss=0.180947, wps=746.7, ups=0.39, wpb=1923.8, bsz=112, num_updates=22900, lr=2.29e-05, gnorm=33.552, clip=100, loss_scale=8, train_wall=129, gb_free=17.7, wall=43868
2025-11-08 05:04:45 | INFO | train_inner | epoch 002:  10009 / 13011 loss=0.176906, wps=1494.8, ups=0.77, wpb=1931.4, bsz=112, num_updates=22950, lr=2.295e-05, gnorm=39.466, clip=100, loss_scale=8, train_wall=64, gb_free=17.8, wall=43932
2025-11-08 05:06:21 | INFO | train_inner | epoch 002:  10059 / 13011 loss=0.172884, wps=996.5, ups=0.52, wpb=1915.4, bsz=112, num_updates=23000, lr=2.3e-05, gnorm=32.634, clip=100, loss_scale=8, train_wall=96, gb_free=18.8, wall=44029
2025-11-08 05:07:59 | INFO | train_inner | epoch 002:  10109 / 13011 loss=0.171278, wps=979.8, ups=0.51, wpb=1919.7, bsz=112, num_updates=23050, lr=2.305e-05, gnorm=32.671, clip=100, loss_scale=8, train_wall=98, gb_free=18.6, wall=44126
2025-11-08 05:09:31 | INFO | train_inner | epoch 002:  10159 / 13011 loss=0.174789, wps=1044.1, ups=0.54, wpb=1918.5, bsz=112, num_updates=23100, lr=2.31e-05, gnorm=33.726, clip=100, loss_scale=8, train_wall=92, gb_free=17.7, wall=44218
2025-11-08 05:11:13 | INFO | train_inner | epoch 002:  10209 / 13011 loss=0.160429, wps=958.4, ups=0.49, wpb=1952.2, bsz=112, num_updates=23150, lr=2.315e-05, gnorm=31.279, clip=100, loss_scale=16, train_wall=102, gb_free=17.2, wall=44320
2025-11-08 05:12:41 | INFO | train_inner | epoch 002:  10259 / 13011 loss=0.166059, wps=1109.6, ups=0.57, wpb=1955.5, bsz=112, num_updates=23200, lr=2.32e-05, gnorm=32.564, clip=100, loss_scale=16, train_wall=88, gb_free=17.2, wall=44408
2025-11-08 05:15:05 | INFO | train_inner | epoch 002:  10309 / 13011 loss=0.182855, wps=664.1, ups=0.35, wpb=1911.8, bsz=112, num_updates=23250, lr=2.325e-05, gnorm=36.461, clip=100, loss_scale=16, train_wall=144, gb_free=17.6, wall=44552
2025-11-08 05:16:41 | INFO | train_inner | epoch 002:  10359 / 13011 loss=0.174165, wps=990.8, ups=0.52, wpb=1897.6, bsz=112, num_updates=23300, lr=2.33e-05, gnorm=30.58, clip=100, loss_scale=16, train_wall=95, gb_free=14.7, wall=44648
2025-11-08 05:18:34 | INFO | train_inner | epoch 002:  10409 / 13011 loss=0.162674, wps=838.8, ups=0.44, wpb=1895.3, bsz=112, num_updates=23350, lr=2.335e-05, gnorm=29.643, clip=100, loss_scale=16, train_wall=113, gb_free=14.4, wall=44761
2025-11-08 05:20:40 | INFO | train_inner | epoch 002:  10459 / 13011 loss=0.168397, wps=778.7, ups=0.4, wpb=1967.8, bsz=112, num_updates=23400, lr=2.34e-05, gnorm=30.599, clip=100, loss_scale=32, train_wall=126, gb_free=18.2, wall=44887
2025-11-08 05:22:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 05:22:40 | INFO | train_inner | epoch 002:  10510 / 13011 loss=0.177353, wps=818, ups=0.42, wpb=1963.2, bsz=112, num_updates=23450, lr=2.345e-05, gnorm=33.191, clip=100, loss_scale=16, train_wall=120, gb_free=15.2, wall=45007
2025-11-08 05:24:49 | INFO | train_inner | epoch 002:  10560 / 13011 loss=0.162888, wps=757.9, ups=0.39, wpb=1956.7, bsz=112, num_updates=23500, lr=2.35e-05, gnorm=35.722, clip=100, loss_scale=16, train_wall=129, gb_free=16.6, wall=45136
2025-11-08 05:26:25 | INFO | train_inner | epoch 002:  10610 / 13011 loss=0.164521, wps=994, ups=0.52, wpb=1907.7, bsz=112, num_updates=23550, lr=2.355e-05, gnorm=32.972, clip=100, loss_scale=16, train_wall=96, gb_free=17.6, wall=45232
2025-11-08 05:28:13 | INFO | train_inner | epoch 002:  10660 / 13011 loss=0.177472, wps=875.1, ups=0.47, wpb=1881.4, bsz=112, num_updates=23600, lr=2.36e-05, gnorm=33.482, clip=100, loss_scale=16, train_wall=107, gb_free=18.3, wall=45340
2025-11-08 05:30:01 | INFO | train_inner | epoch 002:  10710 / 13011 loss=0.167884, wps=872, ups=0.46, wpb=1885.3, bsz=112, num_updates=23650, lr=2.365e-05, gnorm=32.016, clip=100, loss_scale=16, train_wall=108, gb_free=16.7, wall=45448
2025-11-08 05:31:40 | INFO | train_inner | epoch 002:  10760 / 13011 loss=0.163915, wps=949.1, ups=0.5, wpb=1882.8, bsz=112, num_updates=23700, lr=2.37e-05, gnorm=30.741, clip=100, loss_scale=32, train_wall=99, gb_free=17.9, wall=45547
2025-11-08 05:33:14 | INFO | train_inner | epoch 002:  10810 / 13011 loss=0.169626, wps=1038.5, ups=0.53, wpb=1951.8, bsz=111.9, num_updates=23750, lr=2.375e-05, gnorm=37.263, clip=100, loss_scale=32, train_wall=94, gb_free=19.4, wall=45641
2025-11-08 05:34:54 | INFO | train_inner | epoch 002:  10860 / 13011 loss=0.172225, wps=953.9, ups=0.5, wpb=1917.2, bsz=112, num_updates=23800, lr=2.38e-05, gnorm=33.075, clip=100, loss_scale=32, train_wall=100, gb_free=18.9, wall=45742
2025-11-08 05:35:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 05:36:39 | INFO | train_inner | epoch 002:  10911 / 13011 loss=0.175678, wps=915.1, ups=0.48, wpb=1911.7, bsz=112, num_updates=23850, lr=2.385e-05, gnorm=37.664, clip=100, loss_scale=16, train_wall=104, gb_free=18.8, wall=45846
2025-11-08 05:38:43 | INFO | train_inner | epoch 002:  10961 / 13011 loss=0.169691, wps=771, ups=0.4, wpb=1921.1, bsz=112, num_updates=23900, lr=2.39e-05, gnorm=31.334, clip=100, loss_scale=16, train_wall=124, gb_free=15.9, wall=45971
2025-11-08 05:39:56 | INFO | train_inner | epoch 002:  11011 / 13011 loss=0.163171, wps=1324.7, ups=0.69, wpb=1932.4, bsz=112, num_updates=23950, lr=2.395e-05, gnorm=31.345, clip=100, loss_scale=16, train_wall=73, gb_free=16.7, wall=46044
2025-11-08 05:41:47 | INFO | train_inner | epoch 002:  11061 / 13011 loss=0.16178, wps=853.4, ups=0.45, wpb=1886.2, bsz=112, num_updates=24000, lr=2.4e-05, gnorm=31.016, clip=100, loss_scale=16, train_wall=110, gb_free=15.5, wall=46154
2025-11-08 05:42:51 | INFO | train_inner | epoch 002:  11111 / 13011 loss=0.155297, wps=1500.3, ups=0.78, wpb=1935.8, bsz=112, num_updates=24050, lr=2.405e-05, gnorm=30.093, clip=100, loss_scale=16, train_wall=64, gb_free=19.1, wall=46219
2025-11-08 05:44:36 | INFO | train_inner | epoch 002:  11161 / 13011 loss=0.159729, wps=912.2, ups=0.48, wpb=1912.1, bsz=112, num_updates=24100, lr=2.41e-05, gnorm=31.963, clip=100, loss_scale=32, train_wall=105, gb_free=16.5, wall=46324
2025-11-08 05:45:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 05:46:28 | INFO | train_inner | epoch 002:  11212 / 13011 loss=0.166218, wps=865.9, ups=0.45, wpb=1941.9, bsz=112, num_updates=24150, lr=2.415e-05, gnorm=33.429, clip=100, loss_scale=16, train_wall=112, gb_free=17.5, wall=46436
2025-11-08 05:48:16 | INFO | train_inner | epoch 002:  11262 / 13011 loss=0.161219, wps=889.8, ups=0.46, wpb=1923.3, bsz=112, num_updates=24200, lr=2.42e-05, gnorm=33.404, clip=100, loss_scale=16, train_wall=108, gb_free=14.9, wall=46544
2025-11-08 05:50:26 | INFO | train_inner | epoch 002:  11312 / 13011 loss=0.165891, wps=728.4, ups=0.39, wpb=1883.3, bsz=112, num_updates=24250, lr=2.425e-05, gnorm=32.752, clip=100, loss_scale=16, train_wall=129, gb_free=18.4, wall=46673
2025-11-08 05:52:07 | INFO | train_inner | epoch 002:  11362 / 13011 loss=0.152308, wps=945, ups=0.49, wpb=1915.6, bsz=112, num_updates=24300, lr=2.43e-05, gnorm=34.664, clip=100, loss_scale=16, train_wall=101, gb_free=16.5, wall=46774
2025-11-08 05:53:58 | INFO | train_inner | epoch 002:  11412 / 13011 loss=0.152187, wps=868.5, ups=0.45, wpb=1921.4, bsz=112, num_updates=24350, lr=2.435e-05, gnorm=29.013, clip=100, loss_scale=16, train_wall=110, gb_free=18.3, wall=46885
2025-11-08 05:55:48 | INFO | train_inner | epoch 002:  11462 / 13011 loss=0.155744, wps=859.4, ups=0.45, wpb=1896.8, bsz=112, num_updates=24400, lr=2.44e-05, gnorm=31.489, clip=100, loss_scale=32, train_wall=110, gb_free=13.1, wall=46995
2025-11-08 05:57:58 | INFO | train_inner | epoch 002:  11512 / 13011 loss=0.169845, wps=738.8, ups=0.39, wpb=1917.2, bsz=112, num_updates=24450, lr=2.445e-05, gnorm=32.532, clip=100, loss_scale=32, train_wall=129, gb_free=18.2, wall=47125
2025-11-08 05:58:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 05:59:57 | INFO | train_inner | epoch 002:  11563 / 13011 loss=0.168381, wps=812.3, ups=0.42, wpb=1938, bsz=112, num_updates=24500, lr=2.45e-05, gnorm=32.797, clip=100, loss_scale=16, train_wall=119, gb_free=17.5, wall=47244
2025-11-08 06:01:24 | INFO | train_inner | epoch 002:  11613 / 13011 loss=0.152227, wps=1117.4, ups=0.57, wpb=1947, bsz=112, num_updates=24550, lr=2.455e-05, gnorm=29.056, clip=100, loss_scale=16, train_wall=87, gb_free=17.1, wall=47332
2025-11-08 06:03:12 | INFO | train_inner | epoch 002:  11663 / 13011 loss=0.166522, wps=889.9, ups=0.47, wpb=1910.8, bsz=112, num_updates=24600, lr=2.46e-05, gnorm=31.014, clip=100, loss_scale=16, train_wall=107, gb_free=18.3, wall=47439
2025-11-08 06:04:36 | INFO | train_inner | epoch 002:  11713 / 13011 loss=0.162593, wps=1154.3, ups=0.59, wpb=1941.1, bsz=112, num_updates=24650, lr=2.465e-05, gnorm=33.548, clip=100, loss_scale=16, train_wall=84, gb_free=18.2, wall=47523
2025-11-08 06:06:46 | INFO | train_inner | epoch 002:  11763 / 13011 loss=0.152862, wps=744.7, ups=0.38, wpb=1939, bsz=112, num_updates=24700, lr=2.47e-05, gnorm=29.785, clip=100, loss_scale=16, train_wall=130, gb_free=18.2, wall=47653
2025-11-08 06:07:58 | INFO | train_inner | epoch 002:  11813 / 13011 loss=0.156996, wps=1345.4, ups=0.69, wpb=1938.4, bsz=112, num_updates=24750, lr=2.475e-05, gnorm=31.959, clip=100, loss_scale=32, train_wall=72, gb_free=18.4, wall=47725
2025-11-08 06:09:46 | INFO | train_inner | epoch 002:  11863 / 13011 loss=0.162615, wps=867.2, ups=0.46, wpb=1884.3, bsz=112, num_updates=24800, lr=2.48e-05, gnorm=33.077, clip=100, loss_scale=32, train_wall=108, gb_free=14, wall=47834
2025-11-08 06:10:55 | INFO | train_inner | epoch 002:  11913 / 13011 loss=0.147478, wps=1400, ups=0.73, wpb=1914.7, bsz=112, num_updates=24850, lr=2.485e-05, gnorm=28.257, clip=100, loss_scale=32, train_wall=68, gb_free=12.7, wall=47902
2025-11-08 06:12:39 | INFO | train_inner | epoch 002:  11963 / 13011 loss=0.165276, wps=903, ups=0.48, wpb=1886.6, bsz=112, num_updates=24900, lr=2.49e-05, gnorm=30.94, clip=100, loss_scale=32, train_wall=104, gb_free=18.9, wall=48007
2025-11-08 06:14:28 | INFO | train_inner | epoch 002:  12013 / 13011 loss=0.171558, wps=875.8, ups=0.46, wpb=1909.1, bsz=112, num_updates=24950, lr=2.495e-05, gnorm=31.903, clip=100, loss_scale=32, train_wall=109, gb_free=17.2, wall=48116
2025-11-08 06:16:17 | INFO | train_inner | epoch 002:  12063 / 13011 loss=0.159138, wps=881.2, ups=0.46, wpb=1912.5, bsz=112, num_updates=25000, lr=2.5e-05, gnorm=31.019, clip=100, loss_scale=64, train_wall=108, gb_free=17.8, wall=48224
2025-11-08 06:17:49 | INFO | train_inner | epoch 002:  12113 / 13011 loss=0.16239, wps=1046.6, ups=0.54, wpb=1920.8, bsz=112, num_updates=25050, lr=2.505e-05, gnorm=28.401, clip=100, loss_scale=64, train_wall=92, gb_free=11.8, wall=48316
2025-11-08 06:19:32 | INFO | train_inner | epoch 002:  12163 / 13011 loss=0.146066, wps=931.1, ups=0.48, wpb=1931.3, bsz=112, num_updates=25100, lr=2.51e-05, gnorm=28.333, clip=100, loss_scale=64, train_wall=103, gb_free=18, wall=48420
2025-11-08 06:21:39 | INFO | train_inner | epoch 002:  12213 / 13011 loss=0.157903, wps=763.6, ups=0.39, wpb=1937.8, bsz=112, num_updates=25150, lr=2.515e-05, gnorm=29.125, clip=100, loss_scale=64, train_wall=127, gb_free=18.3, wall=48547
2025-11-08 06:21:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 06:23:02 | INFO | train_inner | epoch 002:  12264 / 13011 loss=0.148504, wps=1168.6, ups=0.61, wpb=1924.7, bsz=112, num_updates=25200, lr=2.52e-05, gnorm=31.4, clip=100, loss_scale=32, train_wall=82, gb_free=18, wall=48629
2025-11-08 06:24:42 | INFO | train_inner | epoch 002:  12314 / 13011 loss=0.156391, wps=948.4, ups=0.5, wpb=1914.2, bsz=112, num_updates=25250, lr=2.525e-05, gnorm=32.593, clip=100, loss_scale=32, train_wall=101, gb_free=18.9, wall=48730
2025-11-08 06:26:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 06:26:52 | INFO | train_inner | epoch 002:  12365 / 13011 loss=0.151343, wps=724.6, ups=0.39, wpb=1877.3, bsz=112, num_updates=25300, lr=2.53e-05, gnorm=29.775, clip=100, loss_scale=16, train_wall=129, gb_free=16.5, wall=48859
2025-11-08 06:28:14 | INFO | train_inner | epoch 002:  12415 / 13011 loss=0.154486, wps=1166.6, ups=0.61, wpb=1916.2, bsz=112, num_updates=25350, lr=2.535e-05, gnorm=32.213, clip=100, loss_scale=16, train_wall=82, gb_free=15, wall=48942
2025-11-08 06:29:50 | INFO | train_inner | epoch 002:  12465 / 13011 loss=0.157523, wps=994, ups=0.52, wpb=1900.2, bsz=112, num_updates=25400, lr=2.54e-05, gnorm=32.868, clip=100, loss_scale=16, train_wall=95, gb_free=16.8, wall=49037
2025-11-08 06:31:31 | INFO | train_inner | epoch 002:  12515 / 13011 loss=0.158135, wps=941.9, ups=0.5, wpb=1902.1, bsz=112, num_updates=25450, lr=2.545e-05, gnorm=34.299, clip=100, loss_scale=16, train_wall=101, gb_free=18.6, wall=49138
2025-11-08 06:33:13 | INFO | train_inner | epoch 002:  12565 / 13011 loss=0.159701, wps=918.3, ups=0.49, wpb=1881.1, bsz=112, num_updates=25500, lr=2.55e-05, gnorm=30.339, clip=100, loss_scale=16, train_wall=102, gb_free=18.6, wall=49241
2025-11-08 06:35:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 06:35:11 | INFO | train_inner | epoch 002:  12616 / 13011 loss=0.153204, wps=804.9, ups=0.43, wpb=1890.2, bsz=112, num_updates=25550, lr=2.555e-05, gnorm=29.836, clip=100, loss_scale=16, train_wall=117, gb_free=18, wall=49358
2025-11-08 06:37:04 | INFO | train_inner | epoch 002:  12666 / 13011 loss=0.150818, wps=866.3, ups=0.44, wpb=1959.5, bsz=112, num_updates=25600, lr=2.56e-05, gnorm=32.207, clip=100, loss_scale=16, train_wall=113, gb_free=16.6, wall=49471
2025-11-08 06:38:14 | INFO | train_inner | epoch 002:  12716 / 13011 loss=0.14845, wps=1371.8, ups=0.71, wpb=1923.3, bsz=112, num_updates=25650, lr=2.565e-05, gnorm=31.937, clip=100, loss_scale=16, train_wall=70, gb_free=19.4, wall=49541
2025-11-08 06:39:54 | INFO | train_inner | epoch 002:  12766 / 13011 loss=0.154664, wps=945.3, ups=0.5, wpb=1888.9, bsz=112, num_updates=25700, lr=2.57e-05, gnorm=35.467, clip=100, loss_scale=16, train_wall=100, gb_free=19.2, wall=49641
2025-11-08 06:41:00 | INFO | train_inner | epoch 002:  12816 / 13011 loss=0.150097, wps=1435.8, ups=0.75, wpb=1916.4, bsz=112, num_updates=25750, lr=2.575e-05, gnorm=29.1, clip=100, loss_scale=16, train_wall=67, gb_free=16.3, wall=49708
2025-11-08 06:42:44 | INFO | train_inner | epoch 002:  12866 / 13011 loss=0.141306, wps=920.8, ups=0.48, wpb=1911, bsz=112, num_updates=25800, lr=2.58e-05, gnorm=28.934, clip=100, loss_scale=32, train_wall=104, gb_free=14.3, wall=49812
2025-11-08 06:44:05 | INFO | train_inner | epoch 002:  12916 / 13011 loss=0.157965, wps=1189.6, ups=0.62, wpb=1920.3, bsz=112, num_updates=25850, lr=2.585e-05, gnorm=30.991, clip=100, loss_scale=32, train_wall=80, gb_free=18, wall=49892
2025-11-08 06:46:18 | INFO | train_inner | epoch 002:  12966 / 13011 loss=0.144177, wps=723.2, ups=0.38, wpb=1922.4, bsz=112, num_updates=25900, lr=2.59e-05, gnorm=27.355, clip=100, loss_scale=32, train_wall=133, gb_free=16.2, wall=50025
2025-11-08 06:46:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 06:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-08 07:05:30 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.138893 | wps 1303.4 | wpb 1907.1 | bsz 111.9 | num_updates 25944 | best_loss 0.138893
2025-11-08 07:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 25944 updates
2025-11-08 07:05:30 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint2.pt
2025-11-08 07:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint2.pt
2025-11-08 07:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint2.pt (epoch 2 @ 25944 updates, score 0.138893) (writing took 412.97471980600676 seconds)
2025-11-08 07:12:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2025-11-08 07:12:24 | INFO | train | epoch 002 | loss 0.216353 | wps 813.3 | ups 0.42 | wpb 1916.7 | bsz 112 | num_updates 25944 | lr 2.5944e-05 | gnorm 36.201 | clip 100 | loss_scale 16 | train_wall 28160 | gb_free 13.3 | wall 51591
2025-11-08 07:12:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 13011
2025-11-08 07:12:26 | INFO | fairseq.trainer | begin training epoch 3
2025-11-08 07:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-08 07:13:18 | INFO | train_inner | epoch 003:      6 / 13011 loss=0.154793, wps=58.8, ups=0.03, wpb=1905.4, bsz=110, num_updates=25950, lr=2.595e-05, gnorm=32.535, clip=100, loss_scale=16, train_wall=95, gb_free=16.6, wall=51645
2025-11-08 07:15:59 | INFO | train_inner | epoch 003:     56 / 13011 loss=0.150855, wps=601.1, ups=0.31, wpb=1939.6, bsz=112, num_updates=26000, lr=2.6e-05, gnorm=31.069, clip=100, loss_scale=16, train_wall=161, gb_free=18.1, wall=51807
2025-11-08 07:17:28 | INFO | train_inner | epoch 003:    106 / 13011 loss=0.142899, wps=1078, ups=0.57, wpb=1905.7, bsz=112, num_updates=26050, lr=2.605e-05, gnorm=27.668, clip=100, loss_scale=16, train_wall=88, gb_free=18.6, wall=51895
2025-11-08 07:19:35 | INFO | train_inner | epoch 003:    156 / 13011 loss=0.141562, wps=734.3, ups=0.39, wpb=1862.6, bsz=112, num_updates=26100, lr=2.61e-05, gnorm=27.879, clip=100, loss_scale=16, train_wall=127, gb_free=18.1, wall=52022
2025-11-08 07:22:05 | INFO | train_inner | epoch 003:    206 / 13011 loss=0.147461, wps=648, ups=0.33, wpb=1942, bsz=112, num_updates=26150, lr=2.615e-05, gnorm=31.258, clip=100, loss_scale=16, train_wall=150, gb_free=18.3, wall=52172
2025-11-08 07:22:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 07:23:05 | INFO | train_inner | epoch 003:    257 / 13011 loss=0.145109, wps=1559.4, ups=0.82, wpb=1901, bsz=112, num_updates=26200, lr=2.62e-05, gnorm=32.516, clip=100, loss_scale=8, train_wall=61, gb_free=12.5, wall=52233
2025-11-08 07:25:19 | INFO | train_inner | epoch 003:    307 / 13011 loss=0.142111, wps=724.8, ups=0.38, wpb=1932, bsz=112, num_updates=26250, lr=2.625e-05, gnorm=30.003, clip=100, loss_scale=8, train_wall=91, gb_free=18.2, wall=52366
2025-11-08 07:27:17 | INFO | train_inner | epoch 003:    357 / 13011 loss=0.142603, wps=805.7, ups=0.42, wpb=1903, bsz=112, num_updates=26300, lr=2.63e-05, gnorm=28.97, clip=100, loss_scale=8, train_wall=118, gb_free=18.7, wall=52484
2025-11-08 07:29:52 | INFO | train_inner | epoch 003:    407 / 13011 loss=0.147259, wps=619, ups=0.32, wpb=1923.4, bsz=112, num_updates=26350, lr=2.635e-05, gnorm=33.028, clip=100, loss_scale=8, train_wall=70, gb_free=15.6, wall=52640
2025-11-08 07:31:33 | INFO | train_inner | epoch 003:    457 / 13011 loss=0.153548, wps=961.5, ups=0.5, wpb=1934.3, bsz=112, num_updates=26400, lr=2.64e-05, gnorm=35.628, clip=100, loss_scale=8, train_wall=99, gb_free=14.1, wall=52740
2025-11-08 07:32:55 | INFO | train_inner | epoch 003:    507 / 13011 loss=0.139368, wps=1165.9, ups=0.61, wpb=1911.2, bsz=112, num_updates=26450, lr=2.645e-05, gnorm=28.246, clip=100, loss_scale=16, train_wall=82, gb_free=18.5, wall=52822
2025-11-08 07:33:55 | INFO | train_inner | epoch 003:    557 / 13011 loss=0.139424, wps=1576.9, ups=0.83, wpb=1900.5, bsz=112, num_updates=26500, lr=2.65e-05, gnorm=33.258, clip=100, loss_scale=16, train_wall=60, gb_free=15.4, wall=52882
2025-11-08 07:35:49 | INFO | train_inner | epoch 003:    607 / 13011 loss=0.148196, wps=830.2, ups=0.44, wpb=1897.8, bsz=112, num_updates=26550, lr=2.655e-05, gnorm=29.971, clip=100, loss_scale=16, train_wall=114, gb_free=16, wall=52997
2025-11-08 07:39:02 | INFO | train_inner | epoch 003:    657 / 13011 loss=0.136643, wps=486.5, ups=0.26, wpb=1879.6, bsz=112, num_updates=26600, lr=2.66e-05, gnorm=27.418, clip=100, loss_scale=16, train_wall=193, gb_free=17.8, wall=53190
2025-11-08 07:40:00 | INFO | train_inner | epoch 003:    707 / 13011 loss=0.151578, wps=1644.9, ups=0.87, wpb=1896, bsz=112, num_updates=26650, lr=2.665e-05, gnorm=31.879, clip=100, loss_scale=16, train_wall=57, gb_free=19.1, wall=53248
2025-11-08 07:43:02 | INFO | train_inner | epoch 003:    757 / 13011 loss=0.13262, wps=535.8, ups=0.28, wpb=1946.6, bsz=112, num_updates=26700, lr=2.67e-05, gnorm=28.355, clip=100, loss_scale=32, train_wall=181, gb_free=16.6, wall=53429
2025-11-08 07:44:48 | INFO | train_inner | epoch 003:    807 / 13011 loss=0.145519, wps=892.5, ups=0.47, wpb=1893, bsz=112, num_updates=26750, lr=2.675e-05, gnorm=29.771, clip=100, loss_scale=32, train_wall=106, gb_free=18.5, wall=53535
2025-11-08 07:45:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 07:47:09 | INFO | train_inner | epoch 003:    858 / 13011 loss=0.140514, wps=687.4, ups=0.35, wpb=1945.8, bsz=112, num_updates=26800, lr=2.68e-05, gnorm=32.435, clip=100, loss_scale=16, train_wall=141, gb_free=10.9, wall=53677
2025-11-08 07:49:32 | INFO | train_inner | epoch 003:    908 / 13011 loss=0.140095, wps=683.8, ups=0.35, wpb=1950.2, bsz=112, num_updates=26850, lr=2.685e-05, gnorm=27.87, clip=100, loss_scale=16, train_wall=142, gb_free=17.3, wall=53819
2025-11-08 07:51:00 | INFO | train_inner | epoch 003:    958 / 13011 loss=0.138858, wps=1061.3, ups=0.56, wpb=1879.6, bsz=112, num_updates=26900, lr=2.69e-05, gnorm=28.601, clip=100, loss_scale=16, train_wall=88, gb_free=18.2, wall=53908
2025-11-08 07:53:15 | INFO | train_inner | epoch 003:   1008 / 13011 loss=0.144558, wps=717.8, ups=0.37, wpb=1925.1, bsz=112, num_updates=26950, lr=2.695e-05, gnorm=29.792, clip=100, loss_scale=16, train_wall=134, gb_free=18.2, wall=54042
2025-11-08 07:56:16 | INFO | train_inner | epoch 003:   1058 / 13011 loss=0.140777, wps=532.1, ups=0.28, wpb=1930.3, bsz=112, num_updates=27000, lr=2.7e-05, gnorm=29.398, clip=100, loss_scale=16, train_wall=63, gb_free=18.3, wall=54223
2025-11-08 07:58:28 | INFO | train_inner | epoch 003:   1108 / 13011 loss=0.141105, wps=715.4, ups=0.38, wpb=1894.8, bsz=112, num_updates=27050, lr=2.705e-05, gnorm=29.88, clip=100, loss_scale=32, train_wall=132, gb_free=16.9, wall=54356
2025-11-08 07:59:29 | INFO | train_inner | epoch 003:   1158 / 13011 loss=0.163793, wps=1594.6, ups=0.82, wpb=1936.7, bsz=112, num_updates=27100, lr=2.71e-05, gnorm=33.745, clip=100, loss_scale=32, train_wall=61, gb_free=17.7, wall=54417
2025-11-08 08:01:57 | INFO | train_inner | epoch 003:   1208 / 13011 loss=0.144959, wps=655.5, ups=0.34, wpb=1942.1, bsz=112, num_updates=27150, lr=2.715e-05, gnorm=28.318, clip=100, loss_scale=32, train_wall=63, gb_free=18.3, wall=54565
2025-11-08 08:04:18 | INFO | train_inner | epoch 003:   1258 / 13011 loss=0.13711, wps=682.5, ups=0.36, wpb=1921.4, bsz=112, num_updates=27200, lr=2.72e-05, gnorm=28.974, clip=100, loss_scale=32, train_wall=141, gb_free=17.4, wall=54705
2025-11-08 08:06:38 | INFO | train_inner | epoch 003:   1308 / 13011 loss=0.139549, wps=680.3, ups=0.36, wpb=1900.8, bsz=112, num_updates=27250, lr=2.725e-05, gnorm=27.078, clip=100, loss_scale=32, train_wall=133, gb_free=18.7, wall=54845
2025-11-08 08:09:37 | INFO | train_inner | epoch 003:   1358 / 13011 loss=0.130487, wps=538.5, ups=0.28, wpb=1927.1, bsz=112, num_updates=27300, lr=2.73e-05, gnorm=28.864, clip=100, loss_scale=64, train_wall=160, gb_free=11.9, wall=55024
2025-11-08 08:09:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 08:10:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 08:12:49 | INFO | train_inner | epoch 003:   1410 / 13011 loss=0.141971, wps=500.9, ups=0.26, wpb=1928.4, bsz=112, num_updates=27350, lr=2.735e-05, gnorm=29.481, clip=100, loss_scale=16, train_wall=192, gb_free=18, wall=55217
2025-11-08 08:15:36 | INFO | train_inner | epoch 003:   1460 / 13011 loss=0.142211, wps=582.3, ups=0.3, wpb=1938.8, bsz=112, num_updates=27400, lr=2.74e-05, gnorm=30.077, clip=100, loss_scale=16, train_wall=161, gb_free=17.3, wall=55383
2025-11-08 08:16:34 | INFO | train_inner | epoch 003:   1510 / 13011 loss=0.14122, wps=1619.1, ups=0.85, wpb=1898.1, bsz=112, num_updates=27450, lr=2.745e-05, gnorm=29.473, clip=100, loss_scale=16, train_wall=58, gb_free=17.4, wall=55442
2025-11-08 08:19:54 | INFO | train_inner | epoch 003:   1560 / 13011 loss=0.13263, wps=483.5, ups=0.25, wpb=1930.8, bsz=112, num_updates=27500, lr=2.75e-05, gnorm=26.584, clip=100, loss_scale=16, train_wall=186, gb_free=18.9, wall=55641
2025-11-08 08:20:55 | INFO | train_inner | epoch 003:   1610 / 13011 loss=0.128005, wps=1562.5, ups=0.82, wpb=1901.5, bsz=112, num_updates=27550, lr=2.755e-05, gnorm=24.921, clip=100, loss_scale=16, train_wall=61, gb_free=17.9, wall=55702
2025-11-08 08:23:08 | INFO | train_inner | epoch 003:   1660 / 13011 loss=0.125455, wps=727, ups=0.38, wpb=1936.8, bsz=112, num_updates=27600, lr=2.76e-05, gnorm=26.704, clip=100, loss_scale=32, train_wall=133, gb_free=18.4, wall=55835
2025-11-08 08:25:40 | INFO | train_inner | epoch 003:   1710 / 13011 loss=0.127615, wps=625.9, ups=0.33, wpb=1906.3, bsz=112, num_updates=27650, lr=2.765e-05, gnorm=28.662, clip=100, loss_scale=32, train_wall=137, gb_free=17.3, wall=55988
2025-11-08 08:26:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 08:26:52 | INFO | train_inner | epoch 003:   1761 / 13011 loss=0.131512, wps=1346.8, ups=0.69, wpb=1941.6, bsz=112, num_updates=27700, lr=2.77e-05, gnorm=32.422, clip=100, loss_scale=16, train_wall=72, gb_free=17.4, wall=56060
2025-11-08 08:30:11 | INFO | train_inner | epoch 003:   1811 / 13011 loss=0.137319, wps=481.4, ups=0.25, wpb=1917, bsz=112, num_updates=27750, lr=2.775e-05, gnorm=29.376, clip=100, loss_scale=16, train_wall=124, gb_free=14.6, wall=56259
2025-11-08 08:32:08 | INFO | train_inner | epoch 003:   1861 / 13011 loss=0.135411, wps=832.1, ups=0.43, wpb=1935, bsz=112, num_updates=27800, lr=2.78e-05, gnorm=26.502, clip=100, loss_scale=16, train_wall=116, gb_free=19.6, wall=56375
2025-11-08 08:34:23 | INFO | train_inner | epoch 003:   1911 / 13011 loss=0.133247, wps=705.7, ups=0.37, wpb=1909.1, bsz=112, num_updates=27850, lr=2.785e-05, gnorm=27.797, clip=100, loss_scale=16, train_wall=135, gb_free=17.9, wall=56510
2025-11-08 08:37:08 | INFO | train_inner | epoch 003:   1961 / 13011 loss=0.131131, wps=581.7, ups=0.3, wpb=1920.4, bsz=112, num_updates=27900, lr=2.79e-05, gnorm=28.761, clip=100, loss_scale=16, train_wall=161, gb_free=18.4, wall=56675
2025-11-08 08:40:11 | INFO | train_inner | epoch 003:   2011 / 13011 loss=0.129861, wps=513.4, ups=0.27, wpb=1875.8, bsz=112, num_updates=27950, lr=2.795e-05, gnorm=28.532, clip=100, loss_scale=32, train_wall=174, gb_free=18, wall=56858
2025-11-08 08:41:10 | INFO | train_inner | epoch 003:   2061 / 13011 loss=0.13157, wps=1621.9, ups=0.85, wpb=1910.7, bsz=112, num_updates=28000, lr=2.8e-05, gnorm=27.557, clip=100, loss_scale=32, train_wall=59, gb_free=18.3, wall=56917
2025-11-08 08:43:43 | INFO | train_inner | epoch 003:   2111 / 13011 loss=0.129325, wps=635.5, ups=0.33, wpb=1944.5, bsz=112, num_updates=28050, lr=2.805e-05, gnorm=29.07, clip=100, loss_scale=32, train_wall=153, gb_free=15.5, wall=57070
2025-11-08 08:45:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 08:46:12 | INFO | train_inner | epoch 003:   2162 / 13011 loss=0.132072, wps=644, ups=0.33, wpb=1927.2, bsz=112, num_updates=28100, lr=2.81e-05, gnorm=29.619, clip=100, loss_scale=16, train_wall=149, gb_free=14.3, wall=57220
2025-11-08 08:48:25 | INFO | train_inner | epoch 003:   2212 / 13011 loss=0.129728, wps=729.7, ups=0.38, wpb=1935.8, bsz=112, num_updates=28150, lr=2.815e-05, gnorm=27.066, clip=100, loss_scale=16, train_wall=101, gb_free=18.1, wall=57352
2025-11-08 08:51:01 | INFO | train_inner | epoch 003:   2262 / 13011 loss=0.137105, wps=612.8, ups=0.32, wpb=1918.2, bsz=112, num_updates=28200, lr=2.82e-05, gnorm=30.893, clip=100, loss_scale=16, train_wall=156, gb_free=17.5, wall=57509
2025-11-08 08:53:59 | INFO | train_inner | epoch 003:   2312 / 13011 loss=0.129097, wps=535.4, ups=0.28, wpb=1900.6, bsz=112, num_updates=28250, lr=2.825e-05, gnorm=30.182, clip=100, loss_scale=16, train_wall=59, gb_free=16.4, wall=57686
2025-11-08 08:54:59 | INFO | train_inner | epoch 003:   2362 / 13011 loss=0.134138, wps=1623.9, ups=0.83, wpb=1957.6, bsz=112, num_updates=28300, lr=2.83e-05, gnorm=31.509, clip=100, loss_scale=16, train_wall=60, gb_free=19.2, wall=57747
2025-11-08 08:57:42 | INFO | train_inner | epoch 003:   2412 / 13011 loss=0.136627, wps=589.8, ups=0.31, wpb=1919.1, bsz=112, num_updates=28350, lr=2.835e-05, gnorm=29.807, clip=100, loss_scale=32, train_wall=62, gb_free=17.3, wall=57909
2025-11-08 09:00:03 | INFO | train_inner | epoch 003:   2462 / 13011 loss=0.133622, wps=665.3, ups=0.35, wpb=1883, bsz=112, num_updates=28400, lr=2.84e-05, gnorm=28.77, clip=100, loss_scale=32, train_wall=141, gb_free=13.7, wall=58051
2025-11-08 09:01:55 | INFO | train_inner | epoch 003:   2512 / 13011 loss=0.131252, wps=878, ups=0.45, wpb=1961, bsz=112, num_updates=28450, lr=2.845e-05, gnorm=28.658, clip=100, loss_scale=32, train_wall=111, gb_free=19, wall=58162
2025-11-08 09:04:12 | INFO | train_inner | epoch 003:   2562 / 13011 loss=0.128596, wps=702.3, ups=0.37, wpb=1921.8, bsz=112, num_updates=28500, lr=2.85e-05, gnorm=26.614, clip=100, loss_scale=32, train_wall=111, gb_free=17.4, wall=58299
2025-11-08 09:05:12 | INFO | train_inner | epoch 003:   2612 / 13011 loss=0.127246, wps=1597.7, ups=0.83, wpb=1921.4, bsz=112, num_updates=28550, lr=2.855e-05, gnorm=26.149, clip=100, loss_scale=32, train_wall=60, gb_free=15.6, wall=58359
2025-11-08 09:08:02 | INFO | train_inner | epoch 003:   2662 / 13011 loss=0.124567, wps=556.4, ups=0.29, wpb=1887.4, bsz=112, num_updates=28600, lr=2.86e-05, gnorm=26.432, clip=100, loss_scale=64, train_wall=61, gb_free=17.6, wall=58529
2025-11-08 09:11:02 | INFO | train_inner | epoch 003:   2712 / 13011 loss=0.126483, wps=526.6, ups=0.28, wpb=1890.2, bsz=112, num_updates=28650, lr=2.865e-05, gnorm=24.261, clip=100, loss_scale=64, train_wall=60, gb_free=14.1, wall=58710
2025-11-08 09:13:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 09:13:44 | INFO | train_inner | epoch 003:   2763 / 13011 loss=0.130445, wps=599.9, ups=0.31, wpb=1944.4, bsz=112, num_updates=28700, lr=2.87e-05, gnorm=27.855, clip=100, loss_scale=32, train_wall=162, gb_free=14.7, wall=58872
2025-11-08 09:15:58 | INFO | train_inner | epoch 003:   2813 / 13011 loss=0.123923, wps=712.2, ups=0.38, wpb=1898.7, bsz=112, num_updates=28750, lr=2.875e-05, gnorm=27.837, clip=100, loss_scale=32, train_wall=133, gb_free=15.1, wall=59005
2025-11-08 09:18:25 | INFO | train_inner | epoch 003:   2863 / 13011 loss=0.124124, wps=646.8, ups=0.34, wpb=1900.8, bsz=112, num_updates=28800, lr=2.88e-05, gnorm=24.859, clip=100, loss_scale=32, train_wall=147, gb_free=17.9, wall=59152
2025-11-08 09:21:20 | INFO | train_inner | epoch 003:   2913 / 13011 loss=0.127261, wps=540.9, ups=0.28, wpb=1897.9, bsz=112, num_updates=28850, lr=2.885e-05, gnorm=28.936, clip=100, loss_scale=32, train_wall=175, gb_free=18, wall=59327
2025-11-08 09:22:19 | INFO | train_inner | epoch 003:   2963 / 13011 loss=0.130746, wps=1646, ups=0.85, wpb=1946.8, bsz=112, num_updates=28900, lr=2.89e-05, gnorm=26.379, clip=100, loss_scale=32, train_wall=59, gb_free=16.7, wall=59387
2025-11-08 09:23:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 09:25:24 | INFO | train_inner | epoch 003:   3014 / 13011 loss=0.131497, wps=517.8, ups=0.27, wpb=1919.7, bsz=112, num_updates=28950, lr=2.895e-05, gnorm=27.925, clip=100, loss_scale=16, train_wall=167, gb_free=16.3, wall=59572
2025-11-08 09:26:31 | INFO | train_inner | epoch 003:   3064 / 13011 loss=0.129638, wps=1459.2, ups=0.76, wpb=1926.9, bsz=112, num_updates=29000, lr=2.9e-05, gnorm=29.712, clip=100, loss_scale=16, train_wall=66, gb_free=15.3, wall=59638
2025-11-08 09:28:58 | INFO | train_inner | epoch 003:   3114 / 13011 loss=0.128161, wps=639.4, ups=0.34, wpb=1878.5, bsz=112, num_updates=29050, lr=2.905e-05, gnorm=29.545, clip=100, loss_scale=16, train_wall=147, gb_free=17.9, wall=59785
2025-11-08 09:31:58 | INFO | train_inner | epoch 003:   3164 / 13011 loss=0.134581, wps=527.8, ups=0.28, wpb=1904.5, bsz=112, num_updates=29100, lr=2.91e-05, gnorm=28.191, clip=100, loss_scale=16, train_wall=180, gb_free=15.2, wall=59965
2025-11-08 09:35:01 | INFO | train_inner | epoch 003:   3214 / 13011 loss=0.132861, wps=520.6, ups=0.27, wpb=1899.3, bsz=112, num_updates=29150, lr=2.915e-05, gnorm=27.728, clip=100, loss_scale=16, train_wall=63, gb_free=17.7, wall=60148
2025-11-08 09:37:14 | INFO | train_inner | epoch 003:   3264 / 13011 loss=0.120863, wps=723.5, ups=0.38, wpb=1925.5, bsz=112, num_updates=29200, lr=2.92e-05, gnorm=25.983, clip=100, loss_scale=32, train_wall=133, gb_free=17.4, wall=60281
2025-11-08 09:38:26 | INFO | train_inner | epoch 003:   3314 / 13011 loss=0.120802, wps=1310.6, ups=0.69, wpb=1902.8, bsz=112, num_updates=29250, lr=2.925e-05, gnorm=25.033, clip=100, loss_scale=32, train_wall=72, gb_free=18.1, wall=60354
2025-11-08 09:41:18 | INFO | train_inner | epoch 003:   3364 / 13011 loss=0.123677, wps=551.2, ups=0.29, wpb=1889.3, bsz=112, num_updates=29300, lr=2.93e-05, gnorm=26.295, clip=100, loss_scale=32, train_wall=158, gb_free=12.8, wall=60525
2025-11-08 09:43:28 | INFO | train_inner | epoch 003:   3414 / 13011 loss=0.127615, wps=736.1, ups=0.39, wpb=1910.2, bsz=112, num_updates=29350, lr=2.935e-05, gnorm=27.97, clip=100, loss_scale=32, train_wall=82, gb_free=18.7, wall=60655
2025-11-08 09:44:44 | INFO | train_inner | epoch 003:   3464 / 13011 loss=0.117129, wps=1252.5, ups=0.66, wpb=1910.1, bsz=112, num_updates=29400, lr=2.94e-05, gnorm=24.33, clip=100, loss_scale=32, train_wall=76, gb_free=17.1, wall=60731
2025-11-08 09:46:54 | INFO | train_inner | epoch 003:   3514 / 13011 loss=0.123747, wps=735.5, ups=0.38, wpb=1917.3, bsz=112, num_updates=29450, lr=2.945e-05, gnorm=26.086, clip=100, loss_scale=64, train_wall=116, gb_free=15.6, wall=60862
2025-11-08 09:48:25 | INFO | train_inner | epoch 003:   3564 / 13011 loss=0.112552, wps=1049.3, ups=0.55, wpb=1903.4, bsz=112, num_updates=29500, lr=2.95e-05, gnorm=24.212, clip=100, loss_scale=64, train_wall=90, gb_free=18.3, wall=60952
2025-11-08 09:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 09:50:04 | INFO | train_inner | epoch 003:   3615 / 13011 loss=0.122271, wps=954, ups=0.5, wpb=1896.7, bsz=112, num_updates=29550, lr=2.955e-05, gnorm=25.572, clip=100, loss_scale=32, train_wall=99, gb_free=18.5, wall=61052
2025-11-08 09:51:57 | INFO | train_inner | epoch 003:   3665 / 13011 loss=0.119355, wps=830.7, ups=0.44, wpb=1873.3, bsz=112, num_updates=29600, lr=2.96e-05, gnorm=25.448, clip=100, loss_scale=32, train_wall=113, gb_free=16.5, wall=61165
2025-11-08 09:53:17 | INFO | train_inner | epoch 003:   3715 / 13011 loss=0.112644, wps=1197, ups=0.62, wpb=1922.3, bsz=112, num_updates=29650, lr=2.965e-05, gnorm=24.656, clip=100, loss_scale=32, train_wall=80, gb_free=14, wall=61245
2025-11-08 09:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 09:54:32 | INFO | train_inner | epoch 003:   3766 / 13011 loss=0.127963, wps=1283.1, ups=0.67, wpb=1923.5, bsz=112, num_updates=29700, lr=2.97e-05, gnorm=26.015, clip=100, loss_scale=16, train_wall=75, gb_free=16.8, wall=61320
2025-11-08 09:55:58 | INFO | train_inner | epoch 003:   3816 / 13011 loss=0.127877, wps=1103.7, ups=0.59, wpb=1881.9, bsz=112, num_updates=29750, lr=2.975e-05, gnorm=28.796, clip=100, loss_scale=16, train_wall=85, gb_free=17.9, wall=61405
2025-11-08 09:57:14 | INFO | train_inner | epoch 003:   3866 / 13011 loss=0.119388, wps=1266.9, ups=0.66, wpb=1923.3, bsz=112, num_updates=29800, lr=2.98e-05, gnorm=29.068, clip=100, loss_scale=16, train_wall=74, gb_free=15.5, wall=61481
2025-11-08 09:59:58 | INFO | train_inner | epoch 003:   3916 / 13011 loss=0.125754, wps=575, ups=0.3, wpb=1893.7, bsz=112, num_updates=29850, lr=2.985e-05, gnorm=28.916, clip=100, loss_scale=16, train_wall=164, gb_free=17, wall=61646
2025-11-08 10:01:53 | INFO | train_inner | epoch 003:   3966 / 13011 loss=0.117113, wps=834.3, ups=0.44, wpb=1906.9, bsz=112, num_updates=29900, lr=2.99e-05, gnorm=23.554, clip=100, loss_scale=16, train_wall=114, gb_free=17.4, wall=61760
2025-11-08 10:03:16 | INFO | train_inner | epoch 003:   4016 / 13011 loss=0.121804, wps=1128.8, ups=0.6, wpb=1877.5, bsz=112, num_updates=29950, lr=2.995e-05, gnorm=27.215, clip=100, loss_scale=32, train_wall=83, gb_free=12.4, wall=61843
2025-11-08 10:04:48 | INFO | train_inner | epoch 003:   4066 / 13011 loss=0.121913, wps=1027.1, ups=0.54, wpb=1902, bsz=112, num_updates=30000, lr=3e-05, gnorm=27.3, clip=100, loss_scale=32, train_wall=92, gb_free=18.1, wall=61936
2025-11-08 10:06:17 | INFO | train_inner | epoch 003:   4116 / 13011 loss=0.11685, wps=1097.2, ups=0.57, wpb=1936.5, bsz=112, num_updates=30050, lr=3.005e-05, gnorm=27.028, clip=100, loss_scale=32, train_wall=88, gb_free=19.5, wall=62024
2025-11-08 10:06:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 10:07:28 | INFO | train_inner | epoch 003:   4167 / 13011 loss=0.121719, wps=1360.4, ups=0.7, wpb=1953.6, bsz=112, num_updates=30100, lr=3.01e-05, gnorm=26.361, clip=100, loss_scale=16, train_wall=72, gb_free=17.4, wall=62096
2025-11-08 10:08:30 | INFO | train_inner | epoch 003:   4217 / 13011 loss=0.111563, wps=1571.3, ups=0.81, wpb=1932.4, bsz=112, num_updates=30150, lr=3.015e-05, gnorm=25.686, clip=100, loss_scale=16, train_wall=61, gb_free=18.4, wall=62157
2025-11-08 10:09:41 | INFO | train_inner | epoch 003:   4267 / 13011 loss=0.118799, wps=1334.9, ups=0.7, wpb=1905.8, bsz=112, num_updates=30200, lr=3.02e-05, gnorm=25.65, clip=100, loss_scale=16, train_wall=69, gb_free=15.9, wall=62229
2025-11-08 10:11:00 | INFO | train_inner | epoch 003:   4317 / 13011 loss=0.122064, wps=1187.5, ups=0.64, wpb=1866, bsz=112, num_updates=30250, lr=3.025e-05, gnorm=26.321, clip=100, loss_scale=16, train_wall=78, gb_free=17.1, wall=62307
2025-11-08 10:12:23 | INFO | train_inner | epoch 003:   4367 / 13011 loss=0.118129, wps=1156.5, ups=0.6, wpb=1913.6, bsz=112, num_updates=30300, lr=3.03e-05, gnorm=23.824, clip=100, loss_scale=16, train_wall=77, gb_free=19.2, wall=62390
2025-11-08 10:13:55 | INFO | train_inner | epoch 003:   4417 / 13011 loss=0.116815, wps=1049.5, ups=0.54, wpb=1942.7, bsz=112, num_updates=30350, lr=3.035e-05, gnorm=24.79, clip=100, loss_scale=32, train_wall=86, gb_free=18.7, wall=62483
2025-11-08 10:15:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 10:15:17 | INFO | train_inner | epoch 003:   4468 / 13011 loss=0.121165, wps=1174.1, ups=0.61, wpb=1916.5, bsz=112, num_updates=30400, lr=3.04e-05, gnorm=26.873, clip=100, loss_scale=16, train_wall=81, gb_free=18.7, wall=62564
2025-11-08 10:17:24 | INFO | train_inner | epoch 003:   4518 / 13011 loss=0.11547, wps=758.2, ups=0.39, wpb=1922.6, bsz=112, num_updates=30450, lr=3.045e-05, gnorm=25.153, clip=100, loss_scale=16, train_wall=127, gb_free=16.9, wall=62691
2025-11-08 10:18:49 | INFO | train_inner | epoch 003:   4568 / 13011 loss=0.117254, wps=1127.6, ups=0.58, wpb=1931.4, bsz=112, num_updates=30500, lr=3.05e-05, gnorm=26.034, clip=100, loss_scale=16, train_wall=85, gb_free=17.5, wall=62777
2025-11-08 10:20:37 | INFO | train_inner | epoch 003:   4618 / 13011 loss=0.115526, wps=888.4, ups=0.46, wpb=1921.8, bsz=112, num_updates=30550, lr=3.055e-05, gnorm=24.188, clip=100, loss_scale=16, train_wall=108, gb_free=19.1, wall=62885
2025-11-08 10:22:12 | INFO | train_inner | epoch 003:   4668 / 13011 loss=0.108464, wps=1016.3, ups=0.53, wpb=1927.8, bsz=112, num_updates=30600, lr=3.06e-05, gnorm=23.725, clip=100, loss_scale=16, train_wall=95, gb_free=18.1, wall=62980
2025-11-08 10:23:57 | INFO | train_inner | epoch 003:   4718 / 13011 loss=0.123234, wps=889.9, ups=0.48, wpb=1867.5, bsz=112, num_updates=30650, lr=3.065e-05, gnorm=25.105, clip=100, loss_scale=16, train_wall=105, gb_free=18.2, wall=63085
2025-11-08 10:25:11 | INFO | train_inner | epoch 003:   4768 / 13011 loss=0.111003, wps=1335.7, ups=0.68, wpb=1963.3, bsz=112, num_updates=30700, lr=3.07e-05, gnorm=25.59, clip=100, loss_scale=32, train_wall=73, gb_free=18, wall=63158
2025-11-08 10:26:27 | INFO | train_inner | epoch 003:   4818 / 13011 loss=0.122036, wps=1241.8, ups=0.65, wpb=1905.2, bsz=112, num_updates=30750, lr=3.075e-05, gnorm=27.004, clip=100, loss_scale=32, train_wall=77, gb_free=15.8, wall=63235
2025-11-08 10:28:26 | INFO | train_inner | epoch 003:   4868 / 13011 loss=0.108904, wps=814.1, ups=0.42, wpb=1924.9, bsz=112, num_updates=30800, lr=3.08e-05, gnorm=24.623, clip=100, loss_scale=32, train_wall=118, gb_free=18.3, wall=63353
2025-11-08 10:29:59 | INFO | train_inner | epoch 003:   4918 / 13011 loss=0.112078, wps=1031.6, ups=0.54, wpb=1926.3, bsz=112, num_updates=30850, lr=3.085e-05, gnorm=22.822, clip=100, loss_scale=32, train_wall=93, gb_free=15.5, wall=63446
2025-11-08 10:31:21 | INFO | train_inner | epoch 003:   4968 / 13011 loss=0.117453, wps=1184, ups=0.61, wpb=1931.4, bsz=112, num_updates=30900, lr=3.09e-05, gnorm=24.369, clip=100, loss_scale=32, train_wall=73, gb_free=18.9, wall=63528
2025-11-08 10:32:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 10:32:30 | INFO | train_inner | epoch 003:   5019 / 13011 loss=0.105544, wps=1392.1, ups=0.72, wpb=1931.9, bsz=112, num_updates=30950, lr=3.095e-05, gnorm=23.975, clip=100, loss_scale=32, train_wall=69, gb_free=18.6, wall=63597
2025-11-08 10:33:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 10:34:04 | INFO | train_inner | epoch 003:   5070 / 13011 loss=0.120491, wps=1008, ups=0.53, wpb=1898.3, bsz=112, num_updates=31000, lr=3.1e-05, gnorm=24.112, clip=100, loss_scale=16, train_wall=92, gb_free=13.1, wall=63691
2025-11-08 10:35:05 | INFO | train_inner | epoch 003:   5120 / 13011 loss=0.111834, wps=1560.1, ups=0.82, wpb=1913.4, bsz=112, num_updates=31050, lr=3.105e-05, gnorm=24.754, clip=100, loss_scale=16, train_wall=61, gb_free=8.6, wall=63753
2025-11-08 10:35:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 10:36:45 | INFO | train_inner | epoch 003:   5171 / 13011 loss=0.115673, wps=979.7, ups=0.5, wpb=1948.9, bsz=112, num_updates=31100, lr=3.11e-05, gnorm=25.585, clip=100, loss_scale=8, train_wall=93, gb_free=19.1, wall=63852
2025-11-08 10:38:05 | INFO | train_inner | epoch 003:   5221 / 13011 loss=0.116898, wps=1231, ups=0.63, wpb=1966.2, bsz=112, num_updates=31150, lr=3.115e-05, gnorm=23.643, clip=100, loss_scale=8, train_wall=71, gb_free=15.5, wall=63932
2025-11-08 10:39:54 | INFO | train_inner | epoch 003:   5271 / 13011 loss=0.126616, wps=874.4, ups=0.46, wpb=1909.2, bsz=112, num_updates=31200, lr=3.12e-05, gnorm=25.404, clip=100, loss_scale=8, train_wall=109, gb_free=15.6, wall=64041
2025-11-08 10:41:22 | INFO | train_inner | epoch 003:   5321 / 13011 loss=0.122067, wps=1072.1, ups=0.57, wpb=1880.3, bsz=112, num_updates=31250, lr=3.125e-05, gnorm=26.367, clip=100, loss_scale=8, train_wall=79, gb_free=16.9, wall=64129
2025-11-08 10:43:10 | INFO | train_inner | epoch 003:   5371 / 13011 loss=0.117602, wps=908.5, ups=0.46, wpb=1960.7, bsz=112, num_updates=31300, lr=3.13e-05, gnorm=34.083, clip=100, loss_scale=8, train_wall=108, gb_free=17.4, wall=64237
2025-11-08 10:44:23 | INFO | train_inner | epoch 003:   5421 / 13011 loss=0.123968, wps=1322.2, ups=0.68, wpb=1946.7, bsz=112, num_updates=31350, lr=3.135e-05, gnorm=28.854, clip=100, loss_scale=16, train_wall=72, gb_free=14.3, wall=64311
2025-11-08 10:45:55 | INFO | train_inner | epoch 003:   5471 / 13011 loss=0.114107, wps=1027.2, ups=0.55, wpb=1878.8, bsz=112, num_updates=31400, lr=3.14e-05, gnorm=24.325, clip=100, loss_scale=16, train_wall=91, gb_free=18.4, wall=64402
2025-11-08 10:47:33 | INFO | train_inner | epoch 003:   5521 / 13011 loss=0.116259, wps=979.3, ups=0.51, wpb=1919.7, bsz=112, num_updates=31450, lr=3.145e-05, gnorm=24.14, clip=100, loss_scale=16, train_wall=98, gb_free=16, wall=64500
2025-11-08 10:48:50 | INFO | train_inner | epoch 003:   5571 / 13011 loss=0.114328, wps=1260.6, ups=0.65, wpb=1939.1, bsz=112, num_updates=31500, lr=3.15e-05, gnorm=24.227, clip=100, loss_scale=16, train_wall=66, gb_free=14.7, wall=64577
2025-11-08 10:50:09 | INFO | train_inner | epoch 003:   5621 / 13011 loss=0.113456, wps=1213.9, ups=0.63, wpb=1929.9, bsz=112, num_updates=31550, lr=3.155e-05, gnorm=25.147, clip=100, loss_scale=16, train_wall=79, gb_free=15.5, wall=64656
2025-11-08 10:51:58 | INFO | train_inner | epoch 003:   5671 / 13011 loss=0.111432, wps=886.5, ups=0.46, wpb=1923.5, bsz=112, num_updates=31600, lr=3.16e-05, gnorm=23.368, clip=100, loss_scale=32, train_wall=108, gb_free=17.7, wall=64765
2025-11-08 10:53:15 | INFO | train_inner | epoch 003:   5721 / 13011 loss=0.11922, wps=1217, ups=0.65, wpb=1880.7, bsz=112, num_updates=31650, lr=3.165e-05, gnorm=27.488, clip=100, loss_scale=32, train_wall=77, gb_free=19, wall=64842
2025-11-08 10:55:00 | INFO | train_inner | epoch 003:   5771 / 13011 loss=0.123351, wps=916.4, ups=0.48, wpb=1925.2, bsz=112, num_updates=31700, lr=3.17e-05, gnorm=24.328, clip=100, loss_scale=32, train_wall=105, gb_free=18.3, wall=64947
2025-11-08 10:56:28 | INFO | train_inner | epoch 003:   5821 / 13011 loss=0.119574, wps=1102, ups=0.57, wpb=1932.2, bsz=112, num_updates=31750, lr=3.175e-05, gnorm=24.4, clip=100, loss_scale=32, train_wall=87, gb_free=16, wall=65035
2025-11-08 10:58:12 | INFO | train_inner | epoch 003:   5871 / 13011 loss=0.114048, wps=914.5, ups=0.48, wpb=1905.7, bsz=112, num_updates=31800, lr=3.18e-05, gnorm=24.811, clip=100, loss_scale=32, train_wall=104, gb_free=18.3, wall=65139
2025-11-08 10:59:48 | INFO | train_inner | epoch 003:   5921 / 13011 loss=0.121999, wps=1009.2, ups=0.52, wpb=1944.4, bsz=112, num_updates=31850, lr=3.185e-05, gnorm=23.915, clip=100, loss_scale=64, train_wall=96, gb_free=18.4, wall=65235
2025-11-08 11:00:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 11:00:58 | INFO | train_inner | epoch 003:   5972 / 13011 loss=0.1183, wps=1381.8, ups=0.72, wpb=1926.7, bsz=112, num_updates=31900, lr=3.19e-05, gnorm=25.474, clip=100, loss_scale=32, train_wall=69, gb_free=17.5, wall=65305
2025-11-08 11:02:38 | INFO | train_inner | epoch 003:   6022 / 13011 loss=0.102605, wps=948.6, ups=0.5, wpb=1909.9, bsz=112, num_updates=31950, lr=3.195e-05, gnorm=22.552, clip=100, loss_scale=32, train_wall=100, gb_free=15.2, wall=65406
2025-11-08 11:03:39 | INFO | train_inner | epoch 003:   6072 / 13011 loss=0.118431, wps=1587.1, ups=0.82, wpb=1933.3, bsz=112, num_updates=32000, lr=3.2e-05, gnorm=25.169, clip=100, loss_scale=32, train_wall=61, gb_free=15.3, wall=65467
2025-11-08 11:05:18 | INFO | train_inner | epoch 003:   6122 / 13011 loss=0.111796, wps=954, ups=0.51, wpb=1882.4, bsz=112, num_updates=32050, lr=3.205e-05, gnorm=25.075, clip=100, loss_scale=32, train_wall=98, gb_free=19.4, wall=65565
2025-11-08 11:06:45 | INFO | train_inner | epoch 003:   6172 / 13011 loss=0.112496, wps=1100.6, ups=0.58, wpb=1908.7, bsz=112, num_updates=32100, lr=3.21e-05, gnorm=23.077, clip=100, loss_scale=32, train_wall=84, gb_free=15.2, wall=65652
2025-11-08 11:08:17 | INFO | train_inner | epoch 003:   6222 / 13011 loss=0.109006, wps=1046.2, ups=0.54, wpb=1928.4, bsz=112, num_updates=32150, lr=3.215e-05, gnorm=24.407, clip=100, loss_scale=64, train_wall=65, gb_free=16.6, wall=65744
2025-11-08 11:09:51 | INFO | train_inner | epoch 003:   6272 / 13011 loss=0.099603, wps=1029.5, ups=0.53, wpb=1928.9, bsz=112, num_updates=32200, lr=3.22e-05, gnorm=20.11, clip=100, loss_scale=64, train_wall=86, gb_free=16.9, wall=65838
2025-11-08 11:11:35 | INFO | train_inner | epoch 003:   6322 / 13011 loss=0.110883, wps=912.2, ups=0.48, wpb=1906.8, bsz=112, num_updates=32250, lr=3.225e-05, gnorm=23.492, clip=100, loss_scale=64, train_wall=104, gb_free=16.8, wall=65943
2025-11-08 11:12:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 11:12:57 | INFO | train_inner | epoch 003:   6373 / 13011 loss=0.113027, wps=1172.6, ups=0.61, wpb=1909.9, bsz=112, num_updates=32300, lr=3.23e-05, gnorm=23.582, clip=100, loss_scale=32, train_wall=81, gb_free=16.8, wall=66024
2025-11-08 11:14:34 | INFO | train_inner | epoch 003:   6423 / 13011 loss=0.104026, wps=957.7, ups=0.51, wpb=1871.6, bsz=112, num_updates=32350, lr=3.235e-05, gnorm=23.332, clip=100, loss_scale=32, train_wall=98, gb_free=16.7, wall=66122
2025-11-08 11:16:08 | INFO | train_inner | epoch 003:   6473 / 13011 loss=0.106269, wps=1030.7, ups=0.53, wpb=1929, bsz=112, num_updates=32400, lr=3.24e-05, gnorm=23.658, clip=100, loss_scale=32, train_wall=93, gb_free=18.4, wall=66215
2025-11-08 11:16:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 11:17:49 | INFO | train_inner | epoch 003:   6524 / 13011 loss=0.106449, wps=967.4, ups=0.5, wpb=1949.5, bsz=112, num_updates=32450, lr=3.245e-05, gnorm=23.011, clip=100, loss_scale=16, train_wall=101, gb_free=17.6, wall=66316
2025-11-08 11:19:01 | INFO | train_inner | epoch 003:   6574 / 13011 loss=0.098413, wps=1314.2, ups=0.69, wpb=1903.2, bsz=112, num_updates=32500, lr=3.25e-05, gnorm=21.96, clip=100, loss_scale=16, train_wall=59, gb_free=18.2, wall=66388
2025-11-08 11:20:44 | INFO | train_inner | epoch 003:   6624 / 13011 loss=0.104494, wps=932.1, ups=0.48, wpb=1927.5, bsz=112, num_updates=32550, lr=3.255e-05, gnorm=22.321, clip=100, loss_scale=16, train_wall=93, gb_free=17.5, wall=66492
2025-11-08 11:22:02 | INFO | train_inner | epoch 003:   6674 / 13011 loss=0.104265, wps=1203.2, ups=0.64, wpb=1874.4, bsz=112, num_updates=32600, lr=3.26e-05, gnorm=20.667, clip=100, loss_scale=16, train_wall=78, gb_free=17.1, wall=66570
2025-11-08 11:23:30 | INFO | train_inner | epoch 003:   6724 / 13011 loss=0.117259, wps=1094.2, ups=0.57, wpb=1909, bsz=112, num_updates=32650, lr=3.265e-05, gnorm=26.561, clip=100, loss_scale=16, train_wall=87, gb_free=19.1, wall=66657
2025-11-08 11:24:59 | INFO | train_inner | epoch 003:   6774 / 13011 loss=0.114943, wps=1073.1, ups=0.56, wpb=1930.2, bsz=112, num_updates=32700, lr=3.27e-05, gnorm=25.732, clip=100, loss_scale=32, train_wall=76, gb_free=15.3, wall=66747
2025-11-08 11:26:21 | INFO | train_inner | epoch 003:   6824 / 13011 loss=0.111656, wps=1205.1, ups=0.62, wpb=1956.2, bsz=112, num_updates=32750, lr=3.275e-05, gnorm=27.974, clip=100, loss_scale=32, train_wall=81, gb_free=12.1, wall=66828
2025-11-08 11:27:48 | INFO | train_inner | epoch 003:   6874 / 13011 loss=0.110029, wps=1097.4, ups=0.57, wpb=1914.1, bsz=112, num_updates=32800, lr=3.28e-05, gnorm=26.308, clip=100, loss_scale=32, train_wall=87, gb_free=17.5, wall=66915
2025-11-08 11:29:18 | INFO | train_inner | epoch 003:   6924 / 13011 loss=0.111727, wps=1066.4, ups=0.56, wpb=1912, bsz=112, num_updates=32850, lr=3.285e-05, gnorm=25.177, clip=100, loss_scale=32, train_wall=89, gb_free=16, wall=67005
2025-11-08 11:30:55 | INFO | train_inner | epoch 003:   6974 / 13011 loss=0.109203, wps=987.5, ups=0.52, wpb=1916.6, bsz=112, num_updates=32900, lr=3.29e-05, gnorm=23.875, clip=100, loss_scale=32, train_wall=97, gb_free=14.8, wall=67102
2025-11-08 11:32:22 | INFO | train_inner | epoch 003:   7024 / 13011 loss=0.108225, wps=1116.1, ups=0.57, wpb=1942.7, bsz=112, num_updates=32950, lr=3.295e-05, gnorm=22.06, clip=100, loss_scale=64, train_wall=87, gb_free=18.6, wall=67189
2025-11-08 11:34:05 | INFO | train_inner | epoch 003:   7074 / 13011 loss=0.101784, wps=928.3, ups=0.48, wpb=1919.4, bsz=112, num_updates=33000, lr=3.3e-05, gnorm=21.65, clip=100, loss_scale=64, train_wall=103, gb_free=15.5, wall=67292
2025-11-08 11:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 11:35:36 | INFO | train_inner | epoch 003:   7125 / 13011 loss=0.111536, wps=1022.1, ups=0.55, wpb=1859.9, bsz=112, num_updates=33050, lr=3.305e-05, gnorm=22.804, clip=100, loss_scale=32, train_wall=91, gb_free=19, wall=67383
2025-11-08 11:35:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 11:37:26 | INFO | train_inner | epoch 003:   7176 / 13011 loss=0.099435, wps=887.8, ups=0.45, wpb=1959.5, bsz=112, num_updates=33100, lr=3.31e-05, gnorm=21.075, clip=100, loss_scale=16, train_wall=110, gb_free=17.3, wall=67494
2025-11-08 11:38:49 | INFO | train_inner | epoch 003:   7226 / 13011 loss=0.105913, wps=1152.2, ups=0.61, wpb=1897, bsz=112, num_updates=33150, lr=3.315e-05, gnorm=23.83, clip=100, loss_scale=16, train_wall=82, gb_free=17.9, wall=67576
2025-11-08 11:40:15 | INFO | train_inner | epoch 003:   7276 / 13011 loss=0.099765, wps=1110.7, ups=0.58, wpb=1917.1, bsz=112, num_updates=33200, lr=3.32e-05, gnorm=23.653, clip=100, loss_scale=16, train_wall=86, gb_free=12.5, wall=67662
2025-11-08 11:41:54 | INFO | train_inner | epoch 003:   7326 / 13011 loss=0.10095, wps=949.5, ups=0.5, wpb=1890.3, bsz=112, num_updates=33250, lr=3.325e-05, gnorm=24.11, clip=100, loss_scale=16, train_wall=99, gb_free=13.2, wall=67762
2025-11-08 11:43:01 | INFO | train_inner | epoch 003:   7376 / 13011 loss=0.104013, wps=1415.4, ups=0.75, wpb=1888.7, bsz=112, num_updates=33300, lr=3.33e-05, gnorm=24.218, clip=100, loss_scale=16, train_wall=66, gb_free=15.4, wall=67829
2025-11-08 11:44:50 | INFO | train_inner | epoch 003:   7426 / 13011 loss=0.104037, wps=892.1, ups=0.46, wpb=1943.6, bsz=112, num_updates=33350, lr=3.335e-05, gnorm=23.622, clip=100, loss_scale=32, train_wall=109, gb_free=17.3, wall=67938
2025-11-08 11:45:59 | INFO | train_inner | epoch 003:   7476 / 13011 loss=0.108331, wps=1382, ups=0.72, wpb=1913.6, bsz=112, num_updates=33400, lr=3.34e-05, gnorm=22.574, clip=100, loss_scale=32, train_wall=69, gb_free=17.8, wall=68007
2025-11-08 11:47:24 | INFO | train_inner | epoch 003:   7526 / 13011 loss=0.106027, wps=1111.5, ups=0.59, wpb=1871.2, bsz=112, num_updates=33450, lr=3.345e-05, gnorm=21.899, clip=100, loss_scale=32, train_wall=83, gb_free=16.6, wall=68091
2025-11-08 11:48:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 11:49:21 | INFO | train_inner | epoch 003:   7577 / 13011 loss=0.101613, wps=822.7, ups=0.42, wpb=1936.7, bsz=112, num_updates=33500, lr=3.35e-05, gnorm=21.19, clip=100, loss_scale=16, train_wall=118, gb_free=11.8, wall=68209
2025-11-08 11:50:34 | INFO | train_inner | epoch 003:   7627 / 13011 loss=0.11021, wps=1352.2, ups=0.69, wpb=1956.5, bsz=112, num_updates=33550, lr=3.355e-05, gnorm=23.407, clip=100, loss_scale=16, train_wall=72, gb_free=15.9, wall=68281
2025-11-08 11:52:01 | INFO | train_inner | epoch 003:   7677 / 13011 loss=0.103855, wps=1107.9, ups=0.57, wpb=1928.4, bsz=112, num_updates=33600, lr=3.36e-05, gnorm=23.201, clip=100, loss_scale=16, train_wall=87, gb_free=16.5, wall=68368
2025-11-08 11:53:24 | INFO | train_inner | epoch 003:   7727 / 13011 loss=0.100977, wps=1172.6, ups=0.6, wpb=1949.3, bsz=112, num_updates=33650, lr=3.365e-05, gnorm=20.324, clip=100, loss_scale=16, train_wall=83, gb_free=11.4, wall=68451
2025-11-08 11:54:47 | INFO | train_inner | epoch 003:   7777 / 13011 loss=0.105434, wps=1147.6, ups=0.6, wpb=1909.7, bsz=112, num_updates=33700, lr=3.37e-05, gnorm=21.424, clip=100, loss_scale=16, train_wall=83, gb_free=17.5, wall=68534
2025-11-08 11:56:30 | INFO | train_inner | epoch 003:   7827 / 13011 loss=0.10644, wps=1024.1, ups=0.54, wpb=1913.9, bsz=112, num_updates=33750, lr=3.375e-05, gnorm=21.364, clip=100, loss_scale=32, train_wall=93, gb_free=15.9, wall=68628
2025-11-08 11:58:06 | INFO | train_inner | epoch 003:   7877 / 13011 loss=0.096124, wps=996.5, ups=0.52, wpb=1905.2, bsz=112, num_updates=33800, lr=3.38e-05, gnorm=21.391, clip=100, loss_scale=32, train_wall=95, gb_free=14.8, wall=68733
2025-11-08 11:59:28 | INFO | train_inner | epoch 003:   7927 / 13011 loss=0.110729, wps=1148.8, ups=0.61, wpb=1882.6, bsz=112, num_updates=33850, lr=3.385e-05, gnorm=23.675, clip=100, loss_scale=32, train_wall=82, gb_free=18.3, wall=68815
2025-11-08 12:01:15 | INFO | train_inner | epoch 003:   7977 / 13011 loss=0.108505, wps=878.2, ups=0.47, wpb=1874.9, bsz=112, num_updates=33900, lr=3.39e-05, gnorm=21.361, clip=100, loss_scale=32, train_wall=107, gb_free=18.9, wall=68922
2025-11-08 12:01:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 12:02:38 | INFO | train_inner | epoch 003:   8028 / 13011 loss=0.10477, wps=1147.7, ups=0.6, wpb=1903.8, bsz=112, num_updates=33950, lr=3.395e-05, gnorm=22.2, clip=100, loss_scale=16, train_wall=83, gb_free=18.4, wall=69005
2025-11-08 12:04:01 | INFO | train_inner | epoch 003:   8078 / 13011 loss=0.100096, wps=1176, ups=0.6, wpb=1952.9, bsz=112, num_updates=34000, lr=3.4e-05, gnorm=20.432, clip=100, loss_scale=16, train_wall=83, gb_free=17.6, wall=69088
2025-11-08 12:05:47 | INFO | train_inner | epoch 003:   8128 / 13011 loss=0.097725, wps=915.8, ups=0.47, wpb=1946.1, bsz=112, num_updates=34050, lr=3.405e-05, gnorm=20.689, clip=100, loss_scale=16, train_wall=106, gb_free=14.4, wall=69194
2025-11-08 12:07:01 | INFO | train_inner | epoch 003:   8178 / 13011 loss=0.104996, wps=1298.8, ups=0.68, wpb=1920.5, bsz=112, num_updates=34100, lr=3.41e-05, gnorm=19.883, clip=100, loss_scale=16, train_wall=74, gb_free=17.6, wall=69268
2025-11-08 12:08:28 | INFO | train_inner | epoch 003:   8228 / 13011 loss=0.107365, wps=1084.8, ups=0.58, wpb=1885.1, bsz=112, num_updates=34150, lr=3.415e-05, gnorm=24.891, clip=100, loss_scale=16, train_wall=87, gb_free=18.1, wall=69355
2025-11-08 12:09:59 | INFO | train_inner | epoch 003:   8278 / 13011 loss=0.103543, wps=1069, ups=0.55, wpb=1942.3, bsz=112, num_updates=34200, lr=3.42e-05, gnorm=19.375, clip=100, loss_scale=32, train_wall=91, gb_free=18.3, wall=69446
2025-11-08 12:11:03 | INFO | train_inner | epoch 003:   8328 / 13011 loss=0.096246, wps=1503.2, ups=0.78, wpb=1936.3, bsz=112, num_updates=34250, lr=3.425e-05, gnorm=20.783, clip=100, loss_scale=32, train_wall=63, gb_free=18.4, wall=69510
2025-11-08 12:12:28 | INFO | train_inner | epoch 003:   8378 / 13011 loss=0.107122, wps=1107, ups=0.59, wpb=1882, bsz=112, num_updates=34300, lr=3.43e-05, gnorm=20.038, clip=100, loss_scale=32, train_wall=85, gb_free=16, wall=69595
2025-11-08 12:12:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 12:13:57 | INFO | train_inner | epoch 003:   8429 / 13011 loss=0.099723, wps=1098.9, ups=0.56, wpb=1947.6, bsz=112, num_updates=34350, lr=3.435e-05, gnorm=22.027, clip=100, loss_scale=16, train_wall=88, gb_free=15.9, wall=69684
2025-11-08 12:15:17 | INFO | train_inner | epoch 003:   8479 / 13011 loss=0.093882, wps=1203.7, ups=0.62, wpb=1942.9, bsz=112, num_updates=34400, lr=3.44e-05, gnorm=20.399, clip=100, loss_scale=16, train_wall=80, gb_free=18.3, wall=69765
2025-11-08 12:16:38 | INFO | train_inner | epoch 003:   8529 / 13011 loss=0.097833, wps=1178.1, ups=0.62, wpb=1894.9, bsz=112, num_updates=34450, lr=3.445e-05, gnorm=21.516, clip=100, loss_scale=16, train_wall=80, gb_free=17.4, wall=69845
2025-11-08 12:18:15 | INFO | train_inner | epoch 003:   8579 / 13011 loss=0.111617, wps=978, ups=0.52, wpb=1896.9, bsz=112, num_updates=34500, lr=3.45e-05, gnorm=24.662, clip=100, loss_scale=16, train_wall=97, gb_free=15.9, wall=69942
2025-11-08 12:19:42 | INFO | train_inner | epoch 003:   8629 / 13011 loss=0.100694, wps=1099.7, ups=0.57, wpb=1914, bsz=112, num_updates=34550, lr=3.455e-05, gnorm=28.581, clip=100, loss_scale=16, train_wall=87, gb_free=18.4, wall=70029
2025-11-08 12:21:35 | INFO | train_inner | epoch 003:   8679 / 13011 loss=0.099442, wps=845.8, ups=0.44, wpb=1910.9, bsz=112, num_updates=34600, lr=3.46e-05, gnorm=19.586, clip=100, loss_scale=32, train_wall=113, gb_free=18.7, wall=70142
2025-11-08 12:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 12:23:38 | INFO | train_inner | epoch 003:   8730 / 13011 loss=0.105183, wps=763.1, ups=0.41, wpb=1883.4, bsz=112, num_updates=34650, lr=3.465e-05, gnorm=24.28, clip=100, loss_scale=16, train_wall=123, gb_free=16.6, wall=70266
2025-11-08 12:25:02 | INFO | train_inner | epoch 003:   8780 / 13011 loss=0.102979, wps=1144.2, ups=0.59, wpb=1924.9, bsz=112, num_updates=34700, lr=3.47e-05, gnorm=21.563, clip=100, loss_scale=16, train_wall=84, gb_free=17.6, wall=70350
2025-11-08 12:26:47 | INFO | train_inner | epoch 003:   8830 / 13011 loss=0.098983, wps=914.1, ups=0.48, wpb=1909.9, bsz=112, num_updates=34750, lr=3.475e-05, gnorm=24.342, clip=100, loss_scale=16, train_wall=104, gb_free=18.3, wall=70454
2025-11-08 12:27:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 12:27:54 | INFO | train_inner | epoch 003:   8881 / 13011 loss=0.096787, wps=1385.7, ups=0.74, wpb=1860.8, bsz=112, num_updates=34800, lr=3.48e-05, gnorm=23, clip=100, loss_scale=8, train_wall=67, gb_free=15.3, wall=70521
2025-11-08 12:29:18 | INFO | train_inner | epoch 003:   8931 / 13011 loss=0.095542, wps=1125.1, ups=0.59, wpb=1896.5, bsz=112, num_updates=34850, lr=3.485e-05, gnorm=20.985, clip=100, loss_scale=8, train_wall=84, gb_free=18.8, wall=70606
2025-11-08 12:31:00 | INFO | train_inner | epoch 003:   8981 / 13011 loss=0.111929, wps=950.4, ups=0.49, wpb=1930.3, bsz=112, num_updates=34900, lr=3.49e-05, gnorm=25.825, clip=100, loss_scale=8, train_wall=101, gb_free=17.5, wall=70707
2025-11-08 12:32:02 | INFO | train_inner | epoch 003:   9031 / 13011 loss=0.095741, wps=1543.7, ups=0.8, wpb=1920.2, bsz=112, num_updates=34950, lr=3.495e-05, gnorm=20.747, clip=100, loss_scale=8, train_wall=62, gb_free=12.8, wall=70769
2025-11-08 12:33:29 | INFO | train_inner | epoch 003:   9081 / 13011 loss=0.108025, wps=1101.5, ups=0.58, wpb=1906, bsz=112, num_updates=35000, lr=3.5e-05, gnorm=23.396, clip=100, loss_scale=8, train_wall=86, gb_free=15.1, wall=70856
2025-11-08 12:35:02 | INFO | train_inner | epoch 003:   9131 / 13011 loss=0.10729, wps=1007.6, ups=0.53, wpb=1887.3, bsz=112, num_updates=35050, lr=3.505e-05, gnorm=22.512, clip=100, loss_scale=16, train_wall=93, gb_free=17.8, wall=70950
2025-11-08 12:36:38 | INFO | train_inner | epoch 003:   9181 / 13011 loss=0.108025, wps=991.9, ups=0.52, wpb=1903.3, bsz=112, num_updates=35100, lr=3.51e-05, gnorm=27.86, clip=100, loss_scale=16, train_wall=96, gb_free=14.5, wall=71046
2025-11-08 12:37:57 | INFO | train_inner | epoch 003:   9231 / 13011 loss=0.101228, wps=1216.5, ups=0.64, wpb=1913.3, bsz=112, num_updates=35150, lr=3.515e-05, gnorm=22.586, clip=100, loss_scale=16, train_wall=78, gb_free=17.9, wall=71124
2025-11-08 12:39:15 | INFO | train_inner | epoch 003:   9281 / 13011 loss=0.097451, wps=1242.4, ups=0.64, wpb=1933, bsz=112, num_updates=35200, lr=3.52e-05, gnorm=20.069, clip=100, loss_scale=16, train_wall=77, gb_free=10.1, wall=71202
2025-11-08 12:40:50 | INFO | train_inner | epoch 003:   9331 / 13011 loss=0.097751, wps=1004.2, ups=0.52, wpb=1917.5, bsz=112, num_updates=35250, lr=3.525e-05, gnorm=21.671, clip=100, loss_scale=16, train_wall=94, gb_free=18, wall=71297
2025-11-08 12:42:38 | INFO | train_inner | epoch 003:   9381 / 13011 loss=0.094837, wps=898.6, ups=0.46, wpb=1939.4, bsz=112, num_updates=35300, lr=3.53e-05, gnorm=26.222, clip=100, loss_scale=32, train_wall=99, gb_free=16.8, wall=71405
2025-11-08 12:43:58 | INFO | train_inner | epoch 003:   9431 / 13011 loss=0.102661, wps=1169.5, ups=0.62, wpb=1876, bsz=112, num_updates=35350, lr=3.535e-05, gnorm=20.25, clip=100, loss_scale=32, train_wall=80, gb_free=18.3, wall=71486
2025-11-08 12:45:26 | INFO | train_inner | epoch 003:   9481 / 13011 loss=0.095018, wps=1112.5, ups=0.57, wpb=1956.2, bsz=111.9, num_updates=35400, lr=3.54e-05, gnorm=18.845, clip=100, loss_scale=32, train_wall=88, gb_free=18.7, wall=71574
2025-11-08 12:47:08 | INFO | train_inner | epoch 003:   9531 / 13011 loss=0.093389, wps=934.9, ups=0.49, wpb=1896.4, bsz=112, num_updates=35450, lr=3.545e-05, gnorm=21.941, clip=100, loss_scale=32, train_wall=101, gb_free=15.3, wall=71675
2025-11-08 12:48:27 | INFO | train_inner | epoch 003:   9581 / 13011 loss=0.097026, wps=1224.5, ups=0.63, wpb=1940.1, bsz=112, num_updates=35500, lr=3.55e-05, gnorm=23.081, clip=100, loss_scale=32, train_wall=79, gb_free=17.2, wall=71754
2025-11-08 12:49:54 | INFO | train_inner | epoch 003:   9631 / 13011 loss=0.099825, wps=1088.2, ups=0.57, wpb=1898.6, bsz=112, num_updates=35550, lr=3.555e-05, gnorm=22.275, clip=100, loss_scale=32, train_wall=87, gb_free=18.7, wall=71841
2025-11-08 12:51:25 | INFO | train_inner | epoch 003:   9681 / 13011 loss=0.104843, wps=1048.5, ups=0.55, wpb=1912.8, bsz=112, num_updates=35600, lr=3.56e-05, gnorm=22.915, clip=100, loss_scale=64, train_wall=80, gb_free=14.6, wall=71933
2025-11-08 12:51:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 12:52:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 12:53:13 | INFO | train_inner | epoch 003:   9733 / 13011 loss=0.097921, wps=895, ups=0.46, wpb=1930.4, bsz=112, num_updates=35650, lr=3.565e-05, gnorm=19.672, clip=100, loss_scale=16, train_wall=88, gb_free=17.6, wall=72040
2025-11-08 12:54:35 | INFO | train_inner | epoch 003:   9783 / 13011 loss=0.10394, wps=1167.2, ups=0.61, wpb=1908.9, bsz=112, num_updates=35700, lr=3.57e-05, gnorm=21.985, clip=100, loss_scale=16, train_wall=82, gb_free=15.5, wall=72122
2025-11-08 12:55:55 | INFO | train_inner | epoch 003:   9833 / 13011 loss=0.104408, wps=1191.1, ups=0.62, wpb=1910.7, bsz=112, num_updates=35750, lr=3.575e-05, gnorm=22.779, clip=100, loss_scale=16, train_wall=80, gb_free=12.2, wall=72202
2025-11-08 12:57:13 | INFO | train_inner | epoch 003:   9883 / 13011 loss=0.108195, wps=1234.1, ups=0.64, wpb=1924.3, bsz=112, num_updates=35800, lr=3.58e-05, gnorm=26.757, clip=100, loss_scale=16, train_wall=78, gb_free=17.9, wall=72280
2025-11-08 12:58:49 | INFO | train_inner | epoch 003:   9933 / 13011 loss=0.101437, wps=990.6, ups=0.52, wpb=1903.7, bsz=112, num_updates=35850, lr=3.585e-05, gnorm=19.644, clip=100, loss_scale=16, train_wall=96, gb_free=16.9, wall=72377
2025-11-08 13:00:21 | INFO | train_inner | epoch 003:   9983 / 13011 loss=0.099845, wps=1043.3, ups=0.54, wpb=1916.6, bsz=112, num_updates=35900, lr=3.59e-05, gnorm=22.948, clip=100, loss_scale=32, train_wall=92, gb_free=19.2, wall=72468
2025-11-08 13:00:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 13:01:59 | INFO | train_inner | epoch 003:  10034 / 13011 loss=0.099887, wps=981.7, ups=0.51, wpb=1923.9, bsz=112, num_updates=35950, lr=3.595e-05, gnorm=23.879, clip=100, loss_scale=16, train_wall=98, gb_free=17.8, wall=72566
2025-11-08 13:03:41 | INFO | train_inner | epoch 003:  10084 / 13011 loss=0.09258, wps=918.1, ups=0.49, wpb=1871.5, bsz=112, num_updates=36000, lr=3.6e-05, gnorm=20.186, clip=100, loss_scale=16, train_wall=102, gb_free=18.1, wall=72668
2025-11-08 13:04:56 | INFO | train_inner | epoch 003:  10134 / 13011 loss=0.110576, wps=1284.9, ups=0.66, wpb=1936.2, bsz=112, num_updates=36050, lr=3.605e-05, gnorm=26.314, clip=100, loss_scale=16, train_wall=75, gb_free=16, wall=72744
2025-11-08 13:06:19 | INFO | train_inner | epoch 003:  10184 / 13011 loss=0.098893, wps=1157.8, ups=0.6, wpb=1915.7, bsz=112, num_updates=36100, lr=3.61e-05, gnorm=24.18, clip=100, loss_scale=16, train_wall=82, gb_free=18.6, wall=72826
2025-11-08 13:07:57 | INFO | train_inner | epoch 003:  10234 / 13011 loss=0.104503, wps=997.4, ups=0.51, wpb=1948.9, bsz=112, num_updates=36150, lr=3.615e-05, gnorm=24.363, clip=100, loss_scale=16, train_wall=97, gb_free=18.3, wall=72924
2025-11-08 13:09:07 | INFO | train_inner | epoch 003:  10284 / 13011 loss=0.10051, wps=1386.9, ups=0.71, wpb=1959.3, bsz=112, num_updates=36200, lr=3.62e-05, gnorm=21.69, clip=100, loss_scale=32, train_wall=70, gb_free=17.7, wall=72995
2025-11-08 13:10:32 | INFO | train_inner | epoch 003:  10334 / 13011 loss=0.09602, wps=1165.6, ups=0.59, wpb=1964.6, bsz=112, num_updates=36250, lr=3.625e-05, gnorm=19.9, clip=100, loss_scale=32, train_wall=84, gb_free=18.2, wall=73079
2025-11-08 13:12:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 13:12:15 | INFO | train_inner | epoch 003:  10385 / 13011 loss=0.099721, wps=929.3, ups=0.48, wpb=1931, bsz=112, num_updates=36300, lr=3.63e-05, gnorm=20.536, clip=100, loss_scale=16, train_wall=104, gb_free=16.7, wall=73183
2025-11-08 13:13:49 | INFO | train_inner | epoch 003:  10435 / 13011 loss=0.096857, wps=1040.5, ups=0.53, wpb=1945.3, bsz=112, num_updates=36350, lr=3.635e-05, gnorm=19.621, clip=100, loss_scale=16, train_wall=93, gb_free=18.4, wall=73276
2025-11-08 13:15:06 | INFO | train_inner | epoch 003:  10485 / 13011 loss=0.087538, wps=1247.5, ups=0.65, wpb=1926.1, bsz=112, num_updates=36400, lr=3.64e-05, gnorm=20.256, clip=100, loss_scale=16, train_wall=71, gb_free=15.5, wall=73354
2025-11-08 13:16:44 | INFO | train_inner | epoch 003:  10535 / 13011 loss=0.095799, wps=970.7, ups=0.51, wpb=1905.1, bsz=112, num_updates=36450, lr=3.645e-05, gnorm=20.745, clip=100, loss_scale=16, train_wall=98, gb_free=18.5, wall=73452
2025-11-08 13:18:10 | INFO | train_inner | epoch 003:  10585 / 13011 loss=0.096042, wps=1130.9, ups=0.59, wpb=1928.8, bsz=112, num_updates=36500, lr=3.65e-05, gnorm=21.123, clip=100, loss_scale=16, train_wall=85, gb_free=17.6, wall=73537
2025-11-08 13:19:40 | INFO | train_inner | epoch 003:  10635 / 13011 loss=0.091495, wps=1067.9, ups=0.55, wpb=1938, bsz=112, num_updates=36550, lr=3.655e-05, gnorm=20.207, clip=100, loss_scale=16, train_wall=91, gb_free=17.9, wall=73628
2025-11-08 13:21:02 | INFO | train_inner | epoch 003:  10685 / 13011 loss=0.098983, wps=1152.9, ups=0.61, wpb=1888.1, bsz=112, num_updates=36600, lr=3.66e-05, gnorm=21.523, clip=100, loss_scale=32, train_wall=82, gb_free=18.9, wall=73710
2025-11-08 13:22:21 | INFO | train_inner | epoch 003:  10735 / 13011 loss=0.096961, wps=1200.1, ups=0.63, wpb=1891.2, bsz=112, num_updates=36650, lr=3.665e-05, gnorm=21.77, clip=100, loss_scale=32, train_wall=79, gb_free=16.3, wall=73788
2025-11-08 13:23:46 | INFO | train_inner | epoch 003:  10785 / 13011 loss=0.098431, wps=1140.8, ups=0.59, wpb=1929.7, bsz=112, num_updates=36700, lr=3.67e-05, gnorm=19.898, clip=100, loss_scale=32, train_wall=84, gb_free=17.8, wall=73873
2025-11-08 13:24:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 13:25:13 | INFO | train_inner | epoch 003:  10836 / 13011 loss=0.090083, wps=1115.2, ups=0.57, wpb=1946.7, bsz=112, num_updates=36750, lr=3.675e-05, gnorm=20.724, clip=100, loss_scale=16, train_wall=87, gb_free=14.1, wall=73960
2025-11-08 13:26:38 | INFO | train_inner | epoch 003:  10886 / 13011 loss=0.08977, wps=1131.3, ups=0.59, wpb=1916.4, bsz=112, num_updates=36800, lr=3.68e-05, gnorm=19.532, clip=100, loss_scale=16, train_wall=84, gb_free=19.3, wall=74045
2025-11-08 13:28:04 | INFO | train_inner | epoch 003:  10936 / 13011 loss=0.098298, wps=1095.7, ups=0.58, wpb=1899.1, bsz=112, num_updates=36850, lr=3.685e-05, gnorm=19.186, clip=100, loss_scale=16, train_wall=86, gb_free=17.7, wall=74132
2025-11-08 13:29:47 | INFO | train_inner | epoch 003:  10986 / 13011 loss=0.104385, wps=916, ups=0.49, wpb=1883.2, bsz=112, num_updates=36900, lr=3.69e-05, gnorm=23.313, clip=100, loss_scale=16, train_wall=103, gb_free=12.4, wall=74234
2025-11-08 13:31:32 | INFO | train_inner | epoch 003:  11036 / 13011 loss=0.099563, wps=922.9, ups=0.48, wpb=1935.8, bsz=112, num_updates=36950, lr=3.695e-05, gnorm=20.626, clip=100, loss_scale=16, train_wall=105, gb_free=17.7, wall=74339
2025-11-08 13:33:23 | INFO | train_inner | epoch 003:  11086 / 13011 loss=0.094052, wps=864.9, ups=0.45, wpb=1913.9, bsz=112, num_updates=37000, lr=3.7e-05, gnorm=20.583, clip=100, loss_scale=32, train_wall=110, gb_free=18, wall=74450
2025-11-08 13:35:02 | INFO | train_inner | epoch 003:  11136 / 13011 loss=0.095874, wps=969.1, ups=0.5, wpb=1920, bsz=112, num_updates=37050, lr=3.705e-05, gnorm=19.667, clip=100, loss_scale=32, train_wall=99, gb_free=19.1, wall=74549
2025-11-08 13:36:32 | INFO | train_inner | epoch 003:  11186 / 13011 loss=0.09119, wps=1036.5, ups=0.55, wpb=1881.1, bsz=112, num_updates=37100, lr=3.71e-05, gnorm=22.191, clip=100, loss_scale=32, train_wall=91, gb_free=18.3, wall=74640
2025-11-08 13:37:56 | INFO | train_inner | epoch 003:  11236 / 13011 loss=0.09422, wps=1139.2, ups=0.6, wpb=1904.9, bsz=112, num_updates=37150, lr=3.715e-05, gnorm=20.384, clip=100, loss_scale=32, train_wall=83, gb_free=17.9, wall=74723
2025-11-08 13:39:21 | INFO | train_inner | epoch 003:  11286 / 13011 loss=0.087588, wps=1144.1, ups=0.59, wpb=1940.1, bsz=112, num_updates=37200, lr=3.72e-05, gnorm=18.446, clip=100, loss_scale=32, train_wall=85, gb_free=14.9, wall=74808
2025-11-08 13:40:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 13:40:49 | INFO | train_inner | epoch 003:  11337 / 13011 loss=0.097056, wps=1099.7, ups=0.57, wpb=1946.2, bsz=112, num_updates=37250, lr=3.725e-05, gnorm=20.169, clip=100, loss_scale=32, train_wall=85, gb_free=17.3, wall=74897
2025-11-08 13:42:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 13:42:17 | INFO | train_inner | epoch 003:  11388 / 13011 loss=0.098031, wps=1082.9, ups=0.57, wpb=1898.2, bsz=112, num_updates=37300, lr=3.73e-05, gnorm=20.238, clip=100, loss_scale=16, train_wall=87, gb_free=16.6, wall=74984
2025-11-08 13:43:49 | INFO | train_inner | epoch 003:  11438 / 13011 loss=0.085879, wps=1030.9, ups=0.54, wpb=1897.9, bsz=112, num_updates=37350, lr=3.735e-05, gnorm=19.487, clip=100, loss_scale=16, train_wall=92, gb_free=17.6, wall=75076
2025-11-08 13:45:13 | INFO | train_inner | epoch 003:  11488 / 13011 loss=0.093079, wps=1133.9, ups=0.59, wpb=1913.6, bsz=112, num_updates=37400, lr=3.74e-05, gnorm=17.82, clip=100, loss_scale=16, train_wall=84, gb_free=19, wall=75161
2025-11-08 13:46:41 | INFO | train_inner | epoch 003:  11538 / 13011 loss=0.095707, wps=1101.1, ups=0.57, wpb=1937.2, bsz=112, num_updates=37450, lr=3.745e-05, gnorm=24.502, clip=100, loss_scale=16, train_wall=88, gb_free=17.2, wall=75249
2025-11-08 13:47:47 | INFO | train_inner | epoch 003:  11588 / 13011 loss=0.091952, wps=1442, ups=0.76, wpb=1902.4, bsz=112, num_updates=37500, lr=3.75e-05, gnorm=19.821, clip=100, loss_scale=16, train_wall=65, gb_free=19.2, wall=75315
2025-11-08 13:49:23 | INFO | train_inner | epoch 003:  11638 / 13011 loss=0.094579, wps=983.3, ups=0.52, wpb=1877.5, bsz=112, num_updates=37550, lr=3.755e-05, gnorm=18.864, clip=100, loss_scale=16, train_wall=95, gb_free=11.4, wall=75410
2025-11-08 13:50:55 | INFO | train_inner | epoch 003:  11688 / 13011 loss=0.09946, wps=1035.1, ups=0.54, wpb=1904.8, bsz=112, num_updates=37600, lr=3.76e-05, gnorm=19.894, clip=100, loss_scale=32, train_wall=92, gb_free=17.3, wall=75502
2025-11-08 13:52:45 | INFO | train_inner | epoch 003:  11738 / 13011 loss=0.087911, wps=859.9, ups=0.45, wpb=1903.3, bsz=112, num_updates=37650, lr=3.765e-05, gnorm=17.454, clip=100, loss_scale=32, train_wall=110, gb_free=18.2, wall=75613
2025-11-08 13:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 13:53:56 | INFO | train_inner | epoch 003:  11789 / 13011 loss=0.093239, wps=1353.7, ups=0.71, wpb=1907.1, bsz=112, num_updates=37700, lr=3.77e-05, gnorm=20.52, clip=100, loss_scale=16, train_wall=70, gb_free=18.3, wall=75683
2025-11-08 13:55:21 | INFO | train_inner | epoch 003:  11839 / 13011 loss=0.096575, wps=1139.1, ups=0.59, wpb=1947.1, bsz=112, num_updates=37750, lr=3.775e-05, gnorm=20.213, clip=100, loss_scale=16, train_wall=85, gb_free=18.4, wall=75769
2025-11-08 13:57:09 | INFO | train_inner | epoch 003:  11889 / 13011 loss=0.092324, wps=917.9, ups=0.47, wpb=1937.8, bsz=112, num_updates=37800, lr=3.78e-05, gnorm=19.59, clip=100, loss_scale=16, train_wall=105, gb_free=17.7, wall=75876
2025-11-08 13:58:46 | INFO | train_inner | epoch 003:  11939 / 13011 loss=0.086734, wps=1001.7, ups=0.52, wpb=1944.8, bsz=112, num_updates=37850, lr=3.785e-05, gnorm=22.082, clip=100, loss_scale=16, train_wall=97, gb_free=10.8, wall=75973
2025-11-08 14:00:02 | INFO | train_inner | epoch 003:  11989 / 13011 loss=0.090477, wps=1247.5, ups=0.66, wpb=1898.4, bsz=112, num_updates=37900, lr=3.79e-05, gnorm=18.848, clip=100, loss_scale=16, train_wall=76, gb_free=18, wall=76049
2025-11-08 14:01:26 | INFO | train_inner | epoch 003:  12039 / 13011 loss=0.086896, wps=1154.8, ups=0.6, wpb=1940, bsz=112, num_updates=37950, lr=3.795e-05, gnorm=18.08, clip=100, loss_scale=32, train_wall=84, gb_free=13.4, wall=76133
2025-11-08 14:03:00 | INFO | train_inner | epoch 003:  12089 / 13011 loss=0.094835, wps=1016.8, ups=0.53, wpb=1909.7, bsz=112, num_updates=38000, lr=3.8e-05, gnorm=21.258, clip=100, loss_scale=32, train_wall=94, gb_free=17.5, wall=76227
2025-11-08 14:04:36 | INFO | train_inner | epoch 003:  12139 / 13011 loss=0.084459, wps=993.7, ups=0.52, wpb=1913, bsz=112, num_updates=38050, lr=3.805e-05, gnorm=16.911, clip=100, loss_scale=32, train_wall=96, gb_free=14.4, wall=76323
2025-11-08 14:06:02 | INFO | train_inner | epoch 003:  12189 / 13011 loss=0.090225, wps=1123.3, ups=0.58, wpb=1937.4, bsz=112, num_updates=38100, lr=3.81e-05, gnorm=18.665, clip=100, loss_scale=32, train_wall=85, gb_free=19.4, wall=76410
2025-11-08 14:06:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 14:07:08 | INFO | train_inner | epoch 003:  12240 / 13011 loss=0.089334, wps=1502.4, ups=0.76, wpb=1965.3, bsz=112, num_updates=38150, lr=3.815e-05, gnorm=19.721, clip=100, loss_scale=16, train_wall=65, gb_free=16.5, wall=76475
2025-11-08 14:08:35 | INFO | train_inner | epoch 003:  12290 / 13011 loss=0.093841, wps=1090.2, ups=0.57, wpb=1913.4, bsz=112, num_updates=38200, lr=3.82e-05, gnorm=21.033, clip=100, loss_scale=16, train_wall=88, gb_free=17.5, wall=76563
2025-11-08 14:10:33 | INFO | train_inner | epoch 003:  12340 / 13011 loss=0.089376, wps=818.4, ups=0.43, wpb=1919.6, bsz=112, num_updates=38250, lr=3.825e-05, gnorm=19.192, clip=100, loss_scale=16, train_wall=117, gb_free=18.5, wall=76680
2025-11-08 14:11:51 | INFO | train_inner | epoch 003:  12390 / 13011 loss=0.095277, wps=1245.6, ups=0.64, wpb=1940.1, bsz=112, num_updates=38300, lr=3.83e-05, gnorm=19.342, clip=100, loss_scale=16, train_wall=78, gb_free=17.5, wall=76758
2025-11-08 14:13:12 | INFO | train_inner | epoch 003:  12440 / 13011 loss=0.091402, wps=1172.2, ups=0.61, wpb=1912.8, bsz=112, num_updates=38350, lr=3.835e-05, gnorm=20.631, clip=100, loss_scale=16, train_wall=81, gb_free=18.4, wall=76840
2025-11-08 14:15:04 | INFO | train_inner | epoch 003:  12490 / 13011 loss=0.085809, wps=852.4, ups=0.45, wpb=1908.9, bsz=112, num_updates=38400, lr=3.84e-05, gnorm=18.491, clip=100, loss_scale=32, train_wall=112, gb_free=18, wall=76952
2025-11-08 14:16:31 | INFO | train_inner | epoch 003:  12540 / 13011 loss=0.090846, wps=1133.1, ups=0.58, wpb=1959.1, bsz=112, num_updates=38450, lr=3.845e-05, gnorm=22.688, clip=100, loss_scale=32, train_wall=86, gb_free=17.9, wall=77038
2025-11-08 14:18:10 | INFO | train_inner | epoch 003:  12590 / 13011 loss=0.089683, wps=974.2, ups=0.51, wpb=1928.4, bsz=112, num_updates=38500, lr=3.85e-05, gnorm=19.4, clip=100, loss_scale=32, train_wall=99, gb_free=15.1, wall=77137
2025-11-08 14:20:01 | INFO | train_inner | epoch 003:  12640 / 13011 loss=0.085473, wps=862.6, ups=0.45, wpb=1929.4, bsz=112, num_updates=38550, lr=3.855e-05, gnorm=19.685, clip=100, loss_scale=32, train_wall=112, gb_free=17.5, wall=77249
2025-11-08 14:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 14:21:24 | INFO | train_inner | epoch 003:  12691 / 13011 loss=0.086136, wps=1187.7, ups=0.61, wpb=1961.9, bsz=112, num_updates=38600, lr=3.86e-05, gnorm=17.918, clip=100, loss_scale=16, train_wall=82, gb_free=13.4, wall=77331
2025-11-08 14:22:48 | INFO | train_inner | epoch 003:  12741 / 13011 loss=0.090065, wps=1146.3, ups=0.6, wpb=1917.4, bsz=112, num_updates=38650, lr=3.865e-05, gnorm=20.889, clip=100, loss_scale=16, train_wall=83, gb_free=18, wall=77415
2025-11-08 14:24:11 | INFO | train_inner | epoch 003:  12791 / 13011 loss=0.088688, wps=1152.4, ups=0.6, wpb=1910.5, bsz=112, num_updates=38700, lr=3.87e-05, gnorm=17.527, clip=100, loss_scale=16, train_wall=83, gb_free=16.7, wall=77498
2025-11-08 14:25:44 | INFO | train_inner | epoch 003:  12841 / 13011 loss=0.09046, wps=1042.2, ups=0.54, wpb=1942.7, bsz=112, num_updates=38750, lr=3.875e-05, gnorm=19.255, clip=100, loss_scale=16, train_wall=93, gb_free=13.6, wall=77591
2025-11-08 14:27:07 | INFO | train_inner | epoch 003:  12891 / 13011 loss=0.087997, wps=1133.8, ups=0.6, wpb=1897.7, bsz=112, num_updates=38800, lr=3.88e-05, gnorm=19.368, clip=100, loss_scale=16, train_wall=83, gb_free=16.5, wall=77675
2025-11-08 14:27:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 14:28:29 | INFO | train_inner | epoch 003:  12942 / 13011 loss=0.08109, wps=1200.1, ups=0.62, wpb=1951.1, bsz=112, num_updates=38850, lr=3.885e-05, gnorm=19.264, clip=100, loss_scale=8, train_wall=81, gb_free=12.8, wall=77756
2025-11-08 14:30:13 | INFO | train_inner | epoch 003:  12992 / 13011 loss=0.084386, wps=906.9, ups=0.48, wpb=1894.6, bsz=112, num_updates=38900, lr=3.89e-05, gnorm=20.38, clip=100, loss_scale=8, train_wall=104, gb_free=18.3, wall=77861
2025-11-08 14:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-08 14:49:00 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.082682 | wps 1283.6 | wpb 1907.1 | bsz 111.9 | num_updates 38919 | best_loss 0.082682
2025-11-08 14:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 38919 updates
2025-11-08 14:49:00 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint3.pt
2025-11-08 14:51:41 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint3.pt
2025-11-08 14:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint3.pt (epoch 3 @ 38919 updates, score 0.082682) (writing took 343.87086652900325 seconds)
2025-11-08 14:54:44 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2025-11-08 14:54:44 | INFO | train | epoch 003 | loss 0.112545 | wps 896.6 | ups 0.47 | wpb 1916.9 | bsz 112 | num_updates 38919 | lr 3.8919e-05 | gnorm 24.341 | clip 100 | loss_scale 8 | train_wall 24821 | gb_free 17.8 | wall 79331
2025-11-08 14:54:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 13011
2025-11-08 14:54:46 | INFO | fairseq.trainer | begin training epoch 4
2025-11-08 14:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-08 14:56:57 | INFO | train_inner | epoch 004:     31 / 13011 loss=0.089497, wps=58.2, ups=0.03, wpb=1866.7, bsz=110, num_updates=38950, lr=3.895e-05, gnorm=19.031, clip=100, loss_scale=8, train_wall=150, gb_free=17.7, wall=79464
2025-11-08 14:59:33 | INFO | train_inner | epoch 004:     81 / 13011 loss=0.086646, wps=629.1, ups=0.32, wpb=1966, bsz=112, num_updates=39000, lr=3.9e-05, gnorm=20.806, clip=100, loss_scale=8, train_wall=156, gb_free=16.7, wall=79620
2025-11-08 15:00:32 | INFO | train_inner | epoch 004:    131 / 13011 loss=0.08453, wps=1675.2, ups=0.85, wpb=1973.2, bsz=112, num_updates=39050, lr=3.905e-05, gnorm=19.491, clip=100, loss_scale=8, train_wall=59, gb_free=11.1, wall=79679
2025-11-08 15:03:05 | INFO | train_inner | epoch 004:    181 / 13011 loss=0.084847, wps=617.8, ups=0.33, wpb=1898.6, bsz=112, num_updates=39100, lr=3.91e-05, gnorm=17.416, clip=100, loss_scale=16, train_wall=153, gb_free=14.5, wall=79833
2025-11-08 15:03:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 15:05:57 | INFO | train_inner | epoch 004:    232 / 13011 loss=0.083429, wps=558.4, ups=0.29, wpb=1912.5, bsz=112, num_updates=39150, lr=3.915e-05, gnorm=22.439, clip=100, loss_scale=8, train_wall=171, gb_free=13.3, wall=80004
2025-11-08 15:07:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 15:07:58 | INFO | train_inner | epoch 004:    283 / 13011 loss=0.095187, wps=805.1, ups=0.41, wpb=1947.9, bsz=112, num_updates=39200, lr=3.92e-05, gnorm=21.641, clip=100, loss_scale=4, train_wall=121, gb_free=18, wall=80125
2025-11-08 15:08:56 | INFO | train_inner | epoch 004:    333 / 13011 loss=0.096712, wps=1632.3, ups=0.86, wpb=1894.2, bsz=112, num_updates=39250, lr=3.925e-05, gnorm=26.866, clip=100, loss_scale=4, train_wall=58, gb_free=19.2, wall=80183
2025-11-08 15:10:09 | INFO | train_inner | epoch 004:    383 / 13011 loss=0.091785, wps=1313.8, ups=0.68, wpb=1935.3, bsz=112, num_updates=39300, lr=3.93e-05, gnorm=21.935, clip=100, loss_scale=4, train_wall=73, gb_free=16.5, wall=80257
2025-11-08 15:13:15 | INFO | train_inner | epoch 004:    433 / 13011 loss=0.087242, wps=525.5, ups=0.27, wpb=1952, bsz=112, num_updates=39350, lr=3.935e-05, gnorm=19.683, clip=100, loss_scale=4, train_wall=185, gb_free=18.7, wall=80442
2025-11-08 15:14:32 | INFO | train_inner | epoch 004:    483 / 13011 loss=0.091161, wps=1232.9, ups=0.65, wpb=1905.4, bsz=112, num_updates=39400, lr=3.94e-05, gnorm=20.714, clip=100, loss_scale=4, train_wall=77, gb_free=18.8, wall=80520
2025-11-08 15:16:21 | INFO | train_inner | epoch 004:    533 / 13011 loss=0.09679, wps=898.1, ups=0.46, wpb=1952.7, bsz=112, num_updates=39450, lr=3.945e-05, gnorm=19.034, clip=100, loss_scale=8, train_wall=108, gb_free=18.5, wall=80628
2025-11-08 15:17:48 | INFO | train_inner | epoch 004:    583 / 13011 loss=0.090404, wps=1080.5, ups=0.57, wpb=1891.3, bsz=112, num_updates=39500, lr=3.95e-05, gnorm=16.854, clip=100, loss_scale=8, train_wall=87, gb_free=16.6, wall=80716
2025-11-08 15:17:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 15:19:56 | INFO | train_inner | epoch 004:    634 / 13011 loss=0.094267, wps=766.4, ups=0.39, wpb=1952.1, bsz=112, num_updates=39550, lr=3.955e-05, gnorm=18.22, clip=100, loss_scale=4, train_wall=87, gb_free=18.3, wall=80843
2025-11-08 15:22:21 | INFO | train_inner | epoch 004:    684 / 13011 loss=0.091026, wps=659.4, ups=0.34, wpb=1916.1, bsz=112, num_updates=39600, lr=3.96e-05, gnorm=20.181, clip=100, loss_scale=4, train_wall=136, gb_free=18.8, wall=80989
2025-11-08 15:25:07 | INFO | train_inner | epoch 004:    734 / 13011 loss=0.088889, wps=566.1, ups=0.3, wpb=1882.7, bsz=112, num_updates=39650, lr=3.965e-05, gnorm=19.817, clip=100, loss_scale=4, train_wall=84, gb_free=16.5, wall=81155
2025-11-08 15:27:51 | INFO | train_inner | epoch 004:    784 / 13011 loss=0.092233, wps=576.6, ups=0.3, wpb=1891.3, bsz=112, num_updates=39700, lr=3.97e-05, gnorm=19.134, clip=100, loss_scale=4, train_wall=164, gb_free=15.9, wall=81319
2025-11-08 15:29:04 | INFO | train_inner | epoch 004:    834 / 13011 loss=0.088095, wps=1307.8, ups=0.69, wpb=1892, bsz=112, num_updates=39750, lr=3.975e-05, gnorm=21.876, clip=100, loss_scale=4, train_wall=72, gb_free=17.8, wall=81391
2025-11-08 15:30:56 | INFO | train_inner | epoch 004:    884 / 13011 loss=0.086871, wps=855.4, ups=0.44, wpb=1922.8, bsz=112, num_updates=39800, lr=3.98e-05, gnorm=22.857, clip=100, loss_scale=8, train_wall=88, gb_free=18.7, wall=81504
2025-11-08 15:33:02 | INFO | train_inner | epoch 004:    934 / 13011 loss=0.07965, wps=765.3, ups=0.4, wpb=1931.5, bsz=112, num_updates=39850, lr=3.985e-05, gnorm=16.075, clip=100, loss_scale=8, train_wall=100, gb_free=17.4, wall=81630
2025-11-08 15:35:32 | INFO | train_inner | epoch 004:    984 / 13011 loss=0.08594, wps=644.5, ups=0.33, wpb=1935.1, bsz=112, num_updates=39900, lr=3.99e-05, gnorm=18.721, clip=100, loss_scale=8, train_wall=150, gb_free=17, wall=81780
2025-11-08 15:37:58 | INFO | train_inner | epoch 004:   1034 / 13011 loss=0.086036, wps=670, ups=0.34, wpb=1951.6, bsz=112, num_updates=39950, lr=3.995e-05, gnorm=20.009, clip=100, loss_scale=8, train_wall=145, gb_free=18.3, wall=81925
2025-11-08 15:39:13 | INFO | train_inner | epoch 004:   1084 / 13011 loss=0.092398, wps=1269.9, ups=0.67, wpb=1893, bsz=112, num_updates=40000, lr=4e-05, gnorm=22.54, clip=100, loss_scale=8, train_wall=74, gb_free=19.6, wall=82000
2025-11-08 15:41:23 | INFO | train_inner | epoch 004:   1134 / 13011 loss=0.091989, wps=743.9, ups=0.38, wpb=1933.7, bsz=112, num_updates=40050, lr=4.005e-05, gnorm=19.963, clip=100, loss_scale=16, train_wall=130, gb_free=16.7, wall=82130
2025-11-08 15:44:01 | INFO | train_inner | epoch 004:   1184 / 13011 loss=0.091436, wps=616.3, ups=0.32, wpb=1956.2, bsz=112, num_updates=40100, lr=4.01e-05, gnorm=16.84, clip=100, loss_scale=16, train_wall=108, gb_free=18.1, wall=82289
2025-11-08 15:46:55 | INFO | train_inner | epoch 004:   1234 / 13011 loss=0.0933, wps=567, ups=0.29, wpb=1969.3, bsz=112, num_updates=40150, lr=4.015e-05, gnorm=16.934, clip=100, loss_scale=16, train_wall=173, gb_free=13.9, wall=82463
2025-11-08 15:49:31 | INFO | train_inner | epoch 004:   1284 / 13011 loss=0.093679, wps=613.2, ups=0.32, wpb=1911.1, bsz=112, num_updates=40200, lr=4.02e-05, gnorm=19.074, clip=100, loss_scale=16, train_wall=72, gb_free=17.7, wall=82619
2025-11-08 15:50:37 | INFO | train_inner | epoch 004:   1334 / 13011 loss=0.088647, wps=1461.1, ups=0.76, wpb=1914.8, bsz=112, num_updates=40250, lr=4.025e-05, gnorm=18.748, clip=100, loss_scale=16, train_wall=65, gb_free=17.2, wall=82684
2025-11-08 15:52:52 | INFO | train_inner | epoch 004:   1384 / 13011 loss=0.085282, wps=715.9, ups=0.37, wpb=1930.9, bsz=112, num_updates=40300, lr=4.03e-05, gnorm=19.838, clip=100, loss_scale=32, train_wall=87, gb_free=15.6, wall=82819
2025-11-08 15:55:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 15:55:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 15:55:46 | INFO | train_inner | epoch 004:   1436 / 13011 loss=0.087205, wps=545.8, ups=0.29, wpb=1909.5, bsz=112, num_updates=40350, lr=4.035e-05, gnorm=19.808, clip=100, loss_scale=8, train_wall=137, gb_free=19.7, wall=82994
2025-11-08 15:58:15 | INFO | train_inner | epoch 004:   1486 / 13011 loss=0.090294, wps=640.9, ups=0.34, wpb=1899.4, bsz=112, num_updates=40400, lr=4.04e-05, gnorm=22.557, clip=100, loss_scale=8, train_wall=148, gb_free=18.7, wall=83142
2025-11-08 16:01:40 | INFO | train_inner | epoch 004:   1536 / 13011 loss=0.089865, wps=472.3, ups=0.24, wpb=1935.1, bsz=112, num_updates=40450, lr=4.045e-05, gnorm=24.946, clip=100, loss_scale=8, train_wall=144, gb_free=15.9, wall=83347
2025-11-08 16:04:15 | INFO | train_inner | epoch 004:   1586 / 13011 loss=0.083069, wps=610.8, ups=0.32, wpb=1901, bsz=112, num_updates=40500, lr=4.05e-05, gnorm=17.995, clip=100, loss_scale=8, train_wall=155, gb_free=17.1, wall=83503
2025-11-08 16:06:15 | INFO | train_inner | epoch 004:   1636 / 13011 loss=0.085116, wps=797.9, ups=0.42, wpb=1916.9, bsz=112, num_updates=40550, lr=4.055e-05, gnorm=17.331, clip=100, loss_scale=8, train_wall=120, gb_free=17.9, wall=83623
2025-11-08 16:08:19 | INFO | train_inner | epoch 004:   1686 / 13011 loss=0.084864, wps=769.5, ups=0.4, wpb=1905.5, bsz=112, num_updates=40600, lr=4.06e-05, gnorm=16.609, clip=100, loss_scale=16, train_wall=124, gb_free=15.7, wall=83746
2025-11-08 16:09:27 | INFO | train_inner | epoch 004:   1736 / 13011 loss=0.084381, wps=1396.1, ups=0.73, wpb=1904.8, bsz=112, num_updates=40650, lr=4.065e-05, gnorm=18.262, clip=100, loss_scale=16, train_wall=68, gb_free=14.9, wall=83815
2025-11-08 16:11:34 | INFO | train_inner | epoch 004:   1786 / 13011 loss=0.080007, wps=759, ups=0.39, wpb=1923.9, bsz=112, num_updates=40700, lr=4.07e-05, gnorm=16.542, clip=100, loss_scale=16, train_wall=126, gb_free=18.8, wall=83941
2025-11-08 16:13:40 | INFO | train_inner | epoch 004:   1836 / 13011 loss=0.079609, wps=766.3, ups=0.4, wpb=1924.1, bsz=112, num_updates=40750, lr=4.075e-05, gnorm=16.238, clip=100, loss_scale=16, train_wall=125, gb_free=18.1, wall=84067
2025-11-08 16:15:58 | INFO | train_inner | epoch 004:   1886 / 13011 loss=0.080778, wps=690.5, ups=0.36, wpb=1917, bsz=112, num_updates=40800, lr=4.08e-05, gnorm=16.962, clip=100, loss_scale=16, train_wall=139, gb_free=18.7, wall=84206
2025-11-08 16:18:26 | INFO | train_inner | epoch 004:   1936 / 13011 loss=0.086587, wps=642.6, ups=0.34, wpb=1890.7, bsz=112, num_updates=40850, lr=4.085e-05, gnorm=26.185, clip=100, loss_scale=32, train_wall=75, gb_free=16.9, wall=84353
2025-11-08 16:20:59 | INFO | train_inner | epoch 004:   1986 / 13011 loss=0.079985, wps=614.6, ups=0.33, wpb=1889.7, bsz=112, num_updates=40900, lr=4.09e-05, gnorm=17.437, clip=100, loss_scale=32, train_wall=153, gb_free=17.7, wall=84507
2025-11-08 16:23:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 16:23:18 | INFO | train_inner | epoch 004:   2037 / 13011 loss=0.089166, wps=694.8, ups=0.36, wpb=1921.3, bsz=112, num_updates=40950, lr=4.095e-05, gnorm=17.943, clip=100, loss_scale=16, train_wall=85, gb_free=12.1, wall=84645
2025-11-08 16:25:33 | INFO | train_inner | epoch 004:   2087 / 13011 loss=0.095948, wps=705.1, ups=0.37, wpb=1907.9, bsz=112, num_updates=41000, lr=4.1e-05, gnorm=19.04, clip=100, loss_scale=16, train_wall=135, gb_free=18.2, wall=84780
2025-11-08 16:27:50 | INFO | train_inner | epoch 004:   2137 / 13011 loss=0.093782, wps=698.8, ups=0.36, wpb=1917.7, bsz=112, num_updates=41050, lr=4.105e-05, gnorm=22.656, clip=100, loss_scale=16, train_wall=137, gb_free=18.5, wall=84917
2025-11-08 16:31:25 | INFO | train_inner | epoch 004:   2187 / 13011 loss=0.092107, wps=448.8, ups=0.23, wpb=1925, bsz=112, num_updates=41100, lr=4.11e-05, gnorm=17.667, clip=100, loss_scale=16, train_wall=211, gb_free=11.1, wall=85132
2025-11-08 16:32:30 | INFO | train_inner | epoch 004:   2237 / 13011 loss=0.087313, wps=1458.5, ups=0.76, wpb=1908, bsz=112, num_updates=41150, lr=4.115e-05, gnorm=17.25, clip=100, loss_scale=16, train_wall=65, gb_free=18.8, wall=85197
2025-11-08 16:35:12 | INFO | train_inner | epoch 004:   2287 / 13011 loss=0.082802, wps=597.2, ups=0.31, wpb=1931.2, bsz=112, num_updates=41200, lr=4.12e-05, gnorm=18.043, clip=100, loss_scale=16, train_wall=161, gb_free=17.9, wall=85359
2025-11-08 16:38:02 | INFO | train_inner | epoch 004:   2337 / 13011 loss=0.079027, wps=569.1, ups=0.29, wpb=1937.6, bsz=112, num_updates=41250, lr=4.125e-05, gnorm=17.875, clip=100, loss_scale=32, train_wall=170, gb_free=15.1, wall=85529
2025-11-08 16:38:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 16:40:15 | INFO | train_inner | epoch 004:   2388 / 13011 loss=0.086028, wps=727.3, ups=0.38, wpb=1936, bsz=112, num_updates=41300, lr=4.13e-05, gnorm=21.271, clip=100, loss_scale=16, train_wall=133, gb_free=17.2, wall=85662
2025-11-08 16:42:42 | INFO | train_inner | epoch 004:   2438 / 13011 loss=0.087753, wps=648.5, ups=0.34, wpb=1910.2, bsz=112, num_updates=41350, lr=4.135e-05, gnorm=18.21, clip=100, loss_scale=16, train_wall=77, gb_free=18.8, wall=85810
2025-11-08 16:43:52 | INFO | train_inner | epoch 004:   2488 / 13011 loss=0.083656, wps=1370.3, ups=0.72, wpb=1906.7, bsz=112, num_updates=41400, lr=4.14e-05, gnorm=26.446, clip=100, loss_scale=16, train_wall=69, gb_free=14.7, wall=85879
2025-11-08 16:46:26 | INFO | train_inner | epoch 004:   2538 / 13011 loss=0.08729, wps=611.8, ups=0.32, wpb=1890.2, bsz=112, num_updates=41450, lr=4.145e-05, gnorm=16.408, clip=100, loss_scale=16, train_wall=119, gb_free=10.4, wall=86034
2025-11-08 16:48:32 | INFO | train_inner | epoch 004:   2588 / 13011 loss=0.079992, wps=753.4, ups=0.4, wpb=1898.6, bsz=112, num_updates=41500, lr=4.15e-05, gnorm=17.202, clip=100, loss_scale=16, train_wall=87, gb_free=17.1, wall=86160
2025-11-08 16:51:31 | INFO | train_inner | epoch 004:   2638 / 13011 loss=0.077099, wps=555.5, ups=0.28, wpb=1981.3, bsz=112, num_updates=41550, lr=4.155e-05, gnorm=16.283, clip=100, loss_scale=32, train_wall=160, gb_free=14.7, wall=86338
2025-11-08 16:53:47 | INFO | train_inner | epoch 004:   2688 / 13011 loss=0.08886, wps=702.7, ups=0.37, wpb=1911.2, bsz=112, num_updates=41600, lr=4.16e-05, gnorm=17.277, clip=100, loss_scale=32, train_wall=106, gb_free=16.9, wall=86474
2025-11-08 16:56:07 | INFO | train_inner | epoch 004:   2738 / 13011 loss=0.079586, wps=685.2, ups=0.36, wpb=1918.3, bsz=112, num_updates=41650, lr=4.165e-05, gnorm=16.806, clip=100, loss_scale=32, train_wall=129, gb_free=18.4, wall=86614
2025-11-08 16:58:39 | INFO | train_inner | epoch 004:   2788 / 13011 loss=0.079828, wps=627.1, ups=0.33, wpb=1911.2, bsz=112, num_updates=41700, lr=4.17e-05, gnorm=18.719, clip=100, loss_scale=32, train_wall=152, gb_free=18.4, wall=86767
2025-11-08 16:59:58 | INFO | train_inner | epoch 004:   2838 / 13011 loss=0.085373, wps=1218, ups=0.63, wpb=1926.9, bsz=112, num_updates=41750, lr=4.175e-05, gnorm=17.843, clip=100, loss_scale=32, train_wall=79, gb_free=14, wall=86846
2025-11-08 17:01:42 | INFO | train_inner | epoch 004:   2888 / 13011 loss=0.085741, wps=927.7, ups=0.48, wpb=1925.2, bsz=112, num_updates=41800, lr=4.18e-05, gnorm=17.703, clip=100, loss_scale=64, train_wall=104, gb_free=17.4, wall=86950
2025-11-08 17:03:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 17:03:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 17:04:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 17:04:44 | INFO | train_inner | epoch 004:   2941 / 13011 loss=0.082487, wps=527.7, ups=0.28, wpb=1916.1, bsz=112, num_updates=41850, lr=4.185e-05, gnorm=16.872, clip=100, loss_scale=8, train_wall=134, gb_free=16.7, wall=87131
2025-11-08 17:08:27 | INFO | train_inner | epoch 004:   2991 / 13011 loss=0.083937, wps=427.3, ups=0.22, wpb=1910.1, bsz=112, num_updates=41900, lr=4.19e-05, gnorm=15.624, clip=100, loss_scale=8, train_wall=98, gb_free=18, wall=87355
2025-11-08 17:11:08 | INFO | train_inner | epoch 004:   3041 / 13011 loss=0.079592, wps=600.1, ups=0.31, wpb=1930.3, bsz=112, num_updates=41950, lr=4.195e-05, gnorm=19.453, clip=100, loss_scale=8, train_wall=120, gb_free=17.9, wall=87515
2025-11-08 17:12:21 | INFO | train_inner | epoch 004:   3091 / 13011 loss=0.085085, wps=1314.7, ups=0.68, wpb=1920.6, bsz=112, num_updates=42000, lr=4.2e-05, gnorm=19.407, clip=100, loss_scale=8, train_wall=73, gb_free=18.4, wall=87588
2025-11-08 17:14:55 | INFO | train_inner | epoch 004:   3141 / 13011 loss=0.077564, wps=625.7, ups=0.32, wpb=1928.3, bsz=112, num_updates=42050, lr=4.205e-05, gnorm=14.764, clip=100, loss_scale=8, train_wall=89, gb_free=16.2, wall=87743
2025-11-08 17:16:59 | INFO | train_inner | epoch 004:   3191 / 13011 loss=0.086989, wps=776.4, ups=0.4, wpb=1920.7, bsz=112, num_updates=42100, lr=4.21e-05, gnorm=20.902, clip=100, loss_scale=8, train_wall=79, gb_free=16.7, wall=87866
2025-11-08 17:17:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 17:19:32 | INFO | train_inner | epoch 004:   3242 / 13011 loss=0.088137, wps=626.6, ups=0.33, wpb=1919.3, bsz=112, num_updates=42150, lr=4.215e-05, gnorm=17.778, clip=100, loss_scale=8, train_wall=153, gb_free=16.7, wall=88019
2025-11-08 17:21:53 | INFO | train_inner | epoch 004:   3292 / 13011 loss=0.082071, wps=674.9, ups=0.35, wpb=1901.7, bsz=112, num_updates=42200, lr=4.22e-05, gnorm=16.341, clip=100, loss_scale=8, train_wall=111, gb_free=17.4, wall=88160
2025-11-08 17:23:25 | INFO | train_inner | epoch 004:   3342 / 13011 loss=0.077726, wps=1035.5, ups=0.54, wpb=1904.8, bsz=112, num_updates=42250, lr=4.225e-05, gnorm=16.575, clip=100, loss_scale=8, train_wall=92, gb_free=18.7, wall=88252
2025-11-08 17:25:09 | INFO | train_inner | epoch 004:   3392 / 13011 loss=0.085642, wps=909.7, ups=0.48, wpb=1897.7, bsz=112, num_updates=42300, lr=4.23e-05, gnorm=17.25, clip=100, loss_scale=8, train_wall=104, gb_free=18.2, wall=88357
2025-11-08 17:27:44 | INFO | train_inner | epoch 004:   3442 / 13011 loss=0.071484, wps=618.3, ups=0.32, wpb=1919.4, bsz=112, num_updates=42350, lr=4.235e-05, gnorm=13.867, clip=100, loss_scale=8, train_wall=143, gb_free=17.4, wall=88512
2025-11-08 17:28:57 | INFO | train_inner | epoch 004:   3492 / 13011 loss=0.093259, wps=1315.2, ups=0.69, wpb=1909.2, bsz=112, num_updates=42400, lr=4.24e-05, gnorm=16.819, clip=100, loss_scale=16, train_wall=72, gb_free=18.9, wall=88584
2025-11-08 17:30:48 | INFO | train_inner | epoch 004:   3542 / 13011 loss=0.081796, wps=859.3, ups=0.45, wpb=1903.9, bsz=112, num_updates=42450, lr=4.245e-05, gnorm=15.306, clip=100, loss_scale=16, train_wall=111, gb_free=18.6, wall=88696
2025-11-08 17:32:20 | INFO | train_inner | epoch 004:   3592 / 13011 loss=0.08238, wps=1049.7, ups=0.54, wpb=1936.9, bsz=112, num_updates=42500, lr=4.25e-05, gnorm=16.777, clip=100, loss_scale=16, train_wall=92, gb_free=18.1, wall=88788
2025-11-08 17:33:52 | INFO | train_inner | epoch 004:   3642 / 13011 loss=0.079318, wps=1048.6, ups=0.55, wpb=1919.2, bsz=112, num_updates=42550, lr=4.255e-05, gnorm=16.006, clip=100, loss_scale=16, train_wall=91, gb_free=17.5, wall=88879
2025-11-08 17:35:54 | INFO | train_inner | epoch 004:   3692 / 13011 loss=0.074544, wps=785.9, ups=0.41, wpb=1925, bsz=112, num_updates=42600, lr=4.26e-05, gnorm=17.426, clip=100, loss_scale=16, train_wall=122, gb_free=18, wall=89002
2025-11-08 17:37:34 | INFO | train_inner | epoch 004:   3742 / 13011 loss=0.07617, wps=972.8, ups=0.5, wpb=1927.2, bsz=112, num_updates=42650, lr=4.265e-05, gnorm=15.216, clip=100, loss_scale=32, train_wall=99, gb_free=13, wall=89101
2025-11-08 17:38:59 | INFO | train_inner | epoch 004:   3792 / 13011 loss=0.076074, wps=1120.6, ups=0.58, wpb=1925.8, bsz=112, num_updates=42700, lr=4.27e-05, gnorm=17.668, clip=98, loss_scale=32, train_wall=86, gb_free=10.2, wall=89187
2025-11-08 17:40:39 | INFO | train_inner | epoch 004:   3842 / 13011 loss=0.084024, wps=953.4, ups=0.5, wpb=1896.1, bsz=112, num_updates=42750, lr=4.275e-05, gnorm=16.701, clip=100, loss_scale=32, train_wall=99, gb_free=17.9, wall=89286
2025-11-08 17:42:28 | INFO | train_inner | epoch 004:   3892 / 13011 loss=0.079825, wps=868.2, ups=0.46, wpb=1889.5, bsz=112, num_updates=42800, lr=4.28e-05, gnorm=19.635, clip=100, loss_scale=32, train_wall=109, gb_free=18.4, wall=89395
2025-11-08 17:44:20 | INFO | train_inner | epoch 004:   3942 / 13011 loss=0.076224, wps=849.3, ups=0.45, wpb=1902.4, bsz=112, num_updates=42850, lr=4.285e-05, gnorm=18.269, clip=100, loss_scale=32, train_wall=112, gb_free=19, wall=89507
2025-11-08 17:46:33 | INFO | train_inner | epoch 004:   3992 / 13011 loss=0.082466, wps=717.2, ups=0.37, wpb=1917.8, bsz=112, num_updates=42900, lr=4.29e-05, gnorm=15.405, clip=100, loss_scale=64, train_wall=133, gb_free=15.9, wall=89641
2025-11-08 17:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 17:48:03 | INFO | train_inner | epoch 004:   4043 / 13011 loss=0.086583, wps=1082.6, ups=0.56, wpb=1937.9, bsz=112, num_updates=42950, lr=4.295e-05, gnorm=19.093, clip=100, loss_scale=32, train_wall=89, gb_free=17.5, wall=89730
2025-11-08 17:50:02 | INFO | train_inner | epoch 004:   4093 / 13011 loss=0.083862, wps=818.8, ups=0.42, wpb=1954.5, bsz=112, num_updates=43000, lr=4.3e-05, gnorm=20.174, clip=100, loss_scale=32, train_wall=119, gb_free=12.1, wall=89850
2025-11-08 17:50:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 17:51:15 | INFO | train_inner | epoch 004:   4144 / 13011 loss=0.083401, wps=1325, ups=0.69, wpb=1917.8, bsz=112, num_updates=43050, lr=4.305e-05, gnorm=26.742, clip=100, loss_scale=16, train_wall=72, gb_free=15.4, wall=89922
2025-11-08 17:52:53 | INFO | train_inner | epoch 004:   4194 / 13011 loss=0.082908, wps=975.4, ups=0.51, wpb=1918, bsz=112, num_updates=43100, lr=4.31e-05, gnorm=18.074, clip=100, loss_scale=16, train_wall=98, gb_free=14.5, wall=90020
2025-11-08 17:54:40 | INFO | train_inner | epoch 004:   4244 / 13011 loss=0.078042, wps=906.1, ups=0.47, wpb=1941.8, bsz=112, num_updates=43150, lr=4.315e-05, gnorm=15.457, clip=100, loss_scale=16, train_wall=107, gb_free=18.1, wall=90128
2025-11-08 17:56:37 | INFO | train_inner | epoch 004:   4294 / 13011 loss=0.080174, wps=831.5, ups=0.43, wpb=1950, bsz=112, num_updates=43200, lr=4.32e-05, gnorm=20.006, clip=100, loss_scale=16, train_wall=117, gb_free=15.1, wall=90245
2025-11-08 17:58:18 | INFO | train_inner | epoch 004:   4344 / 13011 loss=0.07838, wps=958.6, ups=0.5, wpb=1923.7, bsz=112, num_updates=43250, lr=4.325e-05, gnorm=22.614, clip=100, loss_scale=16, train_wall=100, gb_free=9.8, wall=90345
2025-11-08 17:59:39 | INFO | train_inner | epoch 004:   4394 / 13011 loss=0.078355, wps=1179.2, ups=0.62, wpb=1913.5, bsz=112, num_updates=43300, lr=4.33e-05, gnorm=16.04, clip=100, loss_scale=32, train_wall=81, gb_free=11.7, wall=90426
2025-11-08 18:00:47 | INFO | train_inner | epoch 004:   4444 / 13011 loss=0.079618, wps=1407.9, ups=0.73, wpb=1924.8, bsz=112, num_updates=43350, lr=4.335e-05, gnorm=16.308, clip=100, loss_scale=32, train_wall=68, gb_free=18.2, wall=90495
2025-11-08 18:03:06 | INFO | train_inner | epoch 004:   4494 / 13011 loss=0.075172, wps=693.9, ups=0.36, wpb=1929.5, bsz=112, num_updates=43400, lr=4.34e-05, gnorm=17.525, clip=100, loss_scale=32, train_wall=139, gb_free=17.9, wall=90634
2025-11-08 18:04:45 | INFO | train_inner | epoch 004:   4544 / 13011 loss=0.080639, wps=958.2, ups=0.51, wpb=1886.3, bsz=112, num_updates=43450, lr=4.345e-05, gnorm=20.814, clip=100, loss_scale=32, train_wall=98, gb_free=17.3, wall=90732
2025-11-08 18:04:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 18:06:22 | INFO | train_inner | epoch 004:   4595 / 13011 loss=0.075138, wps=978.5, ups=0.51, wpb=1902.5, bsz=112, num_updates=43500, lr=4.35e-05, gnorm=14.888, clip=100, loss_scale=16, train_wall=97, gb_free=15.8, wall=90829
2025-11-08 18:07:57 | INFO | train_inner | epoch 004:   4645 / 13011 loss=0.081829, wps=1022.5, ups=0.52, wpb=1950.5, bsz=112, num_updates=43550, lr=4.355e-05, gnorm=17.356, clip=100, loss_scale=16, train_wall=95, gb_free=16.3, wall=90925
2025-11-08 18:09:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 18:09:58 | INFO | train_inner | epoch 004:   4696 / 13011 loss=0.074539, wps=790.7, ups=0.42, wpb=1903.9, bsz=112, num_updates=43600, lr=4.36e-05, gnorm=14.643, clip=100, loss_scale=8, train_wall=120, gb_free=18.7, wall=91045
2025-11-08 18:11:27 | INFO | train_inner | epoch 004:   4746 / 13011 loss=0.075922, wps=1038.4, ups=0.56, wpb=1857.3, bsz=112, num_updates=43650, lr=4.365e-05, gnorm=14.516, clip=100, loss_scale=8, train_wall=89, gb_free=18.5, wall=91135
2025-11-08 18:13:23 | INFO | train_inner | epoch 004:   4796 / 13011 loss=0.075187, wps=830.2, ups=0.43, wpb=1929.9, bsz=112, num_updates=43700, lr=4.37e-05, gnorm=15.473, clip=100, loss_scale=8, train_wall=116, gb_free=15.8, wall=91251
2025-11-08 18:15:01 | INFO | train_inner | epoch 004:   4846 / 13011 loss=0.081913, wps=974.6, ups=0.51, wpb=1903.7, bsz=112, num_updates=43750, lr=4.375e-05, gnorm=19.372, clip=100, loss_scale=8, train_wall=97, gb_free=13.5, wall=91348
2025-11-08 18:16:31 | INFO | train_inner | epoch 004:   4896 / 13011 loss=0.077204, wps=1067.7, ups=0.56, wpb=1919.1, bsz=112, num_updates=43800, lr=4.38e-05, gnorm=14.755, clip=100, loss_scale=8, train_wall=90, gb_free=18.9, wall=91438
2025-11-08 18:18:27 | INFO | train_inner | epoch 004:   4946 / 13011 loss=0.070984, wps=813.4, ups=0.43, wpb=1885.4, bsz=112, num_updates=43850, lr=4.385e-05, gnorm=24.848, clip=100, loss_scale=8, train_wall=116, gb_free=17.9, wall=91554
2025-11-08 18:19:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 18:19:57 | INFO | train_inner | epoch 004:   4997 / 13011 loss=0.080624, wps=1085.3, ups=0.55, wpb=1963.1, bsz=112, num_updates=43900, lr=4.39e-05, gnorm=14.992, clip=100, loss_scale=8, train_wall=86, gb_free=17.1, wall=91645
2025-11-08 18:21:28 | INFO | train_inner | epoch 004:   5047 / 13011 loss=0.078531, wps=1055.7, ups=0.55, wpb=1914.5, bsz=112, num_updates=43950, lr=4.395e-05, gnorm=14.349, clip=100, loss_scale=8, train_wall=90, gb_free=12.2, wall=91735
2025-11-08 18:23:10 | INFO | train_inner | epoch 004:   5097 / 13011 loss=0.082886, wps=921.5, ups=0.49, wpb=1874.9, bsz=112, num_updates=44000, lr=4.4e-05, gnorm=15.625, clip=100, loss_scale=8, train_wall=101, gb_free=18.6, wall=91837
2025-11-08 18:25:09 | INFO | train_inner | epoch 004:   5147 / 13011 loss=0.080785, wps=781.2, ups=0.42, wpb=1856, bsz=112, num_updates=44050, lr=4.405e-05, gnorm=16.415, clip=100, loss_scale=8, train_wall=119, gb_free=17.6, wall=91956
2025-11-08 18:26:53 | INFO | train_inner | epoch 004:   5197 / 13011 loss=0.082646, wps=916.3, ups=0.48, wpb=1910.2, bsz=112, num_updates=44100, lr=4.41e-05, gnorm=17.673, clip=100, loss_scale=8, train_wall=104, gb_free=16.6, wall=92060
2025-11-08 18:28:17 | INFO | train_inner | epoch 004:   5247 / 13011 loss=0.078688, wps=1136.5, ups=0.59, wpb=1920.1, bsz=112, num_updates=44150, lr=4.415e-05, gnorm=14.585, clip=100, loss_scale=16, train_wall=84, gb_free=17.8, wall=92145
2025-11-08 18:29:48 | INFO | train_inner | epoch 004:   5297 / 13011 loss=0.072787, wps=1043.5, ups=0.55, wpb=1900, bsz=112, num_updates=44200, lr=4.42e-05, gnorm=17.22, clip=100, loss_scale=16, train_wall=91, gb_free=18.4, wall=92236
2025-11-08 18:31:16 | INFO | train_inner | epoch 004:   5347 / 13011 loss=0.086005, wps=1079.9, ups=0.57, wpb=1900.4, bsz=112, num_updates=44250, lr=4.425e-05, gnorm=19.676, clip=100, loss_scale=16, train_wall=88, gb_free=17.8, wall=92324
2025-11-08 18:33:08 | INFO | train_inner | epoch 004:   5397 / 13011 loss=0.078059, wps=854.9, ups=0.45, wpb=1902.2, bsz=112, num_updates=44300, lr=4.43e-05, gnorm=15.884, clip=100, loss_scale=16, train_wall=111, gb_free=19, wall=92435
2025-11-08 18:35:04 | INFO | train_inner | epoch 004:   5447 / 13011 loss=0.075471, wps=819.6, ups=0.43, wpb=1908.7, bsz=112, num_updates=44350, lr=4.435e-05, gnorm=18.785, clip=100, loss_scale=16, train_wall=116, gb_free=14.6, wall=92551
2025-11-08 18:36:28 | INFO | train_inner | epoch 004:   5497 / 13011 loss=0.06873, wps=1163.5, ups=0.6, wpb=1945, bsz=112, num_updates=44400, lr=4.44e-05, gnorm=15.627, clip=100, loss_scale=32, train_wall=83, gb_free=17.3, wall=92635
2025-11-08 18:37:56 | INFO | train_inner | epoch 004:   5547 / 13011 loss=0.069969, wps=1086.8, ups=0.57, wpb=1913.5, bsz=112, num_updates=44450, lr=4.445e-05, gnorm=15.908, clip=100, loss_scale=32, train_wall=88, gb_free=18.4, wall=92723
2025-11-08 18:39:45 | INFO | train_inner | epoch 004:   5597 / 13011 loss=0.07673, wps=879.4, ups=0.46, wpb=1922.3, bsz=112, num_updates=44500, lr=4.45e-05, gnorm=14.809, clip=100, loss_scale=32, train_wall=109, gb_free=16.8, wall=92832
2025-11-08 18:41:06 | INFO | train_inner | epoch 004:   5647 / 13011 loss=0.080016, wps=1159.1, ups=0.61, wpb=1887.2, bsz=112, num_updates=44550, lr=4.455e-05, gnorm=15.98, clip=100, loss_scale=32, train_wall=81, gb_free=14.5, wall=92914
2025-11-08 18:42:56 | INFO | train_inner | epoch 004:   5697 / 13011 loss=0.074893, wps=859, ups=0.46, wpb=1886.3, bsz=112, num_updates=44600, lr=4.46e-05, gnorm=13.9, clip=100, loss_scale=32, train_wall=110, gb_free=14, wall=93023
2025-11-08 18:44:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 18:44:38 | INFO | train_inner | epoch 004:   5748 / 13011 loss=0.081896, wps=946.5, ups=0.49, wpb=1921.9, bsz=112, num_updates=44650, lr=4.465e-05, gnorm=19.314, clip=100, loss_scale=32, train_wall=101, gb_free=13.6, wall=93125
2025-11-08 18:46:14 | INFO | train_inner | epoch 004:   5798 / 13011 loss=0.071559, wps=1013.5, ups=0.52, wpb=1951.6, bsz=112, num_updates=44700, lr=4.47e-05, gnorm=15.348, clip=98, loss_scale=32, train_wall=96, gb_free=18, wall=93221
2025-11-08 18:48:02 | INFO | train_inner | epoch 004:   5848 / 13011 loss=0.075161, wps=889.6, ups=0.46, wpb=1921.9, bsz=112, num_updates=44750, lr=4.475e-05, gnorm=15.745, clip=100, loss_scale=32, train_wall=108, gb_free=17.8, wall=93329
2025-11-08 18:48:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 18:49:12 | INFO | train_inner | epoch 004:   5899 / 13011 loss=0.077319, wps=1373.9, ups=0.71, wpb=1930.1, bsz=112, num_updates=44800, lr=4.48e-05, gnorm=17.784, clip=100, loss_scale=16, train_wall=70, gb_free=13.2, wall=93400
2025-11-08 18:51:18 | INFO | train_inner | epoch 004:   5949 / 13011 loss=0.076157, wps=751.3, ups=0.4, wpb=1897.6, bsz=111.9, num_updates=44850, lr=4.485e-05, gnorm=14.957, clip=100, loss_scale=16, train_wall=126, gb_free=16.8, wall=93526
2025-11-08 18:52:43 | INFO | train_inner | epoch 004:   5999 / 13011 loss=0.080149, wps=1138.9, ups=0.59, wpb=1930.8, bsz=112, num_updates=44900, lr=4.49e-05, gnorm=15.345, clip=100, loss_scale=16, train_wall=85, gb_free=14.4, wall=93611
2025-11-08 18:54:19 | INFO | train_inner | epoch 004:   6049 / 13011 loss=0.077274, wps=1000.4, ups=0.52, wpb=1908, bsz=112, num_updates=44950, lr=4.495e-05, gnorm=21.032, clip=100, loss_scale=16, train_wall=95, gb_free=18.5, wall=93706
2025-11-08 18:55:48 | INFO | train_inner | epoch 004:   6099 / 13011 loss=0.074501, wps=1078.1, ups=0.56, wpb=1935.5, bsz=112, num_updates=45000, lr=4.5e-05, gnorm=15.663, clip=100, loss_scale=16, train_wall=90, gb_free=18.1, wall=93796
2025-11-08 18:57:38 | INFO | train_inner | epoch 004:   6149 / 13011 loss=0.081828, wps=874.6, ups=0.46, wpb=1920.6, bsz=112, num_updates=45050, lr=4.505e-05, gnorm=17.374, clip=100, loss_scale=32, train_wall=110, gb_free=17, wall=93906
2025-11-08 18:58:47 | INFO | train_inner | epoch 004:   6199 / 13011 loss=0.072317, wps=1391.3, ups=0.73, wpb=1912.1, bsz=112, num_updates=45100, lr=4.51e-05, gnorm=13.702, clip=100, loss_scale=32, train_wall=68, gb_free=18.9, wall=93974
2025-11-08 19:00:23 | INFO | train_inner | epoch 004:   6249 / 13011 loss=0.074545, wps=1016.2, ups=0.52, wpb=1952.7, bsz=112, num_updates=45150, lr=4.515e-05, gnorm=16.236, clip=100, loss_scale=32, train_wall=96, gb_free=15.9, wall=94070
2025-11-08 19:01:55 | INFO | train_inner | epoch 004:   6299 / 13011 loss=0.073132, wps=1035, ups=0.54, wpb=1907.4, bsz=112, num_updates=45200, lr=4.52e-05, gnorm=13.106, clip=100, loss_scale=32, train_wall=92, gb_free=18.9, wall=94163
2025-11-08 19:03:30 | INFO | train_inner | epoch 004:   6349 / 13011 loss=0.081273, wps=1011.3, ups=0.53, wpb=1913.1, bsz=112, num_updates=45250, lr=4.525e-05, gnorm=17.773, clip=100, loss_scale=32, train_wall=94, gb_free=15.8, wall=94257
2025-11-08 19:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-08 19:04:45 | INFO | train_inner | epoch 004:   6400 / 13011 loss=0.079501, wps=1274.6, ups=0.66, wpb=1922.6, bsz=112, num_updates=45300, lr=4.53e-05, gnorm=16.038, clip=100, loss_scale=32, train_wall=75, gb_free=16.2, wall=94333
2025-11-08 19:06:42 | INFO | train_inner | epoch 004:   6450 / 13011 loss=0.083999, wps=830.8, ups=0.43, wpb=1934.8, bsz=112, num_updates=45350, lr=4.535e-05, gnorm=23.814, clip=100, loss_scale=32, train_wall=116, gb_free=16.2, wall=94449
2025-11-08 19:07:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 19:08:17 | INFO | train_inner | epoch 004:   6501 / 13011 loss=0.081456, wps=1002.8, ups=0.52, wpb=1918.1, bsz=112, num_updates=45400, lr=4.54e-05, gnorm=16.169, clip=100, loss_scale=16, train_wall=95, gb_free=18.8, wall=94545
2025-11-08 19:09:57 | INFO | train_inner | epoch 004:   6551 / 13011 loss=0.080461, wps=950.8, ups=0.5, wpb=1889.9, bsz=112, num_updates=45450, lr=4.545e-05, gnorm=17.661, clip=100, loss_scale=16, train_wall=99, gb_free=18.6, wall=94644
2025-11-08 19:11:40 | INFO | train_inner | epoch 004:   6601 / 13011 loss=0.079784, wps=919.4, ups=0.48, wpb=1901.6, bsz=112, num_updates=45500, lr=4.55e-05, gnorm=18.898, clip=100, loss_scale=16, train_wall=103, gb_free=18.1, wall=94747
2025-11-08 19:11:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 19:13:19 | INFO | train_inner | epoch 004:   6652 / 13011 loss=0.077375, wps=973.4, ups=0.51, wpb=1925.6, bsz=112, num_updates=45550, lr=4.555e-05, gnorm=16.147, clip=100, loss_scale=8, train_wall=99, gb_free=17.9, wall=94846
2025-11-08 19:15:13 | INFO | train_inner | epoch 004:   6702 / 13011 loss=0.076779, wps=855.9, ups=0.44, wpb=1953.7, bsz=112, num_updates=45600, lr=4.56e-05, gnorm=15.61, clip=100, loss_scale=8, train_wall=114, gb_free=14.9, wall=94960
2025-11-08 19:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 19:16:49 | INFO | train_inner | epoch 004:   6753 / 13011 loss=0.082061, wps=988.4, ups=0.52, wpb=1901.6, bsz=112, num_updates=45650, lr=4.565e-05, gnorm=15.036, clip=100, loss_scale=4, train_wall=96, gb_free=16.4, wall=95057
2025-11-08 19:18:19 | INFO | train_inner | epoch 004:   6803 / 13011 loss=0.067729, wps=1061.8, ups=0.56, wpb=1900.1, bsz=112, num_updates=45700, lr=4.57e-05, gnorm=16.79, clip=100, loss_scale=4, train_wall=89, gb_free=17.2, wall=95146
2025-11-08 19:19:54 | INFO | train_inner | epoch 004:   6853 / 13011 loss=0.084516, wps=1004.8, ups=0.53, wpb=1913.1, bsz=112, num_updates=45750, lr=4.575e-05, gnorm=16.695, clip=100, loss_scale=4, train_wall=95, gb_free=18.2, wall=95241
2025-11-08 19:21:05 | INFO | train_inner | epoch 004:   6903 / 13011 loss=0.074879, wps=1326.1, ups=0.7, wpb=1891.4, bsz=112, num_updates=45800, lr=4.58e-05, gnorm=15.894, clip=100, loss_scale=4, train_wall=71, gb_free=17.1, wall=95313
2025-11-08 19:22:50 | INFO | train_inner | epoch 004:   6953 / 13011 loss=0.07985, wps=912.8, ups=0.48, wpb=1904.2, bsz=112, num_updates=45850, lr=4.585e-05, gnorm=18.223, clip=100, loss_scale=4, train_wall=104, gb_free=18.5, wall=95417
2025-11-08 19:24:07 | INFO | train_inner | epoch 004:   7003 / 13011 loss=0.076101, wps=1246, ups=0.64, wpb=1934.8, bsz=112, num_updates=45900, lr=4.59e-05, gnorm=18.877, clip=100, loss_scale=8, train_wall=77, gb_free=17.8, wall=95495
2025-11-08 19:25:34 | INFO | train_inner | epoch 004:   7053 / 13011 loss=0.071737, wps=1088.5, ups=0.58, wpb=1889.6, bsz=112, num_updates=45950, lr=4.595e-05, gnorm=12.932, clip=100, loss_scale=8, train_wall=87, gb_free=9.2, wall=95581
2025-11-08 19:27:14 | INFO | train_inner | epoch 004:   7103 / 13011 loss=0.072151, wps=961.9, ups=0.5, wpb=1920.9, bsz=112, num_updates=46000, lr=4.6e-05, gnorm=13.677, clip=100, loss_scale=8, train_wall=100, gb_free=17.1, wall=95681
2025-11-08 19:27:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 19:29:01 | INFO | train_inner | epoch 004:   7154 / 13011 loss=0.073621, wps=897.7, ups=0.47, wpb=1922.5, bsz=112, num_updates=46050, lr=4.605e-05, gnorm=17.202, clip=100, loss_scale=4, train_wall=107, gb_free=18.6, wall=95788
2025-11-08 19:30:39 | INFO | train_inner | epoch 004:   7204 / 13011 loss=0.078352, wps=974.4, ups=0.51, wpb=1908.6, bsz=112, num_updates=46100, lr=4.61e-05, gnorm=18.094, clip=100, loss_scale=4, train_wall=98, gb_free=16.8, wall=95886
2025-11-08 19:32:10 | INFO | train_inner | epoch 004:   7254 / 13011 loss=0.07342, wps=1057.9, ups=0.55, wpb=1920.1, bsz=112, num_updates=46150, lr=4.615e-05, gnorm=13.658, clip=100, loss_scale=4, train_wall=91, gb_free=14.8, wall=95977
2025-11-08 19:33:44 | INFO | train_inner | epoch 004:   7304 / 13011 loss=0.071925, wps=1010.3, ups=0.53, wpb=1906.5, bsz=112, num_updates=46200, lr=4.62e-05, gnorm=19.385, clip=100, loss_scale=4, train_wall=94, gb_free=19.1, wall=96071
2025-11-08 19:35:22 | INFO | train_inner | epoch 004:   7354 / 13011 loss=0.07686, wps=985.2, ups=0.51, wpb=1922.8, bsz=112, num_updates=46250, lr=4.625e-05, gnorm=20.321, clip=98, loss_scale=4, train_wall=97, gb_free=12.7, wall=96169
2025-11-08 19:36:50 | INFO | train_inner | epoch 004:   7404 / 13011 loss=0.073692, wps=1086.4, ups=0.57, wpb=1916.3, bsz=112, num_updates=46300, lr=4.63e-05, gnorm=16.35, clip=100, loss_scale=8, train_wall=88, gb_free=18.8, wall=96257
2025-11-08 19:38:28 | INFO | train_inner | epoch 004:   7454 / 13011 loss=0.067359, wps=964.3, ups=0.51, wpb=1901.6, bsz=112, num_updates=46350, lr=4.635e-05, gnorm=14.465, clip=100, loss_scale=8, train_wall=98, gb_free=15.9, wall=96356
2025-11-08 19:40:30 | INFO | train_inner | epoch 004:   7504 / 13011 loss=0.076644, wps=791.9, ups=0.41, wpb=1928.7, bsz=112, num_updates=46400, lr=4.64e-05, gnorm=13.162, clip=98, loss_scale=8, train_wall=122, gb_free=17.9, wall=96478
2025-11-08 19:41:31 | INFO | train_inner | epoch 004:   7554 / 13011 loss=0.076774, wps=1584.5, ups=0.82, wpb=1930.1, bsz=112, num_updates=46450, lr=4.645e-05, gnorm=12.963, clip=100, loss_scale=8, train_wall=61, gb_free=10.3, wall=96539
2025-11-08 19:43:11 | INFO | train_inner | epoch 004:   7604 / 13011 loss=0.078489, wps=962.1, ups=0.5, wpb=1914.8, bsz=112, num_updates=46500, lr=4.65e-05, gnorm=15.298, clip=100, loss_scale=8, train_wall=99, gb_free=14.2, wall=96638
2025-11-08 19:44:31 | INFO | train_inner | epoch 004:   7654 / 13011 loss=0.07437, wps=1186.5, ups=0.62, wpb=1908.1, bsz=112, num_updates=46550, lr=4.655e-05, gnorm=14.772, clip=100, loss_scale=16, train_wall=80, gb_free=18.4, wall=96718
2025-11-08 19:46:11 | INFO | train_inner | epoch 004:   7704 / 13011 loss=0.070305, wps=948.1, ups=0.5, wpb=1904, bsz=112, num_updates=46600, lr=4.66e-05, gnorm=14.266, clip=98, loss_scale=16, train_wall=100, gb_free=17, wall=96819
2025-11-08 19:47:38 | INFO | train_inner | epoch 004:   7754 / 13011 loss=0.067256, wps=1106.4, ups=0.58, wpb=1913.9, bsz=112, num_updates=46650, lr=4.665e-05, gnorm=15.398, clip=100, loss_scale=16, train_wall=86, gb_free=16.6, wall=96905
2025-11-08 19:49:16 | INFO | train_inner | epoch 004:   7804 / 13011 loss=0.068338, wps=997.1, ups=0.51, wpb=1959.4, bsz=112, num_updates=46700, lr=4.67e-05, gnorm=15.055, clip=100, loss_scale=16, train_wall=98, gb_free=17.1, wall=97004
2025-11-08 19:51:07 | INFO | train_inner | epoch 004:   7854 / 13011 loss=0.068964, wps=871.7, ups=0.45, wpb=1928.2, bsz=112, num_updates=46750, lr=4.675e-05, gnorm=13.448, clip=100, loss_scale=16, train_wall=110, gb_free=14.7, wall=97114
2025-11-08 19:51:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 19:52:52 | INFO | train_inner | epoch 004:   7905 / 13011 loss=0.066923, wps=921.4, ups=0.47, wpb=1941.4, bsz=112, num_updates=46800, lr=4.68e-05, gnorm=12.145, clip=100, loss_scale=16, train_wall=105, gb_free=17.9, wall=97220
2025-11-08 19:54:08 | INFO | train_inner | epoch 004:   7955 / 13011 loss=0.079835, wps=1271.9, ups=0.66, wpb=1940.7, bsz=112, num_updates=46850, lr=4.685e-05, gnorm=17.515, clip=100, loss_scale=16, train_wall=76, gb_free=18.8, wall=97296
2025-11-08 19:55:48 | INFO | train_inner | epoch 004:   8005 / 13011 loss=0.083001, wps=970.3, ups=0.5, wpb=1941.3, bsz=112, num_updates=46900, lr=4.69e-05, gnorm=19.562, clip=100, loss_scale=16, train_wall=100, gb_free=18.2, wall=97396
2025-11-08 19:57:29 | INFO | train_inner | epoch 004:   8055 / 13011 loss=0.08056, wps=935.1, ups=0.5, wpb=1878.4, bsz=112, num_updates=46950, lr=4.695e-05, gnorm=14.357, clip=100, loss_scale=16, train_wall=100, gb_free=18.5, wall=97496
2025-11-08 19:58:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 19:59:05 | INFO | train_inner | epoch 004:   8106 / 13011 loss=0.080446, wps=1003.6, ups=0.52, wpb=1919, bsz=112, num_updates=47000, lr=4.7e-05, gnorm=20.124, clip=100, loss_scale=8, train_wall=95, gb_free=18.3, wall=97592
2025-11-08 20:00:25 | INFO | train_inner | epoch 004:   8156 / 13011 loss=0.074791, wps=1188.3, ups=0.62, wpb=1914.3, bsz=112, num_updates=47050, lr=4.705e-05, gnorm=17.576, clip=100, loss_scale=8, train_wall=80, gb_free=18.1, wall=97672
2025-11-08 20:01:58 | INFO | train_inner | epoch 004:   8206 / 13011 loss=0.07455, wps=1022.4, ups=0.54, wpb=1895, bsz=112, num_updates=47100, lr=4.71e-05, gnorm=18.278, clip=100, loss_scale=8, train_wall=92, gb_free=18.2, wall=97765
2025-11-08 20:03:36 | INFO | train_inner | epoch 004:   8256 / 13011 loss=0.07175, wps=970.5, ups=0.51, wpb=1907.4, bsz=112, num_updates=47150, lr=4.715e-05, gnorm=13.769, clip=100, loss_scale=8, train_wall=97, gb_free=9.6, wall=97863
2025-11-08 20:04:57 | INFO | train_inner | epoch 004:   8306 / 13011 loss=0.066501, wps=1182.7, ups=0.62, wpb=1907.5, bsz=112, num_updates=47200, lr=4.72e-05, gnorm=18.217, clip=98, loss_scale=8, train_wall=80, gb_free=18, wall=97944
2025-11-08 20:06:14 | INFO | train_inner | epoch 004:   8356 / 13011 loss=0.072799, wps=1224.1, ups=0.65, wpb=1885.6, bsz=112, num_updates=47250, lr=4.725e-05, gnorm=17.137, clip=100, loss_scale=16, train_wall=77, gb_free=18.1, wall=98021
2025-11-08 20:07:52 | INFO | train_inner | epoch 004:   8406 / 13011 loss=0.075972, wps=973.2, ups=0.51, wpb=1909.8, bsz=112, num_updates=47300, lr=4.73e-05, gnorm=16.74, clip=100, loss_scale=16, train_wall=98, gb_free=19.1, wall=98119
2025-11-08 20:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 20:09:51 | INFO | train_inner | epoch 004:   8457 / 13011 loss=0.074485, wps=800.2, ups=0.42, wpb=1911.5, bsz=112, num_updates=47350, lr=4.735e-05, gnorm=17.796, clip=100, loss_scale=8, train_wall=119, gb_free=15.3, wall=98239
2025-11-08 20:11:15 | INFO | train_inner | epoch 004:   8507 / 13011 loss=0.074806, wps=1130.8, ups=0.59, wpb=1901.6, bsz=112, num_updates=47400, lr=4.74e-05, gnorm=25.494, clip=100, loss_scale=8, train_wall=84, gb_free=18, wall=98323
2025-11-08 20:13:17 | INFO | train_inner | epoch 004:   8557 / 13011 loss=0.074453, wps=818.7, ups=0.43, wpb=1903.2, bsz=112, num_updates=47450, lr=4.745e-05, gnorm=15.738, clip=100, loss_scale=8, train_wall=116, gb_free=18.2, wall=98439
2025-11-08 20:13:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 20:14:52 | INFO | train_inner | epoch 004:   8608 / 13011 loss=0.077722, wps=1012.2, ups=0.53, wpb=1920.9, bsz=112, num_updates=47500, lr=4.75e-05, gnorm=15.643, clip=100, loss_scale=4, train_wall=95, gb_free=17.5, wall=98540
2025-11-08 20:16:19 | INFO | train_inner | epoch 004:   8658 / 13011 loss=0.080805, wps=1081, ups=0.57, wpb=1885, bsz=112, num_updates=47550, lr=4.755e-05, gnorm=18.974, clip=100, loss_scale=4, train_wall=87, gb_free=18.4, wall=98627
2025-11-08 20:18:15 | INFO | train_inner | epoch 004:   8708 / 13011 loss=0.071892, wps=833.9, ups=0.43, wpb=1922.7, bsz=112, num_updates=47600, lr=4.76e-05, gnorm=15.426, clip=100, loss_scale=4, train_wall=115, gb_free=14.2, wall=98742
2025-11-08 20:19:38 | INFO | train_inner | epoch 004:   8758 / 13011 loss=0.075644, wps=1128.1, ups=0.6, wpb=1880.3, bsz=112, num_updates=47650, lr=4.765e-05, gnorm=18.306, clip=100, loss_scale=4, train_wall=83, gb_free=18.9, wall=98825
2025-11-08 20:21:18 | INFO | train_inner | epoch 004:   8808 / 13011 loss=0.08442, wps=943.4, ups=0.5, wpb=1891.8, bsz=112, num_updates=47700, lr=4.77e-05, gnorm=18.459, clip=100, loss_scale=4, train_wall=100, gb_free=18.5, wall=98926
2025-11-08 20:22:59 | INFO | train_inner | epoch 004:   8858 / 13011 loss=0.096926, wps=949.5, ups=0.5, wpb=1915.1, bsz=112, num_updates=47750, lr=4.775e-05, gnorm=29.143, clip=100, loss_scale=8, train_wall=101, gb_free=17.9, wall=99026
2025-11-08 20:24:35 | INFO | train_inner | epoch 004:   8908 / 13011 loss=0.085258, wps=1004.4, ups=0.52, wpb=1918.1, bsz=112, num_updates=47800, lr=4.78e-05, gnorm=15.931, clip=100, loss_scale=8, train_wall=95, gb_free=19.8, wall=99122
2025-11-08 20:25:50 | INFO | train_inner | epoch 004:   8958 / 13011 loss=0.077631, wps=1280.8, ups=0.67, wpb=1925.3, bsz=112, num_updates=47850, lr=4.785e-05, gnorm=14.84, clip=100, loss_scale=8, train_wall=75, gb_free=10.7, wall=99197
2025-11-08 20:27:21 | INFO | train_inner | epoch 004:   9008 / 13011 loss=0.085475, wps=1055.8, ups=0.55, wpb=1924.6, bsz=112, num_updates=47900, lr=4.79e-05, gnorm=23.777, clip=100, loss_scale=8, train_wall=91, gb_free=18.6, wall=99288
2025-11-08 20:28:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 20:28:46 | INFO | train_inner | epoch 004:   9059 / 13011 loss=0.131521, wps=1128.3, ups=0.59, wpb=1919.3, bsz=112, num_updates=47950, lr=4.795e-05, gnorm=50.061, clip=100, loss_scale=4, train_wall=85, gb_free=18.5, wall=99373
2025-11-08 20:30:14 | INFO | train_inner | epoch 004:   9109 / 13011 loss=0.111955, wps=1099.9, ups=0.57, wpb=1940.1, bsz=112, num_updates=48000, lr=4.8e-05, gnorm=18.36, clip=100, loss_scale=4, train_wall=88, gb_free=18.3, wall=99462
2025-11-08 20:31:41 | INFO | train_inner | epoch 004:   9159 / 13011 loss=0.079648, wps=1113, ups=0.57, wpb=1943.6, bsz=112, num_updates=48050, lr=4.805e-05, gnorm=16.447, clip=100, loss_scale=4, train_wall=87, gb_free=17.3, wall=99549
2025-11-08 20:33:36 | INFO | train_inner | epoch 004:   9209 / 13011 loss=0.086134, wps=825.2, ups=0.44, wpb=1890.2, bsz=112, num_updates=48100, lr=4.81e-05, gnorm=22.503, clip=100, loss_scale=4, train_wall=114, gb_free=16.4, wall=99663
2025-11-08 20:34:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2025-11-08 20:34:46 | INFO | train_inner | epoch 004:   9260 / 13011 loss=0.089851, wps=1376, ups=0.72, wpb=1922.2, bsz=112, num_updates=48150, lr=4.815e-05, gnorm=21.689, clip=100, loss_scale=2, train_wall=70, gb_free=18.4, wall=99733
2025-11-08 20:36:36 | INFO | train_inner | epoch 004:   9310 / 13011 loss=0.087498, wps=875.1, ups=0.45, wpb=1937, bsz=112, num_updates=48200, lr=4.82e-05, gnorm=20.549, clip=98, loss_scale=2, train_wall=110, gb_free=19.2, wall=99844
2025-11-08 20:37:37 | INFO | train_inner | epoch 004:   9360 / 13011 loss=0.078658, wps=1588.5, ups=0.83, wpb=1924.6, bsz=112, num_updates=48250, lr=4.825e-05, gnorm=15.59, clip=100, loss_scale=2, train_wall=60, gb_free=18.7, wall=99904
2025-11-08 20:39:09 | INFO | train_inner | epoch 004:   9410 / 13011 loss=0.079675, wps=1039.6, ups=0.54, wpb=1913.2, bsz=112, num_updates=48300, lr=4.83e-05, gnorm=14.381, clip=100, loss_scale=2, train_wall=92, gb_free=17.9, wall=99996
2025-11-08 20:40:43 | INFO | train_inner | epoch 004:   9460 / 13011 loss=0.076754, wps=1040.4, ups=0.53, wpb=1960.3, bsz=112, num_updates=48350, lr=4.835e-05, gnorm=13.683, clip=100, loss_scale=2, train_wall=94, gb_free=16.7, wall=100091
2025-11-08 20:42:06 | INFO | train_inner | epoch 004:   9510 / 13011 loss=0.078683, wps=1141, ups=0.6, wpb=1887.1, bsz=112, num_updates=48400, lr=4.84e-05, gnorm=13.413, clip=100, loss_scale=4, train_wall=82, gb_free=18.4, wall=100173
2025-11-08 20:43:37 | INFO | train_inner | epoch 004:   9560 / 13011 loss=0.082166, wps=1044.3, ups=0.55, wpb=1900.1, bsz=112, num_updates=48450, lr=4.845e-05, gnorm=18.213, clip=100, loss_scale=4, train_wall=91, gb_free=18.5, wall=100264
2025-11-08 20:44:57 | INFO | train_inner | epoch 004:   9610 / 13011 loss=0.080307, wps=1167.3, ups=0.63, wpb=1867.4, bsz=112, num_updates=48500, lr=4.85e-05, gnorm=15.759, clip=100, loss_scale=4, train_wall=80, gb_free=16.7, wall=100344
2025-11-08 20:46:16 | INFO | train_inner | epoch 004:   9660 / 13011 loss=0.072909, wps=1217.8, ups=0.64, wpb=1917, bsz=112, num_updates=48550, lr=4.855e-05, gnorm=13.743, clip=100, loss_scale=4, train_wall=78, gb_free=19.2, wall=100423
2025-11-08 20:47:54 | INFO | train_inner | epoch 004:   9710 / 13011 loss=0.063992, wps=984.5, ups=0.51, wpb=1945.1, bsz=112, num_updates=48600, lr=4.86e-05, gnorm=14.405, clip=100, loss_scale=4, train_wall=99, gb_free=18.7, wall=100522
2025-11-08 20:49:26 | INFO | train_inner | epoch 004:   9760 / 13011 loss=0.069937, wps=1035.7, ups=0.54, wpb=1904.9, bsz=112, num_updates=48650, lr=4.865e-05, gnorm=14.835, clip=100, loss_scale=8, train_wall=92, gb_free=16.3, wall=100614
2025-11-08 20:51:07 | INFO | train_inner | epoch 004:   9810 / 13011 loss=0.066563, wps=956.6, ups=0.5, wpb=1932, bsz=112, num_updates=48700, lr=4.87e-05, gnorm=12.731, clip=100, loss_scale=8, train_wall=101, gb_free=17.4, wall=100715
2025-11-08 20:52:46 | INFO | train_inner | epoch 004:   9860 / 13011 loss=0.074134, wps=958.3, ups=0.51, wpb=1888.5, bsz=112, num_updates=48750, lr=4.875e-05, gnorm=17.473, clip=98, loss_scale=8, train_wall=98, gb_free=18.7, wall=100813
2025-11-08 20:54:22 | INFO | train_inner | epoch 004:   9910 / 13011 loss=0.08133, wps=988.4, ups=0.52, wpb=1893.1, bsz=112, num_updates=48800, lr=4.88e-05, gnorm=17.692, clip=100, loss_scale=8, train_wall=96, gb_free=19.2, wall=100909
2025-11-08 20:55:28 | INFO | train_inner | epoch 004:   9960 / 13011 loss=0.080602, wps=1467.9, ups=0.76, wpb=1935.4, bsz=112, num_updates=48850, lr=4.885e-05, gnorm=16.436, clip=100, loss_scale=8, train_wall=66, gb_free=15.5, wall=100975
2025-11-08 20:56:55 | INFO | train_inner | epoch 004:  10010 / 13011 loss=0.081125, wps=1108.4, ups=0.57, wpb=1943.4, bsz=112, num_updates=48900, lr=4.89e-05, gnorm=14.808, clip=100, loss_scale=16, train_wall=87, gb_free=16.9, wall=101063
2025-11-08 20:58:37 | INFO | train_inner | epoch 004:  10060 / 13011 loss=0.079679, wps=945.9, ups=0.49, wpb=1925.9, bsz=112, num_updates=48950, lr=4.895e-05, gnorm=20.126, clip=100, loss_scale=16, train_wall=102, gb_free=17.4, wall=101165
2025-11-08 21:00:05 | INFO | train_inner | epoch 004:  10110 / 13011 loss=0.07754, wps=1087.4, ups=0.57, wpb=1901.4, bsz=112, num_updates=49000, lr=4.9e-05, gnorm=19.031, clip=98, loss_scale=16, train_wall=87, gb_free=17.5, wall=101252
2025-11-08 21:02:02 | INFO | train_inner | epoch 004:  10160 / 13011 loss=0.073133, wps=812.7, ups=0.42, wpb=1913.8, bsz=112, num_updates=49050, lr=4.905e-05, gnorm=11.754, clip=100, loss_scale=16, train_wall=117, gb_free=19.3, wall=101370
2025-11-08 21:03:22 | INFO | train_inner | epoch 004:  10210 / 13011 loss=0.074367, wps=1215.4, ups=0.63, wpb=1930.1, bsz=112, num_updates=49100, lr=4.91e-05, gnorm=11.139, clip=100, loss_scale=16, train_wall=79, gb_free=12, wall=101449
2025-11-08 21:04:37 | INFO | train_inner | epoch 004:  10260 / 13011 loss=0.066311, wps=1279.2, ups=0.66, wpb=1923.7, bsz=112, num_updates=49150, lr=4.915e-05, gnorm=13.264, clip=100, loss_scale=32, train_wall=75, gb_free=12.9, wall=101524
2025-11-08 21:06:33 | INFO | train_inner | epoch 004:  10310 / 13011 loss=0.068785, wps=833.9, ups=0.43, wpb=1935.9, bsz=112, num_updates=49200, lr=4.92e-05, gnorm=13.029, clip=100, loss_scale=32, train_wall=116, gb_free=17.6, wall=101640
2025-11-08 21:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 21:08:26 | INFO | train_inner | epoch 004:  10361 / 13011 loss=0.076399, wps=852.5, ups=0.44, wpb=1924.5, bsz=112, num_updates=49250, lr=4.925e-05, gnorm=15.446, clip=100, loss_scale=16, train_wall=113, gb_free=18.2, wall=101753
2025-11-08 21:09:35 | INFO | train_inner | epoch 004:  10411 / 13011 loss=0.071852, wps=1387.9, ups=0.73, wpb=1911.1, bsz=112, num_updates=49300, lr=4.93e-05, gnorm=14.793, clip=98, loss_scale=16, train_wall=69, gb_free=18.3, wall=101822
2025-11-08 21:10:53 | INFO | train_inner | epoch 004:  10461 / 13011 loss=0.068229, wps=1207.9, ups=0.64, wpb=1898.9, bsz=112, num_updates=49350, lr=4.935e-05, gnorm=12.607, clip=100, loss_scale=16, train_wall=78, gb_free=19.3, wall=101901
2025-11-08 21:12:29 | INFO | train_inner | epoch 004:  10511 / 13011 loss=0.068302, wps=999.7, ups=0.52, wpb=1908.8, bsz=112, num_updates=49400, lr=4.94e-05, gnorm=15.437, clip=100, loss_scale=16, train_wall=95, gb_free=13.1, wall=101996
2025-11-08 21:13:56 | INFO | train_inner | epoch 004:  10561 / 13011 loss=0.069028, wps=1119.7, ups=0.58, wpb=1943.4, bsz=112, num_updates=49450, lr=4.945e-05, gnorm=12.795, clip=100, loss_scale=16, train_wall=87, gb_free=17.8, wall=102083
2025-11-08 21:15:34 | INFO | train_inner | epoch 004:  10611 / 13011 loss=0.063487, wps=963.6, ups=0.51, wpb=1899.6, bsz=112, num_updates=49500, lr=4.95e-05, gnorm=14.547, clip=100, loss_scale=32, train_wall=98, gb_free=16.4, wall=102182
2025-11-08 21:15:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 21:17:10 | INFO | train_inner | epoch 004:  10662 / 13011 loss=0.075979, wps=990.2, ups=0.52, wpb=1904.9, bsz=112, num_updates=49550, lr=4.955e-05, gnorm=15.687, clip=100, loss_scale=16, train_wall=96, gb_free=18, wall=102278
2025-11-08 21:18:23 | INFO | train_inner | epoch 004:  10712 / 13011 loss=0.075825, wps=1327.1, ups=0.69, wpb=1921.2, bsz=112, num_updates=49600, lr=4.96e-05, gnorm=14.019, clip=100, loss_scale=16, train_wall=72, gb_free=14.1, wall=102350
2025-11-08 21:20:37 | INFO | train_inner | epoch 004:  10762 / 13011 loss=0.070252, wps=711.1, ups=0.37, wpb=1903.3, bsz=112, num_updates=49650, lr=4.965e-05, gnorm=12.194, clip=98, loss_scale=16, train_wall=134, gb_free=16.9, wall=102484
2025-11-08 21:21:37 | INFO | train_inner | epoch 004:  10812 / 13011 loss=0.066065, wps=1605.9, ups=0.83, wpb=1934.5, bsz=112, num_updates=49700, lr=4.97e-05, gnorm=15.316, clip=98, loss_scale=16, train_wall=60, gb_free=17.7, wall=102544
2025-11-08 21:23:18 | INFO | train_inner | epoch 004:  10862 / 13011 loss=0.077752, wps=956.5, ups=0.5, wpb=1928, bsz=112, num_updates=49750, lr=4.975e-05, gnorm=18.05, clip=100, loss_scale=16, train_wall=101, gb_free=12.9, wall=102645
2025-11-08 21:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 21:24:57 | INFO | train_inner | epoch 004:  10913 / 13011 loss=0.067289, wps=975.3, ups=0.5, wpb=1946.9, bsz=112, num_updates=49800, lr=4.98e-05, gnorm=15.518, clip=100, loss_scale=16, train_wall=100, gb_free=18.1, wall=102745
2025-11-08 21:26:31 | INFO | train_inner | epoch 004:  10963 / 13011 loss=0.07479, wps=1038.2, ups=0.54, wpb=1938.5, bsz=112, num_updates=49850, lr=4.985e-05, gnorm=15.186, clip=100, loss_scale=16, train_wall=93, gb_free=18.2, wall=102838
2025-11-08 21:28:05 | INFO | train_inner | epoch 004:  11013 / 13011 loss=0.069311, wps=1019.6, ups=0.53, wpb=1927.3, bsz=112, num_updates=49900, lr=4.99e-05, gnorm=11.948, clip=100, loss_scale=16, train_wall=94, gb_free=14.3, wall=102933
2025-11-08 21:29:37 | INFO | train_inner | epoch 004:  11063 / 13011 loss=0.067342, wps=1047.5, ups=0.54, wpb=1930.4, bsz=112, num_updates=49950, lr=4.995e-05, gnorm=13.901, clip=96, loss_scale=16, train_wall=92, gb_free=18.5, wall=103025
2025-11-08 21:31:14 | INFO | train_inner | epoch 004:  11113 / 13011 loss=0.071184, wps=996.2, ups=0.52, wpb=1932.9, bsz=112, num_updates=50000, lr=5e-05, gnorm=13.379, clip=98, loss_scale=16, train_wall=97, gb_free=17.2, wall=103122
2025-11-08 21:33:22 | INFO | train_inner | epoch 004:  11163 / 13011 loss=0.072127, wps=748.8, ups=0.39, wpb=1905.7, bsz=112, num_updates=50050, lr=4.99979e-05, gnorm=15.493, clip=100, loss_scale=32, train_wall=127, gb_free=16.8, wall=103249
2025-11-08 21:34:26 | INFO | train_inner | epoch 004:  11213 / 13011 loss=0.065282, wps=1520.7, ups=0.78, wpb=1943, bsz=112, num_updates=50100, lr=4.99958e-05, gnorm=14.542, clip=98, loss_scale=32, train_wall=64, gb_free=15, wall=103313
2025-11-08 21:36:07 | INFO | train_inner | epoch 004:  11263 / 13011 loss=0.075198, wps=949.5, ups=0.49, wpb=1926.3, bsz=112, num_updates=50150, lr=4.99938e-05, gnorm=16.135, clip=100, loss_scale=32, train_wall=101, gb_free=18.5, wall=103414
2025-11-08 21:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 21:37:28 | INFO | train_inner | epoch 004:  11314 / 13011 loss=0.085284, wps=1161.8, ups=0.62, wpb=1882.4, bsz=112, num_updates=50200, lr=4.99917e-05, gnorm=16.57, clip=98, loss_scale=16, train_wall=81, gb_free=16, wall=103495
2025-11-08 21:39:00 | INFO | train_inner | epoch 004:  11364 / 13011 loss=0.073107, wps=1047.3, ups=0.54, wpb=1935.7, bsz=112, num_updates=50250, lr=4.99896e-05, gnorm=13.357, clip=100, loss_scale=16, train_wall=92, gb_free=17.3, wall=103588
2025-11-08 21:40:49 | INFO | train_inner | epoch 004:  11414 / 13011 loss=0.079736, wps=892.1, ups=0.46, wpb=1932.4, bsz=112, num_updates=50300, lr=4.99875e-05, gnorm=21.948, clip=100, loss_scale=16, train_wall=108, gb_free=17.5, wall=103696
2025-11-08 21:40:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 21:42:29 | INFO | train_inner | epoch 004:  11465 / 13011 loss=0.078511, wps=949.6, ups=0.5, wpb=1911.3, bsz=112, num_updates=50350, lr=4.99854e-05, gnorm=15.32, clip=100, loss_scale=8, train_wall=100, gb_free=12.6, wall=103797
2025-11-08 21:43:52 | INFO | train_inner | epoch 004:  11515 / 13011 loss=0.079283, wps=1171.9, ups=0.6, wpb=1945.6, bsz=112, num_updates=50400, lr=4.99833e-05, gnorm=17.486, clip=98, loss_scale=8, train_wall=83, gb_free=17.4, wall=103880
2025-11-08 21:45:15 | INFO | train_inner | epoch 004:  11565 / 13011 loss=0.07482, wps=1161.6, ups=0.61, wpb=1915.9, bsz=112, num_updates=50450, lr=4.99813e-05, gnorm=13.022, clip=100, loss_scale=8, train_wall=82, gb_free=12.8, wall=103962
2025-11-08 21:47:06 | INFO | train_inner | epoch 004:  11615 / 13011 loss=0.073987, wps=864.4, ups=0.45, wpb=1926.7, bsz=112, num_updates=50500, lr=4.99792e-05, gnorm=13.3, clip=100, loss_scale=8, train_wall=111, gb_free=15.7, wall=104074
2025-11-08 21:48:31 | INFO | train_inner | epoch 004:  11665 / 13011 loss=0.071384, wps=1149.2, ups=0.59, wpb=1939.5, bsz=112, num_updates=50550, lr=4.99771e-05, gnorm=12.087, clip=100, loss_scale=8, train_wall=84, gb_free=19, wall=104158
2025-11-08 21:50:14 | INFO | train_inner | epoch 004:  11715 / 13011 loss=0.072799, wps=928.1, ups=0.49, wpb=1913.1, bsz=112, num_updates=50600, lr=4.9975e-05, gnorm=16.256, clip=100, loss_scale=16, train_wall=103, gb_free=13.9, wall=104261
2025-11-08 21:51:24 | INFO | train_inner | epoch 004:  11765 / 13011 loss=0.07148, wps=1346.4, ups=0.71, wpb=1901.1, bsz=112, num_updates=50650, lr=4.99729e-05, gnorm=12.783, clip=100, loss_scale=16, train_wall=70, gb_free=18.2, wall=104332
2025-11-08 21:53:16 | INFO | train_inner | epoch 004:  11815 / 13011 loss=0.071195, wps=865.1, ups=0.45, wpb=1927, bsz=112, num_updates=50700, lr=4.99708e-05, gnorm=15.11, clip=98, loss_scale=16, train_wall=111, gb_free=18.2, wall=104443
2025-11-08 21:54:41 | INFO | train_inner | epoch 004:  11865 / 13011 loss=0.06381, wps=1127.7, ups=0.59, wpb=1912.7, bsz=112, num_updates=50750, lr=4.99688e-05, gnorm=11.361, clip=100, loss_scale=16, train_wall=85, gb_free=18.9, wall=104528
2025-11-08 21:56:37 | INFO | train_inner | epoch 004:  11915 / 13011 loss=0.071576, wps=813.9, ups=0.43, wpb=1894.3, bsz=112, num_updates=50800, lr=4.99667e-05, gnorm=14.573, clip=100, loss_scale=16, train_wall=116, gb_free=15.3, wall=104644
2025-11-08 21:57:39 | INFO | train_inner | epoch 004:  11965 / 13011 loss=0.064131, wps=1556.8, ups=0.8, wpb=1937.6, bsz=112, num_updates=50850, lr=4.99646e-05, gnorm=13.028, clip=100, loss_scale=32, train_wall=62, gb_free=18.9, wall=104707
2025-11-08 21:59:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 21:59:34 | INFO | train_inner | epoch 004:  12016 / 13011 loss=0.069873, wps=843.3, ups=0.44, wpb=1935.9, bsz=112, num_updates=50900, lr=4.99625e-05, gnorm=14.849, clip=100, loss_scale=16, train_wall=115, gb_free=18.3, wall=104821
2025-11-08 22:00:57 | INFO | train_inner | epoch 004:  12066 / 13011 loss=0.077946, wps=1149.6, ups=0.6, wpb=1918.9, bsz=112, num_updates=50950, lr=4.99604e-05, gnorm=19.361, clip=100, loss_scale=16, train_wall=83, gb_free=18.6, wall=104905
2025-11-08 22:02:39 | INFO | train_inner | epoch 004:  12116 / 13011 loss=0.073762, wps=938.8, ups=0.49, wpb=1910, bsz=112, num_updates=51000, lr=4.99583e-05, gnorm=16.06, clip=100, loss_scale=16, train_wall=102, gb_free=14.9, wall=105007
2025-11-08 22:03:46 | INFO | train_inner | epoch 004:  12166 / 13011 loss=0.076193, wps=1455.4, ups=0.75, wpb=1939.4, bsz=112, num_updates=51050, lr=4.99563e-05, gnorm=15.403, clip=100, loss_scale=16, train_wall=66, gb_free=11.4, wall=105073
2025-11-08 22:05:20 | INFO | train_inner | epoch 004:  12216 / 13011 loss=0.075714, wps=997.2, ups=0.53, wpb=1878, bsz=112, num_updates=51100, lr=4.99542e-05, gnorm=14.225, clip=98, loss_scale=16, train_wall=94, gb_free=15.5, wall=105167
2025-11-08 22:06:44 | INFO | train_inner | epoch 004:  12266 / 13011 loss=0.070206, wps=1130.2, ups=0.59, wpb=1901.1, bsz=112, num_updates=51150, lr=4.99521e-05, gnorm=14.789, clip=100, loss_scale=32, train_wall=84, gb_free=17.4, wall=105251
2025-11-08 22:08:58 | INFO | train_inner | epoch 004:  12316 / 13011 loss=0.072478, wps=718.1, ups=0.37, wpb=1924.5, bsz=112, num_updates=51200, lr=4.995e-05, gnorm=18.063, clip=100, loss_scale=32, train_wall=134, gb_free=15.8, wall=105385
2025-11-08 22:09:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 22:10:01 | INFO | train_inner | epoch 004:  12367 / 13011 loss=0.076104, wps=1514.3, ups=0.79, wpb=1922.2, bsz=112, num_updates=51250, lr=4.99479e-05, gnorm=14.909, clip=98, loss_scale=16, train_wall=63, gb_free=17.4, wall=105449
2025-11-08 22:11:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 22:11:36 | INFO | train_inner | epoch 004:  12418 / 13011 loss=0.068976, wps=1010.8, ups=0.53, wpb=1905, bsz=112, num_updates=51300, lr=4.99458e-05, gnorm=10.446, clip=98, loss_scale=8, train_wall=94, gb_free=16.3, wall=105543
2025-11-08 22:13:44 | INFO | train_inner | epoch 004:  12468 / 13011 loss=0.073436, wps=739, ups=0.39, wpb=1898, bsz=112, num_updates=51350, lr=4.99438e-05, gnorm=15.665, clip=98, loss_scale=8, train_wall=128, gb_free=18.5, wall=105672
2025-11-08 22:15:17 | INFO | train_inner | epoch 004:  12518 / 13011 loss=0.065803, wps=1043.2, ups=0.54, wpb=1945, bsz=112, num_updates=51400, lr=4.99417e-05, gnorm=15.002, clip=98, loss_scale=8, train_wall=93, gb_free=17.5, wall=105765
2025-11-08 22:16:41 | INFO | train_inner | epoch 004:  12568 / 13011 loss=0.066694, wps=1123.7, ups=0.6, wpb=1887.3, bsz=112, num_updates=51450, lr=4.99396e-05, gnorm=21.239, clip=98, loss_scale=8, train_wall=84, gb_free=19.1, wall=105849
2025-11-08 22:18:46 | INFO | train_inner | epoch 004:  12618 / 13011 loss=0.069615, wps=768.2, ups=0.4, wpb=1909, bsz=112, num_updates=51500, lr=4.99375e-05, gnorm=14.323, clip=98, loss_scale=8, train_wall=124, gb_free=16.7, wall=105973
2025-11-08 22:20:36 | INFO | train_inner | epoch 004:  12668 / 13011 loss=0.064085, wps=867.1, ups=0.45, wpb=1909.3, bsz=112, num_updates=51550, lr=4.99354e-05, gnorm=12.269, clip=100, loss_scale=8, train_wall=110, gb_free=17.3, wall=106083
2025-11-08 22:21:36 | INFO | train_inner | epoch 004:  12718 / 13011 loss=0.060621, wps=1594.6, ups=0.82, wpb=1935.6, bsz=112, num_updates=51600, lr=4.99333e-05, gnorm=11.333, clip=98, loss_scale=16, train_wall=60, gb_free=18.5, wall=106144
2025-11-08 22:23:22 | INFO | train_inner | epoch 004:  12768 / 13011 loss=0.061185, wps=907.4, ups=0.47, wpb=1920.9, bsz=112, num_updates=51650, lr=4.99313e-05, gnorm=12.818, clip=94, loss_scale=16, train_wall=106, gb_free=18.2, wall=106250
2025-11-08 22:25:01 | INFO | train_inner | epoch 004:  12818 / 13011 loss=0.062221, wps=962.4, ups=0.5, wpb=1908.3, bsz=112, num_updates=51700, lr=4.99292e-05, gnorm=12.292, clip=100, loss_scale=16, train_wall=99, gb_free=18.9, wall=106349
2025-11-08 22:26:34 | INFO | train_inner | epoch 004:  12868 / 13011 loss=0.074664, wps=1031.1, ups=0.54, wpb=1913.4, bsz=112, num_updates=51750, lr=4.99271e-05, gnorm=14.171, clip=98, loss_scale=16, train_wall=93, gb_free=17.8, wall=106442
2025-11-08 22:28:19 | INFO | train_inner | epoch 004:  12918 / 13011 loss=0.063701, wps=916.3, ups=0.48, wpb=1920.6, bsz=112, num_updates=51800, lr=4.9925e-05, gnorm=17.003, clip=100, loss_scale=16, train_wall=102, gb_free=17.3, wall=106546
2025-11-08 22:29:51 | INFO | train_inner | epoch 004:  12968 / 13011 loss=0.066065, wps=1018.8, ups=0.54, wpb=1877.7, bsz=112, num_updates=51850, lr=4.99229e-05, gnorm=14.329, clip=98, loss_scale=32, train_wall=92, gb_free=17.8, wall=106639
2025-11-08 22:30:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-08 22:49:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.059033 | wps 1292.8 | wpb 1907.1 | bsz 111.9 | num_updates 51893 | best_loss 0.059033
2025-11-08 22:49:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 51893 updates
2025-11-08 22:49:21 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint4.pt
2025-11-08 22:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint4.pt
2025-11-08 22:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint4.pt (epoch 4 @ 51893 updates, score 0.059033) (writing took 401.26075812699855 seconds)
2025-11-08 22:56:02 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2025-11-08 22:56:02 | INFO | train | epoch 004 | loss 0.078774 | wps 861.3 | ups 0.45 | wpb 1917.1 | bsz 112 | num_updates 51893 | lr 4.99211e-05 | gnorm 17.111 | clip 99.7 | loss_scale 32 | train_wall 26128 | gb_free 17.9 | wall 108210
2025-11-08 22:56:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 13011
2025-11-08 22:56:04 | INFO | fairseq.trainer | begin training epoch 5
2025-11-08 22:56:04 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-08 22:56:17 | INFO | train_inner | epoch 005:      7 / 13011 loss=0.059767, wps=59.1, ups=0.03, wpb=1873.2, bsz=110, num_updates=51900, lr=4.99208e-05, gnorm=13.348, clip=96, loss_scale=32, train_wall=72, gb_free=14.8, wall=108224
2025-11-08 22:59:43 | INFO | train_inner | epoch 005:     57 / 13011 loss=0.062189, wps=465.7, ups=0.24, wpb=1919, bsz=112, num_updates=51950, lr=4.99188e-05, gnorm=12.748, clip=98, loss_scale=32, train_wall=206, gb_free=16.9, wall=108430
2025-11-08 23:00:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 23:01:28 | INFO | train_inner | epoch 005:    108 / 13011 loss=0.058865, wps=915.3, ups=0.48, wpb=1926.7, bsz=112, num_updates=52000, lr=4.99167e-05, gnorm=10.776, clip=100, loss_scale=16, train_wall=105, gb_free=17.4, wall=108535
2025-11-08 23:04:20 | INFO | train_inner | epoch 005:    158 / 13011 loss=0.063549, wps=563.2, ups=0.29, wpb=1933.2, bsz=112, num_updates=52050, lr=4.99146e-05, gnorm=11.542, clip=96, loss_scale=16, train_wall=171, gb_free=19.1, wall=108707
2025-11-08 23:06:19 | INFO | train_inner | epoch 005:    208 / 13011 loss=0.066261, wps=804.7, ups=0.42, wpb=1914.8, bsz=112, num_updates=52100, lr=4.99125e-05, gnorm=13.599, clip=100, loss_scale=16, train_wall=119, gb_free=17, wall=108826
2025-11-08 23:07:47 | INFO | train_inner | epoch 005:    258 / 13011 loss=0.066991, wps=1075.4, ups=0.57, wpb=1896, bsz=112, num_updates=52150, lr=4.99104e-05, gnorm=13.564, clip=98, loss_scale=16, train_wall=88, gb_free=18.8, wall=108914
2025-11-08 23:08:52 | INFO | train_inner | epoch 005:    308 / 13011 loss=0.06665, wps=1450.1, ups=0.77, wpb=1881.9, bsz=112, num_updates=52200, lr=4.99083e-05, gnorm=14.548, clip=100, loss_scale=16, train_wall=65, gb_free=17.6, wall=108979
2025-11-08 23:11:38 | INFO | train_inner | epoch 005:    358 / 13011 loss=0.060692, wps=572.7, ups=0.3, wpb=1909.7, bsz=112, num_updates=52250, lr=4.99063e-05, gnorm=11.234, clip=100, loss_scale=32, train_wall=166, gb_free=17.3, wall=109146
2025-11-08 23:14:00 | INFO | train_inner | epoch 005:    408 / 13011 loss=0.057076, wps=684.5, ups=0.35, wpb=1944.7, bsz=112, num_updates=52300, lr=4.99042e-05, gnorm=11.6, clip=100, loss_scale=32, train_wall=110, gb_free=18.3, wall=109288
2025-11-08 23:14:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-08 23:15:49 | INFO | train_inner | epoch 005:    459 / 13011 loss=0.064262, wps=875.6, ups=0.46, wpb=1895.1, bsz=112, num_updates=52350, lr=4.99021e-05, gnorm=13.477, clip=98, loss_scale=16, train_wall=108, gb_free=16.9, wall=109396
2025-11-08 23:16:51 | INFO | train_inner | epoch 005:    509 / 13011 loss=0.065528, wps=1555.2, ups=0.8, wpb=1942.7, bsz=112, num_updates=52400, lr=4.99e-05, gnorm=15.688, clip=100, loss_scale=16, train_wall=62, gb_free=13.9, wall=109458
2025-11-08 23:18:14 | INFO | train_inner | epoch 005:    559 / 13011 loss=0.066758, wps=1136.6, ups=0.6, wpb=1889.3, bsz=112, num_updates=52450, lr=4.98979e-05, gnorm=12.226, clip=94, loss_scale=16, train_wall=71, gb_free=15.9, wall=109542
2025-11-08 23:19:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 23:19:44 | INFO | train_inner | epoch 005:    610 / 13011 loss=0.062681, wps=1059.6, ups=0.56, wpb=1907.7, bsz=112, num_updates=52500, lr=4.98958e-05, gnorm=12.177, clip=96, loss_scale=8, train_wall=90, gb_free=18.6, wall=109632
2025-11-08 23:21:52 | INFO | train_inner | epoch 005:    660 / 13011 loss=0.062141, wps=753.7, ups=0.39, wpb=1920.2, bsz=112, num_updates=52550, lr=4.98938e-05, gnorm=14.327, clip=100, loss_scale=8, train_wall=82, gb_free=13.8, wall=109759
2025-11-08 23:25:02 | INFO | train_inner | epoch 005:    710 / 13011 loss=0.077387, wps=504.5, ups=0.26, wpb=1919.6, bsz=112, num_updates=52600, lr=4.98917e-05, gnorm=13.48, clip=98, loss_scale=8, train_wall=98, gb_free=13, wall=109949
2025-11-08 23:28:06 | INFO | train_inner | epoch 005:    760 / 13011 loss=0.066339, wps=523.7, ups=0.27, wpb=1933.2, bsz=112, num_updates=52650, lr=4.98896e-05, gnorm=21.064, clip=100, loss_scale=8, train_wall=184, gb_free=16.5, wall=110134
2025-11-08 23:29:56 | INFO | train_inner | epoch 005:    810 / 13011 loss=0.061346, wps=871.1, ups=0.46, wpb=1911.5, bsz=112, num_updates=52700, lr=4.98875e-05, gnorm=12.997, clip=98, loss_scale=8, train_wall=110, gb_free=17.6, wall=110244
2025-11-08 23:31:58 | INFO | train_inner | epoch 005:    860 / 13011 loss=0.065599, wps=791.7, ups=0.41, wpb=1931.2, bsz=112, num_updates=52750, lr=4.98854e-05, gnorm=15.16, clip=100, loss_scale=16, train_wall=122, gb_free=16.6, wall=110365
2025-11-08 23:34:18 | INFO | train_inner | epoch 005:    910 / 13011 loss=0.056327, wps=678.1, ups=0.36, wpb=1892.4, bsz=112, num_updates=52800, lr=4.98833e-05, gnorm=9.361, clip=96, loss_scale=16, train_wall=139, gb_free=18.4, wall=110505
2025-11-08 23:36:52 | INFO | train_inner | epoch 005:    960 / 13011 loss=0.059436, wps=630.8, ups=0.32, wpb=1943.9, bsz=112, num_updates=52850, lr=4.98813e-05, gnorm=12.161, clip=94, loss_scale=16, train_wall=154, gb_free=16.3, wall=110659
2025-11-08 23:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-08 23:38:59 | INFO | train_inner | epoch 005:   1011 / 13011 loss=0.06389, wps=755, ups=0.39, wpb=1922.2, bsz=112, num_updates=52900, lr=4.98792e-05, gnorm=11.548, clip=98, loss_scale=8, train_wall=91, gb_free=17, wall=110786
2025-11-08 23:40:00 | INFO | train_inner | epoch 005:   1061 / 13011 loss=0.054, wps=1580.7, ups=0.83, wpb=1915.3, bsz=112, num_updates=52950, lr=4.98771e-05, gnorm=13.135, clip=94, loss_scale=8, train_wall=60, gb_free=18.2, wall=110847
2025-11-08 23:41:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-08 23:42:17 | INFO | train_inner | epoch 005:   1112 / 13011 loss=0.066488, wps=696.2, ups=0.36, wpb=1916.2, bsz=112, num_updates=53000, lr=4.9875e-05, gnorm=17.457, clip=94, loss_scale=4, train_wall=66, gb_free=17.3, wall=110985
2025-11-08 23:44:33 | INFO | train_inner | epoch 005:   1162 / 13011 loss=0.062674, wps=705.6, ups=0.37, wpb=1909.7, bsz=112, num_updates=53050, lr=4.98729e-05, gnorm=13.487, clip=98, loss_scale=4, train_wall=99, gb_free=14.4, wall=111120
2025-11-08 23:46:34 | INFO | train_inner | epoch 005:   1212 / 13011 loss=0.063048, wps=803.4, ups=0.41, wpb=1945.6, bsz=112, num_updates=53100, lr=4.98708e-05, gnorm=13.74, clip=100, loss_scale=4, train_wall=121, gb_free=18.5, wall=111241
2025-11-08 23:49:14 | INFO | train_inner | epoch 005:   1262 / 13011 loss=0.068429, wps=595.1, ups=0.31, wpb=1911.5, bsz=112, num_updates=53150, lr=4.98688e-05, gnorm=12.763, clip=98, loss_scale=4, train_wall=160, gb_free=9.7, wall=111402
2025-11-08 23:51:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2025-11-08 23:51:37 | INFO | train_inner | epoch 005:   1313 / 13011 loss=0.056991, wps=681.4, ups=0.35, wpb=1943.9, bsz=112, num_updates=53200, lr=4.98667e-05, gnorm=11.601, clip=100, loss_scale=2, train_wall=114, gb_free=17.6, wall=111544
2025-11-08 23:54:29 | INFO | train_inner | epoch 005:   1363 / 13011 loss=0.065023, wps=555.1, ups=0.29, wpb=1910.9, bsz=112, num_updates=53250, lr=4.98646e-05, gnorm=16.043, clip=98, loss_scale=2, train_wall=172, gb_free=18.1, wall=111716
2025-11-08 23:57:13 | INFO | train_inner | epoch 005:   1413 / 13011 loss=0.059311, wps=586.6, ups=0.31, wpb=1921.6, bsz=112, num_updates=53300, lr=4.98625e-05, gnorm=37.487, clip=94, loss_scale=2, train_wall=68, gb_free=18.4, wall=111880
2025-11-08 23:59:29 | INFO | train_inner | epoch 005:   1463 / 13011 loss=0.063062, wps=709.9, ups=0.37, wpb=1926.8, bsz=112, num_updates=53350, lr=4.98604e-05, gnorm=10.544, clip=100, loss_scale=2, train_wall=135, gb_free=16.5, wall=112016
2025-11-09 00:00:28 | INFO | train_inner | epoch 005:   1513 / 13011 loss=0.056361, wps=1614.2, ups=0.83, wpb=1934.6, bsz=112, num_updates=53400, lr=4.98583e-05, gnorm=10.327, clip=96, loss_scale=2, train_wall=60, gb_free=15.6, wall=112076
2025-11-09 00:03:30 | INFO | train_inner | epoch 005:   1563 / 13011 loss=0.065419, wps=518.2, ups=0.28, wpb=1880.6, bsz=112, num_updates=53450, lr=4.98563e-05, gnorm=10.522, clip=94, loss_scale=2, train_wall=113, gb_free=10.4, wall=112257
2025-11-09 00:05:50 | INFO | train_inner | epoch 005:   1613 / 13011 loss=0.063151, wps=692.3, ups=0.36, wpb=1937.9, bsz=112, num_updates=53500, lr=4.98542e-05, gnorm=13.321, clip=100, loss_scale=4, train_wall=140, gb_free=19.2, wall=112397
2025-11-09 00:08:20 | INFO | train_inner | epoch 005:   1663 / 13011 loss=0.066268, wps=634.7, ups=0.33, wpb=1903.5, bsz=112, num_updates=53550, lr=4.98521e-05, gnorm=17.678, clip=96, loss_scale=4, train_wall=150, gb_free=18.4, wall=112547
2025-11-09 00:10:37 | INFO | train_inner | epoch 005:   1713 / 13011 loss=0.067777, wps=700.4, ups=0.37, wpb=1917.2, bsz=112, num_updates=53600, lr=4.985e-05, gnorm=12.632, clip=98, loss_scale=4, train_wall=137, gb_free=18.8, wall=112684
2025-11-09 00:12:56 | INFO | train_inner | epoch 005:   1763 / 13011 loss=0.065082, wps=695.5, ups=0.36, wpb=1932.4, bsz=112, num_updates=53650, lr=4.98479e-05, gnorm=13.815, clip=98, loss_scale=4, train_wall=136, gb_free=17.9, wall=112823
2025-11-09 00:15:52 | INFO | train_inner | epoch 005:   1813 / 13011 loss=0.064117, wps=540.1, ups=0.28, wpb=1906, bsz=112, num_updates=53700, lr=4.98458e-05, gnorm=13.769, clip=98, loss_scale=4, train_wall=176, gb_free=17.7, wall=112999
2025-11-09 00:18:20 | INFO | train_inner | epoch 005:   1863 / 13011 loss=0.065823, wps=649.4, ups=0.34, wpb=1915.7, bsz=112, num_updates=53750, lr=4.98438e-05, gnorm=11.939, clip=92, loss_scale=8, train_wall=141, gb_free=18.5, wall=113147
2025-11-09 00:20:36 | INFO | train_inner | epoch 005:   1913 / 13011 loss=0.064321, wps=697.9, ups=0.37, wpb=1910.9, bsz=112, num_updates=53800, lr=4.98417e-05, gnorm=16.98, clip=98, loss_scale=8, train_wall=135, gb_free=16.3, wall=113284
2025-11-09 00:21:37 | INFO | train_inner | epoch 005:   1963 / 13011 loss=0.058024, wps=1579.8, ups=0.82, wpb=1921.9, bsz=112, num_updates=53850, lr=4.98396e-05, gnorm=11.013, clip=96, loss_scale=8, train_wall=61, gb_free=18, wall=113345
2025-11-09 00:24:00 | INFO | train_inner | epoch 005:   2013 / 13011 loss=0.066218, wps=659.2, ups=0.35, wpb=1883.3, bsz=112, num_updates=53900, lr=4.98375e-05, gnorm=12.656, clip=98, loss_scale=8, train_wall=59, gb_free=13.2, wall=113488
2025-11-09 00:26:36 | INFO | train_inner | epoch 005:   2063 / 13011 loss=0.057526, wps=605.4, ups=0.32, wpb=1885.6, bsz=112, num_updates=53950, lr=4.98354e-05, gnorm=10.86, clip=98, loss_scale=8, train_wall=156, gb_free=12.9, wall=113643
2025-11-09 00:28:48 | INFO | train_inner | epoch 005:   2113 / 13011 loss=0.059167, wps=722.8, ups=0.38, wpb=1911.1, bsz=112, num_updates=54000, lr=4.98333e-05, gnorm=11.617, clip=98, loss_scale=16, train_wall=120, gb_free=13.3, wall=113775
2025-11-09 00:31:34 | INFO | train_inner | epoch 005:   2163 / 13011 loss=0.057596, wps=578.5, ups=0.3, wpb=1925, bsz=112, num_updates=54050, lr=4.98313e-05, gnorm=11.609, clip=86, loss_scale=16, train_wall=69, gb_free=18.8, wall=113942
2025-11-09 00:33:42 | INFO | train_inner | epoch 005:   2213 / 13011 loss=0.058031, wps=735.2, ups=0.39, wpb=1869.8, bsz=112, num_updates=54100, lr=4.98292e-05, gnorm=9.966, clip=96, loss_scale=16, train_wall=102, gb_free=17.7, wall=114069
2025-11-09 00:36:01 | INFO | train_inner | epoch 005:   2263 / 13011 loss=0.064548, wps=681.1, ups=0.36, wpb=1899, bsz=112, num_updates=54150, lr=4.98271e-05, gnorm=12.502, clip=98, loss_scale=16, train_wall=60, gb_free=17.9, wall=114208
2025-11-09 00:37:01 | INFO | train_inner | epoch 005:   2313 / 13011 loss=0.063084, wps=1631.3, ups=0.84, wpb=1948, bsz=112, num_updates=54200, lr=4.9825e-05, gnorm=14.837, clip=94, loss_scale=16, train_wall=59, gb_free=15.9, wall=114268
2025-11-09 00:40:27 | INFO | train_inner | epoch 005:   2363 / 13011 loss=0.060181, wps=469.6, ups=0.24, wpb=1931.8, bsz=112, num_updates=54250, lr=4.98229e-05, gnorm=11.682, clip=96, loss_scale=32, train_wall=205, gb_free=15.4, wall=114474
2025-11-09 00:43:24 | INFO | train_inner | epoch 005:   2413 / 13011 loss=0.061442, wps=543, ups=0.28, wpb=1930.8, bsz=112, num_updates=54300, lr=4.98208e-05, gnorm=11.495, clip=98, loss_scale=32, train_wall=178, gb_free=16.7, wall=114652
2025-11-09 00:43:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-09 00:45:36 | INFO | train_inner | epoch 005:   2464 / 13011 loss=0.064821, wps=739.6, ups=0.38, wpb=1949.3, bsz=112, num_updates=54350, lr=4.98188e-05, gnorm=14.894, clip=100, loss_scale=16, train_wall=132, gb_free=17, wall=114784
2025-11-09 00:47:57 | INFO | train_inner | epoch 005:   2514 / 13011 loss=0.05974, wps=671.6, ups=0.35, wpb=1896.6, bsz=112, num_updates=54400, lr=4.98167e-05, gnorm=10.651, clip=94, loss_scale=16, train_wall=93, gb_free=16.6, wall=114925
2025-11-09 00:49:55 | INFO | train_inner | epoch 005:   2564 / 13011 loss=0.055305, wps=800.4, ups=0.43, wpb=1882.3, bsz=112, num_updates=54450, lr=4.98146e-05, gnorm=10.549, clip=96, loss_scale=16, train_wall=117, gb_free=18.8, wall=115042
2025-11-09 00:51:29 | INFO | train_inner | epoch 005:   2614 / 13011 loss=0.056244, wps=1032, ups=0.53, wpb=1937.6, bsz=112, num_updates=54500, lr=4.98125e-05, gnorm=11.81, clip=98, loss_scale=16, train_wall=94, gb_free=17, wall=115136
2025-11-09 00:53:48 | INFO | train_inner | epoch 005:   2664 / 13011 loss=0.06423, wps=685.6, ups=0.36, wpb=1912.3, bsz=112, num_updates=54550, lr=4.98104e-05, gnorm=11.545, clip=100, loss_scale=16, train_wall=76, gb_free=17.4, wall=115276
2025-11-09 00:56:11 | INFO | train_inner | epoch 005:   2714 / 13011 loss=0.058447, wps=667.4, ups=0.35, wpb=1899.6, bsz=112, num_updates=54600, lr=4.98083e-05, gnorm=12.424, clip=96, loss_scale=32, train_wall=135, gb_free=18.7, wall=115418
2025-11-09 00:56:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-09 00:59:21 | INFO | train_inner | epoch 005:   2765 / 13011 loss=0.055541, wps=496.9, ups=0.26, wpb=1895.9, bsz=112, num_updates=54650, lr=4.98063e-05, gnorm=11.936, clip=94, loss_scale=16, train_wall=61, gb_free=12.2, wall=115609
2025-11-09 01:01:22 | INFO | train_inner | epoch 005:   2815 / 13011 loss=0.054178, wps=789.7, ups=0.41, wpb=1912.2, bsz=112, num_updates=54700, lr=4.98042e-05, gnorm=11.364, clip=92, loss_scale=16, train_wall=121, gb_free=17.6, wall=115730
2025-11-09 01:04:16 | INFO | train_inner | epoch 005:   2865 / 13011 loss=0.060697, wps=554, ups=0.29, wpb=1927.6, bsz=112, num_updates=54750, lr=4.98021e-05, gnorm=14.972, clip=96, loss_scale=16, train_wall=72, gb_free=17.7, wall=115904
2025-11-09 01:04:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 01:05:29 | INFO | train_inner | epoch 005:   2916 / 13011 loss=0.059955, wps=1325.8, ups=0.69, wpb=1915.5, bsz=112, num_updates=54800, lr=4.98e-05, gnorm=10.279, clip=90, loss_scale=8, train_wall=72, gb_free=10.1, wall=115976
2025-11-09 01:07:46 | INFO | train_inner | epoch 005:   2966 / 13011 loss=0.061822, wps=696.4, ups=0.36, wpb=1919.5, bsz=112, num_updates=54850, lr=4.97979e-05, gnorm=11.629, clip=98, loss_scale=8, train_wall=138, gb_free=18.3, wall=116114
2025-11-09 01:07:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-09 01:09:55 | INFO | train_inner | epoch 005:   3017 / 13011 loss=0.060736, wps=743.6, ups=0.39, wpb=1915.9, bsz=112, num_updates=54900, lr=4.97958e-05, gnorm=12.578, clip=88, loss_scale=4, train_wall=129, gb_free=18.9, wall=116243
2025-11-09 01:12:50 | INFO | train_inner | epoch 005:   3067 / 13011 loss=0.056349, wps=549.3, ups=0.29, wpb=1913.9, bsz=112, num_updates=54950, lr=4.97938e-05, gnorm=9.628, clip=94, loss_scale=4, train_wall=63, gb_free=17.8, wall=116417
2025-11-09 01:16:00 | INFO | train_inner | epoch 005:   3117 / 13011 loss=0.056824, wps=501.1, ups=0.26, wpb=1909.6, bsz=112, num_updates=55000, lr=4.97917e-05, gnorm=8.964, clip=82, loss_scale=4, train_wall=61, gb_free=16.1, wall=116608
2025-11-09 01:17:02 | INFO | train_inner | epoch 005:   3167 / 13011 loss=0.060341, wps=1576.4, ups=0.81, wpb=1949.4, bsz=112, num_updates=55050, lr=4.97896e-05, gnorm=11.536, clip=92, loss_scale=4, train_wall=62, gb_free=17.7, wall=116669
2025-11-09 01:19:06 | INFO | train_inner | epoch 005:   3217 / 13011 loss=0.066217, wps=764.6, ups=0.4, wpb=1890.8, bsz=112, num_updates=55100, lr=4.97875e-05, gnorm=13.108, clip=98, loss_scale=4, train_wall=123, gb_free=17.7, wall=116793
2025-11-09 01:20:39 | INFO | train_inner | epoch 005:   3267 / 13011 loss=0.055914, wps=1024.7, ups=0.54, wpb=1909, bsz=112, num_updates=55150, lr=4.97854e-05, gnorm=11.371, clip=84, loss_scale=8, train_wall=93, gb_free=15.7, wall=116886
2025-11-09 01:22:11 | INFO | train_inner | epoch 005:   3317 / 13011 loss=0.061329, wps=1067, ups=0.54, wpb=1970.2, bsz=112, num_updates=55200, lr=4.97833e-05, gnorm=13.601, clip=90, loss_scale=8, train_wall=92, gb_free=18.5, wall=116979
2025-11-09 01:23:43 | INFO | train_inner | epoch 005:   3367 / 13011 loss=0.061764, wps=1051.4, ups=0.54, wpb=1931, bsz=112, num_updates=55250, lr=4.97813e-05, gnorm=17.782, clip=94, loss_scale=8, train_wall=92, gb_free=18.4, wall=117070
2025-11-09 01:25:42 | INFO | train_inner | epoch 005:   3417 / 13011 loss=0.061486, wps=803.5, ups=0.42, wpb=1920.5, bsz=112, num_updates=55300, lr=4.97792e-05, gnorm=14.55, clip=100, loss_scale=8, train_wall=119, gb_free=16, wall=117190
2025-11-09 01:28:10 | INFO | train_inner | epoch 005:   3467 / 13011 loss=0.05619, wps=649, ups=0.34, wpb=1917.1, bsz=112, num_updates=55350, lr=4.97771e-05, gnorm=8.861, clip=94, loss_scale=8, train_wall=147, gb_free=13.3, wall=117338
2025-11-09 01:29:38 | INFO | train_inner | epoch 005:   3517 / 13011 loss=0.068767, wps=1069.9, ups=0.57, wpb=1879.7, bsz=112, num_updates=55400, lr=4.9775e-05, gnorm=14.996, clip=96, loss_scale=16, train_wall=88, gb_free=16.5, wall=117425
2025-11-09 01:31:05 | INFO | train_inner | epoch 005:   3567 / 13011 loss=0.077607, wps=1092.3, ups=0.57, wpb=1902.6, bsz=112, num_updates=55450, lr=4.97729e-05, gnorm=21.612, clip=98, loss_scale=16, train_wall=87, gb_free=12.7, wall=117512
2025-11-09 01:31:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 01:32:37 | INFO | train_inner | epoch 005:   3618 / 13011 loss=0.09644, wps=1038.9, ups=0.55, wpb=1901.7, bsz=112, num_updates=55500, lr=4.97708e-05, gnorm=52.684, clip=100, loss_scale=8, train_wall=91, gb_free=17, wall=117604
2025-11-09 01:32:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-09 01:33:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2025-11-09 01:34:00 | INFO | train_inner | epoch 005:   3670 / 13011 loss=0.280711, wps=1156.4, ups=0.6, wpb=1923, bsz=112, num_updates=55550, lr=4.97688e-05, gnorm=224.185, clip=100, loss_scale=2, train_wall=83, gb_free=12.9, wall=117687
2025-11-09 01:35:41 | INFO | train_inner | epoch 005:   3720 / 13011 loss=0.106547, wps=944.8, ups=0.49, wpb=1910.2, bsz=112, num_updates=55600, lr=4.97667e-05, gnorm=80.518, clip=100, loss_scale=2, train_wall=101, gb_free=19, wall=117788
2025-11-09 01:36:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2025-11-09 01:37:03 | INFO | train_inner | epoch 005:   3771 / 13011 loss=0.133693, wps=1173.7, ups=0.61, wpb=1934, bsz=112, num_updates=55650, lr=4.97646e-05, gnorm=86.062, clip=100, loss_scale=1, train_wall=82, gb_free=18.3, wall=117871
2025-11-09 01:39:16 | INFO | train_inner | epoch 005:   3821 / 13011 loss=0.093566, wps=727.6, ups=0.38, wpb=1925.1, bsz=112, num_updates=55700, lr=4.97625e-05, gnorm=18.201, clip=100, loss_scale=1, train_wall=132, gb_free=10.2, wall=118003
2025-11-09 01:40:37 | INFO | train_inner | epoch 005:   3871 / 13011 loss=0.084695, wps=1168.6, ups=0.61, wpb=1907.1, bsz=112, num_updates=55750, lr=4.97604e-05, gnorm=17.044, clip=100, loss_scale=1, train_wall=81, gb_free=17.8, wall=118085
2025-11-09 01:42:09 | INFO | train_inner | epoch 005:   3921 / 13011 loss=0.070269, wps=1038.4, ups=0.55, wpb=1896.9, bsz=112, num_updates=55800, lr=4.97583e-05, gnorm=12.016, clip=100, loss_scale=1, train_wall=91, gb_free=17.5, wall=118176
2025-11-09 01:43:45 | INFO | train_inner | epoch 005:   3971 / 13011 loss=0.069336, wps=975.7, ups=0.52, wpb=1888.3, bsz=112, num_updates=55850, lr=4.97563e-05, gnorm=14.026, clip=100, loss_scale=1, train_wall=97, gb_free=18.7, wall=118273
2025-11-09 01:45:01 | INFO | train_inner | epoch 005:   4021 / 13011 loss=0.072021, wps=1250.3, ups=0.66, wpb=1888.9, bsz=112, num_updates=55900, lr=4.97542e-05, gnorm=11.837, clip=100, loss_scale=2, train_wall=75, gb_free=19.4, wall=118348
2025-11-09 01:46:11 | INFO | train_inner | epoch 005:   4071 / 13011 loss=0.061847, wps=1369.3, ups=0.71, wpb=1935.2, bsz=112, num_updates=55950, lr=4.97521e-05, gnorm=9.424, clip=94, loss_scale=2, train_wall=70, gb_free=16, wall=118419
2025-11-09 01:47:51 | INFO | train_inner | epoch 005:   4121 / 13011 loss=0.064305, wps=949.2, ups=0.5, wpb=1887.5, bsz=112, num_updates=56000, lr=4.975e-05, gnorm=12.721, clip=98, loss_scale=2, train_wall=99, gb_free=18.7, wall=118518
2025-11-09 01:49:09 | INFO | train_inner | epoch 005:   4171 / 13011 loss=0.05896, wps=1243, ups=0.64, wpb=1935.6, bsz=112, num_updates=56050, lr=4.97479e-05, gnorm=17.582, clip=100, loss_scale=2, train_wall=78, gb_free=15.3, wall=118596
2025-11-09 01:50:54 | INFO | train_inner | epoch 005:   4221 / 13011 loss=0.078959, wps=915.3, ups=0.47, wpb=1934.5, bsz=112, num_updates=56100, lr=4.97458e-05, gnorm=108.705, clip=100, loss_scale=2, train_wall=105, gb_free=18.8, wall=118702
2025-11-09 01:51:59 | INFO | train_inner | epoch 005:   4271 / 13011 loss=0.199722, wps=1493.8, ups=0.78, wpb=1918.7, bsz=112, num_updates=56150, lr=4.97438e-05, gnorm=139.14, clip=100, loss_scale=4, train_wall=64, gb_free=15.7, wall=118766
2025-11-09 01:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2025-11-09 01:53:19 | INFO | train_inner | epoch 005:   4322 / 13011 loss=0.117116, wps=1236.6, ups=0.62, wpb=1990.9, bsz=112, num_updates=56200, lr=4.97417e-05, gnorm=32.191, clip=100, loss_scale=2, train_wall=80, gb_free=15.3, wall=118847
2025-11-09 01:55:15 | INFO | train_inner | epoch 005:   4372 / 13011 loss=0.103965, wps=829.2, ups=0.43, wpb=1920.3, bsz=112, num_updates=56250, lr=4.97396e-05, gnorm=73.456, clip=100, loss_scale=2, train_wall=116, gb_free=13.3, wall=118962
2025-11-09 01:56:49 | INFO | train_inner | epoch 005:   4422 / 13011 loss=0.082275, wps=1021.5, ups=0.53, wpb=1927, bsz=112, num_updates=56300, lr=4.97375e-05, gnorm=24.762, clip=100, loss_scale=2, train_wall=94, gb_free=12.6, wall=119057
2025-11-09 01:58:31 | INFO | train_inner | epoch 005:   4472 / 13011 loss=0.067242, wps=947.4, ups=0.49, wpb=1923, bsz=112, num_updates=56350, lr=4.97354e-05, gnorm=12.681, clip=100, loss_scale=2, train_wall=101, gb_free=18.6, wall=119158
2025-11-09 01:59:50 | INFO | train_inner | epoch 005:   4522 / 13011 loss=0.07285, wps=1230.2, ups=0.63, wpb=1958.6, bsz=112, num_updates=56400, lr=4.97333e-05, gnorm=13.557, clip=100, loss_scale=2, train_wall=74, gb_free=18.3, wall=119238
2025-11-09 02:01:35 | INFO | train_inner | epoch 005:   4572 / 13011 loss=0.065803, wps=920, ups=0.48, wpb=1920.9, bsz=112, num_updates=56450, lr=4.97313e-05, gnorm=13.739, clip=100, loss_scale=4, train_wall=104, gb_free=16.5, wall=119342
2025-11-09 02:03:08 | INFO | train_inner | epoch 005:   4622 / 13011 loss=0.069252, wps=997.8, ups=0.53, wpb=1868.6, bsz=112, num_updates=56500, lr=4.97292e-05, gnorm=14.961, clip=96, loss_scale=4, train_wall=93, gb_free=18.1, wall=119436
2025-11-09 02:04:37 | INFO | train_inner | epoch 005:   4672 / 13011 loss=0.059957, wps=1069.2, ups=0.56, wpb=1892.8, bsz=112, num_updates=56550, lr=4.97271e-05, gnorm=11.902, clip=100, loss_scale=4, train_wall=88, gb_free=19, wall=119524
2025-11-09 02:06:15 | INFO | train_inner | epoch 005:   4722 / 13011 loss=0.075701, wps=981.8, ups=0.51, wpb=1924.5, bsz=112, num_updates=56600, lr=4.9725e-05, gnorm=14.665, clip=100, loss_scale=4, train_wall=98, gb_free=18.3, wall=119622
2025-11-09 02:07:42 | INFO | train_inner | epoch 005:   4772 / 13011 loss=0.067374, wps=1099.9, ups=0.57, wpb=1918.8, bsz=112, num_updates=56650, lr=4.97229e-05, gnorm=14.539, clip=100, loss_scale=4, train_wall=87, gb_free=18.9, wall=119710
2025-11-09 02:09:01 | INFO | train_inner | epoch 005:   4822 / 13011 loss=0.061943, wps=1196.1, ups=0.63, wpb=1887.2, bsz=112, num_updates=56700, lr=4.97208e-05, gnorm=10.255, clip=98, loss_scale=8, train_wall=78, gb_free=17.3, wall=119788
2025-11-09 02:10:14 | INFO | train_inner | epoch 005:   4872 / 13011 loss=0.063186, wps=1348.4, ups=0.69, wpb=1958.3, bsz=112, num_updates=56750, lr=4.97188e-05, gnorm=17.631, clip=94, loss_scale=8, train_wall=71, gb_free=14.3, wall=119861
2025-11-09 02:11:51 | INFO | train_inner | epoch 005:   4922 / 13011 loss=0.065195, wps=976.9, ups=0.51, wpb=1902.4, bsz=112, num_updates=56800, lr=4.97167e-05, gnorm=13.388, clip=94, loss_scale=8, train_wall=97, gb_free=17.3, wall=119958
2025-11-09 02:13:32 | INFO | train_inner | epoch 005:   4972 / 13011 loss=0.059032, wps=955.4, ups=0.49, wpb=1930.7, bsz=112, num_updates=56850, lr=4.97146e-05, gnorm=12.182, clip=92, loss_scale=8, train_wall=101, gb_free=13.3, wall=120060
2025-11-09 02:14:57 | INFO | train_inner | epoch 005:   5022 / 13011 loss=0.068686, wps=1115.3, ups=0.59, wpb=1898.2, bsz=112, num_updates=56900, lr=4.97125e-05, gnorm=13.813, clip=94, loss_scale=8, train_wall=85, gb_free=16.3, wall=120145
2025-11-09 02:16:13 | INFO | train_inner | epoch 005:   5072 / 13011 loss=0.056185, wps=1258.1, ups=0.66, wpb=1915.9, bsz=112, num_updates=56950, lr=4.97104e-05, gnorm=10.736, clip=92, loss_scale=16, train_wall=76, gb_free=18.2, wall=120221
2025-11-09 02:18:07 | INFO | train_inner | epoch 005:   5122 / 13011 loss=0.054656, wps=837.6, ups=0.44, wpb=1911.8, bsz=112, num_updates=57000, lr=4.97083e-05, gnorm=12.228, clip=92, loss_scale=16, train_wall=114, gb_free=19, wall=120335
2025-11-09 02:19:34 | INFO | train_inner | epoch 005:   5172 / 13011 loss=0.054436, wps=1089.7, ups=0.58, wpb=1886.1, bsz=112, num_updates=57050, lr=4.97063e-05, gnorm=10.501, clip=96, loss_scale=16, train_wall=86, gb_free=17.2, wall=120421
2025-11-09 02:21:31 | INFO | train_inner | epoch 005:   5222 / 13011 loss=0.057934, wps=818.9, ups=0.43, wpb=1909.9, bsz=112, num_updates=57100, lr=4.97042e-05, gnorm=9.29, clip=88, loss_scale=16, train_wall=111, gb_free=18.9, wall=120538
2025-11-09 02:22:39 | INFO | train_inner | epoch 005:   5272 / 13011 loss=0.051845, wps=1396.5, ups=0.73, wpb=1917.3, bsz=112, num_updates=57150, lr=4.97021e-05, gnorm=9.758, clip=96, loss_scale=16, train_wall=68, gb_free=18.2, wall=120607
2025-11-09 02:24:00 | INFO | train_inner | epoch 005:   5322 / 13011 loss=0.056791, wps=1171.9, ups=0.62, wpb=1897.7, bsz=112, num_updates=57200, lr=4.97e-05, gnorm=9.691, clip=92, loss_scale=32, train_wall=81, gb_free=16.4, wall=120688
2025-11-09 02:25:43 | INFO | train_inner | epoch 005:   5372 / 13011 loss=0.052453, wps=931.9, ups=0.49, wpb=1907.5, bsz=112, num_updates=57250, lr=4.96979e-05, gnorm=11.4, clip=86, loss_scale=32, train_wall=102, gb_free=17.8, wall=120790
2025-11-09 02:27:02 | INFO | train_inner | epoch 005:   5422 / 13011 loss=0.06135, wps=1189.2, ups=0.63, wpb=1895.3, bsz=112, num_updates=57300, lr=4.96958e-05, gnorm=8.896, clip=88, loss_scale=32, train_wall=79, gb_free=15.8, wall=120870
2025-11-09 02:28:25 | INFO | train_inner | epoch 005:   5472 / 13011 loss=0.058532, wps=1179.8, ups=0.6, wpb=1953.3, bsz=112, num_updates=57350, lr=4.96938e-05, gnorm=9.591, clip=92, loss_scale=32, train_wall=79, gb_free=19.1, wall=120953
2025-11-09 02:30:04 | INFO | train_inner | epoch 005:   5522 / 13011 loss=0.049734, wps=969.4, ups=0.51, wpb=1911.7, bsz=112, num_updates=57400, lr=4.96917e-05, gnorm=7.822, clip=70, loss_scale=32, train_wall=98, gb_free=17.8, wall=121051
2025-11-09 02:31:39 | INFO | train_inner | epoch 005:   5572 / 13011 loss=0.055846, wps=1006.4, ups=0.52, wpb=1918.4, bsz=112, num_updates=57450, lr=4.96896e-05, gnorm=8.852, clip=82, loss_scale=64, train_wall=95, gb_free=17.9, wall=121146
2025-11-09 02:32:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-09 02:33:05 | INFO | train_inner | epoch 005:   5623 / 13011 loss=0.052875, wps=1111.1, ups=0.58, wpb=1918.5, bsz=112, num_updates=57500, lr=4.96875e-05, gnorm=9.556, clip=88, loss_scale=32, train_wall=86, gb_free=14.8, wall=121233
2025-11-09 02:34:25 | INFO | train_inner | epoch 005:   5673 / 13011 loss=0.051173, wps=1200.4, ups=0.63, wpb=1912.6, bsz=112, num_updates=57550, lr=4.96854e-05, gnorm=10.709, clip=82, loss_scale=32, train_wall=79, gb_free=17.3, wall=121312
2025-11-09 02:36:07 | INFO | train_inner | epoch 005:   5723 / 13011 loss=0.054492, wps=943, ups=0.49, wpb=1929.7, bsz=112, num_updates=57600, lr=4.96833e-05, gnorm=10.216, clip=94, loss_scale=32, train_wall=77, gb_free=18.8, wall=121415
2025-11-09 02:37:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-09 02:37:23 | INFO | train_inner | epoch 005:   5774 / 13011 loss=0.050786, wps=1249.3, ups=0.66, wpb=1890.3, bsz=112, num_updates=57650, lr=4.96813e-05, gnorm=12.832, clip=94, loss_scale=16, train_wall=75, gb_free=17.5, wall=121490
2025-11-09 02:38:47 | INFO | train_inner | epoch 005:   5824 / 13011 loss=0.050655, wps=1129.8, ups=0.59, wpb=1907.5, bsz=112, num_updates=57700, lr=4.96792e-05, gnorm=10.591, clip=86, loss_scale=16, train_wall=84, gb_free=17.2, wall=121575
2025-11-09 02:39:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 02:40:36 | INFO | train_inner | epoch 005:   5875 / 13011 loss=0.05341, wps=895.3, ups=0.46, wpb=1936.1, bsz=112, num_updates=57750, lr=4.96771e-05, gnorm=18.46, clip=88, loss_scale=8, train_wall=108, gb_free=18.8, wall=121683
2025-11-09 02:42:11 | INFO | train_inner | epoch 005:   5925 / 13011 loss=0.055923, wps=1000.4, ups=0.52, wpb=1916.2, bsz=112, num_updates=57800, lr=4.9675e-05, gnorm=12.527, clip=92, loss_scale=8, train_wall=96, gb_free=14.3, wall=121779
2025-11-09 02:43:32 | INFO | train_inner | epoch 005:   5975 / 13011 loss=0.05416, wps=1190, ups=0.62, wpb=1924.7, bsz=112, num_updates=57850, lr=4.96729e-05, gnorm=10.827, clip=88, loss_scale=8, train_wall=81, gb_free=17.6, wall=121860
2025-11-09 02:45:02 | INFO | train_inner | epoch 005:   6025 / 13011 loss=0.055013, wps=1055.6, ups=0.56, wpb=1887, bsz=112, num_updates=57900, lr=4.96708e-05, gnorm=9.755, clip=90, loss_scale=8, train_wall=89, gb_free=14.9, wall=121949
2025-11-09 02:46:39 | INFO | train_inner | epoch 005:   6075 / 13011 loss=0.05951, wps=969.2, ups=0.51, wpb=1893.7, bsz=112, num_updates=57950, lr=4.96688e-05, gnorm=17.204, clip=94, loss_scale=8, train_wall=97, gb_free=16.7, wall=122047
2025-11-09 02:47:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-09 02:48:21 | INFO | train_inner | epoch 005:   6126 / 13011 loss=0.092368, wps=930.2, ups=0.49, wpb=1892.3, bsz=112, num_updates=58000, lr=4.96667e-05, gnorm=56.987, clip=96, loss_scale=4, train_wall=101, gb_free=17.7, wall=122148
2025-11-09 02:49:57 | INFO | train_inner | epoch 005:   6176 / 13011 loss=0.078589, wps=992.3, ups=0.52, wpb=1907.4, bsz=112, num_updates=58050, lr=4.96646e-05, gnorm=47.048, clip=98, loss_scale=4, train_wall=96, gb_free=18.3, wall=122245
2025-11-09 02:51:29 | INFO | train_inner | epoch 005:   6226 / 13011 loss=0.064675, wps=1056.3, ups=0.55, wpb=1930.7, bsz=112, num_updates=58100, lr=4.96625e-05, gnorm=13.252, clip=98, loss_scale=4, train_wall=91, gb_free=18.8, wall=122336
2025-11-09 02:52:55 | INFO | train_inner | epoch 005:   6276 / 13011 loss=0.069696, wps=1097.6, ups=0.58, wpb=1904.1, bsz=112, num_updates=58150, lr=4.96604e-05, gnorm=11.438, clip=94, loss_scale=4, train_wall=87, gb_free=12.7, wall=122423
2025-11-09 02:54:26 | INFO | train_inner | epoch 005:   6326 / 13011 loss=0.06208, wps=1074.3, ups=0.55, wpb=1940.1, bsz=112, num_updates=58200, lr=4.96583e-05, gnorm=11.669, clip=94, loss_scale=4, train_wall=82, gb_free=16.9, wall=122513
2025-11-09 02:56:09 | INFO | train_inner | epoch 005:   6376 / 13011 loss=0.057937, wps=924.5, ups=0.48, wpb=1917.8, bsz=112, num_updates=58250, lr=4.96563e-05, gnorm=14.021, clip=86, loss_scale=8, train_wall=103, gb_free=17.5, wall=122617
2025-11-09 02:57:38 | INFO | train_inner | epoch 005:   6426 / 13011 loss=0.059104, wps=1072, ups=0.56, wpb=1906, bsz=112, num_updates=58300, lr=4.96542e-05, gnorm=9.104, clip=90, loss_scale=8, train_wall=89, gb_free=12.3, wall=122706
2025-11-09 02:59:18 | INFO | train_inner | epoch 005:   6476 / 13011 loss=0.052243, wps=950.6, ups=0.5, wpb=1897.7, bsz=112, num_updates=58350, lr=4.96521e-05, gnorm=12.673, clip=90, loss_scale=8, train_wall=100, gb_free=17.9, wall=122805
2025-11-09 03:00:19 | INFO | train_inner | epoch 005:   6526 / 13011 loss=0.052009, wps=1588.9, ups=0.82, wpb=1930.7, bsz=112, num_updates=58400, lr=4.965e-05, gnorm=8.895, clip=92, loss_scale=8, train_wall=61, gb_free=19, wall=122866
2025-11-09 03:01:51 | INFO | train_inner | epoch 005:   6576 / 13011 loss=0.065072, wps=1024.4, ups=0.54, wpb=1898.8, bsz=112, num_updates=58450, lr=4.96479e-05, gnorm=11.168, clip=96, loss_scale=8, train_wall=92, gb_free=18.5, wall=122959
2025-11-09 03:02:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 03:03:16 | INFO | train_inner | epoch 005:   6627 / 13011 loss=0.055977, wps=1160.4, ups=0.59, wpb=1951.9, bsz=112, num_updates=58500, lr=4.96458e-05, gnorm=10.171, clip=92, loss_scale=8, train_wall=84, gb_free=17.3, wall=123043
2025-11-09 03:04:28 | INFO | train_inner | epoch 005:   6677 / 13011 loss=0.052974, wps=1331.9, ups=0.69, wpb=1919.5, bsz=112, num_updates=58550, lr=4.96438e-05, gnorm=12.643, clip=96, loss_scale=8, train_wall=72, gb_free=18.4, wall=123115
2025-11-09 03:06:17 | INFO | train_inner | epoch 005:   6727 / 13011 loss=0.060837, wps=900, ups=0.46, wpb=1962.7, bsz=112, num_updates=58600, lr=4.96417e-05, gnorm=13.607, clip=88, loss_scale=8, train_wall=109, gb_free=18.5, wall=123224
2025-11-09 03:07:39 | INFO | train_inner | epoch 005:   6777 / 13011 loss=0.056342, wps=1141.3, ups=0.6, wpb=1888.3, bsz=112, num_updates=58650, lr=4.96396e-05, gnorm=10.826, clip=94, loss_scale=8, train_wall=82, gb_free=19, wall=123307
2025-11-09 03:09:17 | INFO | train_inner | epoch 005:   6827 / 13011 loss=0.058556, wps=978.1, ups=0.51, wpb=1913.5, bsz=112, num_updates=58700, lr=4.96375e-05, gnorm=11.218, clip=94, loss_scale=8, train_wall=98, gb_free=18.1, wall=123405
2025-11-09 03:10:58 | INFO | train_inner | epoch 005:   6877 / 13011 loss=0.062675, wps=959, ups=0.5, wpb=1937.3, bsz=112, num_updates=58750, lr=4.96354e-05, gnorm=11.937, clip=94, loss_scale=16, train_wall=101, gb_free=16.7, wall=123506
2025-11-09 03:12:52 | INFO | train_inner | epoch 005:   6927 / 13011 loss=0.051492, wps=832.1, ups=0.44, wpb=1892.3, bsz=112, num_updates=58800, lr=4.96333e-05, gnorm=11.239, clip=94, loss_scale=16, train_wall=113, gb_free=14.1, wall=123619
2025-11-09 03:13:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 03:13:53 | INFO | train_inner | epoch 005:   6978 / 13011 loss=0.056779, wps=1582, ups=0.82, wpb=1937.7, bsz=112, num_updates=58850, lr=4.96313e-05, gnorm=10.836, clip=86, loss_scale=8, train_wall=61, gb_free=17.7, wall=123681
2025-11-09 03:15:53 | INFO | train_inner | epoch 005:   7028 / 13011 loss=0.056097, wps=784.9, ups=0.42, wpb=1888.1, bsz=112, num_updates=58900, lr=4.96292e-05, gnorm=14.454, clip=84, loss_scale=8, train_wall=120, gb_free=17.3, wall=123801
2025-11-09 03:16:54 | INFO | train_inner | epoch 005:   7078 / 13011 loss=0.055626, wps=1604.7, ups=0.82, wpb=1955.5, bsz=112, num_updates=58950, lr=4.96271e-05, gnorm=16.407, clip=86, loss_scale=8, train_wall=61, gb_free=17.8, wall=123862
2025-11-09 03:18:16 | INFO | train_inner | epoch 005:   7128 / 13011 loss=0.050622, wps=1186.6, ups=0.62, wpb=1926.2, bsz=112, num_updates=59000, lr=4.9625e-05, gnorm=13.266, clip=88, loss_scale=8, train_wall=81, gb_free=18, wall=123943
2025-11-09 03:19:52 | INFO | train_inner | epoch 005:   7178 / 13011 loss=0.054703, wps=993.6, ups=0.52, wpb=1924, bsz=112, num_updates=59050, lr=4.96229e-05, gnorm=10.203, clip=100, loss_scale=8, train_wall=97, gb_free=15.2, wall=124040
2025-11-09 03:21:03 | INFO | train_inner | epoch 005:   7228 / 13011 loss=0.053797, wps=1367.3, ups=0.71, wpb=1921.3, bsz=112, num_updates=59100, lr=4.96208e-05, gnorm=10.833, clip=90, loss_scale=16, train_wall=70, gb_free=13.9, wall=124110
2025-11-09 03:22:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 03:22:53 | INFO | train_inner | epoch 005:   7279 / 13011 loss=0.049708, wps=870.9, ups=0.45, wpb=1922.7, bsz=112, num_updates=59150, lr=4.96188e-05, gnorm=9.293, clip=84, loss_scale=8, train_wall=110, gb_free=19.5, wall=124220
2025-11-09 03:24:16 | INFO | train_inner | epoch 005:   7329 / 13011 loss=0.051954, wps=1167, ups=0.6, wpb=1939.6, bsz=112, num_updates=59200, lr=4.96167e-05, gnorm=16.072, clip=76, loss_scale=8, train_wall=83, gb_free=18.5, wall=124304
2025-11-09 03:25:57 | INFO | train_inner | epoch 005:   7379 / 13011 loss=0.054493, wps=955.4, ups=0.5, wpb=1920.3, bsz=112, num_updates=59250, lr=4.96146e-05, gnorm=11.433, clip=92, loss_scale=8, train_wall=100, gb_free=18.1, wall=124404
2025-11-09 03:26:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-11-09 03:27:13 | INFO | train_inner | epoch 005:   7430 / 13011 loss=0.052003, wps=1278.3, ups=0.66, wpb=1942.6, bsz=112, num_updates=59300, lr=4.96125e-05, gnorm=9.221, clip=94, loss_scale=4, train_wall=76, gb_free=15.9, wall=124480
2025-11-09 03:28:57 | INFO | train_inner | epoch 005:   7480 / 13011 loss=0.056072, wps=911.3, ups=0.48, wpb=1907.3, bsz=112, num_updates=59350, lr=4.96104e-05, gnorm=10.811, clip=90, loss_scale=4, train_wall=104, gb_free=18.4, wall=124585
2025-11-09 03:30:22 | INFO | train_inner | epoch 005:   7530 / 13011 loss=0.056002, wps=1120.1, ups=0.59, wpb=1894.6, bsz=112, num_updates=59400, lr=4.96083e-05, gnorm=17.252, clip=94, loss_scale=4, train_wall=84, gb_free=16.6, wall=124669
2025-11-09 03:31:59 | INFO | train_inner | epoch 005:   7580 / 13011 loss=0.050367, wps=981.4, ups=0.51, wpb=1911.5, bsz=112, num_updates=59450, lr=4.96063e-05, gnorm=11.178, clip=88, loss_scale=4, train_wall=97, gb_free=17.9, wall=124767
2025-11-09 03:33:19 | INFO | train_inner | epoch 005:   7630 / 13011 loss=0.052449, wps=1219.1, ups=0.63, wpb=1932.7, bsz=112, num_updates=59500, lr=4.96042e-05, gnorm=9.91, clip=76, loss_scale=4, train_wall=79, gb_free=17.7, wall=124846
2025-11-09 03:34:56 | INFO | train_inner | epoch 005:   7680 / 13011 loss=0.055186, wps=978.7, ups=0.51, wpb=1906.2, bsz=112, num_updates=59550, lr=4.96021e-05, gnorm=9.097, clip=84, loss_scale=8, train_wall=97, gb_free=18.4, wall=124943
2025-11-09 03:35:59 | INFO | train_inner | epoch 005:   7730 / 13011 loss=0.05316, wps=1502.4, ups=0.79, wpb=1909.4, bsz=112, num_updates=59600, lr=4.96e-05, gnorm=9.873, clip=94, loss_scale=8, train_wall=63, gb_free=9.3, wall=125007
2025-11-09 03:37:31 | INFO | train_inner | epoch 005:   7780 / 13011 loss=0.047156, wps=1054.2, ups=0.55, wpb=1930.4, bsz=112, num_updates=59650, lr=4.95979e-05, gnorm=8.34, clip=88, loss_scale=8, train_wall=91, gb_free=17.5, wall=125098
2025-11-09 03:39:15 | INFO | train_inner | epoch 005:   7830 / 13011 loss=0.045841, wps=916.8, ups=0.48, wpb=1907.3, bsz=112, num_updates=59700, lr=4.95958e-05, gnorm=8.853, clip=76, loss_scale=8, train_wall=104, gb_free=14.8, wall=125202
2025-11-09 03:40:47 | INFO | train_inner | epoch 005:   7880 / 13011 loss=0.051143, wps=1038, ups=0.54, wpb=1913.6, bsz=112, num_updates=59750, lr=4.95938e-05, gnorm=8.654, clip=86, loss_scale=8, train_wall=92, gb_free=18.9, wall=125295
2025-11-09 03:42:19 | INFO | train_inner | epoch 005:   7930 / 13011 loss=0.049816, wps=1065.3, ups=0.55, wpb=1951, bsz=112, num_updates=59800, lr=4.95917e-05, gnorm=8.719, clip=88, loss_scale=16, train_wall=91, gb_free=15.2, wall=125386
2025-11-09 03:43:39 | INFO | train_inner | epoch 005:   7980 / 13011 loss=0.055578, wps=1210.6, ups=0.63, wpb=1932.1, bsz=112, num_updates=59850, lr=4.95896e-05, gnorm=9.418, clip=92, loss_scale=16, train_wall=80, gb_free=17.6, wall=125466
2025-11-09 03:44:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-09 03:45:09 | INFO | train_inner | epoch 005:   8031 / 13011 loss=0.049683, wps=1074.3, ups=0.55, wpb=1952.4, bsz=112, num_updates=59900, lr=4.95875e-05, gnorm=9.224, clip=86, loss_scale=8, train_wall=91, gb_free=17.8, wall=125557
2025-11-09 03:46:42 | INFO | train_inner | epoch 005:   8081 / 13011 loss=0.050631, wps=1048.8, ups=0.54, wpb=1936.3, bsz=112, num_updates=59950, lr=4.95854e-05, gnorm=9.256, clip=74, loss_scale=8, train_wall=92, gb_free=14, wall=125649
2025-11-09 03:48:06 | INFO | train_inner | epoch 005:   8131 / 13011 loss=0.055488, wps=1126.8, ups=0.59, wpb=1895, bsz=112, num_updates=60000, lr=4.95833e-05, gnorm=19.666, clip=72, loss_scale=8, train_wall=84, gb_free=14.3, wall=125733
2025-11-09 03:49:32 | INFO | train_inner | epoch 005:   8181 / 13011 loss=0.050058, wps=1112, ups=0.58, wpb=1908.5, bsz=112, num_updates=60050, lr=4.95813e-05, gnorm=8.988, clip=76, loss_scale=8, train_wall=86, gb_free=18.7, wall=125819
2025-11-09 03:51:16 | INFO | train_inner | epoch 005:   8231 / 13011 loss=0.049587, wps=927, ups=0.48, wpb=1935.9, bsz=112, num_updates=60100, lr=4.95792e-05, gnorm=17.727, clip=82, loss_scale=8, train_wall=104, gb_free=15.9, wall=125924
2025-11-09 03:52:38 | INFO | train_inner | epoch 005:   8281 / 13011 loss=0.057092, wps=1167, ups=0.61, wpb=1911.6, bsz=112, num_updates=60150, lr=4.95771e-05, gnorm=15.622, clip=94, loss_scale=16, train_wall=82, gb_free=18.8, wall=126005
2025-11-09 03:54:21 | INFO | train_inner | epoch 005:   8331 / 13011 loss=0.053178, wps=941.7, ups=0.49, wpb=1938.7, bsz=112, num_updates=60200, lr=4.9575e-05, gnorm=11.965, clip=94, loss_scale=16, train_wall=103, gb_free=18.1, wall=126108
2025-11-09 03:55:35 | INFO | train_inner | epoch 005:   8381 / 13011 loss=0.058417, wps=1287, ups=0.67, wpb=1909.6, bsz=112, num_updates=60250, lr=4.95729e-05, gnorm=12.378, clip=90, loss_scale=16, train_wall=74, gb_free=14.6, wall=126183
2025-11-09 03:57:14 | INFO | train_inner | epoch 005:   8431 / 13011 loss=0.061174, wps=964.7, ups=0.5, wpb=1911.7, bsz=112, num_updates=60300, lr=4.95708e-05, gnorm=18.102, clip=92, loss_scale=16, train_wall=99, gb_free=18.3, wall=126282
2025-11-09 03:57:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
==========================================
 ‚úÖ ‰ªªÂä°ÂÆåÊàê‰∫é: Sun Nov  9 03:59:43 CST 2025
==========================================
