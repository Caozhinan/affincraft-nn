[INFO] Job starting at Fri Nov  7 16:38:31 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä®
 ËäÇÁÇπ:        g0109
 ‰Ωú‰∏öID:      4512485
 GPUs:        0
 ÂêØÂä®Êó∂Èó¥:    Fri Nov  7 16:38:31 CST 2025
==========================================
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - ÂçïGPUÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           1 GPU
DataLoader workers: 6
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/valid_lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     ./affincraft_pretrain_ckpts_lmdb_single_gpu
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   20
===================================================================
2025-11-07 16:42:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-07 16:44:11 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 64, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 100, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 20, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 150, 'max_update': 1400000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './affincraft_pretrain_ckpts_lmdb_single_gpu', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=64, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=20, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=20, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=150, max_update=1400000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts_lmdb_single_gpu', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=512, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=45000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1400000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.1, act_dropout=0.1, dropout=0.1, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 512, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/valid_lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 45000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 1400000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
2025-11-07 16:44:11 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 80,568
2025-11-07 16:44:11 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå80568 ‰∏™Ê†∑Êú¨
2025-11-07 16:44:11 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=64, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=20, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=20, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=150, max_update=1400000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts_lmdb_single_gpu', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=512, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=45000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1400000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.1, act_dropout=0.1, dropout=0.1, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-11-07 16:44:12 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-11-07 16:44:12 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-11-07 16:44:12 | INFO | fairseq_cli.train | model: GraphormerModel
2025-11-07 16:44:12 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-11-07 16:44:12 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-11-07 16:44:12 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-11-07 16:44:12 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 80568
2025-11-07 16:44:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-11-07 16:44:12 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-07 16:44:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-11-07 16:44:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2025-11-07 16:44:12 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 20
2025-11-07 16:44:12 | INFO | fairseq.trainer | Preparing to load checkpoint ./affincraft_pretrain_ckpts_lmdb_single_gpu/checkpoint_last.pt
2025-11-07 16:44:12 | INFO | fairseq.trainer | No existing checkpoint found ./affincraft_pretrain_ckpts_lmdb_single_gpu/checkpoint_last.pt
2025-11-07 16:44:12 | INFO | fairseq.trainer | loading train data for epoch 1
2025-11-07 16:44:12 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-11-07 16:44:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 91072
2025-11-07 16:44:16 | INFO | fairseq.trainer | begin training epoch 1
2025-11-07 16:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-07 16:44:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 16:45:00 | INFO | train_inner | epoch 001:     51 / 91072 loss=0.945312, wps=309.6, ups=1.32, wpb=234.2, bsz=16, num_updates=50, lr=1.11111e-07, gnorm=253.167, clip=100, loss_scale=32, train_wall=39, gb_free=15.9, wall=48
2025-11-07 16:45:31 | INFO | train_inner | epoch 001:    101 / 91072 loss=0.774414, wps=397.9, ups=1.6, wpb=248.4, bsz=16, num_updates=100, lr=2.22222e-07, gnorm=212.506, clip=100, loss_scale=32, train_wall=31, gb_free=18.1, wall=79
2025-11-07 16:46:03 | INFO | train_inner | epoch 001:    151 / 91072 loss=0.703125, wps=404.1, ups=1.6, wpb=251.9, bsz=16, num_updates=150, lr=3.33333e-07, gnorm=198.909, clip=100, loss_scale=32, train_wall=31, gb_free=15.5, wall=110
2025-11-07 16:46:33 | INFO | train_inner | epoch 001:    201 / 91072 loss=0.717285, wps=410.5, ups=1.65, wpb=249.4, bsz=16, num_updates=200, lr=4.44444e-07, gnorm=178.235, clip=100, loss_scale=32, train_wall=30, gb_free=16.5, wall=141
2025-11-07 16:47:04 | INFO | train_inner | epoch 001:    251 / 91072 loss=0.671875, wps=395.9, ups=1.63, wpb=242.5, bsz=16, num_updates=250, lr=5.55556e-07, gnorm=186.852, clip=100, loss_scale=32, train_wall=30, gb_free=9.3, wall=171
2025-11-07 16:47:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 16:47:35 | INFO | train_inner | epoch 001:    302 / 91072 loss=0.698242, wps=389.1, ups=1.61, wpb=241.2, bsz=16, num_updates=300, lr=6.66667e-07, gnorm=194.065, clip=100, loss_scale=32, train_wall=31, gb_free=9.2, wall=202
2025-11-07 16:48:05 | INFO | train_inner | epoch 001:    352 / 91072 loss=0.745117, wps=397.8, ups=1.65, wpb=241.8, bsz=16, num_updates=350, lr=7.77778e-07, gnorm=207.577, clip=100, loss_scale=32, train_wall=30, gb_free=17.4, wall=233
2025-11-07 16:48:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 16:48:36 | INFO | train_inner | epoch 001:    403 / 91072 loss=0.73291, wps=392.6, ups=1.62, wpb=242.8, bsz=16, num_updates=400, lr=8.88889e-07, gnorm=234.914, clip=100, loss_scale=16, train_wall=31, gb_free=13.7, wall=264
2025-11-07 16:49:06 | INFO | train_inner | epoch 001:    453 / 91072 loss=0.570312, wps=398.7, ups=1.64, wpb=243.4, bsz=16, num_updates=450, lr=1e-06, gnorm=179.934, clip=100, loss_scale=16, train_wall=30, gb_free=18.3, wall=294
2025-11-07 16:49:37 | INFO | train_inner | epoch 001:    503 / 91072 loss=0.69873, wps=400.3, ups=1.65, wpb=242.5, bsz=16, num_updates=500, lr=1.11111e-06, gnorm=215.589, clip=100, loss_scale=16, train_wall=30, gb_free=17.2, wall=325
2025-11-07 16:50:08 | INFO | train_inner | epoch 001:    553 / 91072 loss=0.634766, wps=415.5, ups=1.62, wpb=256.4, bsz=16, num_updates=550, lr=1.22222e-06, gnorm=211.993, clip=100, loss_scale=16, train_wall=31, gb_free=10.9, wall=355
2025-11-07 16:50:38 | INFO | train_inner | epoch 001:    603 / 91072 loss=0.615234, wps=403.4, ups=1.64, wpb=245.9, bsz=16, num_updates=600, lr=1.33333e-06, gnorm=168.648, clip=100, loss_scale=16, train_wall=30, gb_free=11.3, wall=386
2025-11-07 16:51:10 | INFO | train_inner | epoch 001:    653 / 91072 loss=0.588379, wps=384, ups=1.55, wpb=247, bsz=16, num_updates=650, lr=1.44444e-06, gnorm=163.719, clip=100, loss_scale=32, train_wall=31, gb_free=14.7, wall=418
2025-11-07 16:51:41 | INFO | train_inner | epoch 001:    703 / 91072 loss=0.615234, wps=403.2, ups=1.65, wpb=244.4, bsz=15.8, num_updates=700, lr=1.55556e-06, gnorm=182.171, clip=100, loss_scale=32, train_wall=30, gb_free=16, wall=448
2025-11-07 16:52:11 | INFO | train_inner | epoch 001:    753 / 91072 loss=0.666016, wps=403.5, ups=1.66, wpb=243.6, bsz=16, num_updates=750, lr=1.66667e-06, gnorm=165.599, clip=100, loss_scale=32, train_wall=30, gb_free=18.4, wall=479
2025-11-07 16:52:41 | INFO | train_inner | epoch 001:    803 / 91072 loss=0.686523, wps=397.2, ups=1.65, wpb=241.4, bsz=16, num_updates=800, lr=1.77778e-06, gnorm=149.587, clip=100, loss_scale=32, train_wall=30, gb_free=19, wall=509
2025-11-07 16:53:12 | INFO | train_inner | epoch 001:    853 / 91072 loss=0.702637, wps=410.8, ups=1.6, wpb=256.8, bsz=16, num_updates=850, lr=1.88889e-06, gnorm=157.581, clip=100, loss_scale=32, train_wall=31, gb_free=18.1, wall=540
2025-11-07 16:53:43 | INFO | train_inner | epoch 001:    903 / 91072 loss=0.740723, wps=399.9, ups=1.65, wpb=241.9, bsz=16, num_updates=900, lr=2e-06, gnorm=114.83, clip=100, loss_scale=64, train_wall=30, gb_free=18, wall=571
2025-11-07 16:54:13 | INFO | train_inner | epoch 001:    953 / 91072 loss=0.525391, wps=401.8, ups=1.66, wpb=242.6, bsz=16, num_updates=950, lr=2.11111e-06, gnorm=102.586, clip=100, loss_scale=64, train_wall=30, gb_free=15.4, wall=601
2025-11-07 16:54:43 | INFO | train_inner | epoch 001:   1003 / 91072 loss=0.645996, wps=404.4, ups=1.64, wpb=247.2, bsz=16, num_updates=1000, lr=2.22222e-06, gnorm=102.797, clip=100, loss_scale=64, train_wall=30, gb_free=18.2, wall=631
2025-11-07 16:55:15 | INFO | train_inner | epoch 001:   1053 / 91072 loss=0.560059, wps=402.9, ups=1.58, wpb=255, bsz=16, num_updates=1050, lr=2.33333e-06, gnorm=92.516, clip=100, loss_scale=64, train_wall=31, gb_free=9.2, wall=663
2025-11-07 16:55:46 | INFO | train_inner | epoch 001:   1103 / 91072 loss=0.593262, wps=411.7, ups=1.63, wpb=251.8, bsz=16, num_updates=1100, lr=2.44444e-06, gnorm=102.165, clip=100, loss_scale=64, train_wall=30, gb_free=14.1, wall=694
2025-11-07 16:56:16 | INFO | train_inner | epoch 001:   1153 / 91072 loss=0.577148, wps=404.3, ups=1.64, wpb=246.4, bsz=16, num_updates=1150, lr=2.55556e-06, gnorm=102.16, clip=100, loss_scale=128, train_wall=30, gb_free=17.1, wall=724
2025-11-07 16:56:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 16:56:47 | INFO | train_inner | epoch 001:   1204 / 91072 loss=0.549805, wps=379.7, ups=1.6, wpb=238, bsz=16, num_updates=1200, lr=2.66667e-06, gnorm=82.021, clip=100, loss_scale=64, train_wall=31, gb_free=16.5, wall=755
2025-11-07 16:57:19 | INFO | train_inner | epoch 001:   1254 / 91072 loss=0.556152, wps=415.7, ups=1.61, wpb=258.8, bsz=16, num_updates=1250, lr=2.77778e-06, gnorm=89.606, clip=100, loss_scale=64, train_wall=31, gb_free=15.6, wall=786
2025-11-07 16:57:49 | INFO | train_inner | epoch 001:   1304 / 91072 loss=0.595215, wps=397.3, ups=1.63, wpb=243.4, bsz=16, num_updates=1300, lr=2.88889e-06, gnorm=87.678, clip=100, loss_scale=64, train_wall=30, gb_free=17.9, wall=817
2025-11-07 16:58:18 | INFO | train_inner | epoch 001:   1354 / 91072 loss=0.583008, wps=388.8, ups=1.71, wpb=227.2, bsz=16, num_updates=1350, lr=3e-06, gnorm=65.777, clip=100, loss_scale=64, train_wall=29, gb_free=17.9, wall=846
2025-11-07 16:58:49 | INFO | train_inner | epoch 001:   1404 / 91072 loss=0.630859, wps=386.4, ups=1.65, wpb=234, bsz=16, num_updates=1400, lr=3.11111e-06, gnorm=76.652, clip=100, loss_scale=64, train_wall=30, gb_free=16.1, wall=877
2025-11-07 16:59:18 | INFO | train_inner | epoch 001:   1454 / 91072 loss=0.510742, wps=391.1, ups=1.68, wpb=232.8, bsz=16, num_updates=1450, lr=3.22222e-06, gnorm=63.96, clip=100, loss_scale=128, train_wall=30, gb_free=18.4, wall=906
2025-11-07 16:59:48 | INFO | train_inner | epoch 001:   1504 / 91072 loss=0.521973, wps=393.3, ups=1.68, wpb=234.1, bsz=16, num_updates=1500, lr=3.33333e-06, gnorm=55.61, clip=100, loss_scale=128, train_wall=30, gb_free=14.9, wall=936
2025-11-07 17:00:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 17:00:20 | INFO | train_inner | epoch 001:   1555 / 91072 loss=0.572754, wps=400.2, ups=1.6, wpb=250.9, bsz=16, num_updates=1550, lr=3.44444e-06, gnorm=83.024, clip=100, loss_scale=64, train_wall=31, gb_free=18, wall=967
2025-11-07 17:00:51 | INFO | train_inner | epoch 001:   1605 / 91072 loss=0.519043, wps=415.4, ups=1.59, wpb=261.5, bsz=16, num_updates=1600, lr=3.55556e-06, gnorm=75.22, clip=100, loss_scale=64, train_wall=31, gb_free=14.2, wall=999
2025-11-07 17:01:22 | INFO | train_inner | epoch 001:   1655 / 91072 loss=0.553223, wps=408, ups=1.61, wpb=253.3, bsz=16, num_updates=1650, lr=3.66667e-06, gnorm=67.831, clip=100, loss_scale=64, train_wall=31, gb_free=12.4, wall=1030
2025-11-07 17:01:53 | INFO | train_inner | epoch 001:   1705 / 91072 loss=0.578613, wps=406.6, ups=1.63, wpb=249.8, bsz=16, num_updates=1700, lr=3.77778e-06, gnorm=57.991, clip=100, loss_scale=64, train_wall=31, gb_free=17.8, wall=1061
2025-11-07 17:02:23 | INFO | train_inner | epoch 001:   1755 / 91072 loss=0.541504, wps=406.9, ups=1.64, wpb=248.6, bsz=16, num_updates=1750, lr=3.88889e-06, gnorm=65.9, clip=100, loss_scale=64, train_wall=30, gb_free=16.1, wall=1091
2025-11-07 17:02:53 | INFO | train_inner | epoch 001:   1805 / 91072 loss=0.583984, wps=392, ups=1.66, wpb=235.8, bsz=16, num_updates=1800, lr=4e-06, gnorm=63.211, clip=100, loss_scale=128, train_wall=30, gb_free=14.8, wall=1121
2025-11-07 17:03:24 | INFO | train_inner | epoch 001:   1855 / 91072 loss=0.51709, wps=393.1, ups=1.65, wpb=238.1, bsz=16, num_updates=1850, lr=4.11111e-06, gnorm=55.489, clip=100, loss_scale=128, train_wall=30, gb_free=15.2, wall=1152
2025-11-07 17:03:55 | INFO | train_inner | epoch 001:   1905 / 91072 loss=0.522949, wps=387.7, ups=1.57, wpb=246.3, bsz=16, num_updates=1900, lr=4.22222e-06, gnorm=66.838, clip=100, loss_scale=128, train_wall=30, gb_free=16.2, wall=1183
2025-11-07 17:04:26 | INFO | train_inner | epoch 001:   1955 / 91072 loss=0.517578, wps=393.3, ups=1.65, wpb=238.6, bsz=16, num_updates=1950, lr=4.33333e-06, gnorm=52.082, clip=100, loss_scale=128, train_wall=30, gb_free=17.7, wall=1214
2025-11-07 17:04:56 | INFO | train_inner | epoch 001:   2005 / 91072 loss=0.572754, wps=402, ups=1.64, wpb=245.1, bsz=16, num_updates=2000, lr=4.44444e-06, gnorm=55.248, clip=100, loss_scale=128, train_wall=30, gb_free=15.2, wall=1244
2025-11-07 17:05:27 | INFO | train_inner | epoch 001:   2055 / 91072 loss=0.503906, wps=398.6, ups=1.65, wpb=241.4, bsz=16, num_updates=2050, lr=4.55556e-06, gnorm=48.019, clip=100, loss_scale=256, train_wall=30, gb_free=18.2, wall=1274
2025-11-07 17:05:57 | INFO | train_inner | epoch 001:   2105 / 91072 loss=0.54834, wps=411.5, ups=1.64, wpb=251, bsz=16, num_updates=2100, lr=4.66667e-06, gnorm=48.267, clip=100, loss_scale=256, train_wall=30, gb_free=16.3, wall=1305
2025-11-07 17:06:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 17:06:28 | INFO | train_inner | epoch 001:   2156 / 91072 loss=0.483154, wps=387.8, ups=1.6, wpb=241.9, bsz=16, num_updates=2150, lr=4.77778e-06, gnorm=46.906, clip=100, loss_scale=128, train_wall=31, gb_free=15.1, wall=1336
2025-11-07 17:06:58 | INFO | train_inner | epoch 001:   2206 / 91072 loss=0.547852, wps=386.3, ups=1.69, wpb=228.4, bsz=16, num_updates=2200, lr=4.88889e-06, gnorm=52.677, clip=100, loss_scale=128, train_wall=29, gb_free=18.1, wall=1366
2025-11-07 17:07:30 | INFO | train_inner | epoch 001:   2256 / 91072 loss=0.525879, wps=426.1, ups=1.56, wpb=272.4, bsz=16, num_updates=2250, lr=5e-06, gnorm=50.158, clip=100, loss_scale=128, train_wall=32, gb_free=19.1, wall=1398
2025-11-07 17:08:00 | INFO | train_inner | epoch 001:   2306 / 91072 loss=0.537598, wps=400.8, ups=1.65, wpb=243.4, bsz=16, num_updates=2300, lr=5.11111e-06, gnorm=51.033, clip=100, loss_scale=128, train_wall=30, gb_free=17.7, wall=1428
2025-11-07 17:08:30 | INFO | train_inner | epoch 001:   2356 / 91072 loss=0.518066, wps=392.6, ups=1.65, wpb=237.5, bsz=16, num_updates=2350, lr=5.22222e-06, gnorm=45.209, clip=100, loss_scale=128, train_wall=30, gb_free=17.5, wall=1458
2025-11-07 17:09:01 | INFO | train_inner | epoch 001:   2406 / 91072 loss=0.468994, wps=396.5, ups=1.66, wpb=239.2, bsz=16, num_updates=2400, lr=5.33333e-06, gnorm=39.673, clip=100, loss_scale=256, train_wall=30, gb_free=17.6, wall=1488
2025-11-07 17:09:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 17:09:32 | INFO | train_inner | epoch 001:   2457 / 91072 loss=0.578125, wps=399.2, ups=1.58, wpb=252.5, bsz=16, num_updates=2450, lr=5.44444e-06, gnorm=51.211, clip=100, loss_scale=128, train_wall=31, gb_free=18, wall=1520
2025-11-07 17:10:03 | INFO | train_inner | epoch 001:   2507 / 91072 loss=0.50293, wps=399.6, ups=1.64, wpb=243.1, bsz=16, num_updates=2500, lr=5.55556e-06, gnorm=44.13, clip=100, loss_scale=128, train_wall=30, gb_free=18.1, wall=1550
2025-11-07 17:10:33 | INFO | train_inner | epoch 001:   2557 / 91072 loss=0.508301, wps=392.3, ups=1.63, wpb=241.3, bsz=16, num_updates=2550, lr=5.66667e-06, gnorm=40.921, clip=100, loss_scale=128, train_wall=31, gb_free=14.5, wall=1581
2025-11-07 17:11:04 | INFO | train_inner | epoch 001:   2607 / 91072 loss=0.543457, wps=415.5, ups=1.62, wpb=256.4, bsz=16, num_updates=2600, lr=5.77778e-06, gnorm=46.334, clip=100, loss_scale=128, train_wall=31, gb_free=18.5, wall=1612
2025-11-07 17:11:35 | INFO | train_inner | epoch 001:   2657 / 91072 loss=0.513184, wps=405.6, ups=1.64, wpb=247.3, bsz=16, num_updates=2650, lr=5.88889e-06, gnorm=41.966, clip=100, loss_scale=128, train_wall=30, gb_free=16.5, wall=1643
2025-11-07 17:11:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 17:12:07 | INFO | train_inner | epoch 001:   2708 / 91072 loss=0.502441, wps=407.5, ups=1.56, wpb=260.8, bsz=16, num_updates=2700, lr=6e-06, gnorm=49.465, clip=100, loss_scale=128, train_wall=32, gb_free=16.9, wall=1675
2025-11-07 17:12:38 | INFO | train_inner | epoch 001:   2758 / 91072 loss=0.447998, wps=400.2, ups=1.61, wpb=249.3, bsz=16, num_updates=2750, lr=6.11111e-06, gnorm=43.069, clip=100, loss_scale=128, train_wall=31, gb_free=16.2, wall=1706
2025-11-07 17:13:08 | INFO | train_inner | epoch 001:   2808 / 91072 loss=0.493408, wps=398.4, ups=1.64, wpb=242.4, bsz=16, num_updates=2800, lr=6.22222e-06, gnorm=40.189, clip=100, loss_scale=128, train_wall=30, gb_free=18.2, wall=1736
2025-11-07 17:13:39 | INFO | train_inner | epoch 001:   2858 / 91072 loss=0.478027, wps=397.3, ups=1.64, wpb=241.7, bsz=16, num_updates=2850, lr=6.33333e-06, gnorm=39.26, clip=100, loss_scale=128, train_wall=30, gb_free=18.1, wall=1767
2025-11-07 17:14:09 | INFO | train_inner | epoch 001:   2908 / 91072 loss=0.52002, wps=398.4, ups=1.65, wpb=241.3, bsz=16, num_updates=2900, lr=6.44444e-06, gnorm=40.255, clip=100, loss_scale=128, train_wall=30, gb_free=15.9, wall=1797
2025-11-07 17:14:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 17:14:40 | INFO | train_inner | epoch 001:   2959 / 91072 loss=0.552734, wps=382, ups=1.6, wpb=239.2, bsz=16, num_updates=2950, lr=6.55556e-06, gnorm=48.074, clip=100, loss_scale=64, train_wall=31, gb_free=16.2, wall=1828
2025-11-07 17:15:11 | INFO | train_inner | epoch 001:   3009 / 91072 loss=0.521973, wps=396.6, ups=1.65, wpb=240.4, bsz=16, num_updates=3000, lr=6.66667e-06, gnorm=38.898, clip=100, loss_scale=64, train_wall=30, gb_free=14, wall=1858
2025-11-07 17:15:42 | INFO | train_inner | epoch 001:   3059 / 91072 loss=0.527832, wps=415, ups=1.6, wpb=259.6, bsz=16, num_updates=3050, lr=6.77778e-06, gnorm=42.424, clip=100, loss_scale=64, train_wall=31, gb_free=18, wall=1890
2025-11-07 17:16:12 | INFO | train_inner | epoch 001:   3109 / 91072 loss=0.534668, wps=390.4, ups=1.65, wpb=236.8, bsz=16, num_updates=3100, lr=6.88889e-06, gnorm=41.617, clip=100, loss_scale=64, train_wall=30, gb_free=18.7, wall=1920
2025-11-07 17:16:42 | INFO | train_inner | epoch 001:   3159 / 91072 loss=0.522949, wps=403.6, ups=1.66, wpb=243.7, bsz=16, num_updates=3150, lr=7e-06, gnorm=36.893, clip=100, loss_scale=64, train_wall=30, gb_free=18.1, wall=1950
2025-11-07 17:17:12 | INFO | train_inner | epoch 001:   3209 / 91072 loss=0.522461, wps=387.5, ups=1.69, wpb=229.7, bsz=16, num_updates=3200, lr=7.11111e-06, gnorm=39.611, clip=100, loss_scale=128, train_wall=29, gb_free=17.8, wall=1980
2025-11-07 17:17:42 | INFO | train_inner | epoch 001:   3259 / 91072 loss=0.497559, wps=402.6, ups=1.65, wpb=244.7, bsz=16, num_updates=3250, lr=7.22222e-06, gnorm=33.56, clip=100, loss_scale=128, train_wall=30, gb_free=15, wall=2010
2025-11-07 17:18:13 | INFO | train_inner | epoch 001:   3309 / 91072 loss=0.498535, wps=396.8, ups=1.63, wpb=243, bsz=16, num_updates=3300, lr=7.33333e-06, gnorm=37.44, clip=100, loss_scale=128, train_wall=30, gb_free=9.5, wall=2041
2025-11-07 17:18:43 | INFO | train_inner | epoch 001:   3359 / 91072 loss=0.459961, wps=393.7, ups=1.67, wpb=236.1, bsz=16, num_updates=3350, lr=7.44444e-06, gnorm=31.354, clip=100, loss_scale=128, train_wall=30, gb_free=16, wall=2071
2025-11-07 17:19:13 | INFO | train_inner | epoch 001:   3409 / 91072 loss=0.471436, wps=399.9, ups=1.65, wpb=243, bsz=16, num_updates=3400, lr=7.55556e-06, gnorm=43.605, clip=100, loss_scale=128, train_wall=30, gb_free=15.1, wall=2101
2025-11-07 17:19:44 | INFO | train_inner | epoch 001:   3459 / 91072 loss=0.509277, wps=403.7, ups=1.63, wpb=247.3, bsz=16, num_updates=3450, lr=7.66667e-06, gnorm=40.019, clip=100, loss_scale=256, train_wall=30, gb_free=16.6, wall=2132
2025-11-07 17:20:14 | INFO | train_inner | epoch 001:   3509 / 91072 loss=0.494385, wps=396.2, ups=1.65, wpb=240.8, bsz=16, num_updates=3500, lr=7.77778e-06, gnorm=36.889, clip=100, loss_scale=256, train_wall=30, gb_free=18.3, wall=2162
2025-11-07 17:20:45 | INFO | train_inner | epoch 001:   3559 / 91072 loss=0.481934, wps=402.7, ups=1.64, wpb=245, bsz=16, num_updates=3550, lr=7.88889e-06, gnorm=33.524, clip=100, loss_scale=256, train_wall=30, gb_free=18.9, wall=2193
2025-11-07 17:21:16 | INFO | train_inner | epoch 001:   3609 / 91072 loss=0.519043, wps=410, ups=1.62, wpb=252.9, bsz=16, num_updates=3600, lr=8e-06, gnorm=34.79, clip=100, loss_scale=256, train_wall=31, gb_free=18.5, wall=2224
2025-11-07 17:21:46 | INFO | train_inner | epoch 001:   3659 / 91072 loss=0.459229, wps=402.1, ups=1.66, wpb=242.7, bsz=16, num_updates=3650, lr=8.11111e-06, gnorm=29.149, clip=100, loss_scale=256, train_wall=30, gb_free=15.6, wall=2254
2025-11-07 17:22:17 | INFO | train_inner | epoch 001:   3709 / 91072 loss=0.49585, wps=380, ups=1.61, wpb=236, bsz=16, num_updates=3700, lr=8.22222e-06, gnorm=36.673, clip=100, loss_scale=256, train_wall=31, gb_free=17.5, wall=2285
2025-11-07 17:22:47 | INFO | train_inner | epoch 001:   3759 / 91072 loss=0.463867, wps=385.4, ups=1.68, wpb=229.2, bsz=16, num_updates=3750, lr=8.33333e-06, gnorm=29.393, clip=100, loss_scale=512, train_wall=30, gb_free=18.3, wall=2315
2025-11-07 17:23:17 | INFO | train_inner | epoch 001:   3809 / 91072 loss=0.467529, wps=399.9, ups=1.65, wpb=242.1, bsz=16, num_updates=3800, lr=8.44444e-06, gnorm=27.424, clip=100, loss_scale=512, train_wall=30, gb_free=18.1, wall=2345
2025-11-07 17:23:47 | INFO | train_inner | epoch 001:   3859 / 91072 loss=0.505859, wps=399.2, ups=1.67, wpb=239.5, bsz=16, num_updates=3850, lr=8.55556e-06, gnorm=34.1, clip=100, loss_scale=512, train_wall=30, gb_free=17.9, wall=2375
2025-11-07 17:24:17 | INFO | train_inner | epoch 001:   3909 / 91072 loss=0.468994, wps=399.4, ups=1.64, wpb=244.2, bsz=16, num_updates=3900, lr=8.66667e-06, gnorm=30.976, clip=100, loss_scale=512, train_wall=30, gb_free=16.9, wall=2405
2025-11-07 17:24:47 | INFO | train_inner | epoch 001:   3959 / 91072 loss=0.528809, wps=389.4, ups=1.68, wpb=231.2, bsz=16, num_updates=3950, lr=8.77778e-06, gnorm=28.131, clip=100, loss_scale=512, train_wall=30, gb_free=15.4, wall=2435
2025-11-07 17:25:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 17:25:18 | INFO | train_inner | epoch 001:   4010 / 91072 loss=0.492188, wps=390.9, ups=1.64, wpb=238.1, bsz=16, num_updates=4000, lr=8.88889e-06, gnorm=26.873, clip=100, loss_scale=512, train_wall=30, gb_free=16.6, wall=2466
2025-11-07 17:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:25:49 | INFO | train_inner | epoch 001:   4061 / 91072 loss=0.490967, wps=398.6, ups=1.61, wpb=247.7, bsz=16, num_updates=4050, lr=9e-06, gnorm=34.194, clip=100, loss_scale=256, train_wall=31, gb_free=17.2, wall=2497
2025-11-07 17:26:19 | INFO | train_inner | epoch 001:   4111 / 91072 loss=0.489258, wps=400, ups=1.65, wpb=243, bsz=16, num_updates=4100, lr=9.11111e-06, gnorm=29.862, clip=100, loss_scale=256, train_wall=30, gb_free=16.3, wall=2527
2025-11-07 17:26:49 | INFO | train_inner | epoch 001:   4161 / 91072 loss=0.50293, wps=396, ups=1.67, wpb=237.5, bsz=16, num_updates=4150, lr=9.22222e-06, gnorm=31.774, clip=100, loss_scale=256, train_wall=30, gb_free=17.6, wall=2557
2025-11-07 17:27:20 | INFO | train_inner | epoch 001:   4211 / 91072 loss=0.468262, wps=407.1, ups=1.63, wpb=250.2, bsz=16, num_updates=4200, lr=9.33333e-06, gnorm=34.027, clip=100, loss_scale=256, train_wall=31, gb_free=17.1, wall=2588
2025-11-07 17:27:50 | INFO | train_inner | epoch 001:   4261 / 91072 loss=0.487549, wps=401.2, ups=1.64, wpb=245.2, bsz=16, num_updates=4250, lr=9.44444e-06, gnorm=33.741, clip=100, loss_scale=256, train_wall=30, gb_free=14.4, wall=2618
2025-11-07 17:28:21 | INFO | train_inner | epoch 001:   4311 / 91072 loss=0.424561, wps=417.6, ups=1.61, wpb=259.5, bsz=16, num_updates=4300, lr=9.55556e-06, gnorm=28.955, clip=100, loss_scale=512, train_wall=31, gb_free=13.3, wall=2649
2025-11-07 17:28:52 | INFO | train_inner | epoch 001:   4361 / 91072 loss=0.473389, wps=401.4, ups=1.65, wpb=242.8, bsz=16, num_updates=4350, lr=9.66667e-06, gnorm=29.451, clip=100, loss_scale=512, train_wall=30, gb_free=17, wall=2680
2025-11-07 17:29:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:29:23 | INFO | train_inner | epoch 001:   4412 / 91072 loss=0.474365, wps=395.7, ups=1.61, wpb=245.2, bsz=16, num_updates=4400, lr=9.77778e-06, gnorm=26.308, clip=100, loss_scale=256, train_wall=31, gb_free=14.6, wall=2711
2025-11-07 17:29:54 | INFO | train_inner | epoch 001:   4462 / 91072 loss=0.47168, wps=407.1, ups=1.6, wpb=254.2, bsz=16, num_updates=4450, lr=9.88889e-06, gnorm=29.901, clip=100, loss_scale=256, train_wall=31, gb_free=15.1, wall=2742
2025-11-07 17:30:24 | INFO | train_inner | epoch 001:   4512 / 91072 loss=0.52832, wps=395.7, ups=1.66, wpb=238.8, bsz=16, num_updates=4500, lr=1e-05, gnorm=29.449, clip=100, loss_scale=256, train_wall=30, gb_free=15.1, wall=2772
2025-11-07 17:30:54 | INFO | train_inner | epoch 001:   4562 / 91072 loss=0.465332, wps=405.2, ups=1.64, wpb=246.6, bsz=16, num_updates=4550, lr=1.01111e-05, gnorm=28.854, clip=100, loss_scale=256, train_wall=30, gb_free=15.5, wall=2802
2025-11-07 17:31:25 | INFO | train_inner | epoch 001:   4612 / 91072 loss=0.461182, wps=404, ups=1.65, wpb=244.7, bsz=16, num_updates=4600, lr=1.02222e-05, gnorm=29.71, clip=100, loss_scale=256, train_wall=30, gb_free=11.6, wall=2833
2025-11-07 17:31:55 | INFO | train_inner | epoch 001:   4662 / 91072 loss=0.44458, wps=392.4, ups=1.64, wpb=238.8, bsz=16, num_updates=4650, lr=1.03333e-05, gnorm=26.868, clip=100, loss_scale=512, train_wall=30, gb_free=17.8, wall=2863
2025-11-07 17:32:26 | INFO | train_inner | epoch 001:   4712 / 91072 loss=0.483643, wps=406.3, ups=1.64, wpb=248.4, bsz=16, num_updates=4700, lr=1.04444e-05, gnorm=29.855, clip=100, loss_scale=512, train_wall=30, gb_free=13.1, wall=2894
2025-11-07 17:32:57 | INFO | train_inner | epoch 001:   4762 / 91072 loss=0.513672, wps=410.9, ups=1.61, wpb=255.1, bsz=16, num_updates=4750, lr=1.05556e-05, gnorm=30.343, clip=100, loss_scale=512, train_wall=31, gb_free=9, wall=2925
2025-11-07 17:33:26 | INFO | train_inner | epoch 001:   4812 / 91072 loss=0.463379, wps=390.1, ups=1.68, wpb=231.7, bsz=16, num_updates=4800, lr=1.06667e-05, gnorm=28.788, clip=100, loss_scale=512, train_wall=30, gb_free=16.2, wall=2954
2025-11-07 17:33:57 | INFO | train_inner | epoch 001:   4862 / 91072 loss=0.465332, wps=397, ups=1.64, wpb=242.4, bsz=16, num_updates=4850, lr=1.07778e-05, gnorm=27.992, clip=100, loss_scale=512, train_wall=30, gb_free=18, wall=2985
2025-11-07 17:34:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 17:34:28 | INFO | train_inner | epoch 001:   4913 / 91072 loss=0.466309, wps=395.3, ups=1.59, wpb=248.7, bsz=16, num_updates=4900, lr=1.08889e-05, gnorm=27.52, clip=100, loss_scale=512, train_wall=31, gb_free=15.8, wall=3016
2025-11-07 17:34:59 | INFO | train_inner | epoch 001:   4963 / 91072 loss=0.52832, wps=397.9, ups=1.65, wpb=241.2, bsz=16, num_updates=4950, lr=1.1e-05, gnorm=27.526, clip=100, loss_scale=512, train_wall=30, gb_free=13.5, wall=3047
2025-11-07 17:35:30 | INFO | train_inner | epoch 001:   5013 / 91072 loss=0.431152, wps=421.8, ups=1.6, wpb=262.8, bsz=16, num_updates=5000, lr=1.11111e-05, gnorm=25.382, clip=100, loss_scale=512, train_wall=31, gb_free=17.8, wall=3078
2025-11-07 17:36:01 | INFO | train_inner | epoch 001:   5063 / 91072 loss=0.434326, wps=396.7, ups=1.61, wpb=246, bsz=16, num_updates=5050, lr=1.12222e-05, gnorm=25.37, clip=100, loss_scale=512, train_wall=31, gb_free=14.4, wall=3109
2025-11-07 17:36:31 | INFO | train_inner | epoch 001:   5113 / 91072 loss=0.53418, wps=392.9, ups=1.68, wpb=234.5, bsz=16, num_updates=5100, lr=1.13333e-05, gnorm=27.817, clip=100, loss_scale=512, train_wall=30, gb_free=16.9, wall=3139
2025-11-07 17:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:37:02 | INFO | train_inner | epoch 001:   5164 / 91072 loss=0.482666, wps=394.7, ups=1.6, wpb=246.8, bsz=16, num_updates=5150, lr=1.14444e-05, gnorm=30.568, clip=100, loss_scale=256, train_wall=31, gb_free=15.2, wall=3170
2025-11-07 17:37:32 | INFO | train_inner | epoch 001:   5214 / 91072 loss=0.418213, wps=381.4, ups=1.68, wpb=226.4, bsz=16, num_updates=5200, lr=1.15556e-05, gnorm=24.87, clip=100, loss_scale=256, train_wall=30, gb_free=14.7, wall=3200
2025-11-07 17:38:03 | INFO | train_inner | epoch 001:   5264 / 91072 loss=0.458984, wps=412.7, ups=1.62, wpb=254.9, bsz=16, num_updates=5250, lr=1.16667e-05, gnorm=29.762, clip=100, loss_scale=256, train_wall=31, gb_free=18.3, wall=3231
2025-11-07 17:38:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 17:38:33 | INFO | train_inner | epoch 001:   5315 / 91072 loss=0.467041, wps=390.5, ups=1.64, wpb=238.4, bsz=16, num_updates=5300, lr=1.17778e-05, gnorm=25.266, clip=100, loss_scale=128, train_wall=30, gb_free=18, wall=3261
2025-11-07 17:39:03 | INFO | train_inner | epoch 001:   5365 / 91072 loss=0.414307, wps=376.8, ups=1.69, wpb=222.6, bsz=16, num_updates=5350, lr=1.18889e-05, gnorm=24.171, clip=100, loss_scale=128, train_wall=29, gb_free=18.7, wall=3291
2025-11-07 17:39:33 | INFO | train_inner | epoch 001:   5415 / 91072 loss=0.463379, wps=400.7, ups=1.63, wpb=245.2, bsz=16, num_updates=5400, lr=1.2e-05, gnorm=28.596, clip=100, loss_scale=128, train_wall=30, gb_free=7.4, wall=3321
2025-11-07 17:40:04 | INFO | train_inner | epoch 001:   5465 / 91072 loss=0.494629, wps=389, ups=1.64, wpb=237.9, bsz=16, num_updates=5450, lr=1.21111e-05, gnorm=25.639, clip=100, loss_scale=128, train_wall=30, gb_free=14.9, wall=3352
2025-11-07 17:40:34 | INFO | train_inner | epoch 001:   5515 / 91072 loss=0.516113, wps=402.1, ups=1.65, wpb=243.4, bsz=16, num_updates=5500, lr=1.22222e-05, gnorm=26.238, clip=100, loss_scale=128, train_wall=30, gb_free=13.1, wall=3382
2025-11-07 17:41:05 | INFO | train_inner | epoch 001:   5565 / 91072 loss=0.467041, wps=416, ups=1.61, wpb=258.7, bsz=16, num_updates=5550, lr=1.23333e-05, gnorm=26.268, clip=100, loss_scale=256, train_wall=31, gb_free=16.3, wall=3413
2025-11-07 17:41:35 | INFO | train_inner | epoch 001:   5615 / 91072 loss=0.404785, wps=387.3, ups=1.66, wpb=233.7, bsz=16, num_updates=5600, lr=1.24444e-05, gnorm=27.005, clip=100, loss_scale=256, train_wall=30, gb_free=16.3, wall=3443
2025-11-07 17:42:05 | INFO | train_inner | epoch 001:   5665 / 91072 loss=0.480469, wps=396.7, ups=1.67, wpb=237.6, bsz=16, num_updates=5650, lr=1.25556e-05, gnorm=27.623, clip=100, loss_scale=256, train_wall=30, gb_free=18.3, wall=3473
2025-11-07 17:42:36 | INFO | train_inner | epoch 001:   5715 / 91072 loss=0.516113, wps=410.3, ups=1.64, wpb=250.2, bsz=16, num_updates=5700, lr=1.26667e-05, gnorm=32.089, clip=100, loss_scale=256, train_wall=30, gb_free=15.8, wall=3504
2025-11-07 17:43:06 | INFO | train_inner | epoch 001:   5765 / 91072 loss=0.47168, wps=403.6, ups=1.66, wpb=243.5, bsz=16, num_updates=5750, lr=1.27778e-05, gnorm=26.466, clip=100, loss_scale=256, train_wall=30, gb_free=17.3, wall=3534
2025-11-07 17:43:36 | INFO | train_inner | epoch 001:   5815 / 91072 loss=0.429932, wps=394.7, ups=1.65, wpb=238.6, bsz=16, num_updates=5800, lr=1.28889e-05, gnorm=24.583, clip=100, loss_scale=512, train_wall=30, gb_free=11.7, wall=3564
2025-11-07 17:44:06 | INFO | train_inner | epoch 001:   5865 / 91072 loss=0.47998, wps=403.4, ups=1.65, wpb=243.9, bsz=16, num_updates=5850, lr=1.3e-05, gnorm=30.092, clip=100, loss_scale=512, train_wall=30, gb_free=18.1, wall=3594
2025-11-07 17:44:37 | INFO | train_inner | epoch 001:   5915 / 91072 loss=0.460938, wps=397.5, ups=1.61, wpb=246.3, bsz=16, num_updates=5900, lr=1.31111e-05, gnorm=26.834, clip=100, loss_scale=512, train_wall=31, gb_free=18.7, wall=3625
2025-11-07 17:45:09 | INFO | train_inner | epoch 001:   5965 / 91072 loss=0.416992, wps=417.7, ups=1.59, wpb=262.1, bsz=16, num_updates=5950, lr=1.32222e-05, gnorm=23.111, clip=100, loss_scale=512, train_wall=31, gb_free=15.7, wall=3657
2025-11-07 17:45:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:45:40 | INFO | train_inner | epoch 001:   6016 / 91072 loss=0.483398, wps=392.2, ups=1.59, wpb=247.4, bsz=16, num_updates=6000, lr=1.33333e-05, gnorm=27.37, clip=100, loss_scale=256, train_wall=31, gb_free=16.9, wall=3688
2025-11-07 17:46:12 | INFO | train_inner | epoch 001:   6066 / 91072 loss=0.40625, wps=393.9, ups=1.58, wpb=249.5, bsz=16, num_updates=6050, lr=1.34444e-05, gnorm=21.672, clip=100, loss_scale=256, train_wall=32, gb_free=17.1, wall=3720
2025-11-07 17:46:43 | INFO | train_inner | epoch 001:   6116 / 91072 loss=0.489014, wps=413.4, ups=1.62, wpb=256, bsz=16, num_updates=6100, lr=1.35556e-05, gnorm=27.765, clip=100, loss_scale=256, train_wall=31, gb_free=18.1, wall=3751
2025-11-07 17:47:13 | INFO | train_inner | epoch 001:   6166 / 91072 loss=0.424316, wps=403.4, ups=1.65, wpb=244.7, bsz=16, num_updates=6150, lr=1.36667e-05, gnorm=25.567, clip=100, loss_scale=256, train_wall=30, gb_free=14.5, wall=3781
2025-11-07 17:47:44 | INFO | train_inner | epoch 001:   6216 / 91072 loss=0.490479, wps=391.1, ups=1.64, wpb=239, bsz=16, num_updates=6200, lr=1.37778e-05, gnorm=25.401, clip=100, loss_scale=256, train_wall=30, gb_free=17.5, wall=3812
2025-11-07 17:47:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:48:14 | INFO | train_inner | epoch 001:   6267 / 91072 loss=0.453857, wps=389.3, ups=1.63, wpb=238.3, bsz=16, num_updates=6250, lr=1.38889e-05, gnorm=31.091, clip=100, loss_scale=256, train_wall=30, gb_free=17.6, wall=3842
2025-11-07 17:48:45 | INFO | train_inner | epoch 001:   6317 / 91072 loss=0.479736, wps=404.8, ups=1.61, wpb=251, bsz=16, num_updates=6300, lr=1.4e-05, gnorm=28.424, clip=100, loss_scale=256, train_wall=31, gb_free=16.8, wall=3873
2025-11-07 17:49:21 | INFO | train_inner | epoch 001:   6367 / 91072 loss=0.450684, wps=352.9, ups=1.39, wpb=253.2, bsz=16, num_updates=6350, lr=1.41111e-05, gnorm=29.526, clip=100, loss_scale=256, train_wall=36, gb_free=19, wall=3909
2025-11-07 17:49:52 | INFO | train_inner | epoch 001:   6417 / 91072 loss=0.445557, wps=409.9, ups=1.64, wpb=249.9, bsz=16, num_updates=6400, lr=1.42222e-05, gnorm=27.659, clip=100, loss_scale=256, train_wall=30, gb_free=15.1, wall=3940
2025-11-07 17:50:22 | INFO | train_inner | epoch 001:   6467 / 91072 loss=0.45459, wps=387.2, ups=1.68, wpb=231.2, bsz=16, num_updates=6450, lr=1.43333e-05, gnorm=27.225, clip=100, loss_scale=256, train_wall=30, gb_free=18.2, wall=3970
2025-11-07 17:50:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:50:53 | INFO | train_inner | epoch 001:   6518 / 91072 loss=0.447021, wps=396.5, ups=1.61, wpb=246.5, bsz=16, num_updates=6500, lr=1.44444e-05, gnorm=26.614, clip=100, loss_scale=256, train_wall=31, gb_free=17.5, wall=4001
2025-11-07 17:51:24 | INFO | train_inner | epoch 001:   6568 / 91072 loss=0.451904, wps=402.5, ups=1.59, wpb=253, bsz=16, num_updates=6550, lr=1.45556e-05, gnorm=20.97, clip=100, loss_scale=256, train_wall=31, gb_free=14.5, wall=4032
2025-11-07 17:51:56 | INFO | train_inner | epoch 001:   6618 / 91072 loss=0.424805, wps=397.6, ups=1.59, wpb=250.6, bsz=16, num_updates=6600, lr=1.46667e-05, gnorm=26.94, clip=100, loss_scale=256, train_wall=31, gb_free=18.7, wall=4064
2025-11-07 17:52:26 | INFO | train_inner | epoch 001:   6668 / 91072 loss=0.494873, wps=401.5, ups=1.63, wpb=245.8, bsz=16, num_updates=6650, lr=1.47778e-05, gnorm=31.759, clip=100, loss_scale=256, train_wall=30, gb_free=17.9, wall=4094
2025-11-07 17:52:57 | INFO | train_inner | epoch 001:   6718 / 91072 loss=0.457275, wps=395.2, ups=1.65, wpb=239.5, bsz=16, num_updates=6700, lr=1.48889e-05, gnorm=25.059, clip=100, loss_scale=256, train_wall=30, gb_free=17.7, wall=4125
2025-11-07 17:53:29 | INFO | train_inner | epoch 001:   6768 / 91072 loss=0.415771, wps=411.6, ups=1.57, wpb=262, bsz=16, num_updates=6750, lr=1.5e-05, gnorm=28.246, clip=100, loss_scale=512, train_wall=32, gb_free=12.7, wall=4156
2025-11-07 17:53:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 17:54:00 | INFO | train_inner | epoch 001:   6819 / 91072 loss=0.498779, wps=405.3, ups=1.58, wpb=255.7, bsz=16, num_updates=6800, lr=1.51111e-05, gnorm=32.385, clip=100, loss_scale=256, train_wall=31, gb_free=16.5, wall=4188
2025-11-07 17:54:31 | INFO | train_inner | epoch 001:   6869 / 91072 loss=0.506348, wps=400, ups=1.64, wpb=244.6, bsz=16, num_updates=6850, lr=1.52222e-05, gnorm=28.147, clip=100, loss_scale=256, train_wall=30, gb_free=17.4, wall=4219
2025-11-07 17:55:01 | INFO | train_inner | epoch 001:   6919 / 91072 loss=0.488525, wps=396.5, ups=1.65, wpb=239.6, bsz=16, num_updates=6900, lr=1.53333e-05, gnorm=25.268, clip=98, loss_scale=256, train_wall=30, gb_free=18.6, wall=4249
2025-11-07 17:55:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 17:55:32 | INFO | train_inner | epoch 001:   6970 / 91072 loss=0.51709, wps=391.5, ups=1.59, wpb=246.1, bsz=16, num_updates=6950, lr=1.54444e-05, gnorm=29.04, clip=100, loss_scale=128, train_wall=31, gb_free=16.5, wall=4280
2025-11-07 17:56:03 | INFO | train_inner | epoch 001:   7020 / 91072 loss=0.466309, wps=410.5, ups=1.62, wpb=253.4, bsz=16, num_updates=7000, lr=1.55556e-05, gnorm=29.529, clip=100, loss_scale=128, train_wall=31, gb_free=18, wall=4311
2025-11-07 17:56:34 | INFO | train_inner | epoch 001:   7070 / 91072 loss=0.423584, wps=405.5, ups=1.62, wpb=250.1, bsz=16, num_updates=7050, lr=1.56667e-05, gnorm=26.989, clip=100, loss_scale=128, train_wall=31, gb_free=17.5, wall=4342
2025-11-07 17:57:05 | INFO | train_inner | epoch 001:   7120 / 91072 loss=0.430664, wps=409.8, ups=1.62, wpb=252.5, bsz=16, num_updates=7100, lr=1.57778e-05, gnorm=27.7, clip=100, loss_scale=128, train_wall=31, gb_free=14.5, wall=4373
2025-11-07 17:57:35 | INFO | train_inner | epoch 001:   7170 / 91072 loss=0.483643, wps=391.8, ups=1.63, wpb=240.5, bsz=16, num_updates=7150, lr=1.58889e-05, gnorm=30.273, clip=100, loss_scale=128, train_wall=31, gb_free=17.8, wall=4403
2025-11-07 17:58:07 | INFO | train_inner | epoch 001:   7220 / 91072 loss=0.50293, wps=407.3, ups=1.6, wpb=254.1, bsz=16, num_updates=7200, lr=1.6e-05, gnorm=27.571, clip=100, loss_scale=256, train_wall=31, gb_free=8.1, wall=4435
2025-11-07 17:58:37 | INFO | train_inner | epoch 001:   7270 / 91072 loss=0.406738, wps=398.8, ups=1.65, wpb=241.9, bsz=16, num_updates=7250, lr=1.61111e-05, gnorm=25.019, clip=100, loss_scale=256, train_wall=30, gb_free=17.5, wall=4465
2025-11-07 17:59:08 | INFO | train_inner | epoch 001:   7320 / 91072 loss=0.468262, wps=398.2, ups=1.62, wpb=245.4, bsz=16, num_updates=7300, lr=1.62222e-05, gnorm=24.153, clip=100, loss_scale=256, train_wall=31, gb_free=16.3, wall=4496
2025-11-07 17:59:38 | INFO | train_inner | epoch 001:   7370 / 91072 loss=0.421875, wps=394.3, ups=1.64, wpb=240.6, bsz=16, num_updates=7350, lr=1.63333e-05, gnorm=29.06, clip=100, loss_scale=256, train_wall=30, gb_free=13.9, wall=4526
2025-11-07 18:00:10 | INFO | train_inner | epoch 001:   7420 / 91072 loss=0.443604, wps=413.7, ups=1.59, wpb=260.1, bsz=16, num_updates=7400, lr=1.64444e-05, gnorm=26.485, clip=100, loss_scale=256, train_wall=31, gb_free=10.9, wall=4558
2025-11-07 18:00:40 | INFO | train_inner | epoch 001:   7470 / 91072 loss=0.458252, wps=401.4, ups=1.64, wpb=244.9, bsz=16, num_updates=7450, lr=1.65556e-05, gnorm=26.813, clip=100, loss_scale=256, train_wall=30, gb_free=15.1, wall=4588
2025-11-07 18:01:11 | INFO | train_inner | epoch 001:   7520 / 91072 loss=0.449219, wps=391.8, ups=1.64, wpb=238.9, bsz=16, num_updates=7500, lr=1.66667e-05, gnorm=24.296, clip=100, loss_scale=512, train_wall=30, gb_free=13.9, wall=4619
2025-11-07 18:01:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 18:01:42 | INFO | train_inner | epoch 001:   7571 / 91072 loss=0.473145, wps=400.5, ups=1.59, wpb=252.2, bsz=16, num_updates=7550, lr=1.67778e-05, gnorm=26.63, clip=100, loss_scale=256, train_wall=31, gb_free=18.7, wall=4650
2025-11-07 18:02:13 | INFO | train_inner | epoch 001:   7621 / 91072 loss=0.400635, wps=400.5, ups=1.62, wpb=247.4, bsz=16, num_updates=7600, lr=1.68889e-05, gnorm=24.827, clip=100, loss_scale=256, train_wall=31, gb_free=14, wall=4681
2025-11-07 18:02:44 | INFO | train_inner | epoch 001:   7671 / 91072 loss=0.483154, wps=406.5, ups=1.61, wpb=252.1, bsz=16, num_updates=7650, lr=1.7e-05, gnorm=28.175, clip=100, loss_scale=256, train_wall=31, gb_free=17.9, wall=4712
2025-11-07 18:03:15 | INFO | train_inner | epoch 001:   7721 / 91072 loss=0.430664, wps=388.6, ups=1.63, wpb=238.3, bsz=16, num_updates=7700, lr=1.71111e-05, gnorm=27.971, clip=100, loss_scale=256, train_wall=31, gb_free=17, wall=4743
2025-11-07 18:03:45 | INFO | train_inner | epoch 001:   7771 / 91072 loss=0.424561, wps=398.9, ups=1.65, wpb=241.3, bsz=16, num_updates=7750, lr=1.72222e-05, gnorm=25.223, clip=100, loss_scale=256, train_wall=30, gb_free=13, wall=4773
2025-11-07 18:03:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 18:04:15 | INFO | train_inner | epoch 001:   7822 / 91072 loss=0.446533, wps=372.8, ups=1.65, wpb=226.2, bsz=16, num_updates=7800, lr=1.73333e-05, gnorm=25.069, clip=100, loss_scale=256, train_wall=30, gb_free=18.8, wall=4803
2025-11-07 18:04:46 | INFO | train_inner | epoch 001:   7872 / 91072 loss=0.456055, wps=391.7, ups=1.66, wpb=236, bsz=16, num_updates=7850, lr=1.74444e-05, gnorm=27.478, clip=100, loss_scale=256, train_wall=30, gb_free=17.6, wall=4833
2025-11-07 18:05:17 | INFO | train_inner | epoch 001:   7922 / 91072 loss=0.480957, wps=411.6, ups=1.57, wpb=262.1, bsz=16, num_updates=7900, lr=1.75556e-05, gnorm=27.113, clip=100, loss_scale=256, train_wall=32, gb_free=16.4, wall=4865
2025-11-07 18:05:48 | INFO | train_inner | epoch 001:   7972 / 91072 loss=0.484619, wps=394.5, ups=1.65, wpb=239.4, bsz=16, num_updates=7950, lr=1.76667e-05, gnorm=26.607, clip=100, loss_scale=256, train_wall=30, gb_free=18.7, wall=4896
2025-11-07 18:06:18 | INFO | train_inner | epoch 001:   8022 / 91072 loss=0.427734, wps=401.7, ups=1.63, wpb=247, bsz=16, num_updates=8000, lr=1.77778e-05, gnorm=24.676, clip=100, loss_scale=256, train_wall=31, gb_free=18.3, wall=4926
2025-11-07 18:06:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 18:06:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 18:06:50 | INFO | train_inner | epoch 001:   8074 / 91072 loss=0.457031, wps=383.1, ups=1.58, wpb=242.5, bsz=16, num_updates=8050, lr=1.78889e-05, gnorm=29.506, clip=100, loss_scale=128, train_wall=31, gb_free=14.3, wall=4958
2025-11-07 18:07:21 | INFO | train_inner | epoch 001:   8124 / 91072 loss=0.544922, wps=393.9, ups=1.63, wpb=242, bsz=16, num_updates=8100, lr=1.8e-05, gnorm=28.884, clip=100, loss_scale=128, train_wall=31, gb_free=16.9, wall=4989
2025-11-07 18:07:51 | INFO | train_inner | epoch 001:   8174 / 91072 loss=0.422607, wps=400.6, ups=1.64, wpb=244.9, bsz=16, num_updates=8150, lr=1.81111e-05, gnorm=26.222, clip=100, loss_scale=128, train_wall=30, gb_free=16.5, wall=5019
2025-11-07 18:08:22 | INFO | train_inner | epoch 001:   8224 / 91072 loss=0.403076, wps=396.2, ups=1.64, wpb=242.3, bsz=16, num_updates=8200, lr=1.82222e-05, gnorm=29.004, clip=100, loss_scale=128, train_wall=30, gb_free=15.9, wall=5050
2025-11-07 18:08:53 | INFO | train_inner | epoch 001:   8274 / 91072 loss=0.421143, wps=401.9, ups=1.61, wpb=249.6, bsz=16, num_updates=8250, lr=1.83333e-05, gnorm=29.68, clip=100, loss_scale=128, train_wall=31, gb_free=16.5, wall=5081
2025-11-07 18:09:24 | INFO | train_inner | epoch 001:   8324 / 91072 loss=0.47583, wps=404.2, ups=1.64, wpb=247, bsz=16, num_updates=8300, lr=1.84444e-05, gnorm=28.206, clip=100, loss_scale=256, train_wall=30, gb_free=17.8, wall=5112
2025-11-07 18:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 18:09:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:09:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 18:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 18:09:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-07 18:09:58 | INFO | train_inner | epoch 001:   8379 / 91072 loss=0.59082, wps=369.6, ups=1.47, wpb=251.1, bsz=16, num_updates=8350, lr=1.85556e-05, gnorm=73.362, clip=100, loss_scale=8, train_wall=34, gb_free=18.1, wall=5145
2025-11-07 18:10:28 | INFO | train_inner | epoch 001:   8429 / 91072 loss=0.703613, wps=404.6, ups=1.63, wpb=248.5, bsz=16, num_updates=8400, lr=1.86667e-05, gnorm=49.061, clip=100, loss_scale=8, train_wall=31, gb_free=17.6, wall=5176
2025-11-07 18:11:00 | INFO | train_inner | epoch 001:   8479 / 91072 loss=0.538574, wps=404.3, ups=1.59, wpb=254.5, bsz=16, num_updates=8450, lr=1.87778e-05, gnorm=125.213, clip=100, loss_scale=8, train_wall=31, gb_free=17.4, wall=5208
2025-11-07 18:11:30 | INFO | train_inner | epoch 001:   8529 / 91072 loss=0.498779, wps=406.4, ups=1.63, wpb=249.5, bsz=16, num_updates=8500, lr=1.88889e-05, gnorm=150.813, clip=98, loss_scale=8, train_wall=31, gb_free=14.1, wall=5238
2025-11-07 18:12:01 | INFO | train_inner | epoch 001:   8579 / 91072 loss=0.472656, wps=400.9, ups=1.64, wpb=244.9, bsz=16, num_updates=8550, lr=1.9e-05, gnorm=120.2, clip=100, loss_scale=8, train_wall=30, gb_free=11.9, wall=5269
2025-11-07 18:12:31 | INFO | train_inner | epoch 001:   8629 / 91072 loss=0.486816, wps=402.9, ups=1.64, wpb=245.1, bsz=16, num_updates=8600, lr=1.91111e-05, gnorm=33.429, clip=100, loss_scale=16, train_wall=30, gb_free=14.8, wall=5299
2025-11-07 18:13:03 | INFO | train_inner | epoch 001:   8679 / 91072 loss=0.411133, wps=402.4, ups=1.58, wpb=254.7, bsz=16, num_updates=8650, lr=1.92222e-05, gnorm=25.688, clip=100, loss_scale=16, train_wall=31, gb_free=14.9, wall=5331
2025-11-07 18:13:33 | INFO | train_inner | epoch 001:   8729 / 91072 loss=0.437988, wps=385.2, ups=1.66, wpb=232.3, bsz=16, num_updates=8700, lr=1.93333e-05, gnorm=23.592, clip=100, loss_scale=16, train_wall=30, gb_free=17.5, wall=5361
2025-11-07 18:14:03 | INFO | train_inner | epoch 001:   8779 / 91072 loss=0.447266, wps=391.1, ups=1.66, wpb=235.5, bsz=16, num_updates=8750, lr=1.94444e-05, gnorm=30.925, clip=100, loss_scale=16, train_wall=30, gb_free=17.2, wall=5391
2025-11-07 18:14:34 | INFO | train_inner | epoch 001:   8829 / 91072 loss=0.463867, wps=406.6, ups=1.63, wpb=249.4, bsz=16, num_updates=8800, lr=1.95556e-05, gnorm=35.252, clip=100, loss_scale=16, train_wall=30, gb_free=16.7, wall=5422
2025-11-07 18:15:06 | INFO | train_inner | epoch 001:   8879 / 91072 loss=0.5, wps=409.1, ups=1.58, wpb=258.7, bsz=16, num_updates=8850, lr=1.96667e-05, gnorm=31.455, clip=100, loss_scale=32, train_wall=31, gb_free=18.1, wall=5454
2025-11-07 18:15:37 | INFO | train_inner | epoch 001:   8929 / 91072 loss=0.446777, wps=408, ups=1.62, wpb=252.2, bsz=16, num_updates=8900, lr=1.97778e-05, gnorm=42.57, clip=100, loss_scale=32, train_wall=31, gb_free=15.6, wall=5484
2025-11-07 18:16:07 | INFO | train_inner | epoch 001:   8979 / 91072 loss=0.513672, wps=411.2, ups=1.62, wpb=253.7, bsz=16, num_updates=8950, lr=1.98889e-05, gnorm=64.24, clip=100, loss_scale=32, train_wall=31, gb_free=18.1, wall=5515
2025-11-07 18:16:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 18:16:38 | INFO | train_inner | epoch 001:   9030 / 91072 loss=0.510254, wps=388.8, ups=1.62, wpb=240.1, bsz=16, num_updates=9000, lr=2e-05, gnorm=78.578, clip=100, loss_scale=16, train_wall=31, gb_free=12.5, wall=5546
2025-11-07 18:17:09 | INFO | train_inner | epoch 001:   9080 / 91072 loss=0.529297, wps=397.1, ups=1.63, wpb=243.4, bsz=16, num_updates=9050, lr=2.01111e-05, gnorm=56.815, clip=100, loss_scale=16, train_wall=30, gb_free=17.3, wall=5577
2025-11-07 18:17:39 | INFO | train_inner | epoch 001:   9130 / 91072 loss=0.4375, wps=390.4, ups=1.68, wpb=233, bsz=16, num_updates=9100, lr=2.02222e-05, gnorm=82.023, clip=98, loss_scale=16, train_wall=30, gb_free=18.8, wall=5607
2025-11-07 18:18:09 | INFO | train_inner | epoch 001:   9180 / 91072 loss=0.422607, wps=398.5, ups=1.67, wpb=238, bsz=16, num_updates=9150, lr=2.03333e-05, gnorm=42.132, clip=100, loss_scale=16, train_wall=30, gb_free=18.7, wall=5637
2025-11-07 18:18:40 | INFO | train_inner | epoch 001:   9230 / 91072 loss=0.468262, wps=396.8, ups=1.62, wpb=245.4, bsz=16, num_updates=9200, lr=2.04444e-05, gnorm=38.209, clip=100, loss_scale=16, train_wall=31, gb_free=18.4, wall=5667
2025-11-07 18:19:10 | INFO | train_inner | epoch 001:   9280 / 91072 loss=0.46875, wps=402.1, ups=1.64, wpb=245.4, bsz=16, num_updates=9250, lr=2.05556e-05, gnorm=36.399, clip=100, loss_scale=32, train_wall=30, gb_free=9.5, wall=5698
2025-11-07 18:19:40 | INFO | train_inner | epoch 001:   9330 / 91072 loss=0.435303, wps=385, ups=1.67, wpb=231.1, bsz=16, num_updates=9300, lr=2.06667e-05, gnorm=28.612, clip=98, loss_scale=32, train_wall=30, gb_free=9.7, wall=5728
2025-11-07 18:20:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 18:20:11 | INFO | train_inner | epoch 001:   9381 / 91072 loss=0.480713, wps=395.3, ups=1.6, wpb=246.6, bsz=16, num_updates=9350, lr=2.07778e-05, gnorm=39, clip=100, loss_scale=16, train_wall=31, gb_free=11.4, wall=5759
2025-11-07 18:20:42 | INFO | train_inner | epoch 001:   9431 / 91072 loss=0.399414, wps=393.1, ups=1.63, wpb=241.1, bsz=16, num_updates=9400, lr=2.08889e-05, gnorm=27.445, clip=100, loss_scale=16, train_wall=30, gb_free=12.8, wall=5790
2025-11-07 18:21:13 | INFO | train_inner | epoch 001:   9481 / 91072 loss=0.443115, wps=406.7, ups=1.62, wpb=250.6, bsz=16, num_updates=9450, lr=2.1e-05, gnorm=26.825, clip=100, loss_scale=16, train_wall=31, gb_free=18.6, wall=5821
2025-11-07 18:21:43 | INFO | train_inner | epoch 001:   9531 / 91072 loss=0.419189, wps=404, ups=1.64, wpb=246.9, bsz=16, num_updates=9500, lr=2.11111e-05, gnorm=32.982, clip=100, loss_scale=16, train_wall=30, gb_free=15.9, wall=5851
2025-11-07 18:22:14 | INFO | train_inner | epoch 001:   9581 / 91072 loss=0.435303, wps=404.4, ups=1.62, wpb=249, bsz=16, num_updates=9550, lr=2.12222e-05, gnorm=23.429, clip=98, loss_scale=16, train_wall=31, gb_free=18.7, wall=5882
2025-11-07 18:22:45 | INFO | train_inner | epoch 001:   9631 / 91072 loss=0.428467, wps=396.6, ups=1.63, wpb=243.7, bsz=16, num_updates=9600, lr=2.13333e-05, gnorm=30.894, clip=100, loss_scale=32, train_wall=31, gb_free=15.4, wall=5913
2025-11-07 18:23:15 | INFO | train_inner | epoch 001:   9681 / 91072 loss=0.434326, wps=406.1, ups=1.64, wpb=248.2, bsz=16, num_updates=9650, lr=2.14444e-05, gnorm=41.279, clip=100, loss_scale=32, train_wall=30, gb_free=14.3, wall=5943
2025-11-07 18:23:45 | INFO | train_inner | epoch 001:   9731 / 91072 loss=0.449707, wps=386.5, ups=1.67, wpb=231.3, bsz=16, num_updates=9700, lr=2.15556e-05, gnorm=30.701, clip=100, loss_scale=32, train_wall=30, gb_free=12.9, wall=5973
2025-11-07 18:24:16 | INFO | train_inner | epoch 001:   9781 / 91072 loss=0.471436, wps=399.1, ups=1.64, wpb=243.1, bsz=16, num_updates=9750, lr=2.16667e-05, gnorm=26.336, clip=98, loss_scale=32, train_wall=30, gb_free=13.4, wall=6004
2025-11-07 18:24:47 | INFO | train_inner | epoch 001:   9831 / 91072 loss=0.474365, wps=405.7, ups=1.58, wpb=257.3, bsz=16, num_updates=9800, lr=2.17778e-05, gnorm=32.242, clip=100, loss_scale=32, train_wall=32, gb_free=16.9, wall=6035
2025-11-07 18:25:18 | INFO | train_inner | epoch 001:   9881 / 91072 loss=0.477051, wps=397.1, ups=1.63, wpb=243.4, bsz=16, num_updates=9850, lr=2.18889e-05, gnorm=32.459, clip=100, loss_scale=64, train_wall=30, gb_free=18.9, wall=6066
2025-11-07 18:25:48 | INFO | train_inner | epoch 001:   9931 / 91072 loss=0.416504, wps=397.8, ups=1.65, wpb=241.3, bsz=16, num_updates=9900, lr=2.2e-05, gnorm=40.238, clip=100, loss_scale=64, train_wall=30, gb_free=18.5, wall=6096
2025-11-07 18:26:18 | INFO | train_inner | epoch 001:   9981 / 91072 loss=0.463379, wps=389.3, ups=1.67, wpb=233.7, bsz=16, num_updates=9950, lr=2.21111e-05, gnorm=30.092, clip=100, loss_scale=64, train_wall=30, gb_free=15.1, wall=6126
2025-11-07 18:26:49 | INFO | train_inner | epoch 001:  10031 / 91072 loss=0.447998, wps=405, ups=1.61, wpb=250.9, bsz=16, num_updates=10000, lr=2.22222e-05, gnorm=27.692, clip=100, loss_scale=64, train_wall=31, gb_free=17.8, wall=6157
2025-11-07 18:27:20 | INFO | train_inner | epoch 001:  10081 / 91072 loss=0.442627, wps=401.8, ups=1.63, wpb=246.2, bsz=16, num_updates=10050, lr=2.23333e-05, gnorm=27.437, clip=100, loss_scale=64, train_wall=30, gb_free=11.8, wall=6188
2025-11-07 18:27:51 | INFO | train_inner | epoch 001:  10131 / 91072 loss=0.493408, wps=401.4, ups=1.64, wpb=244.9, bsz=16, num_updates=10100, lr=2.24444e-05, gnorm=36.124, clip=100, loss_scale=64, train_wall=30, gb_free=18.2, wall=6218
2025-11-07 18:28:22 | INFO | train_inner | epoch 001:  10181 / 91072 loss=0.428711, wps=398.4, ups=1.59, wpb=250.6, bsz=16, num_updates=10150, lr=2.25556e-05, gnorm=29.524, clip=98, loss_scale=128, train_wall=31, gb_free=17.4, wall=6250
2025-11-07 18:28:52 | INFO | train_inner | epoch 001:  10231 / 91072 loss=0.42749, wps=383.7, ups=1.67, wpb=229.9, bsz=16, num_updates=10200, lr=2.26667e-05, gnorm=34.362, clip=100, loss_scale=128, train_wall=30, gb_free=14.1, wall=6280
2025-11-07 18:29:23 | INFO | train_inner | epoch 001:  10281 / 91072 loss=0.51709, wps=410.2, ups=1.6, wpb=255.7, bsz=16, num_updates=10250, lr=2.27778e-05, gnorm=33.206, clip=100, loss_scale=128, train_wall=31, gb_free=14.8, wall=6311
2025-11-07 18:29:53 | INFO | train_inner | epoch 001:  10331 / 91072 loss=0.485352, wps=375.8, ups=1.7, wpb=221.3, bsz=16, num_updates=10300, lr=2.28889e-05, gnorm=33.279, clip=100, loss_scale=128, train_wall=29, gb_free=18.2, wall=6340
2025-11-07 18:30:23 | INFO | train_inner | epoch 001:  10381 / 91072 loss=0.461426, wps=392.1, ups=1.62, wpb=242.1, bsz=16, num_updates=10350, lr=2.3e-05, gnorm=33.897, clip=100, loss_scale=128, train_wall=31, gb_free=18.3, wall=6371
2025-11-07 18:30:54 | INFO | train_inner | epoch 001:  10431 / 91072 loss=0.483398, wps=393.1, ups=1.64, wpb=239.7, bsz=16, num_updates=10400, lr=2.31111e-05, gnorm=30.948, clip=100, loss_scale=256, train_wall=30, gb_free=18, wall=6402
2025-11-07 18:31:24 | INFO | train_inner | epoch 001:  10481 / 91072 loss=0.495605, wps=391.7, ups=1.65, wpb=237.1, bsz=16, num_updates=10450, lr=2.32222e-05, gnorm=31.04, clip=100, loss_scale=256, train_wall=30, gb_free=18.2, wall=6432
2025-11-07 18:31:54 | INFO | train_inner | epoch 001:  10531 / 91072 loss=0.450195, wps=395.7, ups=1.66, wpb=238.5, bsz=16, num_updates=10500, lr=2.33333e-05, gnorm=28.023, clip=100, loss_scale=256, train_wall=30, gb_free=13.7, wall=6462
2025-11-07 18:32:25 | INFO | train_inner | epoch 001:  10581 / 91072 loss=0.468262, wps=392.5, ups=1.64, wpb=240, bsz=16, num_updates=10550, lr=2.34444e-05, gnorm=27.665, clip=100, loss_scale=256, train_wall=30, gb_free=18.9, wall=6493
2025-11-07 18:32:56 | INFO | train_inner | epoch 001:  10631 / 91072 loss=0.411377, wps=412.7, ups=1.62, wpb=255.4, bsz=16, num_updates=10600, lr=2.35556e-05, gnorm=28.539, clip=100, loss_scale=256, train_wall=31, gb_free=18.2, wall=6524
2025-11-07 18:33:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 18:33:26 | INFO | train_inner | epoch 001:  10682 / 91072 loss=0.482666, wps=381.5, ups=1.63, wpb=233.8, bsz=16, num_updates=10650, lr=2.36667e-05, gnorm=30.698, clip=98, loss_scale=256, train_wall=30, gb_free=17.6, wall=6554
2025-11-07 18:33:58 | INFO | train_inner | epoch 001:  10732 / 91072 loss=0.412109, wps=410.8, ups=1.61, wpb=255.1, bsz=16, num_updates=10700, lr=2.37778e-05, gnorm=27.044, clip=100, loss_scale=256, train_wall=31, gb_free=17.5, wall=6585
2025-11-07 18:34:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 18:34:28 | INFO | train_inner | epoch 001:  10783 / 91072 loss=0.412354, wps=383.1, ups=1.62, wpb=236.6, bsz=16, num_updates=10750, lr=2.38889e-05, gnorm=26.705, clip=100, loss_scale=128, train_wall=31, gb_free=16.8, wall=6616
2025-11-07 18:34:59 | INFO | train_inner | epoch 001:  10833 / 91072 loss=0.460449, wps=396, ups=1.64, wpb=241.2, bsz=16, num_updates=10800, lr=2.4e-05, gnorm=32.309, clip=100, loss_scale=128, train_wall=30, gb_free=9.1, wall=6647
2025-11-07 18:35:29 | INFO | train_inner | epoch 001:  10883 / 91072 loss=0.472168, wps=404.1, ups=1.64, wpb=247.1, bsz=16, num_updates=10850, lr=2.41111e-05, gnorm=29.823, clip=98, loss_scale=128, train_wall=30, gb_free=16.3, wall=6677
2025-11-07 18:35:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:36:00 | INFO | train_inner | epoch 001:  10934 / 91072 loss=0.472168, wps=389.6, ups=1.62, wpb=240.2, bsz=16, num_updates=10900, lr=2.42222e-05, gnorm=30.268, clip=100, loss_scale=64, train_wall=31, gb_free=18.5, wall=6708
2025-11-07 18:36:31 | INFO | train_inner | epoch 001:  10984 / 91072 loss=0.463379, wps=394.7, ups=1.61, wpb=245.4, bsz=16, num_updates=10950, lr=2.43333e-05, gnorm=37.863, clip=100, loss_scale=64, train_wall=31, gb_free=16.4, wall=6739
2025-11-07 18:36:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 18:37:02 | INFO | train_inner | epoch 001:  11035 / 91072 loss=0.428467, wps=387.4, ups=1.62, wpb=238.9, bsz=16, num_updates=11000, lr=2.44444e-05, gnorm=30.656, clip=100, loss_scale=32, train_wall=31, gb_free=19.3, wall=6770
2025-11-07 18:37:33 | INFO | train_inner | epoch 001:  11085 / 91072 loss=0.429199, wps=404.1, ups=1.64, wpb=247, bsz=16, num_updates=11050, lr=2.45556e-05, gnorm=49.211, clip=100, loss_scale=32, train_wall=30, gb_free=16.1, wall=6801
2025-11-07 18:38:03 | INFO | train_inner | epoch 001:  11135 / 91072 loss=0.416992, wps=393.9, ups=1.66, wpb=237.9, bsz=16, num_updates=11100, lr=2.46667e-05, gnorm=34.428, clip=100, loss_scale=32, train_wall=30, gb_free=17.1, wall=6831
2025-11-07 18:38:34 | INFO | train_inner | epoch 001:  11185 / 91072 loss=0.398438, wps=397.6, ups=1.62, wpb=246, bsz=16, num_updates=11150, lr=2.47778e-05, gnorm=30.706, clip=100, loss_scale=32, train_wall=31, gb_free=18.7, wall=6862
2025-11-07 18:39:05 | INFO | train_inner | epoch 001:  11235 / 91072 loss=0.476562, wps=406.5, ups=1.62, wpb=251, bsz=16, num_updates=11200, lr=2.48889e-05, gnorm=35.291, clip=100, loss_scale=32, train_wall=31, gb_free=15.5, wall=6893
2025-11-07 18:39:35 | INFO | train_inner | epoch 001:  11285 / 91072 loss=0.474854, wps=394.4, ups=1.65, wpb=239.4, bsz=16, num_updates=11250, lr=2.5e-05, gnorm=35.775, clip=98, loss_scale=64, train_wall=30, gb_free=15.8, wall=6923
2025-11-07 18:40:06 | INFO | train_inner | epoch 001:  11335 / 91072 loss=0.421631, wps=398.7, ups=1.62, wpb=245.4, bsz=16, num_updates=11300, lr=2.51111e-05, gnorm=33.592, clip=100, loss_scale=64, train_wall=31, gb_free=16.2, wall=6954
2025-11-07 18:40:37 | INFO | train_inner | epoch 001:  11385 / 91072 loss=0.454834, wps=412.9, ups=1.62, wpb=254.1, bsz=16, num_updates=11350, lr=2.52222e-05, gnorm=39.195, clip=100, loss_scale=64, train_wall=31, gb_free=17.8, wall=6985
2025-11-07 18:41:07 | INFO | train_inner | epoch 001:  11435 / 91072 loss=0.45459, wps=401.7, ups=1.63, wpb=247.1, bsz=16, num_updates=11400, lr=2.53333e-05, gnorm=32.307, clip=100, loss_scale=64, train_wall=31, gb_free=17.9, wall=7015
2025-11-07 18:41:38 | INFO | train_inner | epoch 001:  11485 / 91072 loss=0.398193, wps=409, ups=1.63, wpb=250.6, bsz=16, num_updates=11450, lr=2.54444e-05, gnorm=37.226, clip=100, loss_scale=64, train_wall=30, gb_free=16.9, wall=7046
2025-11-07 18:42:09 | INFO | train_inner | epoch 001:  11535 / 91072 loss=0.460205, wps=396, ups=1.63, wpb=243.3, bsz=16, num_updates=11500, lr=2.55556e-05, gnorm=33.992, clip=100, loss_scale=128, train_wall=31, gb_free=12.4, wall=7077
2025-11-07 18:42:40 | INFO | train_inner | epoch 001:  11585 / 91072 loss=0.472168, wps=412.5, ups=1.61, wpb=256.3, bsz=16, num_updates=11550, lr=2.56667e-05, gnorm=34.058, clip=100, loss_scale=128, train_wall=31, gb_free=15.9, wall=7108
2025-11-07 18:43:11 | INFO | train_inner | epoch 001:  11635 / 91072 loss=0.486084, wps=377.3, ups=1.59, wpb=237.6, bsz=16, num_updates=11600, lr=2.57778e-05, gnorm=29.473, clip=100, loss_scale=128, train_wall=31, gb_free=10.5, wall=7139
2025-11-07 18:43:44 | INFO | train_inner | epoch 001:  11685 / 91072 loss=0.466064, wps=364.1, ups=1.56, wpb=233.3, bsz=16, num_updates=11650, lr=2.58889e-05, gnorm=32.548, clip=100, loss_scale=128, train_wall=32, gb_free=16.7, wall=7172
2025-11-07 18:44:15 | INFO | train_inner | epoch 001:  11735 / 91072 loss=0.421631, wps=366.8, ups=1.59, wpb=231.3, bsz=16, num_updates=11700, lr=2.6e-05, gnorm=31.384, clip=100, loss_scale=128, train_wall=31, gb_free=17.8, wall=7203
2025-11-07 18:44:46 | INFO | train_inner | epoch 001:  11785 / 91072 loss=0.450928, wps=403.6, ups=1.63, wpb=248.1, bsz=16, num_updates=11750, lr=2.61111e-05, gnorm=27.588, clip=100, loss_scale=256, train_wall=31, gb_free=16, wall=7234
2025-11-07 18:45:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 18:45:17 | INFO | train_inner | epoch 001:  11836 / 91072 loss=0.44458, wps=387.6, ups=1.58, wpb=244.9, bsz=16, num_updates=11800, lr=2.62222e-05, gnorm=33.818, clip=100, loss_scale=128, train_wall=31, gb_free=18, wall=7265
2025-11-07 18:45:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:45:49 | INFO | train_inner | epoch 001:  11887 / 91072 loss=0.501465, wps=396.8, ups=1.59, wpb=249.6, bsz=16, num_updates=11850, lr=2.63333e-05, gnorm=42.104, clip=100, loss_scale=64, train_wall=31, gb_free=17.3, wall=7297
2025-11-07 18:46:20 | INFO | train_inner | epoch 001:  11937 / 91072 loss=0.43335, wps=390.4, ups=1.63, wpb=238.8, bsz=16, num_updates=11900, lr=2.64444e-05, gnorm=33.584, clip=100, loss_scale=64, train_wall=30, gb_free=17.6, wall=7327
2025-11-07 18:46:50 | INFO | train_inner | epoch 001:  11987 / 91072 loss=0.44458, wps=395.6, ups=1.65, wpb=239.8, bsz=16, num_updates=11950, lr=2.65556e-05, gnorm=36.758, clip=100, loss_scale=64, train_wall=30, gb_free=18.8, wall=7358
2025-11-07 18:47:21 | INFO | train_inner | epoch 001:  12037 / 91072 loss=0.408447, wps=399.8, ups=1.63, wpb=245.3, bsz=16, num_updates=12000, lr=2.66667e-05, gnorm=31.357, clip=100, loss_scale=64, train_wall=31, gb_free=18.1, wall=7388
2025-11-07 18:47:51 | INFO | train_inner | epoch 001:  12087 / 91072 loss=0.447021, wps=407.3, ups=1.62, wpb=251.4, bsz=16, num_updates=12050, lr=2.67778e-05, gnorm=30.365, clip=100, loss_scale=64, train_wall=31, gb_free=18.2, wall=7419
2025-11-07 18:48:23 | INFO | train_inner | epoch 001:  12137 / 91072 loss=0.457275, wps=400.1, ups=1.6, wpb=249.4, bsz=16, num_updates=12100, lr=2.68889e-05, gnorm=32.522, clip=100, loss_scale=128, train_wall=31, gb_free=17.4, wall=7450
2025-11-07 18:48:53 | INFO | train_inner | epoch 001:  12187 / 91072 loss=0.407471, wps=403, ups=1.62, wpb=248.7, bsz=16, num_updates=12150, lr=2.7e-05, gnorm=31.666, clip=100, loss_scale=128, train_wall=31, gb_free=15, wall=7481
2025-11-07 18:49:24 | INFO | train_inner | epoch 001:  12237 / 91072 loss=0.460693, wps=405.8, ups=1.62, wpb=250.8, bsz=16, num_updates=12200, lr=2.71111e-05, gnorm=32.12, clip=100, loss_scale=128, train_wall=31, gb_free=11.9, wall=7512
2025-11-07 18:49:55 | INFO | train_inner | epoch 001:  12287 / 91072 loss=0.431152, wps=399.4, ups=1.61, wpb=248.5, bsz=16, num_updates=12250, lr=2.72222e-05, gnorm=30.013, clip=100, loss_scale=128, train_wall=31, gb_free=16.9, wall=7543
2025-11-07 18:50:27 | INFO | train_inner | epoch 001:  12337 / 91072 loss=0.4646, wps=413.4, ups=1.6, wpb=257.8, bsz=16, num_updates=12300, lr=2.73333e-05, gnorm=34.217, clip=100, loss_scale=128, train_wall=31, gb_free=15.7, wall=7574
2025-11-07 18:50:57 | INFO | train_inner | epoch 001:  12387 / 91072 loss=0.437744, wps=396.2, ups=1.66, wpb=239, bsz=16, num_updates=12350, lr=2.74444e-05, gnorm=27.845, clip=100, loss_scale=256, train_wall=30, gb_free=17.6, wall=7605
2025-11-07 18:51:27 | INFO | train_inner | epoch 001:  12437 / 91072 loss=0.436523, wps=398.9, ups=1.64, wpb=242.9, bsz=16, num_updates=12400, lr=2.75556e-05, gnorm=28.849, clip=100, loss_scale=256, train_wall=30, gb_free=17.2, wall=7635
2025-11-07 18:51:58 | INFO | train_inner | epoch 001:  12487 / 91072 loss=0.455322, wps=389.1, ups=1.64, wpb=237.9, bsz=16, num_updates=12450, lr=2.76667e-05, gnorm=29.405, clip=100, loss_scale=256, train_wall=30, gb_free=17.6, wall=7666
2025-11-07 18:52:28 | INFO | train_inner | epoch 001:  12537 / 91072 loss=0.434082, wps=395.7, ups=1.66, wpb=238.9, bsz=16, num_updates=12500, lr=2.77778e-05, gnorm=32.268, clip=100, loss_scale=256, train_wall=30, gb_free=17.9, wall=7696
2025-11-07 18:52:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 18:52:59 | INFO | train_inner | epoch 001:  12588 / 91072 loss=0.426758, wps=386.2, ups=1.62, wpb=238.7, bsz=16, num_updates=12550, lr=2.78889e-05, gnorm=29.64, clip=100, loss_scale=128, train_wall=31, gb_free=11.8, wall=7727
2025-11-07 18:53:30 | INFO | train_inner | epoch 001:  12638 / 91072 loss=0.452148, wps=405.8, ups=1.61, wpb=251.4, bsz=16, num_updates=12600, lr=2.8e-05, gnorm=32.069, clip=100, loss_scale=128, train_wall=31, gb_free=17.7, wall=7758
2025-11-07 18:53:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 18:54:02 | INFO | train_inner | epoch 001:  12689 / 91072 loss=0.505371, wps=396.3, ups=1.57, wpb=252.5, bsz=16, num_updates=12650, lr=2.81111e-05, gnorm=28.105, clip=100, loss_scale=64, train_wall=32, gb_free=18.6, wall=7790
2025-11-07 18:54:32 | INFO | train_inner | epoch 001:  12739 / 91072 loss=0.4375, wps=409.5, ups=1.64, wpb=249.6, bsz=16, num_updates=12700, lr=2.82222e-05, gnorm=27.696, clip=100, loss_scale=64, train_wall=30, gb_free=16.5, wall=7820
2025-11-07 18:55:04 | INFO | train_inner | epoch 001:  12789 / 91072 loss=0.424072, wps=376.5, ups=1.58, wpb=238.6, bsz=16, num_updates=12750, lr=2.83333e-05, gnorm=33.015, clip=100, loss_scale=64, train_wall=31, gb_free=16.3, wall=7852
2025-11-07 18:55:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 18:55:38 | INFO | train_inner | epoch 001:  12840 / 91072 loss=0.416992, wps=350, ups=1.45, wpb=241.2, bsz=16, num_updates=12800, lr=2.84444e-05, gnorm=35.757, clip=100, loss_scale=32, train_wall=34, gb_free=18.7, wall=7886
2025-11-07 18:56:09 | INFO | train_inner | epoch 001:  12890 / 91072 loss=0.473389, wps=383.4, ups=1.61, wpb=238.3, bsz=16, num_updates=12850, lr=2.85556e-05, gnorm=31.372, clip=100, loss_scale=32, train_wall=31, gb_free=16.8, wall=7917
2025-11-07 18:56:40 | INFO | train_inner | epoch 001:  12940 / 91072 loss=0.484375, wps=403.4, ups=1.62, wpb=249.5, bsz=16, num_updates=12900, lr=2.86667e-05, gnorm=35.138, clip=100, loss_scale=32, train_wall=31, gb_free=18.7, wall=7948
2025-11-07 18:57:11 | INFO | train_inner | epoch 001:  12990 / 91072 loss=0.454834, wps=403.4, ups=1.64, wpb=245.7, bsz=16, num_updates=12950, lr=2.87778e-05, gnorm=40.285, clip=100, loss_scale=32, train_wall=30, gb_free=17.5, wall=7979
2025-11-07 18:57:41 | INFO | train_inner | epoch 001:  13040 / 91072 loss=0.411133, wps=402.1, ups=1.64, wpb=244.7, bsz=16, num_updates=13000, lr=2.88889e-05, gnorm=30.217, clip=100, loss_scale=32, train_wall=30, gb_free=14.6, wall=8009
2025-11-07 18:58:12 | INFO | train_inner | epoch 001:  13090 / 91072 loss=0.439209, wps=398.3, ups=1.61, wpb=247.4, bsz=16, num_updates=13050, lr=2.9e-05, gnorm=33.13, clip=100, loss_scale=64, train_wall=31, gb_free=17.5, wall=8040
2025-11-07 18:58:43 | INFO | train_inner | epoch 001:  13140 / 91072 loss=0.440674, wps=408.5, ups=1.63, wpb=250.5, bsz=16, num_updates=13100, lr=2.91111e-05, gnorm=30.601, clip=100, loss_scale=64, train_wall=30, gb_free=14.4, wall=8071
2025-11-07 18:59:13 | INFO | train_inner | epoch 001:  13190 / 91072 loss=0.46167, wps=392.7, ups=1.65, wpb=238.6, bsz=16, num_updates=13150, lr=2.92222e-05, gnorm=32.608, clip=100, loss_scale=64, train_wall=30, gb_free=17.4, wall=8101
2025-11-07 18:59:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 18:59:44 | INFO | train_inner | epoch 001:  13241 / 91072 loss=0.47168, wps=388.4, ups=1.61, wpb=240.5, bsz=16, num_updates=13200, lr=2.93333e-05, gnorm=53.417, clip=100, loss_scale=32, train_wall=31, gb_free=15.5, wall=8132
2025-11-07 19:00:15 | INFO | train_inner | epoch 001:  13291 / 91072 loss=0.428467, wps=414.6, ups=1.62, wpb=255.5, bsz=16, num_updates=13250, lr=2.94444e-05, gnorm=37.997, clip=100, loss_scale=32, train_wall=31, gb_free=17, wall=8163
2025-11-07 19:00:45 | INFO | train_inner | epoch 001:  13341 / 91072 loss=0.51416, wps=392.3, ups=1.65, wpb=237.7, bsz=16, num_updates=13300, lr=2.95556e-05, gnorm=27.004, clip=100, loss_scale=32, train_wall=30, gb_free=17.1, wall=8193
2025-11-07 19:01:16 | INFO | train_inner | epoch 001:  13391 / 91072 loss=0.487549, wps=398.3, ups=1.64, wpb=242.8, bsz=16, num_updates=13350, lr=2.96667e-05, gnorm=26.734, clip=100, loss_scale=32, train_wall=30, gb_free=16.7, wall=8224
2025-11-07 19:01:47 | INFO | train_inner | epoch 001:  13441 / 91072 loss=0.468018, wps=399.4, ups=1.61, wpb=248, bsz=16, num_updates=13400, lr=2.97778e-05, gnorm=31.577, clip=100, loss_scale=32, train_wall=31, gb_free=11.9, wall=8255
2025-11-07 19:02:18 | INFO | train_inner | epoch 001:  13491 / 91072 loss=0.401855, wps=415.6, ups=1.61, wpb=258, bsz=16, num_updates=13450, lr=2.98889e-05, gnorm=26.045, clip=100, loss_scale=64, train_wall=31, gb_free=14.3, wall=8286
2025-11-07 19:02:49 | INFO | train_inner | epoch 001:  13541 / 91072 loss=0.425537, wps=407.5, ups=1.64, wpb=249.2, bsz=16, num_updates=13500, lr=3e-05, gnorm=28.993, clip=100, loss_scale=64, train_wall=30, gb_free=16.8, wall=8316
2025-11-07 19:03:19 | INFO | train_inner | epoch 001:  13591 / 91072 loss=0.471436, wps=398.2, ups=1.66, wpb=240.3, bsz=16, num_updates=13550, lr=3.01111e-05, gnorm=33.931, clip=100, loss_scale=64, train_wall=30, gb_free=14.8, wall=8347
2025-11-07 19:03:50 | INFO | train_inner | epoch 001:  13641 / 91072 loss=0.470947, wps=406.2, ups=1.59, wpb=255.9, bsz=16, num_updates=13600, lr=3.02222e-05, gnorm=33.904, clip=100, loss_scale=64, train_wall=31, gb_free=14.3, wall=8378
2025-11-07 19:04:21 | INFO | train_inner | epoch 001:  13691 / 91072 loss=0.472412, wps=406.6, ups=1.62, wpb=250.8, bsz=16, num_updates=13650, lr=3.03333e-05, gnorm=33.672, clip=100, loss_scale=64, train_wall=31, gb_free=18.6, wall=8409
2025-11-07 19:04:52 | INFO | train_inner | epoch 001:  13741 / 91072 loss=0.4104, wps=406, ups=1.62, wpb=250.2, bsz=16, num_updates=13700, lr=3.04444e-05, gnorm=36.473, clip=100, loss_scale=64, train_wall=31, gb_free=10.8, wall=8440
2025-11-07 19:05:23 | INFO | train_inner | epoch 001:  13791 / 91072 loss=0.481201, wps=409.1, ups=1.62, wpb=252.1, bsz=16, num_updates=13750, lr=3.05556e-05, gnorm=34.15, clip=100, loss_scale=128, train_wall=31, gb_free=12.3, wall=8471
2025-11-07 19:05:53 | INFO | train_inner | epoch 001:  13841 / 91072 loss=0.396973, wps=395.6, ups=1.64, wpb=241.8, bsz=16, num_updates=13800, lr=3.06667e-05, gnorm=33.072, clip=100, loss_scale=128, train_wall=30, gb_free=18.2, wall=8501
2025-11-07 19:06:23 | INFO | train_inner | epoch 001:  13891 / 91072 loss=0.438477, wps=390.1, ups=1.67, wpb=233.3, bsz=16, num_updates=13850, lr=3.07778e-05, gnorm=30.238, clip=100, loss_scale=128, train_wall=30, gb_free=17.7, wall=8531
2025-11-07 19:06:53 | INFO | train_inner | epoch 001:  13941 / 91072 loss=0.492432, wps=397.3, ups=1.65, wpb=240.1, bsz=16, num_updates=13900, lr=3.08889e-05, gnorm=32.599, clip=100, loss_scale=128, train_wall=30, gb_free=17.5, wall=8561
2025-11-07 19:07:24 | INFO | train_inner | epoch 001:  13991 / 91072 loss=0.445068, wps=399.9, ups=1.63, wpb=245.6, bsz=16, num_updates=13950, lr=3.1e-05, gnorm=35.824, clip=100, loss_scale=128, train_wall=31, gb_free=18.5, wall=8592
2025-11-07 19:07:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:07:55 | INFO | train_inner | epoch 001:  14042 / 91072 loss=0.4646, wps=384.9, ups=1.61, wpb=238.9, bsz=16, num_updates=14000, lr=3.11111e-05, gnorm=29.008, clip=100, loss_scale=128, train_wall=31, gb_free=16.7, wall=8623
2025-11-07 19:08:26 | INFO | train_inner | epoch 001:  14092 / 91072 loss=0.438721, wps=406, ups=1.64, wpb=248.1, bsz=16, num_updates=14050, lr=3.12222e-05, gnorm=31.243, clip=100, loss_scale=128, train_wall=30, gb_free=18.8, wall=8654
2025-11-07 19:08:55 | INFO | train_inner | epoch 001:  14142 / 91072 loss=0.451416, wps=385, ups=1.69, wpb=227.8, bsz=16, num_updates=14100, lr=3.13333e-05, gnorm=29.146, clip=100, loss_scale=128, train_wall=29, gb_free=17.1, wall=8683
2025-11-07 19:09:26 | INFO | train_inner | epoch 001:  14192 / 91072 loss=0.429199, wps=396.3, ups=1.65, wpb=240.1, bsz=16, num_updates=14150, lr=3.14444e-05, gnorm=30.616, clip=100, loss_scale=128, train_wall=30, gb_free=16.5, wall=8713
2025-11-07 19:09:56 | INFO | train_inner | epoch 001:  14242 / 91072 loss=0.511719, wps=392.1, ups=1.63, wpb=240.3, bsz=16, num_updates=14200, lr=3.15556e-05, gnorm=37.196, clip=100, loss_scale=128, train_wall=30, gb_free=17.6, wall=8744
2025-11-07 19:10:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:10:28 | INFO | train_inner | epoch 001:  14293 / 91072 loss=0.503906, wps=394.8, ups=1.58, wpb=249.4, bsz=16, num_updates=14250, lr=3.16667e-05, gnorm=37.172, clip=100, loss_scale=128, train_wall=31, gb_free=18.2, wall=8776
2025-11-07 19:10:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:10:59 | INFO | train_inner | epoch 001:  14344 / 91072 loss=0.410156, wps=397.1, ups=1.59, wpb=249.7, bsz=16, num_updates=14300, lr=3.17778e-05, gnorm=29.258, clip=100, loss_scale=64, train_wall=31, gb_free=15.7, wall=8807
2025-11-07 19:11:30 | INFO | train_inner | epoch 001:  14394 / 91072 loss=0.5, wps=397.4, ups=1.62, wpb=244.6, bsz=16, num_updates=14350, lr=3.18889e-05, gnorm=43.814, clip=100, loss_scale=64, train_wall=31, gb_free=13.7, wall=8838
2025-11-07 19:12:01 | INFO | train_inner | epoch 001:  14444 / 91072 loss=0.462158, wps=403.7, ups=1.63, wpb=246.9, bsz=16, num_updates=14400, lr=3.2e-05, gnorm=34.548, clip=100, loss_scale=64, train_wall=30, gb_free=18.1, wall=8869
2025-11-07 19:12:35 | INFO | train_inner | epoch 001:  14494 / 91072 loss=0.447754, wps=367.4, ups=1.47, wpb=250, bsz=16, num_updates=14450, lr=3.21111e-05, gnorm=35.692, clip=100, loss_scale=64, train_wall=34, gb_free=16.4, wall=8903
2025-11-07 19:13:05 | INFO | train_inner | epoch 001:  14544 / 91072 loss=0.399658, wps=392.7, ups=1.63, wpb=240.9, bsz=16, num_updates=14500, lr=3.22222e-05, gnorm=31.112, clip=100, loss_scale=64, train_wall=31, gb_free=8.4, wall=8933
2025-11-07 19:13:38 | INFO | train_inner | epoch 001:  14594 / 91072 loss=0.436279, wps=375.4, ups=1.52, wpb=247.2, bsz=16, num_updates=14550, lr=3.23333e-05, gnorm=37.168, clip=100, loss_scale=128, train_wall=33, gb_free=9, wall=8966
2025-11-07 19:14:09 | INFO | train_inner | epoch 001:  14644 / 91072 loss=0.440674, wps=399.9, ups=1.63, wpb=244.9, bsz=16, num_updates=14600, lr=3.24444e-05, gnorm=27.771, clip=100, loss_scale=128, train_wall=30, gb_free=18.2, wall=8997
2025-11-07 19:14:40 | INFO | train_inner | epoch 001:  14694 / 91072 loss=0.469482, wps=400.9, ups=1.63, wpb=246.3, bsz=16, num_updates=14650, lr=3.25556e-05, gnorm=42.324, clip=100, loss_scale=128, train_wall=31, gb_free=16.3, wall=9028
2025-11-07 19:15:10 | INFO | train_inner | epoch 001:  14744 / 91072 loss=0.457764, wps=400.7, ups=1.62, wpb=246.9, bsz=16, num_updates=14700, lr=3.26667e-05, gnorm=37.99, clip=100, loss_scale=128, train_wall=31, gb_free=17.9, wall=9058
2025-11-07 19:15:41 | INFO | train_inner | epoch 001:  14794 / 91072 loss=0.469727, wps=396.2, ups=1.63, wpb=242.7, bsz=16, num_updates=14750, lr=3.27778e-05, gnorm=27.321, clip=98, loss_scale=128, train_wall=30, gb_free=12.9, wall=9089
2025-11-07 19:16:12 | INFO | train_inner | epoch 001:  14844 / 91072 loss=0.469727, wps=400.1, ups=1.61, wpb=249.3, bsz=16, num_updates=14800, lr=3.28889e-05, gnorm=34.602, clip=100, loss_scale=256, train_wall=31, gb_free=9.3, wall=9120
2025-11-07 19:16:43 | INFO | train_inner | epoch 001:  14894 / 91072 loss=0.4104, wps=401.2, ups=1.63, wpb=245.9, bsz=16, num_updates=14850, lr=3.3e-05, gnorm=28.409, clip=100, loss_scale=256, train_wall=30, gb_free=16.6, wall=9151
2025-11-07 19:16:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 19:17:14 | INFO | train_inner | epoch 001:  14945 / 91072 loss=0.458252, wps=387.3, ups=1.58, wpb=245, bsz=16, num_updates=14900, lr=3.31111e-05, gnorm=26.588, clip=100, loss_scale=128, train_wall=31, gb_free=18.6, wall=9182
2025-11-07 19:17:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:17:46 | INFO | train_inner | epoch 001:  14996 / 91072 loss=0.398193, wps=379.7, ups=1.57, wpb=241.8, bsz=16, num_updates=14950, lr=3.32222e-05, gnorm=33.545, clip=100, loss_scale=64, train_wall=32, gb_free=14.6, wall=9214
2025-11-07 19:18:17 | INFO | train_inner | epoch 001:  15046 / 91072 loss=0.408691, wps=400.5, ups=1.63, wpb=245.9, bsz=16, num_updates=15000, lr=3.33333e-05, gnorm=34.699, clip=100, loss_scale=64, train_wall=31, gb_free=17.8, wall=9245
2025-11-07 19:18:47 | INFO | train_inner | epoch 001:  15096 / 91072 loss=0.438477, wps=392.1, ups=1.64, wpb=238.8, bsz=16, num_updates=15050, lr=3.34444e-05, gnorm=33.194, clip=100, loss_scale=64, train_wall=30, gb_free=17.2, wall=9275
2025-11-07 19:19:18 | INFO | train_inner | epoch 001:  15146 / 91072 loss=0.488037, wps=406.2, ups=1.63, wpb=249.3, bsz=16, num_updates=15100, lr=3.35556e-05, gnorm=49.837, clip=98, loss_scale=64, train_wall=31, gb_free=16, wall=9306
2025-11-07 19:19:49 | INFO | train_inner | epoch 001:  15196 / 91072 loss=0.46875, wps=386.3, ups=1.64, wpb=235, bsz=16, num_updates=15150, lr=3.36667e-05, gnorm=37.759, clip=100, loss_scale=64, train_wall=30, gb_free=18.7, wall=9336
2025-11-07 19:20:19 | INFO | train_inner | epoch 001:  15246 / 91072 loss=0.436523, wps=402.4, ups=1.62, wpb=248.3, bsz=16, num_updates=15200, lr=3.37778e-05, gnorm=32.678, clip=100, loss_scale=128, train_wall=31, gb_free=14.5, wall=9367
2025-11-07 19:20:50 | INFO | train_inner | epoch 001:  15296 / 91072 loss=0.431641, wps=404.8, ups=1.61, wpb=251.1, bsz=16, num_updates=15250, lr=3.38889e-05, gnorm=34.086, clip=100, loss_scale=128, train_wall=31, gb_free=15.9, wall=9398
2025-11-07 19:21:22 | INFO | train_inner | epoch 001:  15346 / 91072 loss=0.447021, wps=404.6, ups=1.59, wpb=254.2, bsz=16, num_updates=15300, lr=3.4e-05, gnorm=36.676, clip=100, loss_scale=128, train_wall=31, gb_free=14.5, wall=9430
2025-11-07 19:21:52 | INFO | train_inner | epoch 001:  15396 / 91072 loss=0.459961, wps=392.7, ups=1.64, wpb=240, bsz=16, num_updates=15350, lr=3.41111e-05, gnorm=35.187, clip=100, loss_scale=128, train_wall=30, gb_free=17.8, wall=9460
2025-11-07 19:22:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:22:24 | INFO | train_inner | epoch 001:  15447 / 91072 loss=0.485352, wps=384.2, ups=1.56, wpb=246.1, bsz=16, num_updates=15400, lr=3.42222e-05, gnorm=41.444, clip=100, loss_scale=64, train_wall=32, gb_free=18.7, wall=9492
2025-11-07 19:22:56 | INFO | train_inner | epoch 001:  15497 / 91072 loss=0.491455, wps=416.8, ups=1.56, wpb=266.4, bsz=16, num_updates=15450, lr=3.43333e-05, gnorm=36.724, clip=100, loss_scale=64, train_wall=32, gb_free=11.2, wall=9524
2025-11-07 19:23:28 | INFO | train_inner | epoch 001:  15547 / 91072 loss=0.414795, wps=398.1, ups=1.59, wpb=251, bsz=16, num_updates=15500, lr=3.44444e-05, gnorm=30.452, clip=100, loss_scale=64, train_wall=31, gb_free=10.3, wall=9556
2025-11-07 19:23:58 | INFO | train_inner | epoch 001:  15597 / 91072 loss=0.46167, wps=387.7, ups=1.66, wpb=234.2, bsz=16, num_updates=15550, lr=3.45556e-05, gnorm=32.354, clip=100, loss_scale=64, train_wall=30, gb_free=18.2, wall=9586
2025-11-07 19:24:28 | INFO | train_inner | epoch 001:  15647 / 91072 loss=0.424805, wps=391.3, ups=1.66, wpb=235.1, bsz=16, num_updates=15600, lr=3.46667e-05, gnorm=49.083, clip=100, loss_scale=64, train_wall=30, gb_free=18.2, wall=9616
2025-11-07 19:24:59 | INFO | train_inner | epoch 001:  15697 / 91072 loss=0.43457, wps=393.2, ups=1.63, wpb=240.6, bsz=16, num_updates=15650, lr=3.47778e-05, gnorm=28.33, clip=100, loss_scale=64, train_wall=30, gb_free=19.2, wall=9647
2025-11-07 19:25:29 | INFO | train_inner | epoch 001:  15747 / 91072 loss=0.477539, wps=378.5, ups=1.66, wpb=227.4, bsz=16, num_updates=15700, lr=3.48889e-05, gnorm=31.506, clip=100, loss_scale=128, train_wall=30, gb_free=16.9, wall=9677
2025-11-07 19:25:59 | INFO | train_inner | epoch 001:  15797 / 91072 loss=0.54248, wps=395.4, ups=1.65, wpb=240, bsz=16, num_updates=15750, lr=3.5e-05, gnorm=45.003, clip=98, loss_scale=128, train_wall=30, gb_free=16.7, wall=9707
2025-11-07 19:26:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:26:30 | INFO | train_inner | epoch 001:  15848 / 91072 loss=0.469482, wps=385.3, ups=1.6, wpb=240.5, bsz=16, num_updates=15800, lr=3.51111e-05, gnorm=36.897, clip=96, loss_scale=64, train_wall=31, gb_free=17.8, wall=9738
2025-11-07 19:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 19:27:02 | INFO | train_inner | epoch 001:  15899 / 91072 loss=0.480225, wps=393.6, ups=1.6, wpb=246.4, bsz=16, num_updates=15850, lr=3.52222e-05, gnorm=45.308, clip=100, loss_scale=32, train_wall=31, gb_free=17, wall=9770
2025-11-07 19:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 19:27:33 | INFO | train_inner | epoch 001:  15950 / 91072 loss=0.439209, wps=384.9, ups=1.6, wpb=241, bsz=16, num_updates=15900, lr=3.53333e-05, gnorm=47.285, clip=96, loss_scale=16, train_wall=31, gb_free=18.3, wall=9801
2025-11-07 19:28:04 | INFO | train_inner | epoch 001:  16000 / 91072 loss=0.459229, wps=393.2, ups=1.64, wpb=240, bsz=16, num_updates=15950, lr=3.54444e-05, gnorm=29.584, clip=98, loss_scale=16, train_wall=30, gb_free=18.5, wall=9831
2025-11-07 19:28:34 | INFO | train_inner | epoch 001:  16050 / 91072 loss=0.381348, wps=406.9, ups=1.62, wpb=251.7, bsz=16, num_updates=16000, lr=3.55556e-05, gnorm=28.669, clip=100, loss_scale=16, train_wall=31, gb_free=16.6, wall=9862
2025-11-07 19:29:05 | INFO | train_inner | epoch 001:  16100 / 91072 loss=0.470947, wps=391.1, ups=1.65, wpb=236.6, bsz=16, num_updates=16050, lr=3.56667e-05, gnorm=37.068, clip=100, loss_scale=16, train_wall=30, gb_free=17.8, wall=9893
2025-11-07 19:29:36 | INFO | train_inner | epoch 001:  16150 / 91072 loss=0.472412, wps=398, ups=1.61, wpb=247.3, bsz=16, num_updates=16100, lr=3.57778e-05, gnorm=39.624, clip=100, loss_scale=16, train_wall=31, gb_free=17.9, wall=9924
2025-11-07 19:30:07 | INFO | train_inner | epoch 001:  16200 / 91072 loss=0.436523, wps=402.9, ups=1.62, wpb=248.3, bsz=16, num_updates=16150, lr=3.58889e-05, gnorm=29.903, clip=100, loss_scale=32, train_wall=31, gb_free=15.4, wall=9955
2025-11-07 19:30:38 | INFO | train_inner | epoch 001:  16250 / 91072 loss=0.439453, wps=406.8, ups=1.61, wpb=253, bsz=16, num_updates=16200, lr=3.6e-05, gnorm=32.793, clip=100, loss_scale=32, train_wall=31, gb_free=14.9, wall=9986
2025-11-07 19:31:09 | INFO | train_inner | epoch 001:  16300 / 91072 loss=0.468262, wps=409.4, ups=1.59, wpb=257.6, bsz=16, num_updates=16250, lr=3.61111e-05, gnorm=41.518, clip=100, loss_scale=32, train_wall=31, gb_free=12.4, wall=10017
2025-11-07 19:31:40 | INFO | train_inner | epoch 001:  16350 / 91072 loss=0.430908, wps=408.5, ups=1.61, wpb=254.4, bsz=16, num_updates=16300, lr=3.62222e-05, gnorm=27.544, clip=100, loss_scale=32, train_wall=31, gb_free=17.3, wall=10048
2025-11-07 19:32:11 | INFO | train_inner | epoch 001:  16400 / 91072 loss=0.423096, wps=396.9, ups=1.63, wpb=243.7, bsz=16, num_updates=16350, lr=3.63333e-05, gnorm=26.374, clip=100, loss_scale=32, train_wall=31, gb_free=9.9, wall=10079
2025-11-07 19:32:42 | INFO | train_inner | epoch 001:  16450 / 91072 loss=0.406006, wps=413.9, ups=1.61, wpb=256.6, bsz=16, num_updates=16400, lr=3.64444e-05, gnorm=32.513, clip=100, loss_scale=64, train_wall=31, gb_free=15.1, wall=10110
2025-11-07 19:33:13 | INFO | train_inner | epoch 001:  16500 / 91072 loss=0.459229, wps=386.3, ups=1.59, wpb=242.6, bsz=16, num_updates=16450, lr=3.65556e-05, gnorm=32.61, clip=100, loss_scale=64, train_wall=31, gb_free=13.5, wall=10141
2025-11-07 19:33:43 | INFO | train_inner | epoch 001:  16550 / 91072 loss=0.470459, wps=390.7, ups=1.66, wpb=234.8, bsz=16, num_updates=16500, lr=3.66667e-05, gnorm=41.229, clip=98, loss_scale=64, train_wall=30, gb_free=17.8, wall=10171
2025-11-07 19:34:14 | INFO | train_inner | epoch 001:  16600 / 91072 loss=0.474365, wps=389.7, ups=1.66, wpb=235, bsz=16, num_updates=16550, lr=3.67778e-05, gnorm=29.109, clip=96, loss_scale=64, train_wall=30, gb_free=14.6, wall=10202
2025-11-07 19:34:45 | INFO | train_inner | epoch 001:  16650 / 91072 loss=0.472656, wps=407.2, ups=1.61, wpb=253.2, bsz=16, num_updates=16600, lr=3.68889e-05, gnorm=30.903, clip=100, loss_scale=64, train_wall=31, gb_free=18.6, wall=10233
2025-11-07 19:35:16 | INFO | train_inner | epoch 001:  16700 / 91072 loss=0.458008, wps=400.9, ups=1.6, wpb=250, bsz=16, num_updates=16650, lr=3.7e-05, gnorm=35.535, clip=98, loss_scale=128, train_wall=31, gb_free=17.6, wall=10264
2025-11-07 19:35:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-07 19:35:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 19:35:48 | INFO | train_inner | epoch 001:  16752 / 91072 loss=0.464844, wps=384.8, ups=1.57, wpb=244.9, bsz=16, num_updates=16700, lr=3.71111e-05, gnorm=48.009, clip=98, loss_scale=32, train_wall=32, gb_free=17.1, wall=10296
2025-11-07 19:36:18 | INFO | train_inner | epoch 001:  16802 / 91072 loss=0.473145, wps=398.7, ups=1.64, wpb=242.7, bsz=16, num_updates=16750, lr=3.72222e-05, gnorm=36.528, clip=94, loss_scale=32, train_wall=30, gb_free=17.9, wall=10326
2025-11-07 19:36:49 | INFO | train_inner | epoch 001:  16852 / 91072 loss=0.455322, wps=399.7, ups=1.63, wpb=245.9, bsz=16, num_updates=16800, lr=3.73333e-05, gnorm=38.667, clip=100, loss_scale=32, train_wall=31, gb_free=12.2, wall=10357
2025-11-07 19:37:20 | INFO | train_inner | epoch 001:  16902 / 91072 loss=0.446289, wps=394, ups=1.6, wpb=246, bsz=16, num_updates=16850, lr=3.74444e-05, gnorm=30.005, clip=100, loss_scale=32, train_wall=31, gb_free=16.9, wall=10388
2025-11-07 19:37:51 | INFO | train_inner | epoch 001:  16952 / 91072 loss=0.541504, wps=400.5, ups=1.62, wpb=246.8, bsz=16, num_updates=16900, lr=3.75556e-05, gnorm=32.668, clip=100, loss_scale=32, train_wall=31, gb_free=15.3, wall=10419
2025-11-07 19:38:22 | INFO | train_inner | epoch 001:  17002 / 91072 loss=0.516113, wps=400.2, ups=1.63, wpb=245, bsz=16, num_updates=16950, lr=3.76667e-05, gnorm=37.368, clip=96, loss_scale=64, train_wall=30, gb_free=10.1, wall=10449
2025-11-07 19:38:52 | INFO | train_inner | epoch 001:  17052 / 91072 loss=0.450195, wps=402.8, ups=1.64, wpb=246.1, bsz=16, num_updates=17000, lr=3.77778e-05, gnorm=40.454, clip=100, loss_scale=64, train_wall=30, gb_free=15.9, wall=10480
2025-11-07 19:39:22 | INFO | train_inner | epoch 001:  17102 / 91072 loss=0.473633, wps=388.5, ups=1.65, wpb=235.3, bsz=16, num_updates=17050, lr=3.78889e-05, gnorm=34.118, clip=100, loss_scale=64, train_wall=30, gb_free=16.9, wall=10510
2025-11-07 19:39:53 | INFO | train_inner | epoch 001:  17152 / 91072 loss=0.474121, wps=396.6, ups=1.65, wpb=240.4, bsz=16, num_updates=17100, lr=3.8e-05, gnorm=31.447, clip=100, loss_scale=64, train_wall=30, gb_free=14, wall=10541
2025-11-07 19:40:23 | INFO | train_inner | epoch 001:  17202 / 91072 loss=0.465088, wps=390.7, ups=1.64, wpb=237.5, bsz=16, num_updates=17150, lr=3.81111e-05, gnorm=31.255, clip=98, loss_scale=64, train_wall=30, gb_free=19.1, wall=10571
2025-11-07 19:40:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-07 19:40:54 | INFO | train_inner | epoch 001:  17253 / 91072 loss=0.462402, wps=387.1, ups=1.61, wpb=240.5, bsz=16, num_updates=17200, lr=3.82222e-05, gnorm=44.348, clip=94, loss_scale=32, train_wall=31, gb_free=18.2, wall=10602
2025-11-07 19:41:25 | INFO | train_inner | epoch 001:  17303 / 91072 loss=0.590332, wps=394.1, ups=1.63, wpb=241.1, bsz=16, num_updates=17250, lr=3.83333e-05, gnorm=16.762, clip=80, loss_scale=32, train_wall=30, gb_free=8.7, wall=10633
2025-11-07 19:41:55 | INFO | train_inner | epoch 001:  17353 / 91072 loss=0.569336, wps=406.7, ups=1.64, wpb=248.3, bsz=16, num_updates=17300, lr=3.84444e-05, gnorm=30.799, clip=94, loss_scale=32, train_wall=30, gb_free=11.1, wall=10663
2025-11-07 19:42:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-07 19:42:26 | INFO | train_inner | epoch 001:  17404 / 91072 loss=0.483643, wps=376.7, ups=1.64, wpb=230.1, bsz=16, num_updates=17350, lr=3.85556e-05, gnorm=24.644, clip=96, loss_scale=16, train_wall=30, gb_free=18.6, wall=10694
2025-11-07 19:42:57 | INFO | train_inner | epoch 001:  17454 / 91072 loss=0.486328, wps=393.4, ups=1.61, wpb=244.1, bsz=16, num_updates=17400, lr=3.86667e-05, gnorm=53.777, clip=98, loss_scale=16, train_wall=31, gb_free=17.4, wall=10725
2025-11-07 19:43:27 | INFO | train_inner | epoch 001:  17504 / 91072 loss=0.53125, wps=398.7, ups=1.64, wpb=243.2, bsz=16, num_updates=17450, lr=3.87778e-05, gnorm=31.698, clip=96, loss_scale=16, train_wall=30, gb_free=15.7, wall=10755
2025-11-07 19:43:58 | INFO | train_inner | epoch 001:  17554 / 91072 loss=0.506836, wps=402.4, ups=1.65, wpb=243.7, bsz=16, num_updates=17500, lr=3.88889e-05, gnorm=30.993, clip=94, loss_scale=16, train_wall=30, gb_free=17.6, wall=10786
2025-11-07 19:44:28 | INFO | train_inner | epoch 001:  17604 / 91072 loss=0.585449, wps=398.6, ups=1.64, wpb=243.5, bsz=16, num_updates=17550, lr=3.9e-05, gnorm=44.236, clip=86, loss_scale=16, train_wall=30, gb_free=12.7, wall=10816
2025-11-07 19:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-07 19:45:01 | INFO | train_inner | epoch 001:  17655 / 91072 loss=0.614258, wps=390.8, ups=1.55, wpb=252.8, bsz=16, num_updates=17600, lr=3.91111e-05, gnorm=19.457, clip=90, loss_scale=8, train_wall=32, gb_free=8.2, wall=10848
2025-11-07 19:45:31 | INFO | train_inner | epoch 001:  17705 / 91072 loss=0.482422, wps=400.4, ups=1.64, wpb=244.1, bsz=16, num_updates=17650, lr=3.92222e-05, gnorm=52.993, clip=96, loss_scale=8, train_wall=30, gb_free=17.9, wall=10879
2025-11-07 19:46:02 | INFO | train_inner | epoch 001:  17755 / 91072 loss=0.59375, wps=401.2, ups=1.63, wpb=246.8, bsz=16, num_updates=17700, lr=3.93333e-05, gnorm=36.425, clip=98, loss_scale=8, train_wall=31, gb_free=17.4, wall=10910
2025-11-07 19:46:33 | INFO | train_inner | epoch 001:  17805 / 91072 loss=0.465088, wps=399.3, ups=1.61, wpb=247.4, bsz=16, num_updates=17750, lr=3.94444e-05, gnorm=96.699, clip=96, loss_scale=8, train_wall=31, gb_free=13.9, wall=10941
2025-11-07 19:47:04 | INFO | train_inner | epoch 001:  17855 / 91072 loss=0.529297, wps=394, ups=1.58, wpb=248.7, bsz=16, num_updates=17800, lr=3.95556e-05, gnorm=31.786, clip=98, loss_scale=8, train_wall=31, gb_free=17.3, wall=10972
2025-11-07 19:47:35 | INFO | train_inner | epoch 001:  17905 / 91072 loss=0.645508, wps=399.3, ups=1.63, wpb=244.8, bsz=16, num_updates=17850, lr=3.96667e-05, gnorm=31.311, clip=80, loss_scale=16, train_wall=30, gb_free=18, wall=11003
2025-11-07 19:48:06 | INFO | train_inner | epoch 001:  17955 / 91072 loss=0.56543, wps=407, ups=1.62, wpb=251.7, bsz=16, num_updates=17900, lr=3.97778e-05, gnorm=58.791, clip=90, loss_scale=16, train_wall=31, gb_free=17.6, wall=11034
2025-11-07 19:48:36 | INFO | train_inner | epoch 001:  18005 / 91072 loss=0.46875, wps=394, ups=1.66, wpb=238, bsz=16, num_updates=17950, lr=3.98889e-05, gnorm=40.56, clip=100, loss_scale=16, train_wall=30, gb_free=18.7, wall=11064
2025-11-07 19:49:06 | INFO | train_inner | epoch 001:  18055 / 91072 loss=0.50293, wps=381.4, ups=1.67, wpb=227.9, bsz=16, num_updates=18000, lr=4e-05, gnorm=42.406, clip=98, loss_scale=16, train_wall=30, gb_free=18.5, wall=11094
2025-11-07 19:49:37 | INFO | train_inner | epoch 001:  18105 / 91072 loss=0.529785, wps=408.1, ups=1.62, wpb=251.5, bsz=16, num_updates=18050, lr=4.01111e-05, gnorm=90.134, clip=96, loss_scale=16, train_wall=31, gb_free=16.5, wall=11125
2025-11-07 19:49:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-07 19:50:08 | INFO | train_inner | epoch 001:  18156 / 91072 loss=0.638672, wps=387.8, ups=1.61, wpb=240.7, bsz=16, num_updates=18100, lr=4.02222e-05, gnorm=24.981, clip=88, loss_scale=8, train_wall=31, gb_free=17.6, wall=11156
2025-11-07 19:50:39 | INFO | train_inner | epoch 001:  18206 / 91072 loss=0.519043, wps=420.1, ups=1.58, wpb=265.1, bsz=16, num_updates=18150, lr=4.03333e-05, gnorm=25.432, clip=78, loss_scale=8, train_wall=31, gb_free=12, wall=11187
2025-11-07 19:51:10 | INFO | train_inner | epoch 001:  18256 / 91072 loss=0.633789, wps=397.9, ups=1.62, wpb=245.5, bsz=16, num_updates=18200, lr=4.04444e-05, gnorm=42.751, clip=76, loss_scale=8, train_wall=31, gb_free=15.7, wall=11218
2025-11-07 19:51:41 | INFO | train_inner | epoch 001:  18306 / 91072 loss=0.613281, wps=398.7, ups=1.64, wpb=243.4, bsz=16, num_updates=18250, lr=4.05556e-05, gnorm=42.576, clip=100, loss_scale=8, train_wall=30, gb_free=19, wall=11249
2025-11-07 19:52:11 | INFO | train_inner | epoch 001:  18356 / 91072 loss=0.549316, wps=400.7, ups=1.63, wpb=245.7, bsz=16, num_updates=18300, lr=4.06667e-05, gnorm=94.63, clip=96, loss_scale=8, train_wall=30, gb_free=18.3, wall=11279
2025-11-07 19:52:43 | INFO | train_inner | epoch 001:  18406 / 91072 loss=0.599609, wps=394.6, ups=1.6, wpb=247.1, bsz=16, num_updates=18350, lr=4.07778e-05, gnorm=76.084, clip=90, loss_scale=16, train_wall=31, gb_free=17.4, wall=11311
2025-11-07 19:53:14 | INFO | train_inner | epoch 001:  18456 / 91072 loss=0.52002, wps=399.1, ups=1.62, wpb=246.6, bsz=16, num_updates=18400, lr=4.08889e-05, gnorm=71.117, clip=96, loss_scale=16, train_wall=31, gb_free=16.1, wall=11342
2025-11-07 19:53:43 | INFO | train_inner | epoch 001:  18506 / 91072 loss=0.505371, wps=384.1, ups=1.68, wpb=228.8, bsz=16, num_updates=18450, lr=4.1e-05, gnorm=30.426, clip=94, loss_scale=16, train_wall=30, gb_free=18.3, wall=11371
2025-11-07 19:54:14 | INFO | train_inner | epoch 001:  18556 / 91072 loss=0.568848, wps=403.8, ups=1.61, wpb=250.5, bsz=16, num_updates=18500, lr=4.11111e-05, gnorm=35.801, clip=82, loss_scale=16, train_wall=31, gb_free=13.6, wall=11402
2025-11-07 19:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-07 19:54:46 | INFO | train_inner | epoch 001:  18607 / 91072 loss=0.664551, wps=397.5, ups=1.58, wpb=251.6, bsz=16, num_updates=18550, lr=4.12222e-05, gnorm=9.209, clip=74, loss_scale=8, train_wall=31, gb_free=16.6, wall=11434
2025-11-07 19:55:17 | INFO | train_inner | epoch 001:  18657 / 91072 loss=0.5625, wps=404.2, ups=1.62, wpb=249.8, bsz=16, num_updates=18600, lr=4.13333e-05, gnorm=49.462, clip=88, loss_scale=8, train_wall=31, gb_free=18.5, wall=11465
2025-11-07 19:55:48 | INFO | train_inner | epoch 001:  18707 / 91072 loss=0.515137, wps=409.5, ups=1.61, wpb=254.2, bsz=16, num_updates=18650, lr=4.14444e-05, gnorm=41.607, clip=84, loss_scale=8, train_wall=31, gb_free=14.5, wall=11496
2025-11-07 19:56:19 | INFO | train_inner | epoch 001:  18757 / 91072 loss=0.634277, wps=399.1, ups=1.64, wpb=243.4, bsz=16, num_updates=18700, lr=4.15556e-05, gnorm=13.706, clip=78, loss_scale=8, train_wall=30, gb_free=12.2, wall=11526
2025-11-07 19:56:50 | INFO | train_inner | epoch 001:  18807 / 91072 loss=0.750977, wps=396.7, ups=1.6, wpb=248.7, bsz=16, num_updates=18750, lr=4.16667e-05, gnorm=9.474, clip=76, loss_scale=8, train_wall=31, gb_free=13.9, wall=11558
2025-11-07 19:57:21 | INFO | train_inner | epoch 001:  18857 / 91072 loss=0.644531, wps=401.2, ups=1.63, wpb=246.9, bsz=16, num_updates=18800, lr=4.17778e-05, gnorm=11.178, clip=76, loss_scale=16, train_wall=31, gb_free=17.6, wall=11589
2025-11-07 19:57:51 | INFO | train_inner | epoch 001:  18907 / 91072 loss=0.739746, wps=396, ups=1.67, wpb=237.3, bsz=16, num_updates=18850, lr=4.18889e-05, gnorm=13.712, clip=82, loss_scale=16, train_wall=30, gb_free=17.5, wall=11619
2025-11-07 19:58:22 | INFO | train_inner | epoch 001:  18957 / 91072 loss=0.662109, wps=402.3, ups=1.62, wpb=248.7, bsz=16, num_updates=18900, lr=4.2e-05, gnorm=11.887, clip=78, loss_scale=16, train_wall=31, gb_free=15.6, wall=11649
2025-11-07 19:58:53 | INFO | train_inner | epoch 001:  19007 / 91072 loss=0.62207, wps=382.1, ups=1.58, wpb=241.7, bsz=16, num_updates=18950, lr=4.21111e-05, gnorm=12.496, clip=76, loss_scale=16, train_wall=31, gb_free=13.1, wall=11681
2025-11-07 19:59:23 | INFO | train_inner | epoch 001:  19057 / 91072 loss=0.591309, wps=395.8, ups=1.65, wpb=239.9, bsz=16, num_updates=19000, lr=4.22222e-05, gnorm=10.389, clip=76, loss_scale=16, train_wall=30, gb_free=15.4, wall=11711
2025-11-07 19:59:54 | INFO | train_inner | epoch 001:  19107 / 91072 loss=0.65625, wps=409.2, ups=1.62, wpb=251.9, bsz=16, num_updates=19050, lr=4.23333e-05, gnorm=12.904, clip=66, loss_scale=16, train_wall=31, gb_free=18.1, wall=11742
2025-11-07 20:00:24 | INFO | train_inner | epoch 001:  19157 / 91072 loss=0.689453, wps=384.4, ups=1.67, wpb=230.1, bsz=16, num_updates=19100, lr=4.24444e-05, gnorm=10.817, clip=74, loss_scale=32, train_wall=30, gb_free=15.6, wall=11772
2025-11-07 20:00:55 | INFO | train_inner | epoch 001:  19207 / 91072 loss=0.637207, wps=411.4, ups=1.6, wpb=256.3, bsz=16, num_updates=19150, lr=4.25556e-05, gnorm=11.496, clip=76, loss_scale=32, train_wall=31, gb_free=14.4, wall=11803
2025-11-07 20:01:26 | INFO | train_inner | epoch 001:  19257 / 91072 loss=0.703613, wps=404, ups=1.63, wpb=247.4, bsz=16, num_updates=19200, lr=4.26667e-05, gnorm=12.456, clip=78, loss_scale=32, train_wall=30, gb_free=18.3, wall=11834
2025-11-07 20:01:56 | INFO | train_inner | epoch 001:  19307 / 91072 loss=0.668945, wps=401, ups=1.64, wpb=243.9, bsz=16, num_updates=19250, lr=4.27778e-05, gnorm=9.93, clip=64, loss_scale=32, train_wall=30, gb_free=12, wall=11864
2025-11-07 20:02:27 | INFO | train_inner | epoch 001:  19357 / 91072 loss=0.692871, wps=403.6, ups=1.63, wpb=247.8, bsz=16, num_updates=19300, lr=4.28889e-05, gnorm=11.87, clip=68, loss_scale=32, train_wall=31, gb_free=17.8, wall=11895
2025-11-07 20:02:57 | INFO | train_inner | epoch 001:  19407 / 91072 loss=0.650391, wps=393.6, ups=1.66, wpb=237.8, bsz=16, num_updates=19350, lr=4.3e-05, gnorm=10.644, clip=68, loss_scale=64, train_wall=30, gb_free=17.7, wall=11925
2025-11-07 20:03:27 | INFO | train_inner | epoch 001:  19457 / 91072 loss=0.643066, wps=395.9, ups=1.66, wpb=239.1, bsz=16, num_updates=19400, lr=4.31111e-05, gnorm=12.525, clip=74, loss_scale=64, train_wall=30, gb_free=15.7, wall=11955
2025-11-07 20:03:59 | INFO | train_inner | epoch 001:  19507 / 91072 loss=0.608398, wps=417.8, ups=1.6, wpb=261.6, bsz=16, num_updates=19450, lr=4.32222e-05, gnorm=11.521, clip=76, loss_scale=64, train_wall=31, gb_free=17.6, wall=11987
2025-11-07 20:04:31 | INFO | train_inner | epoch 001:  19557 / 91072 loss=0.695312, wps=384, ups=1.56, wpb=246.4, bsz=16, num_updates=19500, lr=4.33333e-05, gnorm=11.746, clip=74, loss_scale=64, train_wall=32, gb_free=17.6, wall=12019
2025-11-07 20:05:02 | INFO | train_inner | epoch 001:  19607 / 91072 loss=0.668945, wps=386.5, ups=1.61, wpb=239.5, bsz=16, num_updates=19550, lr=4.34444e-05, gnorm=13.895, clip=86, loss_scale=64, train_wall=31, gb_free=18.6, wall=12050
2025-11-07 20:05:34 | INFO | train_inner | epoch 001:  19657 / 91072 loss=0.631348, wps=413.8, ups=1.57, wpb=263.2, bsz=16, num_updates=19600, lr=4.35556e-05, gnorm=11.774, clip=78, loss_scale=128, train_wall=32, gb_free=14.3, wall=12082
2025-11-07 20:06:05 | INFO | train_inner | epoch 001:  19707 / 91072 loss=0.638184, wps=408.7, ups=1.61, wpb=254.2, bsz=16, num_updates=19650, lr=4.36667e-05, gnorm=11.852, clip=64, loss_scale=128, train_wall=31, gb_free=16.9, wall=12113
2025-11-07 20:06:36 | INFO | train_inner | epoch 001:  19757 / 91072 loss=0.633301, wps=395.6, ups=1.58, wpb=249.7, bsz=16, num_updates=19700, lr=4.37778e-05, gnorm=11.463, clip=72, loss_scale=128, train_wall=31, gb_free=14.9, wall=12144
2025-11-07 20:07:07 | INFO | train_inner | epoch 001:  19807 / 91072 loss=0.729004, wps=400.6, ups=1.65, wpb=242.8, bsz=16, num_updates=19750, lr=4.38889e-05, gnorm=13.578, clip=78, loss_scale=128, train_wall=30, gb_free=15.5, wall=12175
2025-11-07 20:07:37 | INFO | train_inner | epoch 001:  19857 / 91072 loss=0.62793, wps=393.9, ups=1.66, wpb=237.9, bsz=16, num_updates=19800, lr=4.4e-05, gnorm=9.973, clip=72, loss_scale=128, train_wall=30, gb_free=18.2, wall=12205
2025-11-07 20:08:07 | INFO | train_inner | epoch 001:  19907 / 91072 loss=0.652832, wps=394.2, ups=1.66, wpb=238.2, bsz=16, num_updates=19850, lr=4.41111e-05, gnorm=11.397, clip=74, loss_scale=256, train_wall=30, gb_free=17.4, wall=12235
2025-11-07 20:08:38 | INFO | train_inner | epoch 001:  19957 / 91072 loss=0.711914, wps=394.3, ups=1.61, wpb=245.3, bsz=16, num_updates=19900, lr=4.42222e-05, gnorm=12.37, clip=70, loss_scale=256, train_wall=31, gb_free=13.5, wall=12266
2025-11-07 20:09:09 | INFO | train_inner | epoch 001:  20007 / 91072 loss=0.614258, wps=396.6, ups=1.65, wpb=240.9, bsz=16, num_updates=19950, lr=4.43333e-05, gnorm=12.19, clip=82, loss_scale=256, train_wall=30, gb_free=13.9, wall=12296
2025-11-07 20:09:39 | INFO | train_inner | epoch 001:  20057 / 91072 loss=0.628906, wps=389.5, ups=1.65, wpb=236.1, bsz=16, num_updates=20000, lr=4.44444e-05, gnorm=10.756, clip=76, loss_scale=256, train_wall=30, gb_free=18.1, wall=12327
2025-11-07 20:10:10 | INFO | train_inner | epoch 001:  20107 / 91072 loss=0.698242, wps=406.7, ups=1.62, wpb=250.9, bsz=16, num_updates=20050, lr=4.45556e-05, gnorm=12.981, clip=76, loss_scale=256, train_wall=31, gb_free=18.4, wall=12358
2025-11-07 20:10:41 | INFO | train_inner | epoch 001:  20157 / 91072 loss=0.727051, wps=402.8, ups=1.61, wpb=250.7, bsz=16, num_updates=20100, lr=4.46667e-05, gnorm=10.564, clip=70, loss_scale=512, train_wall=31, gb_free=18.9, wall=12389
2025-11-07 20:11:11 | INFO | train_inner | epoch 001:  20207 / 91072 loss=0.569824, wps=390.2, ups=1.66, wpb=234.7, bsz=16, num_updates=20150, lr=4.47778e-05, gnorm=9.46, clip=72, loss_scale=512, train_wall=30, gb_free=15.3, wall=12419
2025-11-07 20:11:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:11:42 | INFO | train_inner | epoch 001:  20258 / 91072 loss=0.689453, wps=390.8, ups=1.63, wpb=240.4, bsz=16, num_updates=20200, lr=4.48889e-05, gnorm=10.314, clip=74, loss_scale=256, train_wall=31, gb_free=17, wall=12450
2025-11-07 20:12:11 | INFO | train_inner | epoch 001:  20308 / 91072 loss=0.592773, wps=386.2, ups=1.68, wpb=230, bsz=16, num_updates=20250, lr=4.5e-05, gnorm=9.79, clip=64, loss_scale=256, train_wall=30, gb_free=16.9, wall=12479
2025-11-07 20:12:42 | INFO | train_inner | epoch 001:  20358 / 91072 loss=0.636719, wps=400.4, ups=1.62, wpb=247.5, bsz=16, num_updates=20300, lr=4.51111e-05, gnorm=11.44, clip=72, loss_scale=256, train_wall=31, gb_free=16.3, wall=12510
2025-11-07 20:13:14 | INFO | train_inner | epoch 001:  20408 / 91072 loss=0.692383, wps=419, ups=1.58, wpb=264.9, bsz=16, num_updates=20350, lr=4.52222e-05, gnorm=10.681, clip=78, loss_scale=256, train_wall=31, gb_free=16.9, wall=12542
2025-11-07 20:13:45 | INFO | train_inner | epoch 001:  20458 / 91072 loss=0.664551, wps=411.2, ups=1.63, wpb=252.8, bsz=16, num_updates=20400, lr=4.53333e-05, gnorm=10.557, clip=64, loss_scale=256, train_wall=31, gb_free=16.6, wall=12573
2025-11-07 20:14:15 | INFO | train_inner | epoch 001:  20508 / 91072 loss=0.681641, wps=389.9, ups=1.65, wpb=237, bsz=16, num_updates=20450, lr=4.54444e-05, gnorm=12.11, clip=66, loss_scale=512, train_wall=30, gb_free=15.6, wall=12603
2025-11-07 20:14:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:14:47 | INFO | train_inner | epoch 001:  20559 / 91072 loss=0.663086, wps=396.9, ups=1.58, wpb=250.7, bsz=16, num_updates=20500, lr=4.55556e-05, gnorm=12.192, clip=74, loss_scale=256, train_wall=31, gb_free=17.6, wall=12635
2025-11-07 20:15:16 | INFO | train_inner | epoch 001:  20609 / 91072 loss=0.599121, wps=384.5, ups=1.69, wpb=227.7, bsz=16, num_updates=20550, lr=4.56667e-05, gnorm=11.061, clip=74, loss_scale=256, train_wall=29, gb_free=17, wall=12664
2025-11-07 20:15:46 | INFO | train_inner | epoch 001:  20659 / 91072 loss=0.671875, wps=392.5, ups=1.66, wpb=237, bsz=16, num_updates=20600, lr=4.57778e-05, gnorm=13.278, clip=76, loss_scale=256, train_wall=30, gb_free=16.1, wall=12694
2025-11-07 20:16:17 | INFO | train_inner | epoch 001:  20709 / 91072 loss=0.605469, wps=380.4, ups=1.64, wpb=232.2, bsz=16, num_updates=20650, lr=4.58889e-05, gnorm=10.57, clip=70, loss_scale=256, train_wall=30, gb_free=17.6, wall=12725
2025-11-07 20:16:47 | INFO | train_inner | epoch 001:  20759 / 91072 loss=0.653809, wps=390.7, ups=1.67, wpb=233.4, bsz=16, num_updates=20700, lr=4.6e-05, gnorm=11.446, clip=68, loss_scale=256, train_wall=30, gb_free=17, wall=12755
2025-11-07 20:17:18 | INFO | train_inner | epoch 001:  20809 / 91072 loss=0.630859, wps=408.7, ups=1.62, wpb=252, bsz=16, num_updates=20750, lr=4.61111e-05, gnorm=11.156, clip=70, loss_scale=512, train_wall=31, gb_free=17.7, wall=12786
2025-11-07 20:17:49 | INFO | train_inner | epoch 001:  20859 / 91072 loss=0.620605, wps=396.1, ups=1.62, wpb=245.1, bsz=16, num_updates=20800, lr=4.62222e-05, gnorm=12.797, clip=78, loss_scale=512, train_wall=31, gb_free=18.2, wall=12817
2025-11-07 20:18:19 | INFO | train_inner | epoch 001:  20909 / 91072 loss=0.648438, wps=397.1, ups=1.63, wpb=244.1, bsz=16, num_updates=20850, lr=4.63333e-05, gnorm=10.102, clip=74, loss_scale=512, train_wall=31, gb_free=16.3, wall=12847
2025-11-07 20:18:51 | INFO | train_inner | epoch 001:  20959 / 91072 loss=0.622559, wps=413.9, ups=1.59, wpb=260.6, bsz=16, num_updates=20900, lr=4.64444e-05, gnorm=12.682, clip=80, loss_scale=512, train_wall=31, gb_free=9.3, wall=12879
2025-11-07 20:19:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:19:22 | INFO | train_inner | epoch 001:  21010 / 91072 loss=0.618164, wps=387.8, ups=1.62, wpb=239.3, bsz=16, num_updates=20950, lr=4.65556e-05, gnorm=9.803, clip=68, loss_scale=256, train_wall=31, gb_free=17.8, wall=12910
2025-11-07 20:19:52 | INFO | train_inner | epoch 001:  21060 / 91072 loss=0.62793, wps=398.9, ups=1.65, wpb=242.1, bsz=16, num_updates=21000, lr=4.66667e-05, gnorm=11.362, clip=62, loss_scale=256, train_wall=30, gb_free=17.4, wall=12940
2025-11-07 20:20:22 | INFO | train_inner | epoch 001:  21110 / 91072 loss=0.643555, wps=386.8, ups=1.64, wpb=235.3, bsz=16, num_updates=21050, lr=4.67778e-05, gnorm=12.103, clip=76, loss_scale=256, train_wall=30, gb_free=14, wall=12970
2025-11-07 20:20:53 | INFO | train_inner | epoch 001:  21160 / 91072 loss=0.663574, wps=403.4, ups=1.62, wpb=249.4, bsz=16, num_updates=21100, lr=4.68889e-05, gnorm=12.058, clip=78, loss_scale=256, train_wall=31, gb_free=17.3, wall=13001
2025-11-07 20:21:25 | INFO | train_inner | epoch 001:  21210 / 91072 loss=0.647461, wps=406.9, ups=1.59, wpb=256.3, bsz=16, num_updates=21150, lr=4.7e-05, gnorm=12.64, clip=78, loss_scale=256, train_wall=31, gb_free=14.5, wall=13033
2025-11-07 20:21:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:21:56 | INFO | train_inner | epoch 001:  21261 / 91072 loss=0.600586, wps=377.4, ups=1.63, wpb=231.8, bsz=16, num_updates=21200, lr=4.71111e-05, gnorm=9.226, clip=66, loss_scale=256, train_wall=31, gb_free=17.8, wall=13063
2025-11-07 20:22:26 | INFO | train_inner | epoch 001:  21311 / 91072 loss=0.687012, wps=396, ups=1.63, wpb=242.8, bsz=16, num_updates=21250, lr=4.72222e-05, gnorm=11.207, clip=78, loss_scale=256, train_wall=31, gb_free=18.2, wall=13094
2025-11-07 20:22:56 | INFO | train_inner | epoch 001:  21361 / 91072 loss=0.627441, wps=383.9, ups=1.68, wpb=228.3, bsz=16, num_updates=21300, lr=4.73333e-05, gnorm=12.207, clip=72, loss_scale=256, train_wall=30, gb_free=17.3, wall=13124
2025-11-07 20:23:26 | INFO | train_inner | epoch 001:  21411 / 91072 loss=0.681152, wps=384.5, ups=1.68, wpb=228.8, bsz=16, num_updates=21350, lr=4.74444e-05, gnorm=10.56, clip=72, loss_scale=256, train_wall=30, gb_free=18.8, wall=13154
2025-11-07 20:23:57 | INFO | train_inner | epoch 001:  21461 / 91072 loss=0.664551, wps=399.3, ups=1.62, wpb=246.9, bsz=16, num_updates=21400, lr=4.75556e-05, gnorm=11.82, clip=78, loss_scale=256, train_wall=31, gb_free=13.4, wall=13185
2025-11-07 20:24:27 | INFO | train_inner | epoch 001:  21511 / 91072 loss=0.57959, wps=390.6, ups=1.67, wpb=234.5, bsz=16, num_updates=21450, lr=4.76667e-05, gnorm=11.759, clip=74, loss_scale=512, train_wall=30, gb_free=17.4, wall=13215
2025-11-07 20:24:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:24:59 | INFO | train_inner | epoch 001:  21562 / 91072 loss=0.712891, wps=387.7, ups=1.54, wpb=251.4, bsz=16, num_updates=21500, lr=4.77778e-05, gnorm=11.782, clip=74, loss_scale=256, train_wall=32, gb_free=17.8, wall=13247
2025-11-07 20:25:31 | INFO | train_inner | epoch 001:  21612 / 91072 loss=0.69873, wps=419.5, ups=1.59, wpb=264.6, bsz=16, num_updates=21550, lr=4.78889e-05, gnorm=11.523, clip=74, loss_scale=256, train_wall=31, gb_free=16.9, wall=13279
2025-11-07 20:26:01 | INFO | train_inner | epoch 001:  21662 / 91072 loss=0.744141, wps=397.4, ups=1.63, wpb=244.4, bsz=16, num_updates=21600, lr=4.8e-05, gnorm=14.032, clip=84, loss_scale=256, train_wall=31, gb_free=18.5, wall=13309
2025-11-07 20:26:32 | INFO | train_inner | epoch 001:  21712 / 91072 loss=0.633301, wps=395.3, ups=1.65, wpb=239.8, bsz=16, num_updates=21650, lr=4.81111e-05, gnorm=10.42, clip=66, loss_scale=256, train_wall=30, gb_free=17.7, wall=13340
2025-11-07 20:27:03 | INFO | train_inner | epoch 001:  21762 / 91072 loss=0.732422, wps=408.7, ups=1.62, wpb=252.2, bsz=16, num_updates=21700, lr=4.82222e-05, gnorm=11.577, clip=72, loss_scale=256, train_wall=31, gb_free=17.7, wall=13370
2025-11-07 20:27:33 | INFO | train_inner | epoch 001:  21812 / 91072 loss=0.708496, wps=398.7, ups=1.64, wpb=243.5, bsz=16, num_updates=21750, lr=4.83333e-05, gnorm=12.832, clip=74, loss_scale=512, train_wall=30, gb_free=15.1, wall=13401
2025-11-07 20:27:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:28:05 | INFO | train_inner | epoch 001:  21863 / 91072 loss=0.604004, wps=389.3, ups=1.57, wpb=247.7, bsz=16, num_updates=21800, lr=4.84444e-05, gnorm=10.608, clip=74, loss_scale=256, train_wall=32, gb_free=17.7, wall=13433
2025-11-07 20:28:35 | INFO | train_inner | epoch 001:  21913 / 91072 loss=0.700195, wps=389, ups=1.66, wpb=233.8, bsz=16, num_updates=21850, lr=4.85556e-05, gnorm=11.896, clip=70, loss_scale=256, train_wall=30, gb_free=16.5, wall=13463
2025-11-07 20:29:05 | INFO | train_inner | epoch 001:  21963 / 91072 loss=0.604004, wps=392.1, ups=1.67, wpb=235.4, bsz=16, num_updates=21900, lr=4.86667e-05, gnorm=10.949, clip=70, loss_scale=256, train_wall=30, gb_free=18.3, wall=13493
2025-11-07 20:29:35 | INFO | train_inner | epoch 001:  22013 / 91072 loss=0.700195, wps=403.8, ups=1.64, wpb=245.6, bsz=16, num_updates=21950, lr=4.87778e-05, gnorm=11.926, clip=82, loss_scale=256, train_wall=30, gb_free=18.4, wall=13523
2025-11-07 20:30:06 | INFO | train_inner | epoch 001:  22063 / 91072 loss=0.617188, wps=383.5, ups=1.64, wpb=233.5, bsz=16, num_updates=22000, lr=4.88889e-05, gnorm=11.219, clip=78, loss_scale=256, train_wall=30, gb_free=9.9, wall=13554
2025-11-07 20:30:36 | INFO | train_inner | epoch 001:  22113 / 91072 loss=0.643066, wps=394.6, ups=1.64, wpb=240, bsz=16, num_updates=22050, lr=4.9e-05, gnorm=11.516, clip=78, loss_scale=512, train_wall=30, gb_free=18.1, wall=13584
2025-11-07 20:31:08 | INFO | train_inner | epoch 001:  22163 / 91072 loss=0.637695, wps=398.6, ups=1.6, wpb=249.8, bsz=16, num_updates=22100, lr=4.91111e-05, gnorm=11.093, clip=70, loss_scale=512, train_wall=31, gb_free=17.6, wall=13616
2025-11-07 20:31:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:31:39 | INFO | train_inner | epoch 001:  22214 / 91072 loss=0.65625, wps=385.3, ups=1.58, wpb=243.6, bsz=16, num_updates=22150, lr=4.92222e-05, gnorm=13.532, clip=76, loss_scale=256, train_wall=31, gb_free=18.9, wall=13647
2025-11-07 20:32:10 | INFO | train_inner | epoch 001:  22264 / 91072 loss=0.663086, wps=398.7, ups=1.61, wpb=247.3, bsz=16, num_updates=22200, lr=4.93333e-05, gnorm=11.169, clip=78, loss_scale=256, train_wall=31, gb_free=17.9, wall=13678
2025-11-07 20:32:41 | INFO | train_inner | epoch 001:  22314 / 91072 loss=0.657227, wps=401.2, ups=1.64, wpb=244.2, bsz=16, num_updates=22250, lr=4.94444e-05, gnorm=11.099, clip=74, loss_scale=256, train_wall=30, gb_free=18.2, wall=13709
2025-11-07 20:33:11 | INFO | train_inner | epoch 001:  22364 / 91072 loss=0.661621, wps=393.8, ups=1.64, wpb=239.4, bsz=16, num_updates=22300, lr=4.95556e-05, gnorm=12.156, clip=84, loss_scale=256, train_wall=30, gb_free=12.6, wall=13739
2025-11-07 20:33:42 | INFO | train_inner | epoch 001:  22414 / 91072 loss=0.674805, wps=401.5, ups=1.61, wpb=249.6, bsz=16, num_updates=22350, lr=4.96667e-05, gnorm=12.633, clip=76, loss_scale=256, train_wall=31, gb_free=15.6, wall=13770
2025-11-07 20:33:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:34:14 | INFO | train_inner | epoch 001:  22465 / 91072 loss=0.601074, wps=382.5, ups=1.58, wpb=242.5, bsz=16, num_updates=22400, lr=4.97778e-05, gnorm=10.793, clip=62, loss_scale=256, train_wall=32, gb_free=15.1, wall=13802
2025-11-07 20:34:44 | INFO | train_inner | epoch 001:  22515 / 91072 loss=0.634277, wps=389.8, ups=1.67, wpb=233.8, bsz=16, num_updates=22450, lr=4.98889e-05, gnorm=11.702, clip=70, loss_scale=256, train_wall=30, gb_free=16.5, wall=13832
2025-11-07 20:35:14 | INFO | train_inner | epoch 001:  22565 / 91072 loss=0.636719, wps=398.1, ups=1.64, wpb=242.8, bsz=16, num_updates=22500, lr=5e-05, gnorm=11.952, clip=76, loss_scale=256, train_wall=30, gb_free=17.4, wall=13862
2025-11-07 20:35:45 | INFO | train_inner | epoch 001:  22615 / 91072 loss=0.609375, wps=396.3, ups=1.61, wpb=245.9, bsz=16, num_updates=22550, lr=5.01111e-05, gnorm=10.597, clip=68, loss_scale=256, train_wall=31, gb_free=17.2, wall=13893
2025-11-07 20:36:15 | INFO | train_inner | epoch 001:  22665 / 91072 loss=0.727051, wps=389.2, ups=1.67, wpb=233.7, bsz=16, num_updates=22600, lr=5.02222e-05, gnorm=14.994, clip=84, loss_scale=256, train_wall=30, gb_free=16.6, wall=13923
2025-11-07 20:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:36:47 | INFO | train_inner | epoch 001:  22716 / 91072 loss=0.695312, wps=380.7, ups=1.57, wpb=242.6, bsz=16, num_updates=22650, lr=5.03333e-05, gnorm=9.922, clip=74, loss_scale=256, train_wall=32, gb_free=15.8, wall=13955
2025-11-07 20:37:18 | INFO | train_inner | epoch 001:  22766 / 91072 loss=0.64209, wps=401, ups=1.63, wpb=246.1, bsz=16, num_updates=22700, lr=5.04444e-05, gnorm=13.921, clip=78, loss_scale=256, train_wall=31, gb_free=17.8, wall=13986
2025-11-07 20:37:49 | INFO | train_inner | epoch 001:  22816 / 91072 loss=0.625, wps=386.1, ups=1.62, wpb=238.6, bsz=16, num_updates=22750, lr=5.05556e-05, gnorm=12.044, clip=82, loss_scale=256, train_wall=31, gb_free=18, wall=14017
2025-11-07 20:38:20 | INFO | train_inner | epoch 001:  22866 / 91072 loss=0.67334, wps=405.9, ups=1.62, wpb=250.7, bsz=16, num_updates=22800, lr=5.06667e-05, gnorm=11.166, clip=68, loss_scale=256, train_wall=31, gb_free=14.6, wall=14048
2025-11-07 20:38:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 20:38:51 | INFO | train_inner | epoch 001:  22917 / 91072 loss=0.702148, wps=395, ups=1.58, wpb=250.5, bsz=16, num_updates=22850, lr=5.07778e-05, gnorm=12.372, clip=66, loss_scale=128, train_wall=32, gb_free=16.3, wall=14079
2025-11-07 20:39:22 | INFO | train_inner | epoch 001:  22967 / 91072 loss=0.616211, wps=400.7, ups=1.64, wpb=245, bsz=16, num_updates=22900, lr=5.08889e-05, gnorm=10.604, clip=70, loss_scale=128, train_wall=30, gb_free=13.5, wall=14110
2025-11-07 20:39:53 | INFO | train_inner | epoch 001:  23017 / 91072 loss=0.679688, wps=396, ups=1.59, wpb=248.3, bsz=16, num_updates=22950, lr=5.1e-05, gnorm=11.202, clip=70, loss_scale=128, train_wall=31, gb_free=16.8, wall=14141
2025-11-07 20:40:24 | INFO | train_inner | epoch 001:  23067 / 91072 loss=0.701172, wps=400.6, ups=1.63, wpb=246, bsz=16, num_updates=23000, lr=5.11111e-05, gnorm=12.303, clip=74, loss_scale=128, train_wall=31, gb_free=14.4, wall=14172
2025-11-07 20:40:55 | INFO | train_inner | epoch 001:  23117 / 91072 loss=0.556641, wps=402.7, ups=1.63, wpb=247.5, bsz=16, num_updates=23050, lr=5.12222e-05, gnorm=9.867, clip=62, loss_scale=128, train_wall=31, gb_free=17.7, wall=14203
2025-11-07 20:41:26 | INFO | train_inner | epoch 001:  23167 / 91072 loss=0.659668, wps=403.4, ups=1.62, wpb=249.3, bsz=16, num_updates=23100, lr=5.13333e-05, gnorm=12.013, clip=72, loss_scale=256, train_wall=31, gb_free=19.5, wall=14234
2025-11-07 20:41:58 | INFO | train_inner | epoch 001:  23217 / 91072 loss=0.69043, wps=389.9, ups=1.57, wpb=248.8, bsz=16, num_updates=23150, lr=5.14444e-05, gnorm=9.396, clip=70, loss_scale=256, train_wall=32, gb_free=14.6, wall=14265
2025-11-07 20:42:28 | INFO | train_inner | epoch 001:  23267 / 91072 loss=0.652344, wps=391.4, ups=1.64, wpb=238.1, bsz=16, num_updates=23200, lr=5.15556e-05, gnorm=11.728, clip=72, loss_scale=256, train_wall=30, gb_free=18, wall=14296
2025-11-07 20:42:58 | INFO | train_inner | epoch 001:  23317 / 91072 loss=0.671875, wps=378.5, ups=1.67, wpb=227.3, bsz=16, num_updates=23250, lr=5.16667e-05, gnorm=12.894, clip=72, loss_scale=256, train_wall=30, gb_free=17, wall=14326
2025-11-07 20:43:29 | INFO | train_inner | epoch 001:  23367 / 91072 loss=0.726074, wps=405.4, ups=1.63, wpb=249, bsz=16, num_updates=23300, lr=5.17778e-05, gnorm=13.652, clip=80, loss_scale=256, train_wall=31, gb_free=18.8, wall=14357
2025-11-07 20:44:00 | INFO | train_inner | epoch 001:  23417 / 91072 loss=0.637207, wps=400.3, ups=1.61, wpb=247.9, bsz=16, num_updates=23350, lr=5.18889e-05, gnorm=11.688, clip=80, loss_scale=512, train_wall=31, gb_free=17.3, wall=14388
2025-11-07 20:44:30 | INFO | train_inner | epoch 001:  23467 / 91072 loss=0.619629, wps=388.2, ups=1.67, wpb=232.6, bsz=16, num_updates=23400, lr=5.2e-05, gnorm=10.661, clip=70, loss_scale=512, train_wall=30, gb_free=16.8, wall=14418
2025-11-07 20:45:00 | INFO | train_inner | epoch 001:  23517 / 91072 loss=0.707031, wps=402.9, ups=1.64, wpb=245.8, bsz=16, num_updates=23450, lr=5.21111e-05, gnorm=13.049, clip=76, loss_scale=512, train_wall=30, gb_free=17.7, wall=14448
2025-11-07 20:45:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:45:32 | INFO | train_inner | epoch 001:  23568 / 91072 loss=0.60498, wps=379.8, ups=1.59, wpb=238.9, bsz=16, num_updates=23500, lr=5.22222e-05, gnorm=11.61, clip=76, loss_scale=256, train_wall=31, gb_free=15, wall=14480
2025-11-07 20:46:03 | INFO | train_inner | epoch 001:  23618 / 91072 loss=0.76123, wps=419.5, ups=1.59, wpb=264.7, bsz=16, num_updates=23550, lr=5.23333e-05, gnorm=13.431, clip=80, loss_scale=256, train_wall=31, gb_free=17.9, wall=14511
2025-11-07 20:46:33 | INFO | train_inner | epoch 001:  23668 / 91072 loss=0.58252, wps=395.3, ups=1.65, wpb=239.3, bsz=16, num_updates=23600, lr=5.24444e-05, gnorm=10.309, clip=72, loss_scale=256, train_wall=30, gb_free=17.6, wall=14541
2025-11-07 20:47:04 | INFO | train_inner | epoch 001:  23718 / 91072 loss=0.609375, wps=397.5, ups=1.65, wpb=241.6, bsz=16, num_updates=23650, lr=5.25556e-05, gnorm=12.444, clip=82, loss_scale=256, train_wall=30, gb_free=9.2, wall=14572
2025-11-07 20:47:35 | INFO | train_inner | epoch 001:  23768 / 91072 loss=0.700195, wps=393.1, ups=1.63, wpb=241.7, bsz=16, num_updates=23700, lr=5.26667e-05, gnorm=11.642, clip=68, loss_scale=256, train_wall=31, gb_free=18, wall=14602
2025-11-07 20:48:05 | INFO | train_inner | epoch 001:  23818 / 91072 loss=0.712402, wps=395.4, ups=1.65, wpb=239.5, bsz=16, num_updates=23750, lr=5.27778e-05, gnorm=14.121, clip=82, loss_scale=512, train_wall=30, gb_free=16.3, wall=14633
2025-11-07 20:48:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:48:37 | INFO | train_inner | epoch 001:  23869 / 91072 loss=0.683594, wps=396.1, ups=1.54, wpb=257, bsz=16, num_updates=23800, lr=5.28889e-05, gnorm=14.211, clip=86, loss_scale=256, train_wall=32, gb_free=18, wall=14665
2025-11-07 20:49:08 | INFO | train_inner | epoch 001:  23919 / 91072 loss=0.690918, wps=391.7, ups=1.62, wpb=241.3, bsz=16, num_updates=23850, lr=5.3e-05, gnorm=9.872, clip=76, loss_scale=256, train_wall=31, gb_free=13.8, wall=14696
2025-11-07 20:49:40 | INFO | train_inner | epoch 001:  23969 / 91072 loss=0.710938, wps=407.5, ups=1.59, wpb=256.2, bsz=16, num_updates=23900, lr=5.31111e-05, gnorm=13.104, clip=68, loss_scale=256, train_wall=31, gb_free=17.9, wall=14727
2025-11-07 20:50:10 | INFO | train_inner | epoch 001:  24019 / 91072 loss=0.696777, wps=391.1, ups=1.66, wpb=236.3, bsz=16, num_updates=23950, lr=5.32222e-05, gnorm=12.767, clip=66, loss_scale=256, train_wall=30, gb_free=16.5, wall=14758
2025-11-07 20:50:40 | INFO | train_inner | epoch 001:  24069 / 91072 loss=0.67041, wps=395.9, ups=1.65, wpb=240.7, bsz=16, num_updates=24000, lr=5.33333e-05, gnorm=11.865, clip=72, loss_scale=256, train_wall=30, gb_free=17.9, wall=14788
2025-11-07 20:51:11 | INFO | train_inner | epoch 001:  24119 / 91072 loss=0.69043, wps=407.8, ups=1.62, wpb=251.5, bsz=16, num_updates=24050, lr=5.34444e-05, gnorm=11.629, clip=78, loss_scale=512, train_wall=31, gb_free=13.4, wall=14819
2025-11-07 20:51:42 | INFO | train_inner | epoch 001:  24169 / 91072 loss=0.620605, wps=399.7, ups=1.61, wpb=247.9, bsz=16, num_updates=24100, lr=5.35556e-05, gnorm=11.139, clip=76, loss_scale=512, train_wall=31, gb_free=17.7, wall=14850
2025-11-07 20:52:12 | INFO | train_inner | epoch 001:  24219 / 91072 loss=0.649414, wps=387.1, ups=1.66, wpb=233.1, bsz=16, num_updates=24150, lr=5.36667e-05, gnorm=11.395, clip=74, loss_scale=512, train_wall=30, gb_free=15.6, wall=14880
2025-11-07 20:52:43 | INFO | train_inner | epoch 001:  24269 / 91072 loss=0.623047, wps=404, ups=1.64, wpb=246.6, bsz=16, num_updates=24200, lr=5.37778e-05, gnorm=9.794, clip=72, loss_scale=512, train_wall=30, gb_free=14.2, wall=14911
2025-11-07 20:53:13 | INFO | train_inner | epoch 001:  24319 / 91072 loss=0.61084, wps=400.3, ups=1.65, wpb=243.1, bsz=16, num_updates=24250, lr=5.38889e-05, gnorm=9.599, clip=66, loss_scale=512, train_wall=30, gb_free=10.2, wall=14941
2025-11-07 20:53:45 | INFO | train_inner | epoch 001:  24369 / 91072 loss=0.705078, wps=413.1, ups=1.57, wpb=263.6, bsz=16, num_updates=24300, lr=5.4e-05, gnorm=12.659, clip=88, loss_scale=512, train_wall=32, gb_free=18.6, wall=14973
2025-11-07 20:53:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 20:54:16 | INFO | train_inner | epoch 001:  24420 / 91072 loss=0.68457, wps=394.5, ups=1.61, wpb=244.7, bsz=16, num_updates=24350, lr=5.41111e-05, gnorm=12.891, clip=84, loss_scale=512, train_wall=31, gb_free=16.5, wall=15004
2025-11-07 20:54:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:54:48 | INFO | train_inner | epoch 001:  24471 / 91072 loss=0.685059, wps=398.5, ups=1.58, wpb=252.9, bsz=16, num_updates=24400, lr=5.42222e-05, gnorm=12.805, clip=72, loss_scale=256, train_wall=32, gb_free=18.2, wall=15036
2025-11-07 20:55:18 | INFO | train_inner | epoch 001:  24521 / 91072 loss=0.634277, wps=384.9, ups=1.65, wpb=233.7, bsz=16, num_updates=24450, lr=5.43333e-05, gnorm=12.997, clip=74, loss_scale=256, train_wall=30, gb_free=17.5, wall=15066
2025-11-07 20:55:48 | INFO | train_inner | epoch 001:  24571 / 91072 loss=0.686523, wps=400.9, ups=1.66, wpb=241.3, bsz=16, num_updates=24500, lr=5.44444e-05, gnorm=11.166, clip=74, loss_scale=256, train_wall=30, gb_free=16.6, wall=15096
2025-11-07 20:56:18 | INFO | train_inner | epoch 001:  24621 / 91072 loss=0.690918, wps=389.8, ups=1.68, wpb=232.5, bsz=16, num_updates=24550, lr=5.45556e-05, gnorm=11.034, clip=72, loss_scale=256, train_wall=30, gb_free=16.9, wall=15126
2025-11-07 20:56:49 | INFO | train_inner | epoch 001:  24671 / 91072 loss=0.649902, wps=406.5, ups=1.62, wpb=251.2, bsz=16, num_updates=24600, lr=5.46667e-05, gnorm=10.289, clip=56, loss_scale=256, train_wall=31, gb_free=17.5, wall=15157
2025-11-07 20:57:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 20:57:20 | INFO | train_inner | epoch 001:  24722 / 91072 loss=0.621094, wps=378.9, ups=1.59, wpb=237.6, bsz=16, num_updates=24650, lr=5.47778e-05, gnorm=11.649, clip=82, loss_scale=256, train_wall=31, gb_free=16.1, wall=15188
2025-11-07 20:57:51 | INFO | train_inner | epoch 001:  24772 / 91072 loss=0.638672, wps=404.3, ups=1.65, wpb=245.6, bsz=16, num_updates=24700, lr=5.48889e-05, gnorm=12.49, clip=74, loss_scale=256, train_wall=30, gb_free=14.5, wall=15218
2025-11-07 20:58:21 | INFO | train_inner | epoch 001:  24822 / 91072 loss=0.678711, wps=392.8, ups=1.66, wpb=237, bsz=16, num_updates=24750, lr=5.5e-05, gnorm=10.939, clip=72, loss_scale=256, train_wall=30, gb_free=17.4, wall=15249
2025-11-07 20:58:52 | INFO | train_inner | epoch 001:  24872 / 91072 loss=0.624512, wps=407.5, ups=1.62, wpb=251.7, bsz=16, num_updates=24800, lr=5.51111e-05, gnorm=10.59, clip=72, loss_scale=256, train_wall=31, gb_free=18.7, wall=15280
2025-11-07 20:59:22 | INFO | train_inner | epoch 001:  24922 / 91072 loss=0.697754, wps=388, ups=1.66, wpb=234.4, bsz=16, num_updates=24850, lr=5.52222e-05, gnorm=11.862, clip=74, loss_scale=256, train_wall=30, gb_free=17.1, wall=15310
2025-11-07 20:59:52 | INFO | train_inner | epoch 001:  24972 / 91072 loss=0.645508, wps=399.9, ups=1.65, wpb=242, bsz=16, num_updates=24900, lr=5.53333e-05, gnorm=13.297, clip=82, loss_scale=512, train_wall=30, gb_free=16.1, wall=15340
2025-11-07 21:00:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:00:24 | INFO | train_inner | epoch 001:  25023 / 91072 loss=0.63916, wps=398.6, ups=1.58, wpb=252.3, bsz=16, num_updates=24950, lr=5.54444e-05, gnorm=11.612, clip=80, loss_scale=256, train_wall=31, gb_free=17, wall=15372
2025-11-07 21:00:55 | INFO | train_inner | epoch 001:  25073 / 91072 loss=0.72168, wps=412.9, ups=1.6, wpb=257.3, bsz=16, num_updates=25000, lr=5.55556e-05, gnorm=13.647, clip=78, loss_scale=256, train_wall=31, gb_free=17, wall=15403
2025-11-07 21:01:26 | INFO | train_inner | epoch 001:  25123 / 91072 loss=0.693848, wps=400.8, ups=1.62, wpb=247.8, bsz=16, num_updates=25050, lr=5.56667e-05, gnorm=13.485, clip=76, loss_scale=256, train_wall=31, gb_free=18, wall=15434
2025-11-07 21:01:56 | INFO | train_inner | epoch 001:  25173 / 91072 loss=0.711426, wps=399.9, ups=1.64, wpb=243.5, bsz=16, num_updates=25100, lr=5.57778e-05, gnorm=16.329, clip=86, loss_scale=256, train_wall=30, gb_free=19.3, wall=15464
2025-11-07 21:02:27 | INFO | train_inner | epoch 001:  25223 / 91072 loss=0.614746, wps=410.6, ups=1.64, wpb=250.1, bsz=16, num_updates=25150, lr=5.58889e-05, gnorm=11.011, clip=72, loss_scale=256, train_wall=30, gb_free=17.7, wall=15495
2025-11-07 21:02:57 | INFO | train_inner | epoch 001:  25273 / 91072 loss=0.632324, wps=396.1, ups=1.66, wpb=238.6, bsz=16, num_updates=25200, lr=5.6e-05, gnorm=11.383, clip=74, loss_scale=512, train_wall=30, gb_free=17.5, wall=15525
2025-11-07 21:03:28 | INFO | train_inner | epoch 001:  25323 / 91072 loss=0.67041, wps=397.9, ups=1.6, wpb=248, bsz=16, num_updates=25250, lr=5.61111e-05, gnorm=9.482, clip=66, loss_scale=512, train_wall=31, gb_free=18, wall=15556
2025-11-07 21:03:59 | INFO | train_inner | epoch 001:  25373 / 91072 loss=0.628418, wps=405.6, ups=1.64, wpb=247.8, bsz=16, num_updates=25300, lr=5.62222e-05, gnorm=12.285, clip=86, loss_scale=512, train_wall=30, gb_free=18.7, wall=15586
2025-11-07 21:04:29 | INFO | train_inner | epoch 001:  25423 / 91072 loss=0.590332, wps=394.7, ups=1.65, wpb=239.9, bsz=16, num_updates=25350, lr=5.63333e-05, gnorm=9.538, clip=68, loss_scale=512, train_wall=30, gb_free=10.8, wall=15617
2025-11-07 21:05:00 | INFO | train_inner | epoch 001:  25473 / 91072 loss=0.649414, wps=408.3, ups=1.6, wpb=254.9, bsz=16, num_updates=25400, lr=5.64444e-05, gnorm=11.651, clip=72, loss_scale=512, train_wall=31, gb_free=12, wall=15648
2025-11-07 21:05:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:05:31 | INFO | train_inner | epoch 001:  25524 / 91072 loss=0.628418, wps=397.6, ups=1.62, wpb=245.5, bsz=16, num_updates=25450, lr=5.65556e-05, gnorm=11.55, clip=66, loss_scale=256, train_wall=31, gb_free=15.6, wall=15679
2025-11-07 21:06:02 | INFO | train_inner | epoch 001:  25574 / 91072 loss=0.708496, wps=404.1, ups=1.64, wpb=246.8, bsz=16, num_updates=25500, lr=5.66667e-05, gnorm=14.104, clip=82, loss_scale=256, train_wall=30, gb_free=12.9, wall=15709
2025-11-07 21:06:32 | INFO | train_inner | epoch 001:  25624 / 91072 loss=0.674805, wps=404.2, ups=1.64, wpb=246.5, bsz=16, num_updates=25550, lr=5.67778e-05, gnorm=12.186, clip=70, loss_scale=256, train_wall=30, gb_free=17.4, wall=15740
2025-11-07 21:07:03 | INFO | train_inner | epoch 001:  25674 / 91072 loss=0.705566, wps=391.2, ups=1.64, wpb=238.6, bsz=16, num_updates=25600, lr=5.68889e-05, gnorm=13.03, clip=74, loss_scale=256, train_wall=30, gb_free=19.1, wall=15770
2025-11-07 21:07:33 | INFO | train_inner | epoch 001:  25724 / 91072 loss=0.69873, wps=414.8, ups=1.62, wpb=256.3, bsz=16, num_updates=25650, lr=5.7e-05, gnorm=11.952, clip=70, loss_scale=256, train_wall=31, gb_free=16.2, wall=15801
2025-11-07 21:08:04 | INFO | train_inner | epoch 001:  25774 / 91072 loss=0.694824, wps=404.7, ups=1.64, wpb=246, bsz=16, num_updates=25700, lr=5.71111e-05, gnorm=14.082, clip=78, loss_scale=512, train_wall=30, gb_free=15, wall=15832
2025-11-07 21:08:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:08:35 | INFO | train_inner | epoch 001:  25825 / 91072 loss=0.661621, wps=386, ups=1.62, wpb=238.4, bsz=16, num_updates=25750, lr=5.72222e-05, gnorm=11.911, clip=72, loss_scale=256, train_wall=31, gb_free=15.1, wall=15863
2025-11-07 21:09:05 | INFO | train_inner | epoch 001:  25875 / 91072 loss=0.664551, wps=392.7, ups=1.65, wpb=238.3, bsz=16, num_updates=25800, lr=5.73333e-05, gnorm=12.841, clip=82, loss_scale=256, train_wall=30, gb_free=18.3, wall=15893
2025-11-07 21:09:36 | INFO | train_inner | epoch 001:  25925 / 91072 loss=0.674316, wps=413, ups=1.6, wpb=258.6, bsz=16, num_updates=25850, lr=5.74444e-05, gnorm=11.573, clip=70, loss_scale=256, train_wall=31, gb_free=18.2, wall=15924
2025-11-07 21:10:07 | INFO | train_inner | epoch 001:  25975 / 91072 loss=0.638184, wps=402.9, ups=1.66, wpb=243.4, bsz=16, num_updates=25900, lr=5.75556e-05, gnorm=11.048, clip=72, loss_scale=256, train_wall=30, gb_free=16.1, wall=15954
2025-11-07 21:10:37 | INFO | train_inner | epoch 001:  26025 / 91072 loss=0.663574, wps=391.8, ups=1.65, wpb=237.7, bsz=15.7, num_updates=25950, lr=5.76667e-05, gnorm=10.085, clip=66, loss_scale=256, train_wall=30, gb_free=15.8, wall=15985
2025-11-07 21:11:07 | INFO | train_inner | epoch 001:  26075 / 91072 loss=0.599121, wps=379.7, ups=1.65, wpb=230.2, bsz=16, num_updates=26000, lr=5.77778e-05, gnorm=10.869, clip=74, loss_scale=512, train_wall=30, gb_free=17.1, wall=16015
2025-11-07 21:11:38 | INFO | train_inner | epoch 001:  26125 / 91072 loss=0.62793, wps=388.5, ups=1.6, wpb=242.7, bsz=16, num_updates=26050, lr=5.78889e-05, gnorm=10.2, clip=74, loss_scale=512, train_wall=31, gb_free=17.5, wall=16046
2025-11-07 21:11:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:12:09 | INFO | train_inner | epoch 001:  26176 / 91072 loss=0.625488, wps=376.6, ups=1.64, wpb=229.4, bsz=16, num_updates=26100, lr=5.8e-05, gnorm=10.679, clip=72, loss_scale=256, train_wall=30, gb_free=18.3, wall=16077
2025-11-07 21:12:39 | INFO | train_inner | epoch 001:  26226 / 91072 loss=0.696777, wps=403.2, ups=1.65, wpb=245, bsz=16, num_updates=26150, lr=5.81111e-05, gnorm=11.594, clip=68, loss_scale=256, train_wall=30, gb_free=10.4, wall=16107
2025-11-07 21:13:10 | INFO | train_inner | epoch 001:  26276 / 91072 loss=0.704102, wps=394.9, ups=1.64, wpb=240.9, bsz=16, num_updates=26200, lr=5.82222e-05, gnorm=13.89, clip=76, loss_scale=256, train_wall=30, gb_free=18.4, wall=16138
2025-11-07 21:13:40 | INFO | train_inner | epoch 001:  26326 / 91072 loss=0.661621, wps=398.4, ups=1.67, wpb=239.2, bsz=16, num_updates=26250, lr=5.83333e-05, gnorm=10.533, clip=66, loss_scale=256, train_wall=30, gb_free=17.2, wall=16168
2025-11-07 21:14:10 | INFO | train_inner | epoch 001:  26376 / 91072 loss=0.637207, wps=408.1, ups=1.64, wpb=248.1, bsz=16, num_updates=26300, lr=5.84444e-05, gnorm=12.546, clip=84, loss_scale=256, train_wall=30, gb_free=16.3, wall=16198
2025-11-07 21:14:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:14:41 | INFO | train_inner | epoch 001:  26427 / 91072 loss=0.632812, wps=387.5, ups=1.6, wpb=241.8, bsz=16, num_updates=26350, lr=5.85556e-05, gnorm=10.694, clip=74, loss_scale=256, train_wall=31, gb_free=17.3, wall=16229
2025-11-07 21:15:13 | INFO | train_inner | epoch 001:  26477 / 91072 loss=0.631348, wps=379.3, ups=1.57, wpb=242, bsz=16, num_updates=26400, lr=5.86667e-05, gnorm=12.199, clip=66, loss_scale=256, train_wall=32, gb_free=18, wall=16261
2025-11-07 21:15:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-07 21:15:44 | INFO | train_inner | epoch 001:  26528 / 91072 loss=0.62207, wps=389.8, ups=1.63, wpb=239.3, bsz=16, num_updates=26450, lr=5.87778e-05, gnorm=9.855, clip=74, loss_scale=128, train_wall=31, gb_free=17.2, wall=16292
2025-11-07 21:16:19 | INFO | train_inner | epoch 001:  26578 / 91072 loss=0.615723, wps=357.9, ups=1.44, wpb=248.6, bsz=16, num_updates=26500, lr=5.88889e-05, gnorm=13.305, clip=76, loss_scale=128, train_wall=35, gb_free=16.3, wall=16327
2025-11-07 21:16:57 | INFO | train_inner | epoch 001:  26628 / 91072 loss=0.617676, wps=302.5, ups=1.29, wpb=234.3, bsz=16, num_updates=26550, lr=5.9e-05, gnorm=10.569, clip=66, loss_scale=128, train_wall=38, gb_free=17.3, wall=16365
2025-11-07 21:17:28 | INFO | train_inner | epoch 001:  26678 / 91072 loss=0.568359, wps=402, ups=1.64, wpb=245.7, bsz=16, num_updates=26600, lr=5.91111e-05, gnorm=10.762, clip=70, loss_scale=128, train_wall=30, gb_free=16.3, wall=16396
2025-11-07 21:18:05 | INFO | train_inner | epoch 001:  26728 / 91072 loss=0.709961, wps=333.9, ups=1.35, wpb=247, bsz=16, num_updates=26650, lr=5.92222e-05, gnorm=12.156, clip=86, loss_scale=128, train_wall=37, gb_free=17.3, wall=16433
2025-11-07 21:18:36 | INFO | train_inner | epoch 001:  26778 / 91072 loss=0.647949, wps=399.1, ups=1.63, wpb=245.5, bsz=16, num_updates=26700, lr=5.93333e-05, gnorm=10.733, clip=64, loss_scale=256, train_wall=31, gb_free=15.3, wall=16464
2025-11-07 21:19:12 | INFO | train_inner | epoch 001:  26828 / 91072 loss=0.708496, wps=334.3, ups=1.38, wpb=242.3, bsz=16, num_updates=26750, lr=5.94444e-05, gnorm=12.412, clip=64, loss_scale=256, train_wall=36, gb_free=17.2, wall=16500
2025-11-07 21:19:44 | INFO | train_inner | epoch 001:  26878 / 91072 loss=0.661621, wps=376.4, ups=1.58, wpb=237.5, bsz=16, num_updates=26800, lr=5.95556e-05, gnorm=11.86, clip=84, loss_scale=256, train_wall=31, gb_free=15.7, wall=16532
2025-11-07 21:20:20 | INFO | train_inner | epoch 001:  26928 / 91072 loss=0.728027, wps=323, ups=1.37, wpb=235.4, bsz=16, num_updates=26850, lr=5.96667e-05, gnorm=12.001, clip=78, loss_scale=256, train_wall=36, gb_free=18, wall=16568
2025-11-07 21:20:51 | INFO | train_inner | epoch 001:  26978 / 91072 loss=0.705566, wps=390.2, ups=1.63, wpb=239.9, bsz=16, num_updates=26900, lr=5.97778e-05, gnorm=11.473, clip=70, loss_scale=256, train_wall=31, gb_free=18, wall=16599
2025-11-07 21:21:29 | INFO | train_inner | epoch 001:  27028 / 91072 loss=0.662109, wps=321.2, ups=1.32, wpb=243.1, bsz=16, num_updates=26950, lr=5.98889e-05, gnorm=10.713, clip=76, loss_scale=512, train_wall=38, gb_free=16.7, wall=16637
2025-11-07 21:21:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:22:09 | INFO | train_inner | epoch 001:  27079 / 91072 loss=0.716309, wps=297.7, ups=1.23, wpb=242.7, bsz=16, num_updates=27000, lr=6e-05, gnorm=11.455, clip=72, loss_scale=256, train_wall=40, gb_free=14.9, wall=16677
2025-11-07 21:22:44 | INFO | train_inner | epoch 001:  27129 / 91072 loss=0.615723, wps=355.3, ups=1.44, wpb=247, bsz=16, num_updates=27050, lr=6.01111e-05, gnorm=11.426, clip=74, loss_scale=256, train_wall=34, gb_free=17, wall=16712
2025-11-07 21:23:25 | INFO | train_inner | epoch 001:  27179 / 91072 loss=0.682617, wps=293.6, ups=1.23, wpb=239.1, bsz=16, num_updates=27100, lr=6.02222e-05, gnorm=13.705, clip=70, loss_scale=256, train_wall=40, gb_free=17.5, wall=16753
2025-11-07 21:24:02 | INFO | train_inner | epoch 001:  27229 / 91072 loss=0.685059, wps=333.1, ups=1.34, wpb=249.4, bsz=16, num_updates=27150, lr=6.03333e-05, gnorm=11.134, clip=74, loss_scale=256, train_wall=37, gb_free=18.2, wall=16790
2025-11-07 21:24:33 | INFO | train_inner | epoch 001:  27279 / 91072 loss=0.644043, wps=399.1, ups=1.66, wpb=241, bsz=16, num_updates=27200, lr=6.04444e-05, gnorm=9.26, clip=68, loss_scale=256, train_wall=30, gb_free=13, wall=16820
2025-11-07 21:25:05 | INFO | train_inner | epoch 001:  27329 / 91072 loss=0.699707, wps=376.2, ups=1.52, wpb=247.3, bsz=16, num_updates=27250, lr=6.05556e-05, gnorm=11.143, clip=72, loss_scale=512, train_wall=33, gb_free=16.7, wall=16853
2025-11-07 21:25:42 | INFO | train_inner | epoch 001:  27379 / 91072 loss=0.643555, wps=332.9, ups=1.36, wpb=244.6, bsz=16, num_updates=27300, lr=6.06667e-05, gnorm=11.453, clip=68, loss_scale=512, train_wall=36, gb_free=16.9, wall=16890
2025-11-07 21:26:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:26:14 | INFO | train_inner | epoch 001:  27430 / 91072 loss=0.67041, wps=402.2, ups=1.55, wpb=259, bsz=16, num_updates=27350, lr=6.07778e-05, gnorm=11.685, clip=82, loss_scale=256, train_wall=32, gb_free=11, wall=16922
2025-11-07 21:26:45 | INFO | train_inner | epoch 001:  27480 / 91072 loss=0.67627, wps=397.1, ups=1.66, wpb=239.6, bsz=16, num_updates=27400, lr=6.08889e-05, gnorm=12.507, clip=82, loss_scale=256, train_wall=30, gb_free=17.9, wall=16952
2025-11-07 21:27:18 | INFO | train_inner | epoch 001:  27530 / 91072 loss=0.756348, wps=386.4, ups=1.49, wpb=259.7, bsz=16, num_updates=27450, lr=6.1e-05, gnorm=14.428, clip=76, loss_scale=256, train_wall=33, gb_free=17.3, wall=16986
2025-11-07 21:27:52 | INFO | train_inner | epoch 001:  27580 / 91072 loss=0.651855, wps=354.4, ups=1.48, wpb=239.4, bsz=16, num_updates=27500, lr=6.11111e-05, gnorm=10.349, clip=66, loss_scale=256, train_wall=34, gb_free=16.8, wall=17020
2025-11-07 21:28:29 | INFO | train_inner | epoch 001:  27630 / 91072 loss=0.603516, wps=344.2, ups=1.36, wpb=252.2, bsz=16, num_updates=27550, lr=6.12222e-05, gnorm=9.508, clip=72, loss_scale=256, train_wall=36, gb_free=14.2, wall=17057
2025-11-07 21:29:01 | INFO | train_inner | epoch 001:  27680 / 91072 loss=0.654785, wps=377.4, ups=1.56, wpb=242.4, bsz=16, num_updates=27600, lr=6.13333e-05, gnorm=12.867, clip=84, loss_scale=512, train_wall=32, gb_free=18.5, wall=17089
2025-11-07 21:29:35 | INFO | train_inner | epoch 001:  27730 / 91072 loss=0.677246, wps=378.5, ups=1.48, wpb=256.5, bsz=16, num_updates=27650, lr=6.14444e-05, gnorm=10.476, clip=74, loss_scale=512, train_wall=34, gb_free=15.7, wall=17123
2025-11-07 21:30:11 | INFO | train_inner | epoch 001:  27780 / 91072 loss=0.711914, wps=329.4, ups=1.36, wpb=241.7, bsz=16, num_updates=27700, lr=6.15556e-05, gnorm=13.226, clip=74, loss_scale=512, train_wall=36, gb_free=15.8, wall=17159
2025-11-07 21:30:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:30:46 | INFO | train_inner | epoch 001:  27831 / 91072 loss=0.679688, wps=356, ups=1.44, wpb=247.1, bsz=16, num_updates=27750, lr=6.16667e-05, gnorm=12.613, clip=88, loss_scale=256, train_wall=34, gb_free=14.9, wall=17194
2025-11-07 21:31:16 | INFO | train_inner | epoch 001:  27881 / 91072 loss=0.59375, wps=403, ups=1.67, wpb=242, bsz=16, num_updates=27800, lr=6.17778e-05, gnorm=9.981, clip=60, loss_scale=256, train_wall=30, gb_free=18.1, wall=17224
2025-11-07 21:31:47 | INFO | train_inner | epoch 001:  27931 / 91072 loss=0.715332, wps=403.2, ups=1.6, wpb=251.8, bsz=16, num_updates=27850, lr=6.18889e-05, gnorm=13.381, clip=80, loss_scale=256, train_wall=31, gb_free=13.9, wall=17255
2025-11-07 21:32:24 | INFO | train_inner | epoch 001:  27981 / 91072 loss=0.687012, wps=349.1, ups=1.35, wpb=258.2, bsz=16, num_updates=27900, lr=6.2e-05, gnorm=10.382, clip=70, loss_scale=256, train_wall=37, gb_free=14.9, wall=17292
2025-11-07 21:32:59 | INFO | train_inner | epoch 001:  28031 / 91072 loss=0.620605, wps=356.6, ups=1.45, wpb=246.2, bsz=16, num_updates=27950, lr=6.21111e-05, gnorm=10.141, clip=70, loss_scale=256, train_wall=34, gb_free=18.9, wall=17327
2025-11-07 21:33:35 | INFO | train_inner | epoch 001:  28081 / 91072 loss=0.669922, wps=321.1, ups=1.36, wpb=235.3, bsz=16, num_updates=28000, lr=6.22222e-05, gnorm=11.095, clip=76, loss_scale=512, train_wall=36, gb_free=18.5, wall=17363
2025-11-07 21:33:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:34:10 | INFO | train_inner | epoch 001:  28132 / 91072 loss=0.739746, wps=357.5, ups=1.45, wpb=247.1, bsz=16, num_updates=28050, lr=6.23333e-05, gnorm=12.831, clip=70, loss_scale=256, train_wall=34, gb_free=17.2, wall=17398
2025-11-07 21:34:45 | INFO | train_inner | epoch 001:  28182 / 91072 loss=0.646484, wps=345.3, ups=1.44, wpb=240.5, bsz=16, num_updates=28100, lr=6.24444e-05, gnorm=11.54, clip=72, loss_scale=256, train_wall=35, gb_free=11.4, wall=17433
2025-11-07 21:35:23 | INFO | train_inner | epoch 001:  28232 / 91072 loss=0.626953, wps=300.5, ups=1.31, wpb=228.9, bsz=16, num_updates=28150, lr=6.25556e-05, gnorm=11.927, clip=68, loss_scale=256, train_wall=38, gb_free=13.2, wall=17471
2025-11-07 21:35:57 | INFO | train_inner | epoch 001:  28282 / 91072 loss=0.760742, wps=342.9, ups=1.47, wpb=232.8, bsz=16, num_updates=28200, lr=6.26667e-05, gnorm=13.344, clip=74, loss_scale=256, train_wall=34, gb_free=18.3, wall=17505
2025-11-07 21:36:28 | INFO | train_inner | epoch 001:  28332 / 91072 loss=0.697266, wps=370.7, ups=1.6, wpb=232.2, bsz=16, num_updates=28250, lr=6.27778e-05, gnorm=12.447, clip=70, loss_scale=256, train_wall=31, gb_free=18.3, wall=17536
2025-11-07 21:37:03 | INFO | train_inner | epoch 001:  28382 / 91072 loss=0.702637, wps=345.3, ups=1.43, wpb=242, bsz=16, num_updates=28300, lr=6.28889e-05, gnorm=11.656, clip=78, loss_scale=512, train_wall=35, gb_free=15.4, wall=17571
2025-11-07 21:37:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:37:36 | INFO | train_inner | epoch 001:  28433 / 91072 loss=0.615723, wps=365.4, ups=1.51, wpb=241.7, bsz=16, num_updates=28350, lr=6.3e-05, gnorm=12.48, clip=80, loss_scale=256, train_wall=33, gb_free=17, wall=17604
2025-11-07 21:38:07 | INFO | train_inner | epoch 001:  28483 / 91072 loss=0.778809, wps=403.3, ups=1.64, wpb=246.2, bsz=16, num_updates=28400, lr=6.31111e-05, gnorm=15.489, clip=78, loss_scale=256, train_wall=30, gb_free=14.5, wall=17635
2025-11-07 21:38:38 | INFO | train_inner | epoch 001:  28533 / 91072 loss=0.621094, wps=397.8, ups=1.63, wpb=244.7, bsz=16, num_updates=28450, lr=6.32222e-05, gnorm=10.863, clip=72, loss_scale=256, train_wall=31, gb_free=17.9, wall=17665
2025-11-07 21:39:09 | INFO | train_inner | epoch 001:  28583 / 91072 loss=0.64502, wps=420.5, ups=1.59, wpb=264, bsz=16, num_updates=28500, lr=6.33333e-05, gnorm=10.644, clip=74, loss_scale=256, train_wall=31, gb_free=17.6, wall=17697
2025-11-07 21:39:39 | INFO | train_inner | epoch 001:  28633 / 91072 loss=0.674316, wps=401.2, ups=1.64, wpb=244.9, bsz=16, num_updates=28550, lr=6.34444e-05, gnorm=13.18, clip=80, loss_scale=256, train_wall=30, gb_free=17.4, wall=17727
2025-11-07 21:40:10 | INFO | train_inner | epoch 001:  28683 / 91072 loss=0.650879, wps=410.6, ups=1.64, wpb=250.3, bsz=16, num_updates=28600, lr=6.35556e-05, gnorm=11.102, clip=72, loss_scale=512, train_wall=30, gb_free=17.7, wall=17758
2025-11-07 21:40:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:40:41 | INFO | train_inner | epoch 001:  28734 / 91072 loss=0.69873, wps=389.2, ups=1.59, wpb=244.2, bsz=16, num_updates=28650, lr=6.36667e-05, gnorm=13.296, clip=88, loss_scale=256, train_wall=31, gb_free=16.1, wall=17789
2025-11-07 21:41:12 | INFO | train_inner | epoch 001:  28784 / 91072 loss=0.699707, wps=404.6, ups=1.64, wpb=247.2, bsz=16, num_updates=28700, lr=6.37778e-05, gnorm=13.927, clip=74, loss_scale=256, train_wall=30, gb_free=18.3, wall=17820
2025-11-07 21:41:42 | INFO | train_inner | epoch 001:  28834 / 91072 loss=0.668457, wps=407.4, ups=1.65, wpb=247.4, bsz=16, num_updates=28750, lr=6.38889e-05, gnorm=12.486, clip=76, loss_scale=256, train_wall=30, gb_free=18, wall=17850
2025-11-07 21:42:12 | INFO | train_inner | epoch 001:  28884 / 91072 loss=0.708984, wps=396.6, ups=1.67, wpb=237.9, bsz=16, num_updates=28800, lr=6.4e-05, gnorm=12.824, clip=74, loss_scale=256, train_wall=30, gb_free=18.1, wall=17880
2025-11-07 21:42:44 | INFO | train_inner | epoch 001:  28934 / 91072 loss=0.638184, wps=380.2, ups=1.55, wpb=244.6, bsz=16, num_updates=28850, lr=6.41111e-05, gnorm=9.808, clip=64, loss_scale=256, train_wall=32, gb_free=17.2, wall=17912
2025-11-07 21:43:18 | INFO | train_inner | epoch 001:  28984 / 91072 loss=0.682129, wps=367.2, ups=1.51, wpb=243.8, bsz=16, num_updates=28900, lr=6.42222e-05, gnorm=10.307, clip=74, loss_scale=512, train_wall=33, gb_free=16.9, wall=17945
2025-11-07 21:43:48 | INFO | train_inner | epoch 001:  29034 / 91072 loss=0.673828, wps=390.3, ups=1.65, wpb=237.3, bsz=16, num_updates=28950, lr=6.43333e-05, gnorm=9.622, clip=70, loss_scale=512, train_wall=30, gb_free=18.2, wall=17976
2025-11-07 21:44:19 | INFO | train_inner | epoch 001:  29084 / 91072 loss=0.63916, wps=363.2, ups=1.6, wpb=227.6, bsz=16, num_updates=29000, lr=6.44444e-05, gnorm=10.09, clip=66, loss_scale=512, train_wall=31, gb_free=17.2, wall=18007
2025-11-07 21:44:50 | INFO | train_inner | epoch 001:  29134 / 91072 loss=0.639648, wps=387, ups=1.64, wpb=236.2, bsz=16, num_updates=29050, lr=6.45556e-05, gnorm=10.232, clip=62, loss_scale=512, train_wall=30, gb_free=15.9, wall=18038
2025-11-07 21:45:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:45:21 | INFO | train_inner | epoch 001:  29185 / 91072 loss=0.631836, wps=378.4, ups=1.63, wpb=232.2, bsz=16, num_updates=29100, lr=6.46667e-05, gnorm=11.43, clip=72, loss_scale=256, train_wall=31, gb_free=18, wall=18068
2025-11-07 21:45:52 | INFO | train_inner | epoch 001:  29235 / 91072 loss=0.675293, wps=410.6, ups=1.61, wpb=254.6, bsz=16, num_updates=29150, lr=6.47778e-05, gnorm=12.149, clip=72, loss_scale=256, train_wall=31, gb_free=12.2, wall=18099
2025-11-07 21:46:22 | INFO | train_inner | epoch 001:  29285 / 91072 loss=0.708984, wps=391.4, ups=1.64, wpb=238.7, bsz=16, num_updates=29200, lr=6.48889e-05, gnorm=11.529, clip=72, loss_scale=256, train_wall=30, gb_free=13, wall=18130
2025-11-07 21:47:02 | INFO | train_inner | epoch 001:  29335 / 91072 loss=0.649902, wps=311, ups=1.24, wpb=251.6, bsz=16, num_updates=29250, lr=6.5e-05, gnorm=10.456, clip=70, loss_scale=256, train_wall=40, gb_free=17.9, wall=18170
2025-11-07 21:47:35 | INFO | train_inner | epoch 001:  29385 / 91072 loss=0.61377, wps=388.8, ups=1.55, wpb=250.3, bsz=16, num_updates=29300, lr=6.51111e-05, gnorm=9.915, clip=72, loss_scale=256, train_wall=32, gb_free=18.6, wall=18203
2025-11-07 21:47:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:48:08 | INFO | train_inner | epoch 001:  29436 / 91072 loss=0.635742, wps=347.8, ups=1.49, wpb=233.4, bsz=16, num_updates=29350, lr=6.52222e-05, gnorm=11.478, clip=76, loss_scale=256, train_wall=33, gb_free=17.2, wall=18236
2025-11-07 21:48:45 | INFO | train_inner | epoch 001:  29486 / 91072 loss=0.682129, wps=345.7, ups=1.37, wpb=252.2, bsz=16, num_updates=29400, lr=6.53333e-05, gnorm=11.094, clip=62, loss_scale=256, train_wall=36, gb_free=17, wall=18273
2025-11-07 21:49:19 | INFO | train_inner | epoch 001:  29536 / 91072 loss=0.64502, wps=365.6, ups=1.45, wpb=251.4, bsz=16, num_updates=29450, lr=6.54444e-05, gnorm=11.013, clip=76, loss_scale=256, train_wall=34, gb_free=18.6, wall=18307
2025-11-07 21:49:49 | INFO | train_inner | epoch 001:  29586 / 91072 loss=0.666016, wps=398, ups=1.67, wpb=238.4, bsz=16, num_updates=29500, lr=6.55556e-05, gnorm=11.547, clip=78, loss_scale=256, train_wall=30, gb_free=16.6, wall=18337
2025-11-07 21:50:21 | INFO | train_inner | epoch 001:  29636 / 91072 loss=0.656738, wps=373.4, ups=1.55, wpb=240.2, bsz=16, num_updates=29550, lr=6.56667e-05, gnorm=9.718, clip=70, loss_scale=256, train_wall=32, gb_free=18.1, wall=18369
2025-11-07 21:50:54 | INFO | train_inner | epoch 001:  29686 / 91072 loss=0.677734, wps=357.1, ups=1.53, wpb=233.5, bsz=16, num_updates=29600, lr=6.57778e-05, gnorm=11.688, clip=76, loss_scale=512, train_wall=32, gb_free=17.4, wall=18402
2025-11-07 21:51:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:51:27 | INFO | train_inner | epoch 001:  29737 / 91072 loss=0.671387, wps=367.5, ups=1.49, wpb=246, bsz=16, num_updates=29650, lr=6.58889e-05, gnorm=11.941, clip=76, loss_scale=256, train_wall=33, gb_free=18.4, wall=18435
2025-11-07 21:51:59 | INFO | train_inner | epoch 001:  29787 / 91072 loss=0.658203, wps=399.5, ups=1.58, wpb=253.5, bsz=16, num_updates=29700, lr=6.6e-05, gnorm=12.083, clip=74, loss_scale=256, train_wall=32, gb_free=14.3, wall=18467
2025-11-07 21:52:37 | INFO | train_inner | epoch 001:  29837 / 91072 loss=0.685547, wps=324, ups=1.31, wpb=247, bsz=16, num_updates=29750, lr=6.61111e-05, gnorm=11.574, clip=78, loss_scale=256, train_wall=38, gb_free=15.5, wall=18505
2025-11-07 21:53:12 | INFO | train_inner | epoch 001:  29887 / 91072 loss=0.659668, wps=327.2, ups=1.42, wpb=230.4, bsz=16, num_updates=29800, lr=6.62222e-05, gnorm=10.037, clip=70, loss_scale=256, train_wall=35, gb_free=18.2, wall=18540
2025-11-07 21:53:45 | INFO | train_inner | epoch 001:  29937 / 91072 loss=0.685547, wps=379.9, ups=1.52, wpb=249.5, bsz=16, num_updates=29850, lr=6.63333e-05, gnorm=11.776, clip=74, loss_scale=256, train_wall=33, gb_free=14.3, wall=18573
2025-11-07 21:54:21 | INFO | train_inner | epoch 001:  29987 / 91072 loss=0.708008, wps=348.1, ups=1.42, wpb=245.8, bsz=16, num_updates=29900, lr=6.64444e-05, gnorm=10.125, clip=76, loss_scale=512, train_wall=35, gb_free=17.4, wall=18608
2025-11-07 21:54:51 | INFO | train_inner | epoch 001:  30037 / 91072 loss=0.611816, wps=401.8, ups=1.66, wpb=241.6, bsz=16, num_updates=29950, lr=6.65556e-05, gnorm=11.012, clip=76, loss_scale=512, train_wall=30, gb_free=10.9, wall=18639
2025-11-07 21:55:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:55:25 | INFO | train_inner | epoch 001:  30088 / 91072 loss=0.66748, wps=359.6, ups=1.47, wpb=245.4, bsz=16, num_updates=30000, lr=6.66667e-05, gnorm=11.733, clip=66, loss_scale=256, train_wall=34, gb_free=17.6, wall=18673
2025-11-07 21:55:57 | INFO | train_inner | epoch 001:  30138 / 91072 loss=0.588867, wps=373.4, ups=1.53, wpb=243.8, bsz=16, num_updates=30050, lr=6.67778e-05, gnorm=11.995, clip=82, loss_scale=256, train_wall=32, gb_free=17.2, wall=18705
2025-11-07 21:56:28 | INFO | train_inner | epoch 001:  30188 / 91072 loss=0.664551, wps=405.2, ups=1.66, wpb=244.4, bsz=16, num_updates=30100, lr=6.68889e-05, gnorm=11.075, clip=70, loss_scale=256, train_wall=30, gb_free=17.3, wall=18736
2025-11-07 21:56:59 | INFO | train_inner | epoch 001:  30238 / 91072 loss=0.69043, wps=411.4, ups=1.61, wpb=255.1, bsz=16, num_updates=30150, lr=6.7e-05, gnorm=12.875, clip=70, loss_scale=256, train_wall=31, gb_free=16, wall=18767
2025-11-07 21:57:30 | INFO | train_inner | epoch 001:  30288 / 91072 loss=0.663574, wps=414.2, ups=1.59, wpb=260.9, bsz=16, num_updates=30200, lr=6.71111e-05, gnorm=11.011, clip=80, loss_scale=256, train_wall=31, gb_free=17.3, wall=18798
2025-11-07 21:58:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 21:58:00 | INFO | train_inner | epoch 001:  30339 / 91072 loss=0.62207, wps=390.2, ups=1.65, wpb=236, bsz=16, num_updates=30250, lr=6.72222e-05, gnorm=10.44, clip=72, loss_scale=256, train_wall=30, gb_free=14.5, wall=18828
2025-11-07 21:58:32 | INFO | train_inner | epoch 001:  30389 / 91072 loss=0.674805, wps=381, ups=1.58, wpb=240.4, bsz=16, num_updates=30300, lr=6.73333e-05, gnorm=12.833, clip=86, loss_scale=256, train_wall=31, gb_free=17.5, wall=18860
2025-11-07 21:59:06 | INFO | train_inner | epoch 001:  30439 / 91072 loss=0.625, wps=348.8, ups=1.46, wpb=239.1, bsz=16, num_updates=30350, lr=6.74444e-05, gnorm=11.627, clip=74, loss_scale=256, train_wall=34, gb_free=17.8, wall=18894
2025-11-07 21:59:39 | INFO | train_inner | epoch 001:  30489 / 91072 loss=0.648438, wps=374, ups=1.51, wpb=247.7, bsz=16, num_updates=30400, lr=6.75556e-05, gnorm=11.346, clip=76, loss_scale=256, train_wall=33, gb_free=17.4, wall=18927
2025-11-07 22:00:10 | INFO | train_inner | epoch 001:  30539 / 91072 loss=0.694824, wps=415.6, ups=1.62, wpb=256.1, bsz=16, num_updates=30450, lr=6.76667e-05, gnorm=10.049, clip=70, loss_scale=256, train_wall=31, gb_free=16.1, wall=18958
2025-11-07 22:00:40 | INFO | train_inner | epoch 001:  30589 / 91072 loss=0.705078, wps=409.5, ups=1.67, wpb=245.6, bsz=16, num_updates=30500, lr=6.77778e-05, gnorm=11.502, clip=72, loss_scale=256, train_wall=30, gb_free=17.2, wall=18988
2025-11-07 22:01:12 | INFO | train_inner | epoch 001:  30639 / 91072 loss=0.684082, wps=380.8, ups=1.59, wpb=239.8, bsz=16, num_updates=30550, lr=6.78889e-05, gnorm=10.665, clip=76, loss_scale=512, train_wall=31, gb_free=17.9, wall=19020
2025-11-07 22:01:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:01:46 | INFO | train_inner | epoch 001:  30690 / 91072 loss=0.664551, wps=350.6, ups=1.45, wpb=241.5, bsz=16, num_updates=30600, lr=6.8e-05, gnorm=10.703, clip=72, loss_scale=256, train_wall=34, gb_free=17.2, wall=19054
2025-11-07 22:02:20 | INFO | train_inner | epoch 001:  30740 / 91072 loss=0.686523, wps=357.9, ups=1.45, wpb=246.1, bsz=16, num_updates=30650, lr=6.81111e-05, gnorm=10.978, clip=68, loss_scale=256, train_wall=34, gb_free=16.8, wall=19088
2025-11-07 22:02:52 | INFO | train_inner | epoch 001:  30790 / 91072 loss=0.699219, wps=369.3, ups=1.58, wpb=233.9, bsz=16, num_updates=30700, lr=6.82222e-05, gnorm=11.39, clip=66, loss_scale=256, train_wall=31, gb_free=11.7, wall=19120
2025-11-07 22:03:23 | INFO | train_inner | epoch 001:  30840 / 91072 loss=0.649414, wps=391.8, ups=1.6, wpb=245.4, bsz=16, num_updates=30750, lr=6.83333e-05, gnorm=10.075, clip=62, loss_scale=256, train_wall=31, gb_free=18.2, wall=19151
2025-11-07 22:03:58 | INFO | train_inner | epoch 001:  30890 / 91072 loss=0.611816, wps=370.3, ups=1.44, wpb=257.1, bsz=16, num_updates=30800, lr=6.84444e-05, gnorm=11.155, clip=68, loss_scale=256, train_wall=35, gb_free=10.9, wall=19186
2025-11-07 22:04:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:04:30 | INFO | train_inner | epoch 001:  30941 / 91072 loss=0.609863, wps=385.7, ups=1.55, wpb=249.1, bsz=16, num_updates=30850, lr=6.85556e-05, gnorm=9.244, clip=62, loss_scale=256, train_wall=32, gb_free=14.1, wall=19218
2025-11-07 22:05:05 | INFO | train_inner | epoch 001:  30991 / 91072 loss=0.726074, wps=356, ups=1.43, wpb=248.2, bsz=16, num_updates=30900, lr=6.86667e-05, gnorm=12.145, clip=84, loss_scale=256, train_wall=35, gb_free=18.9, wall=19253
2025-11-07 22:05:40 | INFO | train_inner | epoch 001:  31041 / 91072 loss=0.646484, wps=344.2, ups=1.42, wpb=242, bsz=16, num_updates=30950, lr=6.87778e-05, gnorm=10.258, clip=62, loss_scale=256, train_wall=35, gb_free=16.7, wall=19288
2025-11-07 22:06:12 | INFO | train_inner | epoch 001:  31091 / 91072 loss=0.670898, wps=415.4, ups=1.61, wpb=258, bsz=16, num_updates=31000, lr=6.88889e-05, gnorm=11.793, clip=74, loss_scale=256, train_wall=31, gb_free=17.9, wall=19319
2025-11-07 22:06:42 | INFO | train_inner | epoch 001:  31141 / 91072 loss=0.621094, wps=406.7, ups=1.66, wpb=245.2, bsz=16, num_updates=31050, lr=6.9e-05, gnorm=11.072, clip=70, loss_scale=256, train_wall=30, gb_free=17.4, wall=19350
2025-11-07 22:07:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:07:12 | INFO | train_inner | epoch 001:  31192 / 91072 loss=0.65332, wps=384.2, ups=1.67, wpb=230.4, bsz=16, num_updates=31100, lr=6.91111e-05, gnorm=10.394, clip=72, loss_scale=256, train_wall=30, gb_free=18.1, wall=19380
2025-11-07 22:07:43 | INFO | train_inner | epoch 001:  31242 / 91072 loss=0.729492, wps=412.9, ups=1.58, wpb=261.4, bsz=16, num_updates=31150, lr=6.92222e-05, gnorm=12.932, clip=78, loss_scale=256, train_wall=31, gb_free=18.3, wall=19411
2025-11-07 22:08:13 | INFO | train_inner | epoch 001:  31292 / 91072 loss=0.6875, wps=397.8, ups=1.66, wpb=240, bsz=16, num_updates=31200, lr=6.93333e-05, gnorm=9.682, clip=76, loss_scale=256, train_wall=30, gb_free=15.1, wall=19441
2025-11-07 22:08:43 | INFO | train_inner | epoch 001:  31342 / 91072 loss=0.657715, wps=392.1, ups=1.67, wpb=235.5, bsz=16, num_updates=31250, lr=6.94444e-05, gnorm=11.559, clip=74, loss_scale=256, train_wall=30, gb_free=18.1, wall=19471
2025-11-07 22:09:14 | INFO | train_inner | epoch 001:  31392 / 91072 loss=0.614258, wps=407.8, ups=1.63, wpb=250.8, bsz=16, num_updates=31300, lr=6.95556e-05, gnorm=10.901, clip=74, loss_scale=256, train_wall=31, gb_free=12.3, wall=19502
2025-11-07 22:09:50 | INFO | train_inner | epoch 001:  31442 / 91072 loss=0.693848, wps=347, ups=1.41, wpb=245.6, bsz=16, num_updates=31350, lr=6.96667e-05, gnorm=11.865, clip=76, loss_scale=512, train_wall=35, gb_free=17.1, wall=19538
2025-11-07 22:10:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:10:23 | INFO | train_inner | epoch 001:  31493 / 91072 loss=0.614746, wps=349.8, ups=1.49, wpb=234.9, bsz=16, num_updates=31400, lr=6.97778e-05, gnorm=10.508, clip=66, loss_scale=256, train_wall=33, gb_free=17.5, wall=19571
2025-11-07 22:10:54 | INFO | train_inner | epoch 001:  31543 / 91072 loss=0.678711, wps=412.6, ups=1.61, wpb=256.1, bsz=16, num_updates=31450, lr=6.98889e-05, gnorm=11.492, clip=76, loss_scale=256, train_wall=31, gb_free=17.8, wall=19602
2025-11-07 22:11:27 | INFO | train_inner | epoch 001:  31593 / 91072 loss=0.677734, wps=357.7, ups=1.51, wpb=236.1, bsz=16, num_updates=31500, lr=7e-05, gnorm=14.156, clip=82, loss_scale=256, train_wall=33, gb_free=18.1, wall=19635
2025-11-07 22:11:59 | INFO | train_inner | epoch 001:  31643 / 91072 loss=0.704102, wps=407.8, ups=1.58, wpb=257.8, bsz=16, num_updates=31550, lr=7.01111e-05, gnorm=11.946, clip=72, loss_scale=256, train_wall=31, gb_free=17.4, wall=19667
2025-11-07 22:12:32 | INFO | train_inner | epoch 001:  31693 / 91072 loss=0.65625, wps=376.6, ups=1.51, wpb=249.9, bsz=16, num_updates=31600, lr=7.02222e-05, gnorm=9.717, clip=76, loss_scale=256, train_wall=33, gb_free=17.1, wall=19700
2025-11-07 22:13:04 | INFO | train_inner | epoch 001:  31743 / 91072 loss=0.655273, wps=392.3, ups=1.55, wpb=252.9, bsz=16, num_updates=31650, lr=7.03333e-05, gnorm=10.273, clip=70, loss_scale=256, train_wall=32, gb_free=17.4, wall=19732
2025-11-07 22:13:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:13:35 | INFO | train_inner | epoch 001:  31794 / 91072 loss=0.636719, wps=375.2, ups=1.6, wpb=233.9, bsz=16, num_updates=31700, lr=7.04444e-05, gnorm=11.225, clip=80, loss_scale=256, train_wall=31, gb_free=17.9, wall=19763
2025-11-07 22:14:05 | INFO | train_inner | epoch 001:  31844 / 91072 loss=0.608398, wps=392.9, ups=1.67, wpb=235.4, bsz=16, num_updates=31750, lr=7.05556e-05, gnorm=11.955, clip=76, loss_scale=256, train_wall=30, gb_free=17.4, wall=19793
2025-11-07 22:14:36 | INFO | train_inner | epoch 001:  31894 / 91072 loss=0.681641, wps=409.8, ups=1.64, wpb=249.7, bsz=16, num_updates=31800, lr=7.06667e-05, gnorm=11.8, clip=80, loss_scale=256, train_wall=30, gb_free=16.3, wall=19824
2025-11-07 22:15:06 | INFO | train_inner | epoch 001:  31944 / 91072 loss=0.643555, wps=387, ups=1.68, wpb=230.1, bsz=16, num_updates=31850, lr=7.07778e-05, gnorm=9.943, clip=68, loss_scale=256, train_wall=30, gb_free=9.1, wall=19854
2025-11-07 22:15:36 | INFO | train_inner | epoch 001:  31994 / 91072 loss=0.557129, wps=395.8, ups=1.64, wpb=241.6, bsz=16, num_updates=31900, lr=7.08889e-05, gnorm=9.581, clip=64, loss_scale=256, train_wall=30, gb_free=17.1, wall=19884
2025-11-07 22:16:06 | INFO | train_inner | epoch 001:  32044 / 91072 loss=0.650879, wps=388.4, ups=1.68, wpb=231.7, bsz=16, num_updates=31950, lr=7.1e-05, gnorm=10.821, clip=68, loss_scale=512, train_wall=30, gb_free=7.8, wall=19914
2025-11-07 22:16:36 | INFO | train_inner | epoch 001:  32094 / 91072 loss=0.568848, wps=394.7, ups=1.69, wpb=233.4, bsz=16, num_updates=32000, lr=7.11111e-05, gnorm=8.231, clip=64, loss_scale=512, train_wall=29, gb_free=17.4, wall=19943
2025-11-07 22:17:06 | INFO | train_inner | epoch 001:  32144 / 91072 loss=0.626953, wps=401, ups=1.65, wpb=242.5, bsz=16, num_updates=32050, lr=7.12222e-05, gnorm=11.277, clip=72, loss_scale=512, train_wall=30, gb_free=14.7, wall=19974
2025-11-07 22:17:36 | INFO | train_inner | epoch 001:  32194 / 91072 loss=0.652832, wps=395.2, ups=1.63, wpb=241.8, bsz=16, num_updates=32100, lr=7.13333e-05, gnorm=10.834, clip=68, loss_scale=512, train_wall=30, gb_free=16.3, wall=20004
2025-11-07 22:17:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:18:11 | INFO | train_inner | epoch 001:  32245 / 91072 loss=0.703125, wps=345.8, ups=1.43, wpb=241.6, bsz=16, num_updates=32150, lr=7.14444e-05, gnorm=12.383, clip=82, loss_scale=256, train_wall=35, gb_free=16.4, wall=20039
2025-11-07 22:18:44 | INFO | train_inner | epoch 001:  32295 / 91072 loss=0.747559, wps=373.8, ups=1.51, wpb=247.6, bsz=16, num_updates=32200, lr=7.15556e-05, gnorm=12.855, clip=76, loss_scale=256, train_wall=33, gb_free=17.9, wall=20072
2025-11-07 22:19:14 | INFO | train_inner | epoch 001:  32345 / 91072 loss=0.644531, wps=397.3, ups=1.67, wpb=238.3, bsz=16, num_updates=32250, lr=7.16667e-05, gnorm=11.748, clip=82, loss_scale=256, train_wall=30, gb_free=15.2, wall=20102
2025-11-07 22:19:49 | INFO | train_inner | epoch 001:  32395 / 91072 loss=0.68457, wps=372.9, ups=1.46, wpb=256.1, bsz=16, num_updates=32300, lr=7.17778e-05, gnorm=10.698, clip=78, loss_scale=256, train_wall=34, gb_free=17.6, wall=20137
2025-11-07 22:20:20 | INFO | train_inner | epoch 001:  32445 / 91072 loss=0.623535, wps=386.4, ups=1.61, wpb=240.4, bsz=16, num_updates=32350, lr=7.18889e-05, gnorm=12.873, clip=80, loss_scale=256, train_wall=31, gb_free=14.6, wall=20168
2025-11-07 22:20:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:20:56 | INFO | train_inner | epoch 001:  32496 / 91072 loss=0.659668, wps=335.8, ups=1.37, wpb=245.3, bsz=16, num_updates=32400, lr=7.2e-05, gnorm=11.559, clip=70, loss_scale=256, train_wall=36, gb_free=10.3, wall=20204
2025-11-07 22:21:31 | INFO | train_inner | epoch 001:  32546 / 91072 loss=0.663574, wps=377.7, ups=1.45, wpb=260.8, bsz=16, num_updates=32450, lr=7.21111e-05, gnorm=11.917, clip=70, loss_scale=256, train_wall=34, gb_free=15.5, wall=20239
2025-11-07 22:22:03 | INFO | train_inner | epoch 001:  32596 / 91072 loss=0.668457, wps=379.9, ups=1.57, wpb=242, bsz=16, num_updates=32500, lr=7.22222e-05, gnorm=11.637, clip=72, loss_scale=256, train_wall=32, gb_free=18.2, wall=20271
2025-11-07 22:22:34 | INFO | train_inner | epoch 001:  32646 / 91072 loss=0.660645, wps=379.9, ups=1.61, wpb=235.3, bsz=16, num_updates=32550, lr=7.23333e-05, gnorm=10.822, clip=60, loss_scale=256, train_wall=31, gb_free=15.1, wall=20302
2025-11-07 22:23:07 | INFO | train_inner | epoch 001:  32696 / 91072 loss=0.70752, wps=359.4, ups=1.5, wpb=239.4, bsz=16, num_updates=32600, lr=7.24444e-05, gnorm=12.456, clip=84, loss_scale=256, train_wall=33, gb_free=15.7, wall=20335
2025-11-07 22:23:38 | INFO | train_inner | epoch 001:  32746 / 91072 loss=0.6875, wps=387.5, ups=1.6, wpb=241.9, bsz=16, num_updates=32650, lr=7.25556e-05, gnorm=12.533, clip=72, loss_scale=512, train_wall=31, gb_free=15.9, wall=20366
2025-11-07 22:24:12 | INFO | train_inner | epoch 001:  32796 / 91072 loss=0.65625, wps=385.2, ups=1.49, wpb=258, bsz=16, num_updates=32700, lr=7.26667e-05, gnorm=10.468, clip=72, loss_scale=512, train_wall=33, gb_free=17.4, wall=20400
2025-11-07 22:24:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:24:43 | INFO | train_inner | epoch 001:  32847 / 91072 loss=0.654785, wps=391.8, ups=1.63, wpb=240.5, bsz=16, num_updates=32750, lr=7.27778e-05, gnorm=10.529, clip=68, loss_scale=256, train_wall=31, gb_free=16.7, wall=20430
2025-11-07 22:25:15 | INFO | train_inner | epoch 001:  32897 / 91072 loss=0.697754, wps=366.9, ups=1.54, wpb=238.8, bsz=16, num_updates=32800, lr=7.28889e-05, gnorm=11.568, clip=70, loss_scale=256, train_wall=32, gb_free=19.1, wall=20463
2025-11-07 22:25:51 | INFO | train_inner | epoch 001:  32947 / 91072 loss=0.771484, wps=334.1, ups=1.38, wpb=242.6, bsz=16, num_updates=32850, lr=7.3e-05, gnorm=13.417, clip=84, loss_scale=256, train_wall=36, gb_free=17.8, wall=20499
2025-11-07 22:26:23 | INFO | train_inner | epoch 001:  32997 / 91072 loss=0.649902, wps=380.4, ups=1.6, wpb=238.4, bsz=16, num_updates=32900, lr=7.31111e-05, gnorm=10.755, clip=66, loss_scale=256, train_wall=31, gb_free=17.3, wall=20531
2025-11-07 22:26:53 | INFO | train_inner | epoch 001:  33047 / 91072 loss=0.651855, wps=399.2, ups=1.64, wpb=243.9, bsz=16, num_updates=32950, lr=7.32222e-05, gnorm=11.457, clip=80, loss_scale=256, train_wall=30, gb_free=17.8, wall=20561
2025-11-07 22:27:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:27:25 | INFO | train_inner | epoch 001:  33098 / 91072 loss=0.723633, wps=394.6, ups=1.58, wpb=249, bsz=16, num_updates=33000, lr=7.33333e-05, gnorm=11.832, clip=74, loss_scale=256, train_wall=31, gb_free=17.1, wall=20593
2025-11-07 22:27:56 | INFO | train_inner | epoch 001:  33148 / 91072 loss=0.606445, wps=386.8, ups=1.61, wpb=239.7, bsz=16, num_updates=33050, lr=7.34444e-05, gnorm=11.309, clip=76, loss_scale=256, train_wall=31, gb_free=17.5, wall=20624
2025-11-07 22:28:28 | INFO | train_inner | epoch 001:  33198 / 91072 loss=0.71875, wps=392, ups=1.53, wpb=255.8, bsz=16, num_updates=33100, lr=7.35556e-05, gnorm=11.086, clip=78, loss_scale=256, train_wall=32, gb_free=18.3, wall=20656
2025-11-07 22:28:59 | INFO | train_inner | epoch 001:  33248 / 91072 loss=0.6875, wps=404.6, ups=1.62, wpb=249.2, bsz=16, num_updates=33150, lr=7.36667e-05, gnorm=12.826, clip=72, loss_scale=256, train_wall=31, gb_free=15.6, wall=20687
2025-11-07 22:29:30 | INFO | train_inner | epoch 001:  33298 / 91072 loss=0.666016, wps=406.3, ups=1.63, wpb=249.4, bsz=16, num_updates=33200, lr=7.37778e-05, gnorm=11.698, clip=76, loss_scale=256, train_wall=31, gb_free=18.8, wall=20718
2025-11-07 22:30:01 | INFO | train_inner | epoch 001:  33348 / 91072 loss=0.703613, wps=393.6, ups=1.59, wpb=248.1, bsz=16, num_updates=33250, lr=7.38889e-05, gnorm=14.037, clip=88, loss_scale=256, train_wall=31, gb_free=17.6, wall=20749
2025-11-07 22:30:32 | INFO | train_inner | epoch 001:  33398 / 91072 loss=0.602051, wps=402.2, ups=1.63, wpb=246.8, bsz=16, num_updates=33300, lr=7.4e-05, gnorm=10.62, clip=78, loss_scale=512, train_wall=31, gb_free=18.9, wall=20780
2025-11-07 22:30:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:31:05 | INFO | train_inner | epoch 001:  33449 / 91072 loss=0.61084, wps=358.3, ups=1.51, wpb=237.8, bsz=16, num_updates=33350, lr=7.41111e-05, gnorm=11.148, clip=82, loss_scale=256, train_wall=33, gb_free=18, wall=20813
2025-11-07 22:31:40 | INFO | train_inner | epoch 001:  33499 / 91072 loss=0.67041, wps=359.5, ups=1.44, wpb=250.2, bsz=16, num_updates=33400, lr=7.42222e-05, gnorm=12.469, clip=82, loss_scale=256, train_wall=35, gb_free=17, wall=20848
2025-11-07 22:32:11 | INFO | train_inner | epoch 001:  33549 / 91072 loss=0.631836, wps=403.8, ups=1.61, wpb=250, bsz=16, num_updates=33450, lr=7.43333e-05, gnorm=9.329, clip=60, loss_scale=256, train_wall=31, gb_free=12.3, wall=20879
2025-11-07 22:32:41 | INFO | train_inner | epoch 001:  33599 / 91072 loss=0.682129, wps=404.3, ups=1.65, wpb=244.3, bsz=16, num_updates=33500, lr=7.44444e-05, gnorm=11.115, clip=64, loss_scale=256, train_wall=30, gb_free=8.1, wall=20909
2025-11-07 22:33:12 | INFO | train_inner | epoch 001:  33649 / 91072 loss=0.651367, wps=400.9, ups=1.64, wpb=244, bsz=16, num_updates=33550, lr=7.45556e-05, gnorm=11.137, clip=76, loss_scale=256, train_wall=30, gb_free=18.2, wall=20940
2025-11-07 22:33:42 | INFO | train_inner | epoch 001:  33699 / 91072 loss=0.673828, wps=409.5, ups=1.65, wpb=248.8, bsz=16, num_updates=33600, lr=7.46667e-05, gnorm=11.772, clip=76, loss_scale=512, train_wall=30, gb_free=18.3, wall=20970
2025-11-07 22:34:13 | INFO | train_inner | epoch 001:  33749 / 91072 loss=0.643555, wps=396, ups=1.63, wpb=242.4, bsz=16, num_updates=33650, lr=7.47778e-05, gnorm=10.265, clip=74, loss_scale=512, train_wall=30, gb_free=17.3, wall=21001
2025-11-07 22:34:43 | INFO | train_inner | epoch 001:  33799 / 91072 loss=0.621094, wps=404.3, ups=1.63, wpb=247.9, bsz=16, num_updates=33700, lr=7.48889e-05, gnorm=11.008, clip=74, loss_scale=512, train_wall=30, gb_free=14.1, wall=21031
2025-11-07 22:35:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:35:15 | INFO | train_inner | epoch 001:  33850 / 91072 loss=0.734375, wps=399, ups=1.58, wpb=251.9, bsz=16, num_updates=33750, lr=7.5e-05, gnorm=11.363, clip=72, loss_scale=256, train_wall=31, gb_free=18, wall=21063
2025-11-07 22:35:45 | INFO | train_inner | epoch 001:  33900 / 91072 loss=0.684082, wps=399.1, ups=1.64, wpb=243.8, bsz=16, num_updates=33800, lr=7.51111e-05, gnorm=12.299, clip=76, loss_scale=256, train_wall=30, gb_free=17.6, wall=21093
2025-11-07 22:36:16 | INFO | train_inner | epoch 001:  33950 / 91072 loss=0.649414, wps=396.7, ups=1.66, wpb=238.5, bsz=16, num_updates=33850, lr=7.52222e-05, gnorm=12.214, clip=66, loss_scale=256, train_wall=30, gb_free=18.4, wall=21123
2025-11-07 22:36:46 | INFO | train_inner | epoch 001:  34000 / 91072 loss=0.65332, wps=410.8, ups=1.64, wpb=250.7, bsz=16, num_updates=33900, lr=7.53333e-05, gnorm=9.288, clip=66, loss_scale=256, train_wall=30, gb_free=16.6, wall=21154
2025-11-07 22:37:17 | INFO | train_inner | epoch 001:  34050 / 91072 loss=0.702148, wps=407.4, ups=1.62, wpb=251.8, bsz=16, num_updates=33950, lr=7.54444e-05, gnorm=13.184, clip=76, loss_scale=256, train_wall=31, gb_free=14.3, wall=21185
2025-11-07 22:37:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:37:50 | INFO | train_inner | epoch 001:  34101 / 91072 loss=0.70752, wps=378.3, ups=1.52, wpb=249.5, bsz=16, num_updates=34000, lr=7.55556e-05, gnorm=10.542, clip=70, loss_scale=256, train_wall=33, gb_free=16.4, wall=21218
2025-11-07 22:38:22 | INFO | train_inner | epoch 001:  34151 / 91072 loss=0.722168, wps=384.4, ups=1.58, wpb=242.8, bsz=16, num_updates=34050, lr=7.56667e-05, gnorm=10.13, clip=72, loss_scale=256, train_wall=31, gb_free=18.5, wall=21249
2025-11-07 22:38:52 | INFO | train_inner | epoch 001:  34201 / 91072 loss=0.641602, wps=393.4, ups=1.62, wpb=242.9, bsz=16, num_updates=34100, lr=7.57778e-05, gnorm=12.281, clip=84, loss_scale=256, train_wall=31, gb_free=18.2, wall=21280
2025-11-07 22:39:23 | INFO | train_inner | epoch 001:  34251 / 91072 loss=0.71875, wps=387, ups=1.63, wpb=237.8, bsz=16, num_updates=34150, lr=7.58889e-05, gnorm=12.918, clip=82, loss_scale=256, train_wall=31, gb_free=18.8, wall=21311
2025-11-07 22:39:55 | INFO | train_inner | epoch 001:  34301 / 91072 loss=0.655273, wps=379.3, ups=1.59, wpb=238.4, bsz=16, num_updates=34200, lr=7.6e-05, gnorm=11.286, clip=72, loss_scale=256, train_wall=31, gb_free=16, wall=21342
2025-11-07 22:40:25 | INFO | train_inner | epoch 001:  34351 / 91072 loss=0.632324, wps=411.5, ups=1.63, wpb=252.4, bsz=16, num_updates=34250, lr=7.61111e-05, gnorm=12.327, clip=72, loss_scale=512, train_wall=31, gb_free=17.9, wall=21373
2025-11-07 22:40:57 | INFO | train_inner | epoch 001:  34401 / 91072 loss=0.711914, wps=398.4, ups=1.59, wpb=250.9, bsz=16, num_updates=34300, lr=7.62222e-05, gnorm=13.672, clip=78, loss_scale=512, train_wall=31, gb_free=17.7, wall=21405
2025-11-07 22:41:29 | INFO | train_inner | epoch 001:  34451 / 91072 loss=0.621094, wps=381.6, ups=1.55, wpb=245.9, bsz=16, num_updates=34350, lr=7.63333e-05, gnorm=11.271, clip=76, loss_scale=512, train_wall=32, gb_free=13.1, wall=21437
2025-11-07 22:41:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:42:00 | INFO | train_inner | epoch 001:  34502 / 91072 loss=0.602539, wps=355.9, ups=1.61, wpb=220.6, bsz=16, num_updates=34400, lr=7.64444e-05, gnorm=9.172, clip=78, loss_scale=256, train_wall=31, gb_free=18.1, wall=21468
2025-11-07 22:42:33 | INFO | train_inner | epoch 001:  34552 / 91072 loss=0.626953, wps=367.5, ups=1.51, wpb=244.1, bsz=16, num_updates=34450, lr=7.65556e-05, gnorm=10.125, clip=72, loss_scale=256, train_wall=33, gb_free=16.8, wall=21501
2025-11-07 22:43:05 | INFO | train_inner | epoch 001:  34602 / 91072 loss=0.713379, wps=395.1, ups=1.58, wpb=249.6, bsz=16, num_updates=34500, lr=7.66667e-05, gnorm=12.048, clip=76, loss_scale=256, train_wall=31, gb_free=11.3, wall=21533
2025-11-07 22:43:36 | INFO | train_inner | epoch 001:  34652 / 91072 loss=0.693359, wps=379.7, ups=1.6, wpb=237.8, bsz=16, num_updates=34550, lr=7.67778e-05, gnorm=12.38, clip=82, loss_scale=256, train_wall=31, gb_free=18.8, wall=21564
2025-11-07 22:44:07 | INFO | train_inner | epoch 001:  34702 / 91072 loss=0.67041, wps=399.6, ups=1.62, wpb=246.7, bsz=16, num_updates=34600, lr=7.68889e-05, gnorm=11.259, clip=80, loss_scale=256, train_wall=31, gb_free=17.1, wall=21595
2025-11-07 22:44:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:44:38 | INFO | train_inner | epoch 001:  34753 / 91072 loss=0.649414, wps=390.6, ups=1.62, wpb=241.4, bsz=16, num_updates=34650, lr=7.7e-05, gnorm=10.1, clip=62, loss_scale=256, train_wall=31, gb_free=17.3, wall=21626
2025-11-07 22:45:08 | INFO | train_inner | epoch 001:  34803 / 91072 loss=0.674805, wps=395.4, ups=1.65, wpb=239.1, bsz=16, num_updates=34700, lr=7.71111e-05, gnorm=10.792, clip=74, loss_scale=256, train_wall=30, gb_free=16.8, wall=21656
2025-11-07 22:45:40 | INFO | train_inner | epoch 001:  34853 / 91072 loss=0.671387, wps=400.2, ups=1.59, wpb=252.4, bsz=16, num_updates=34750, lr=7.72222e-05, gnorm=11.936, clip=76, loss_scale=256, train_wall=31, gb_free=8.3, wall=21688
2025-11-07 22:46:10 | INFO | train_inner | epoch 001:  34903 / 91072 loss=0.711914, wps=406.3, ups=1.66, wpb=245.5, bsz=16, num_updates=34800, lr=7.73333e-05, gnorm=14.744, clip=86, loss_scale=256, train_wall=30, gb_free=16.9, wall=21718
2025-11-07 22:46:40 | INFO | train_inner | epoch 001:  34953 / 91072 loss=0.614258, wps=390.2, ups=1.68, wpb=232, bsz=16, num_updates=34850, lr=7.74444e-05, gnorm=10.899, clip=70, loss_scale=256, train_wall=30, gb_free=18.5, wall=21747
2025-11-07 22:46:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:47:11 | INFO | train_inner | epoch 001:  35004 / 91072 loss=0.633789, wps=400.8, ups=1.61, wpb=249.1, bsz=16, num_updates=34900, lr=7.75556e-05, gnorm=12.126, clip=78, loss_scale=256, train_wall=31, gb_free=13.3, wall=21779
2025-11-07 22:47:41 | INFO | train_inner | epoch 001:  35054 / 91072 loss=0.71875, wps=391.9, ups=1.65, wpb=237.1, bsz=16, num_updates=34950, lr=7.76667e-05, gnorm=11.352, clip=62, loss_scale=256, train_wall=30, gb_free=14.4, wall=21809
2025-11-07 22:48:12 | INFO | train_inner | epoch 001:  35104 / 91072 loss=0.567871, wps=407.2, ups=1.6, wpb=254.6, bsz=16, num_updates=35000, lr=7.77778e-05, gnorm=10.893, clip=80, loss_scale=256, train_wall=31, gb_free=18.9, wall=21840
2025-11-07 22:48:43 | INFO | train_inner | epoch 001:  35154 / 91072 loss=0.629395, wps=417.9, ups=1.62, wpb=257.4, bsz=16, num_updates=35050, lr=7.78889e-05, gnorm=8.436, clip=64, loss_scale=256, train_wall=31, gb_free=15.7, wall=21871
2025-11-07 22:49:14 | INFO | train_inner | epoch 001:  35204 / 91072 loss=0.575195, wps=411.4, ups=1.62, wpb=254.1, bsz=16, num_updates=35100, lr=7.8e-05, gnorm=9.419, clip=74, loss_scale=256, train_wall=31, gb_free=15.7, wall=21902
2025-11-07 22:49:45 | INFO | train_inner | epoch 001:  35254 / 91072 loss=0.718262, wps=396.1, ups=1.62, wpb=244.2, bsz=16, num_updates=35150, lr=7.81111e-05, gnorm=12.813, clip=78, loss_scale=512, train_wall=31, gb_free=18.3, wall=21933
2025-11-07 22:50:16 | INFO | train_inner | epoch 001:  35304 / 91072 loss=0.676758, wps=392.2, ups=1.6, wpb=244.9, bsz=16, num_updates=35200, lr=7.82222e-05, gnorm=11.369, clip=66, loss_scale=512, train_wall=31, gb_free=17.5, wall=21964
2025-11-07 22:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:50:47 | INFO | train_inner | epoch 001:  35355 / 91072 loss=0.646484, wps=365.9, ups=1.61, wpb=227.2, bsz=16, num_updates=35250, lr=7.83333e-05, gnorm=10.515, clip=76, loss_scale=256, train_wall=31, gb_free=18.6, wall=21995
2025-11-07 22:51:17 | INFO | train_inner | epoch 001:  35405 / 91072 loss=0.689941, wps=409.6, ups=1.65, wpb=249, bsz=16, num_updates=35300, lr=7.84444e-05, gnorm=12.226, clip=70, loss_scale=256, train_wall=30, gb_free=16.3, wall=22025
2025-11-07 22:51:49 | INFO | train_inner | epoch 001:  35455 / 91072 loss=0.645508, wps=401.5, ups=1.59, wpb=252.9, bsz=16, num_updates=35350, lr=7.85556e-05, gnorm=12.041, clip=78, loss_scale=256, train_wall=31, gb_free=11.5, wall=22057
2025-11-07 22:52:19 | INFO | train_inner | epoch 001:  35505 / 91072 loss=0.665039, wps=401.7, ups=1.64, wpb=245, bsz=16, num_updates=35400, lr=7.86667e-05, gnorm=12.337, clip=80, loss_scale=256, train_wall=30, gb_free=16.3, wall=22087
2025-11-07 22:52:51 | INFO | train_inner | epoch 001:  35555 / 91072 loss=0.660645, wps=389.4, ups=1.56, wpb=249.8, bsz=16, num_updates=35450, lr=7.87778e-05, gnorm=11.774, clip=78, loss_scale=256, train_wall=32, gb_free=12.6, wall=22119
2025-11-07 22:53:25 | INFO | train_inner | epoch 001:  35605 / 91072 loss=0.644531, wps=359.4, ups=1.47, wpb=244.3, bsz=16, num_updates=35500, lr=7.88889e-05, gnorm=12.339, clip=78, loss_scale=512, train_wall=34, gb_free=19, wall=22153
2025-11-07 22:53:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:53:56 | INFO | train_inner | epoch 001:  35656 / 91072 loss=0.72168, wps=385.8, ups=1.62, wpb=238.7, bsz=16, num_updates=35550, lr=7.9e-05, gnorm=11.048, clip=80, loss_scale=256, train_wall=31, gb_free=17.4, wall=22184
2025-11-07 22:54:27 | INFO | train_inner | epoch 001:  35706 / 91072 loss=0.668945, wps=407.1, ups=1.64, wpb=247.8, bsz=16, num_updates=35600, lr=7.91111e-05, gnorm=13.012, clip=76, loss_scale=256, train_wall=30, gb_free=16.9, wall=22215
2025-11-07 22:54:57 | INFO | train_inner | epoch 001:  35756 / 91072 loss=0.635742, wps=391.1, ups=1.68, wpb=233.2, bsz=16, num_updates=35650, lr=7.92222e-05, gnorm=12.467, clip=80, loss_scale=256, train_wall=30, gb_free=18.5, wall=22244
2025-11-07 22:55:28 | INFO | train_inner | epoch 001:  35806 / 91072 loss=0.669434, wps=413.5, ups=1.61, wpb=256.4, bsz=16, num_updates=35700, lr=7.93333e-05, gnorm=11.404, clip=74, loss_scale=256, train_wall=31, gb_free=15, wall=22275
2025-11-07 22:55:59 | INFO | train_inner | epoch 001:  35856 / 91072 loss=0.78418, wps=408.2, ups=1.6, wpb=255.4, bsz=16, num_updates=35750, lr=7.94444e-05, gnorm=13.171, clip=78, loss_scale=256, train_wall=31, gb_free=16.9, wall=22307
2025-11-07 22:56:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 22:56:30 | INFO | train_inner | epoch 001:  35907 / 91072 loss=0.60791, wps=401.5, ups=1.6, wpb=251.2, bsz=16, num_updates=35800, lr=7.95556e-05, gnorm=9.596, clip=64, loss_scale=256, train_wall=31, gb_free=16.5, wall=22338
2025-11-07 22:57:01 | INFO | train_inner | epoch 001:  35957 / 91072 loss=0.687988, wps=405.4, ups=1.64, wpb=247.4, bsz=16, num_updates=35850, lr=7.96667e-05, gnorm=13.049, clip=78, loss_scale=256, train_wall=30, gb_free=17.6, wall=22369
2025-11-07 22:57:32 | INFO | train_inner | epoch 001:  36007 / 91072 loss=0.657227, wps=405, ups=1.61, wpb=251.8, bsz=16, num_updates=35900, lr=7.97778e-05, gnorm=9.496, clip=60, loss_scale=256, train_wall=31, gb_free=15.6, wall=22400
2025-11-07 22:58:02 | INFO | train_inner | epoch 001:  36057 / 91072 loss=0.741211, wps=397.8, ups=1.65, wpb=241, bsz=16, num_updates=35950, lr=7.98889e-05, gnorm=12.53, clip=78, loss_scale=256, train_wall=30, gb_free=14.8, wall=22430
2025-11-07 22:58:34 | INFO | train_inner | epoch 001:  36107 / 91072 loss=0.696289, wps=382.2, ups=1.57, wpb=243.3, bsz=16, num_updates=36000, lr=8e-05, gnorm=13.775, clip=82, loss_scale=256, train_wall=32, gb_free=14, wall=22462
2025-11-07 22:59:06 | INFO | train_inner | epoch 001:  36157 / 91072 loss=0.628906, wps=409.6, ups=1.55, wpb=263.8, bsz=16, num_updates=36050, lr=8.01111e-05, gnorm=9.345, clip=72, loss_scale=512, train_wall=32, gb_free=18.1, wall=22494
2025-11-07 22:59:38 | INFO | train_inner | epoch 001:  36207 / 91072 loss=0.606445, wps=390.1, ups=1.57, wpb=248.8, bsz=16, num_updates=36100, lr=8.02222e-05, gnorm=10.008, clip=74, loss_scale=512, train_wall=32, gb_free=15.7, wall=22526
2025-11-07 22:59:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:00:11 | INFO | train_inner | epoch 001:  36258 / 91072 loss=0.65625, wps=373.1, ups=1.53, wpb=244.3, bsz=16, num_updates=36150, lr=8.03333e-05, gnorm=11.352, clip=70, loss_scale=256, train_wall=33, gb_free=17.6, wall=22559
2025-11-07 23:00:42 | INFO | train_inner | epoch 001:  36308 / 91072 loss=0.682129, wps=394.6, ups=1.62, wpb=243.9, bsz=16, num_updates=36200, lr=8.04444e-05, gnorm=11.973, clip=70, loss_scale=256, train_wall=31, gb_free=14.8, wall=22590
2025-11-07 23:01:12 | INFO | train_inner | epoch 001:  36358 / 91072 loss=0.59668, wps=405.6, ups=1.67, wpb=243.5, bsz=16, num_updates=36250, lr=8.05556e-05, gnorm=9.354, clip=68, loss_scale=256, train_wall=30, gb_free=17.5, wall=22620
2025-11-07 23:01:43 | INFO | train_inner | epoch 001:  36408 / 91072 loss=0.618652, wps=383.8, ups=1.6, wpb=239.4, bsz=16, num_updates=36300, lr=8.06667e-05, gnorm=12.007, clip=78, loss_scale=256, train_wall=31, gb_free=17.7, wall=22651
2025-11-07 23:02:15 | INFO | train_inner | epoch 001:  36458 / 91072 loss=0.678711, wps=403.3, ups=1.56, wpb=258.2, bsz=16, num_updates=36350, lr=8.07778e-05, gnorm=11.713, clip=70, loss_scale=256, train_wall=32, gb_free=18.7, wall=22683
2025-11-07 23:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:02:47 | INFO | train_inner | epoch 001:  36509 / 91072 loss=0.648926, wps=385.1, ups=1.58, wpb=243.6, bsz=16, num_updates=36400, lr=8.08889e-05, gnorm=12.537, clip=84, loss_scale=256, train_wall=31, gb_free=16.4, wall=22714
2025-11-07 23:03:18 | INFO | train_inner | epoch 001:  36559 / 91072 loss=0.702637, wps=407.1, ups=1.59, wpb=256.3, bsz=16, num_updates=36450, lr=8.1e-05, gnorm=13.9, clip=86, loss_scale=256, train_wall=31, gb_free=16.6, wall=22746
2025-11-07 23:03:49 | INFO | train_inner | epoch 001:  36609 / 91072 loss=0.631836, wps=386.5, ups=1.6, wpb=241.6, bsz=16, num_updates=36500, lr=8.11111e-05, gnorm=10.54, clip=64, loss_scale=256, train_wall=31, gb_free=18, wall=22777
2025-11-07 23:04:20 | INFO | train_inner | epoch 001:  36659 / 91072 loss=0.665039, wps=384.1, ups=1.64, wpb=234.3, bsz=16, num_updates=36550, lr=8.12222e-05, gnorm=11.957, clip=82, loss_scale=256, train_wall=30, gb_free=15.8, wall=22808
2025-11-07 23:04:51 | INFO | train_inner | epoch 001:  36709 / 91072 loss=0.935059, wps=417.1, ups=1.62, wpb=257.4, bsz=16, num_updates=36600, lr=8.13333e-05, gnorm=18.546, clip=80, loss_scale=256, train_wall=31, gb_free=16.1, wall=22838
2025-11-07 23:05:22 | INFO | train_inner | epoch 001:  36759 / 91072 loss=0.751465, wps=404.9, ups=1.61, wpb=250.7, bsz=16, num_updates=36650, lr=8.14444e-05, gnorm=7.845, clip=64, loss_scale=512, train_wall=31, gb_free=14.5, wall=22869
2025-11-07 23:05:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:05:53 | INFO | train_inner | epoch 001:  36810 / 91072 loss=0.785156, wps=377.1, ups=1.59, wpb=236.9, bsz=16, num_updates=36700, lr=8.15556e-05, gnorm=8.748, clip=54, loss_scale=256, train_wall=31, gb_free=16.7, wall=22901
2025-11-07 23:06:23 | INFO | train_inner | epoch 001:  36860 / 91072 loss=0.88623, wps=402.4, ups=1.66, wpb=242.5, bsz=16, num_updates=36750, lr=8.16667e-05, gnorm=10.342, clip=60, loss_scale=256, train_wall=30, gb_free=18.1, wall=22931
2025-11-07 23:06:53 | INFO | train_inner | epoch 001:  36910 / 91072 loss=0.805176, wps=390.1, ups=1.66, wpb=235.3, bsz=16, num_updates=36800, lr=8.17778e-05, gnorm=10.974, clip=74, loss_scale=256, train_wall=30, gb_free=14.6, wall=22961
2025-11-07 23:07:24 | INFO | train_inner | epoch 001:  36960 / 91072 loss=0.833008, wps=392.6, ups=1.62, wpb=242.8, bsz=16, num_updates=36850, lr=8.18889e-05, gnorm=10.068, clip=76, loss_scale=256, train_wall=31, gb_free=17, wall=22992
2025-11-07 23:07:55 | INFO | train_inner | epoch 001:  37010 / 91072 loss=0.773926, wps=404.9, ups=1.65, wpb=245.8, bsz=16, num_updates=36900, lr=8.2e-05, gnorm=10.351, clip=76, loss_scale=256, train_wall=30, gb_free=12.2, wall=23022
2025-11-07 23:08:25 | INFO | train_inner | epoch 001:  37060 / 91072 loss=0.775879, wps=401.5, ups=1.66, wpb=241.3, bsz=16, num_updates=36950, lr=8.21111e-05, gnorm=9.169, clip=68, loss_scale=512, train_wall=30, gb_free=14.3, wall=23052
2025-11-07 23:08:55 | INFO | train_inner | epoch 001:  37110 / 91072 loss=0.792969, wps=405.9, ups=1.63, wpb=249.4, bsz=16, num_updates=37000, lr=8.22222e-05, gnorm=10.106, clip=68, loss_scale=512, train_wall=31, gb_free=17.1, wall=23083
2025-11-07 23:09:25 | INFO | train_inner | epoch 001:  37160 / 91072 loss=0.738281, wps=389, ups=1.67, wpb=233, bsz=16, num_updates=37050, lr=8.23333e-05, gnorm=8.657, clip=72, loss_scale=512, train_wall=30, gb_free=18.6, wall=23113
2025-11-07 23:09:56 | INFO | train_inner | epoch 001:  37210 / 91072 loss=0.792969, wps=401.5, ups=1.64, wpb=244.4, bsz=16, num_updates=37100, lr=8.24444e-05, gnorm=9.296, clip=58, loss_scale=512, train_wall=30, gb_free=15.2, wall=23144
2025-11-07 23:10:26 | INFO | train_inner | epoch 001:  37260 / 91072 loss=0.683594, wps=402.8, ups=1.66, wpb=243, bsz=16, num_updates=37150, lr=8.25556e-05, gnorm=8.283, clip=58, loss_scale=512, train_wall=30, gb_free=18.5, wall=23174
2025-11-07 23:10:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 23:10:57 | INFO | train_inner | epoch 001:  37311 / 91072 loss=0.808594, wps=392, ups=1.59, wpb=247, bsz=16, num_updates=37200, lr=8.26667e-05, gnorm=9.351, clip=74, loss_scale=512, train_wall=31, gb_free=15.7, wall=23205
2025-11-07 23:11:28 | INFO | train_inner | epoch 001:  37361 / 91072 loss=0.735352, wps=365.4, ups=1.63, wpb=224.8, bsz=16, num_updates=37250, lr=8.27778e-05, gnorm=9.188, clip=70, loss_scale=512, train_wall=31, gb_free=17.3, wall=23236
2025-11-07 23:12:00 | INFO | train_inner | epoch 001:  37411 / 91072 loss=0.843262, wps=419.3, ups=1.59, wpb=264, bsz=16, num_updates=37300, lr=8.28889e-05, gnorm=10.318, clip=74, loss_scale=512, train_wall=31, gb_free=15.5, wall=23268
2025-11-07 23:12:30 | INFO | train_inner | epoch 001:  37461 / 91072 loss=0.755371, wps=378.4, ups=1.62, wpb=233.4, bsz=16, num_updates=37350, lr=8.3e-05, gnorm=8.963, clip=62, loss_scale=512, train_wall=31, gb_free=17.8, wall=23298
2025-11-07 23:13:01 | INFO | train_inner | epoch 001:  37511 / 91072 loss=0.844727, wps=403.5, ups=1.62, wpb=249.6, bsz=16, num_updates=37400, lr=8.31111e-05, gnorm=8.997, clip=72, loss_scale=512, train_wall=31, gb_free=14.1, wall=23329
2025-11-07 23:13:35 | INFO | train_inner | epoch 001:  37561 / 91072 loss=0.815918, wps=374.1, ups=1.51, wpb=248.2, bsz=16, num_updates=37450, lr=8.32222e-05, gnorm=9.732, clip=76, loss_scale=1024, train_wall=33, gb_free=18.6, wall=23362
2025-11-07 23:13:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 23:14:09 | INFO | train_inner | epoch 001:  37612 / 91072 loss=0.717773, wps=367.3, ups=1.46, wpb=250.8, bsz=16, num_updates=37500, lr=8.33333e-05, gnorm=9.135, clip=64, loss_scale=512, train_wall=34, gb_free=13.3, wall=23397
2025-11-07 23:14:40 | INFO | train_inner | epoch 001:  37662 / 91072 loss=0.791504, wps=405.4, ups=1.6, wpb=252.7, bsz=16, num_updates=37550, lr=8.34444e-05, gnorm=9.276, clip=64, loss_scale=512, train_wall=31, gb_free=13.3, wall=23428
2025-11-07 23:14:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:15:11 | INFO | train_inner | epoch 001:  37713 / 91072 loss=0.733887, wps=385.5, ups=1.6, wpb=240.3, bsz=16, num_updates=37600, lr=8.35556e-05, gnorm=7.785, clip=62, loss_scale=256, train_wall=31, gb_free=12.4, wall=23459
2025-11-07 23:15:43 | INFO | train_inner | epoch 001:  37763 / 91072 loss=0.745605, wps=396.9, ups=1.57, wpb=253.5, bsz=16, num_updates=37650, lr=8.36667e-05, gnorm=8.905, clip=72, loss_scale=256, train_wall=32, gb_free=16.2, wall=23491
2025-11-07 23:16:14 | INFO | train_inner | epoch 001:  37813 / 91072 loss=0.747559, wps=386.4, ups=1.64, wpb=236, bsz=16, num_updates=37700, lr=8.37778e-05, gnorm=9.777, clip=78, loss_scale=256, train_wall=30, gb_free=17.7, wall=23521
2025-11-07 23:16:45 | INFO | train_inner | epoch 001:  37863 / 91072 loss=0.749512, wps=393.7, ups=1.61, wpb=244.5, bsz=16, num_updates=37750, lr=8.38889e-05, gnorm=9.64, clip=66, loss_scale=256, train_wall=31, gb_free=16.8, wall=23552
2025-11-07 23:17:16 | INFO | train_inner | epoch 001:  37913 / 91072 loss=0.770508, wps=413.1, ups=1.6, wpb=257.8, bsz=16, num_updates=37800, lr=8.4e-05, gnorm=9.942, clip=70, loss_scale=256, train_wall=31, gb_free=16, wall=23584
2025-11-07 23:17:47 | INFO | train_inner | epoch 001:  37963 / 91072 loss=0.749512, wps=401.5, ups=1.62, wpb=248.3, bsz=16, num_updates=37850, lr=8.41111e-05, gnorm=9.426, clip=70, loss_scale=512, train_wall=31, gb_free=12.2, wall=23615
2025-11-07 23:18:17 | INFO | train_inner | epoch 001:  38013 / 91072 loss=0.775879, wps=406.5, ups=1.64, wpb=248.6, bsz=16, num_updates=37900, lr=8.42222e-05, gnorm=9.139, clip=66, loss_scale=512, train_wall=30, gb_free=15.6, wall=23645
2025-11-07 23:18:48 | INFO | train_inner | epoch 001:  38063 / 91072 loss=0.738281, wps=405.5, ups=1.62, wpb=249.7, bsz=16, num_updates=37950, lr=8.43333e-05, gnorm=9.439, clip=62, loss_scale=512, train_wall=31, gb_free=18.6, wall=23676
2025-11-07 23:19:18 | INFO | train_inner | epoch 001:  38113 / 91072 loss=0.708496, wps=393.2, ups=1.65, wpb=238.6, bsz=16, num_updates=38000, lr=8.44444e-05, gnorm=9.934, clip=68, loss_scale=512, train_wall=30, gb_free=13.6, wall=23706
2025-11-07 23:19:49 | INFO | train_inner | epoch 001:  38163 / 91072 loss=0.778809, wps=400.5, ups=1.64, wpb=243.7, bsz=16, num_updates=38050, lr=8.45556e-05, gnorm=8.245, clip=56, loss_scale=512, train_wall=30, gb_free=14.6, wall=23737
2025-11-07 23:20:19 | INFO | train_inner | epoch 001:  38213 / 91072 loss=0.757324, wps=395, ups=1.65, wpb=239.9, bsz=16, num_updates=38100, lr=8.46667e-05, gnorm=7.787, clip=54, loss_scale=1024, train_wall=30, gb_free=18.5, wall=23767
2025-11-07 23:20:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 23:20:50 | INFO | train_inner | epoch 001:  38264 / 91072 loss=0.802246, wps=400.4, ups=1.6, wpb=249.8, bsz=16, num_updates=38150, lr=8.47778e-05, gnorm=10.868, clip=80, loss_scale=512, train_wall=31, gb_free=14.7, wall=23798
2025-11-07 23:21:21 | INFO | train_inner | epoch 001:  38314 / 91072 loss=0.750488, wps=402.9, ups=1.62, wpb=248.3, bsz=16, num_updates=38200, lr=8.48889e-05, gnorm=10.535, clip=72, loss_scale=512, train_wall=31, gb_free=15.9, wall=23829
2025-11-07 23:21:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:21:52 | INFO | train_inner | epoch 001:  38365 / 91072 loss=0.74707, wps=402.2, ups=1.62, wpb=248, bsz=16, num_updates=38250, lr=8.5e-05, gnorm=9.555, clip=70, loss_scale=256, train_wall=31, gb_free=17, wall=23860
2025-11-07 23:22:22 | INFO | train_inner | epoch 001:  38415 / 91072 loss=0.81543, wps=395.7, ups=1.69, wpb=233.7, bsz=16, num_updates=38300, lr=8.51111e-05, gnorm=10.142, clip=70, loss_scale=256, train_wall=29, gb_free=15.3, wall=23889
2025-11-07 23:22:52 | INFO | train_inner | epoch 001:  38465 / 91072 loss=0.812988, wps=398.2, ups=1.66, wpb=239.5, bsz=16, num_updates=38350, lr=8.52222e-05, gnorm=10.797, clip=78, loss_scale=256, train_wall=30, gb_free=14.5, wall=23920
2025-11-07 23:23:23 | INFO | train_inner | epoch 001:  38515 / 91072 loss=0.749512, wps=398.1, ups=1.59, wpb=249.8, bsz=16, num_updates=38400, lr=8.53333e-05, gnorm=10.948, clip=74, loss_scale=256, train_wall=31, gb_free=18.4, wall=23951
2025-11-07 23:23:56 | INFO | train_inner | epoch 001:  38565 / 91072 loss=0.754395, wps=369.6, ups=1.5, wpb=246.6, bsz=16, num_updates=38450, lr=8.54444e-05, gnorm=9.285, clip=64, loss_scale=256, train_wall=33, gb_free=17.2, wall=23984
2025-11-07 23:24:30 | INFO | train_inner | epoch 001:  38615 / 91072 loss=0.762695, wps=366.4, ups=1.48, wpb=247.7, bsz=16, num_updates=38500, lr=8.55556e-05, gnorm=9.139, clip=70, loss_scale=512, train_wall=34, gb_free=11.1, wall=24018
2025-11-07 23:25:02 | INFO | train_inner | epoch 001:  38665 / 91072 loss=0.822266, wps=363.6, ups=1.58, wpb=229.9, bsz=16, num_updates=38550, lr=8.56667e-05, gnorm=8.966, clip=70, loss_scale=512, train_wall=31, gb_free=15.8, wall=24050
2025-11-07 23:25:34 | INFO | train_inner | epoch 001:  38715 / 91072 loss=0.838379, wps=393, ups=1.58, wpb=249.4, bsz=16, num_updates=38600, lr=8.57778e-05, gnorm=8.479, clip=64, loss_scale=512, train_wall=31, gb_free=17.7, wall=24081
2025-11-07 23:26:03 | INFO | train_inner | epoch 001:  38765 / 91072 loss=0.821777, wps=389, ups=1.69, wpb=230.6, bsz=16, num_updates=38650, lr=8.58889e-05, gnorm=10.045, clip=60, loss_scale=512, train_wall=29, gb_free=12.6, wall=24111
2025-11-07 23:26:33 | INFO | train_inner | epoch 001:  38815 / 91072 loss=0.757812, wps=400.1, ups=1.67, wpb=240, bsz=16, num_updates=38700, lr=8.6e-05, gnorm=9.947, clip=74, loss_scale=512, train_wall=30, gb_free=17.3, wall=24141
2025-11-07 23:26:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 23:27:03 | INFO | train_inner | epoch 001:  38866 / 91072 loss=0.791504, wps=389.3, ups=1.65, wpb=235.7, bsz=16, num_updates=38750, lr=8.61111e-05, gnorm=10.855, clip=78, loss_scale=512, train_wall=30, gb_free=18, wall=24171
2025-11-07 23:27:35 | INFO | train_inner | epoch 001:  38916 / 91072 loss=0.75293, wps=395.2, ups=1.59, wpb=248.5, bsz=16, num_updates=38800, lr=8.62222e-05, gnorm=7.847, clip=60, loss_scale=512, train_wall=31, gb_free=17.5, wall=24203
2025-11-07 23:28:05 | INFO | train_inner | epoch 001:  38966 / 91072 loss=0.788574, wps=406.2, ups=1.66, wpb=244.1, bsz=16, num_updates=38850, lr=8.63333e-05, gnorm=9.874, clip=68, loss_scale=512, train_wall=30, gb_free=17, wall=24233
2025-11-07 23:28:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:28:39 | INFO | train_inner | epoch 001:  39017 / 91072 loss=0.744141, wps=340.5, ups=1.45, wpb=234.1, bsz=16, num_updates=38900, lr=8.64444e-05, gnorm=7.92, clip=58, loss_scale=256, train_wall=34, gb_free=17.8, wall=24267
2025-11-07 23:29:15 | INFO | train_inner | epoch 001:  39067 / 91072 loss=0.824707, wps=350.2, ups=1.42, wpb=247.5, bsz=16, num_updates=38950, lr=8.65556e-05, gnorm=7.304, clip=66, loss_scale=256, train_wall=35, gb_free=17.5, wall=24303
2025-11-07 23:29:44 | INFO | train_inner | epoch 001:  39117 / 91072 loss=0.794434, wps=399.1, ups=1.68, wpb=237.6, bsz=16, num_updates=39000, lr=8.66667e-05, gnorm=9.829, clip=70, loss_scale=256, train_wall=30, gb_free=18.6, wall=24332
2025-11-07 23:30:15 | INFO | train_inner | epoch 001:  39167 / 91072 loss=0.735352, wps=391, ups=1.64, wpb=238.8, bsz=16, num_updates=39050, lr=8.67778e-05, gnorm=8.227, clip=70, loss_scale=256, train_wall=30, gb_free=18.5, wall=24363
2025-11-07 23:30:48 | INFO | train_inner | epoch 001:  39217 / 91072 loss=0.695801, wps=383.1, ups=1.54, wpb=249.3, bsz=16, num_updates=39100, lr=8.68889e-05, gnorm=8.026, clip=68, loss_scale=256, train_wall=32, gb_free=18.1, wall=24395
2025-11-07 23:31:19 | INFO | train_inner | epoch 001:  39267 / 91072 loss=0.787109, wps=412, ups=1.61, wpb=256, bsz=16, num_updates=39150, lr=8.7e-05, gnorm=7.717, clip=54, loss_scale=512, train_wall=31, gb_free=18.5, wall=24426
2025-11-07 23:31:49 | INFO | train_inner | epoch 001:  39317 / 91072 loss=0.762695, wps=402.5, ups=1.66, wpb=242, bsz=16, num_updates=39200, lr=8.71111e-05, gnorm=10.279, clip=76, loss_scale=512, train_wall=30, gb_free=18.5, wall=24457
2025-11-07 23:32:20 | INFO | train_inner | epoch 001:  39367 / 91072 loss=0.742676, wps=396.9, ups=1.6, wpb=248.7, bsz=16, num_updates=39250, lr=8.72222e-05, gnorm=8.983, clip=54, loss_scale=512, train_wall=31, gb_free=17.5, wall=24488
2025-11-07 23:32:50 | INFO | train_inner | epoch 001:  39417 / 91072 loss=0.713867, wps=399.5, ups=1.67, wpb=239.1, bsz=16, num_updates=39300, lr=8.73333e-05, gnorm=8.003, clip=62, loss_scale=512, train_wall=30, gb_free=15.3, wall=24518
2025-11-07 23:33:22 | INFO | train_inner | epoch 001:  39467 / 91072 loss=0.753906, wps=384.8, ups=1.56, wpb=246.2, bsz=16, num_updates=39350, lr=8.74444e-05, gnorm=9.148, clip=60, loss_scale=512, train_wall=32, gb_free=17.9, wall=24550
2025-11-07 23:33:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 23:33:54 | INFO | train_inner | epoch 001:  39518 / 91072 loss=0.777832, wps=409.2, ups=1.58, wpb=259.3, bsz=16, num_updates=39400, lr=8.75556e-05, gnorm=10.796, clip=78, loss_scale=512, train_wall=32, gb_free=18.4, wall=24581
2025-11-07 23:34:24 | INFO | train_inner | epoch 001:  39568 / 91072 loss=0.8125, wps=411.9, ups=1.64, wpb=251.3, bsz=16, num_updates=39450, lr=8.76667e-05, gnorm=10.38, clip=66, loss_scale=512, train_wall=30, gb_free=10.3, wall=24612
2025-11-07 23:34:54 | INFO | train_inner | epoch 001:  39618 / 91072 loss=0.760254, wps=406.6, ups=1.65, wpb=246.8, bsz=16, num_updates=39500, lr=8.77778e-05, gnorm=9.407, clip=70, loss_scale=512, train_wall=30, gb_free=17.8, wall=24642
2025-11-07 23:35:25 | INFO | train_inner | epoch 001:  39668 / 91072 loss=0.712891, wps=389.6, ups=1.64, wpb=238.1, bsz=16, num_updates=39550, lr=8.78889e-05, gnorm=9.123, clip=72, loss_scale=512, train_wall=30, gb_free=18.5, wall=24673
2025-11-07 23:35:55 | INFO | train_inner | epoch 001:  39718 / 91072 loss=0.765137, wps=406.9, ups=1.65, wpb=246.4, bsz=16, num_updates=39600, lr=8.8e-05, gnorm=7.521, clip=58, loss_scale=512, train_wall=30, gb_free=18.6, wall=24703
2025-11-07 23:36:26 | INFO | train_inner | epoch 001:  39768 / 91072 loss=0.789062, wps=409.7, ups=1.65, wpb=248.3, bsz=16, num_updates=39650, lr=8.81111e-05, gnorm=7.51, clip=60, loss_scale=1024, train_wall=30, gb_free=15.6, wall=24733
2025-11-07 23:36:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-07 23:36:57 | INFO | train_inner | epoch 001:  39819 / 91072 loss=0.75293, wps=400.8, ups=1.61, wpb=249.2, bsz=16, num_updates=39700, lr=8.82222e-05, gnorm=7.707, clip=58, loss_scale=512, train_wall=31, gb_free=18.3, wall=24765
2025-11-07 23:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:37:28 | INFO | train_inner | epoch 001:  39870 / 91072 loss=0.739258, wps=388.5, ups=1.62, wpb=240.1, bsz=16, num_updates=39750, lr=8.83333e-05, gnorm=7.294, clip=56, loss_scale=256, train_wall=31, gb_free=15.6, wall=24795
2025-11-07 23:37:59 | INFO | train_inner | epoch 001:  39920 / 91072 loss=0.813965, wps=392.1, ups=1.57, wpb=250, bsz=16, num_updates=39800, lr=8.84444e-05, gnorm=9.442, clip=72, loss_scale=256, train_wall=32, gb_free=18.1, wall=24827
2025-11-07 23:38:31 | INFO | train_inner | epoch 001:  39970 / 91072 loss=0.775391, wps=389.3, ups=1.58, wpb=246.2, bsz=16, num_updates=39850, lr=8.85556e-05, gnorm=9.566, clip=70, loss_scale=256, train_wall=31, gb_free=16.2, wall=24859
2025-11-07 23:39:02 | INFO | train_inner | epoch 001:  40020 / 91072 loss=0.740723, wps=369.1, ups=1.62, wpb=227.8, bsz=16, num_updates=39900, lr=8.86667e-05, gnorm=10.896, clip=74, loss_scale=256, train_wall=31, gb_free=17.4, wall=24890
2025-11-07 23:39:33 | INFO | train_inner | epoch 001:  40070 / 91072 loss=0.833984, wps=418.2, ups=1.64, wpb=255.7, bsz=16, num_updates=39950, lr=8.87778e-05, gnorm=10.539, clip=66, loss_scale=256, train_wall=30, gb_free=15.9, wall=24920
2025-11-07 23:39:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:40:03 | INFO | train_inner | epoch 001:  40121 / 91072 loss=0.783691, wps=377.1, ups=1.66, wpb=227.8, bsz=16, num_updates=40000, lr=8.88889e-05, gnorm=8.527, clip=64, loss_scale=256, train_wall=30, gb_free=17.3, wall=24951
2025-11-07 23:40:36 | INFO | train_inner | epoch 001:  40171 / 91072 loss=0.75293, wps=393.6, ups=1.52, wpb=258.2, bsz=16, num_updates=40050, lr=8.9e-05, gnorm=8.858, clip=66, loss_scale=256, train_wall=33, gb_free=11.2, wall=24983
2025-11-07 23:41:07 | INFO | train_inner | epoch 001:  40221 / 91072 loss=0.712402, wps=374.7, ups=1.58, wpb=237, bsz=16, num_updates=40100, lr=8.91111e-05, gnorm=6.982, clip=56, loss_scale=256, train_wall=31, gb_free=17.7, wall=25015
2025-11-07 23:41:37 | INFO | train_inner | epoch 001:  40271 / 91072 loss=0.686035, wps=406.6, ups=1.65, wpb=246.1, bsz=16, num_updates=40150, lr=8.92222e-05, gnorm=6.975, clip=58, loss_scale=256, train_wall=30, gb_free=17.2, wall=25045
2025-11-07 23:42:07 | INFO | train_inner | epoch 001:  40321 / 91072 loss=0.806641, wps=398.1, ups=1.69, wpb=236.1, bsz=16, num_updates=40200, lr=8.93333e-05, gnorm=9.464, clip=70, loss_scale=256, train_wall=30, gb_free=16.8, wall=25075
2025-11-07 23:42:37 | INFO | train_inner | epoch 001:  40371 / 91072 loss=0.727539, wps=406.5, ups=1.65, wpb=246, bsz=16, num_updates=40250, lr=8.94444e-05, gnorm=8.753, clip=58, loss_scale=512, train_wall=30, gb_free=16.8, wall=25105
2025-11-07 23:43:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:43:09 | INFO | train_inner | epoch 001:  40422 / 91072 loss=0.717773, wps=393.9, ups=1.6, wpb=246.3, bsz=16, num_updates=40300, lr=8.95556e-05, gnorm=8.492, clip=64, loss_scale=256, train_wall=31, gb_free=18.7, wall=25137
2025-11-07 23:43:39 | INFO | train_inner | epoch 001:  40472 / 91072 loss=0.777832, wps=402.9, ups=1.66, wpb=242.2, bsz=16, num_updates=40350, lr=8.96667e-05, gnorm=7.878, clip=60, loss_scale=256, train_wall=30, gb_free=15.8, wall=25167
2025-11-07 23:44:09 | INFO | train_inner | epoch 001:  40522 / 91072 loss=0.654785, wps=408.3, ups=1.65, wpb=247.7, bsz=16, num_updates=40400, lr=8.97778e-05, gnorm=8.753, clip=68, loss_scale=256, train_wall=30, gb_free=17.6, wall=25197
2025-11-07 23:44:39 | INFO | train_inner | epoch 001:  40572 / 91072 loss=0.811523, wps=406.9, ups=1.66, wpb=245.5, bsz=16, num_updates=40450, lr=8.98889e-05, gnorm=11.079, clip=74, loss_scale=256, train_wall=30, gb_free=17.6, wall=25227
2025-11-07 23:45:10 | INFO | train_inner | epoch 001:  40622 / 91072 loss=0.819824, wps=404.7, ups=1.63, wpb=248, bsz=16, num_updates=40500, lr=9e-05, gnorm=9.82, clip=70, loss_scale=256, train_wall=30, gb_free=15.4, wall=25258
2025-11-07 23:45:40 | INFO | train_inner | epoch 001:  40672 / 91072 loss=0.777344, wps=396.7, ups=1.65, wpb=239.7, bsz=16, num_updates=40550, lr=9.01111e-05, gnorm=9.219, clip=68, loss_scale=512, train_wall=30, gb_free=15.9, wall=25288
2025-11-07 23:46:10 | INFO | train_inner | epoch 001:  40722 / 91072 loss=0.868164, wps=410.3, ups=1.65, wpb=248.4, bsz=16, num_updates=40600, lr=9.02222e-05, gnorm=10.266, clip=68, loss_scale=512, train_wall=30, gb_free=14.4, wall=25318
2025-11-07 23:46:40 | INFO | train_inner | epoch 001:  40772 / 91072 loss=0.765625, wps=406.6, ups=1.67, wpb=243.9, bsz=16, num_updates=40650, lr=9.03333e-05, gnorm=6.557, clip=56, loss_scale=512, train_wall=30, gb_free=16.8, wall=25348
2025-11-07 23:47:12 | INFO | train_inner | epoch 001:  40822 / 91072 loss=0.70166, wps=383, ups=1.57, wpb=243.8, bsz=16, num_updates=40700, lr=9.04444e-05, gnorm=7.535, clip=62, loss_scale=512, train_wall=32, gb_free=15.8, wall=25380
2025-11-07 23:47:43 | INFO | train_inner | epoch 001:  40872 / 91072 loss=0.844238, wps=408.5, ups=1.62, wpb=252.1, bsz=16, num_updates=40750, lr=9.05556e-05, gnorm=9.285, clip=68, loss_scale=512, train_wall=31, gb_free=18, wall=25411
2025-11-07 23:48:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:48:14 | INFO | train_inner | epoch 001:  40923 / 91072 loss=0.723145, wps=406.2, ups=1.6, wpb=254.4, bsz=16, num_updates=40800, lr=9.06667e-05, gnorm=9.282, clip=70, loss_scale=256, train_wall=31, gb_free=18.8, wall=25442
2025-11-07 23:48:45 | INFO | train_inner | epoch 001:  40973 / 91072 loss=0.79248, wps=398.6, ups=1.64, wpb=243.7, bsz=16, num_updates=40850, lr=9.07778e-05, gnorm=8.861, clip=62, loss_scale=256, train_wall=30, gb_free=14.1, wall=25473
2025-11-07 23:49:15 | INFO | train_inner | epoch 001:  41023 / 91072 loss=0.735352, wps=399, ups=1.68, wpb=236.9, bsz=16, num_updates=40900, lr=9.08889e-05, gnorm=8.198, clip=64, loss_scale=256, train_wall=30, gb_free=16.3, wall=25502
2025-11-07 23:49:45 | INFO | train_inner | epoch 001:  41073 / 91072 loss=0.757324, wps=402.3, ups=1.64, wpb=244.6, bsz=16, num_updates=40950, lr=9.1e-05, gnorm=8.571, clip=60, loss_scale=256, train_wall=30, gb_free=16.5, wall=25533
2025-11-07 23:50:16 | INFO | train_inner | epoch 001:  41123 / 91072 loss=0.726074, wps=381.2, ups=1.59, wpb=240.3, bsz=16, num_updates=41000, lr=9.11111e-05, gnorm=9.511, clip=68, loss_scale=256, train_wall=31, gb_free=14.9, wall=25564
2025-11-07 23:50:48 | INFO | train_inner | epoch 001:  41173 / 91072 loss=0.804199, wps=388.5, ups=1.6, wpb=242.9, bsz=16, num_updates=41050, lr=9.12222e-05, gnorm=7.747, clip=62, loss_scale=512, train_wall=31, gb_free=17.2, wall=25596
2025-11-07 23:51:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:51:19 | INFO | train_inner | epoch 001:  41224 / 91072 loss=0.753906, wps=375.6, ups=1.62, wpb=232.5, bsz=16, num_updates=41100, lr=9.13333e-05, gnorm=8.596, clip=60, loss_scale=256, train_wall=31, gb_free=16.7, wall=25627
2025-11-07 23:51:49 | INFO | train_inner | epoch 001:  41274 / 91072 loss=0.776367, wps=405.5, ups=1.65, wpb=245.9, bsz=16, num_updates=41150, lr=9.14444e-05, gnorm=10.747, clip=68, loss_scale=256, train_wall=30, gb_free=15.9, wall=25657
2025-11-07 23:52:19 | INFO | train_inner | epoch 001:  41324 / 91072 loss=0.835449, wps=407.2, ups=1.67, wpb=244.1, bsz=16, num_updates=41200, lr=9.15556e-05, gnorm=10.576, clip=76, loss_scale=256, train_wall=30, gb_free=16.6, wall=25687
2025-11-07 23:52:50 | INFO | train_inner | epoch 001:  41374 / 91072 loss=0.768066, wps=399.8, ups=1.63, wpb=245.4, bsz=16, num_updates=41250, lr=9.16667e-05, gnorm=9.948, clip=70, loss_scale=256, train_wall=31, gb_free=16.3, wall=25718
2025-11-07 23:53:20 | INFO | train_inner | epoch 001:  41424 / 91072 loss=0.770508, wps=403.7, ups=1.67, wpb=242.4, bsz=16, num_updates=41300, lr=9.17778e-05, gnorm=10.705, clip=74, loss_scale=256, train_wall=30, gb_free=17.3, wall=25748
2025-11-07 23:53:49 | INFO | train_inner | epoch 001:  41474 / 91072 loss=0.76123, wps=390.6, ups=1.69, wpb=231.7, bsz=16, num_updates=41350, lr=9.18889e-05, gnorm=10.451, clip=66, loss_scale=512, train_wall=30, gb_free=16.4, wall=25777
2025-11-07 23:54:20 | INFO | train_inner | epoch 001:  41524 / 91072 loss=0.793457, wps=407.3, ups=1.66, wpb=245.9, bsz=16, num_updates=41400, lr=9.2e-05, gnorm=9.194, clip=72, loss_scale=512, train_wall=30, gb_free=17.8, wall=25807
2025-11-07 23:54:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:54:50 | INFO | train_inner | epoch 001:  41575 / 91072 loss=0.767578, wps=386.7, ups=1.63, wpb=237.6, bsz=16, num_updates=41450, lr=9.21111e-05, gnorm=9.753, clip=72, loss_scale=256, train_wall=31, gb_free=15.1, wall=25838
2025-11-07 23:55:20 | INFO | train_inner | epoch 001:  41625 / 91072 loss=0.750488, wps=393.3, ups=1.68, wpb=234.6, bsz=16, num_updates=41500, lr=9.22222e-05, gnorm=9.262, clip=70, loss_scale=256, train_wall=30, gb_free=17.8, wall=25868
2025-11-07 23:55:50 | INFO | train_inner | epoch 001:  41675 / 91072 loss=0.833984, wps=400.7, ups=1.65, wpb=242.3, bsz=16, num_updates=41550, lr=9.23333e-05, gnorm=9.988, clip=70, loss_scale=256, train_wall=30, gb_free=12.8, wall=25898
2025-11-07 23:56:20 | INFO | train_inner | epoch 001:  41725 / 91072 loss=0.732422, wps=397.2, ups=1.66, wpb=239.1, bsz=16, num_updates=41600, lr=9.24444e-05, gnorm=8.754, clip=70, loss_scale=256, train_wall=30, gb_free=12.5, wall=25928
2025-11-07 23:56:51 | INFO | train_inner | epoch 001:  41775 / 91072 loss=0.714844, wps=391.5, ups=1.61, wpb=243.2, bsz=16, num_updates=41650, lr=9.25556e-05, gnorm=8.206, clip=62, loss_scale=256, train_wall=31, gb_free=14.5, wall=25959
2025-11-07 23:57:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-07 23:57:22 | INFO | train_inner | epoch 001:  41826 / 91072 loss=0.742188, wps=396.5, ups=1.63, wpb=243.4, bsz=16, num_updates=41700, lr=9.26667e-05, gnorm=7.578, clip=64, loss_scale=256, train_wall=31, gb_free=17.6, wall=25990
2025-11-07 23:57:52 | INFO | train_inner | epoch 001:  41876 / 91072 loss=0.748535, wps=404.1, ups=1.66, wpb=243.5, bsz=16, num_updates=41750, lr=9.27778e-05, gnorm=8.394, clip=64, loss_scale=256, train_wall=30, gb_free=18.2, wall=26020
2025-11-07 23:58:23 | INFO | train_inner | epoch 001:  41926 / 91072 loss=0.742676, wps=414.5, ups=1.62, wpb=255.9, bsz=16, num_updates=41800, lr=9.28889e-05, gnorm=9.585, clip=78, loss_scale=256, train_wall=31, gb_free=15.8, wall=26051
2025-11-07 23:58:54 | INFO | train_inner | epoch 001:  41976 / 91072 loss=0.789551, wps=406.7, ups=1.62, wpb=251.6, bsz=16, num_updates=41850, lr=9.3e-05, gnorm=7.303, clip=54, loss_scale=256, train_wall=31, gb_free=18.5, wall=26082
2025-11-07 23:59:24 | INFO | train_inner | epoch 001:  42026 / 91072 loss=0.773926, wps=396.2, ups=1.7, wpb=233, bsz=16, num_updates=41900, lr=9.31111e-05, gnorm=10.822, clip=78, loss_scale=256, train_wall=29, gb_free=15.9, wall=26111
2025-11-07 23:59:53 | INFO | train_inner | epoch 001:  42076 / 91072 loss=0.75293, wps=397.6, ups=1.69, wpb=235.9, bsz=16, num_updates=41950, lr=9.32222e-05, gnorm=9.119, clip=72, loss_scale=512, train_wall=30, gb_free=19.1, wall=26141
2025-11-07 23:59:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:00:24 | INFO | train_inner | epoch 001:  42127 / 91072 loss=0.797363, wps=389.5, ups=1.62, wpb=240.5, bsz=16, num_updates=42000, lr=9.33333e-05, gnorm=8.828, clip=68, loss_scale=256, train_wall=31, gb_free=17.5, wall=26172
2025-11-08 00:00:55 | INFO | train_inner | epoch 001:  42177 / 91072 loss=0.782227, wps=417.9, ups=1.62, wpb=257.8, bsz=16, num_updates=42050, lr=9.34444e-05, gnorm=7.507, clip=56, loss_scale=256, train_wall=31, gb_free=15.2, wall=26203
2025-11-08 00:01:25 | INFO | train_inner | epoch 001:  42227 / 91072 loss=0.742676, wps=400.4, ups=1.67, wpb=240, bsz=16, num_updates=42100, lr=9.35556e-05, gnorm=7.181, clip=56, loss_scale=256, train_wall=30, gb_free=17.8, wall=26233
2025-11-08 00:01:56 | INFO | train_inner | epoch 001:  42277 / 91072 loss=0.690918, wps=384.5, ups=1.6, wpb=240.7, bsz=16, num_updates=42150, lr=9.36667e-05, gnorm=8.145, clip=62, loss_scale=256, train_wall=31, gb_free=12.4, wall=26264
2025-11-08 00:02:27 | INFO | train_inner | epoch 001:  42327 / 91072 loss=0.835449, wps=405, ups=1.61, wpb=251.7, bsz=16, num_updates=42200, lr=9.37778e-05, gnorm=8.662, clip=62, loss_scale=256, train_wall=31, gb_free=17.7, wall=26295
2025-11-08 00:02:58 | INFO | train_inner | epoch 001:  42377 / 91072 loss=0.78418, wps=409, ups=1.64, wpb=249.7, bsz=16, num_updates=42250, lr=9.38889e-05, gnorm=9.251, clip=62, loss_scale=512, train_wall=30, gb_free=15.6, wall=26326
2025-11-08 00:03:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:03:29 | INFO | train_inner | epoch 001:  42428 / 91072 loss=0.802246, wps=385.9, ups=1.62, wpb=238.9, bsz=16, num_updates=42300, lr=9.4e-05, gnorm=8.908, clip=70, loss_scale=256, train_wall=31, gb_free=12.8, wall=26357
2025-11-08 00:03:59 | INFO | train_inner | epoch 001:  42478 / 91072 loss=0.710938, wps=406.6, ups=1.63, wpb=248.9, bsz=16, num_updates=42350, lr=9.41111e-05, gnorm=9.036, clip=78, loss_scale=256, train_wall=30, gb_free=13, wall=26387
2025-11-08 00:04:30 | INFO | train_inner | epoch 001:  42528 / 91072 loss=0.795898, wps=386.9, ups=1.61, wpb=239.9, bsz=16, num_updates=42400, lr=9.42222e-05, gnorm=12.181, clip=82, loss_scale=256, train_wall=31, gb_free=17.6, wall=26418
2025-11-08 00:05:01 | INFO | train_inner | epoch 001:  42578 / 91072 loss=0.769531, wps=400.7, ups=1.65, wpb=242.6, bsz=16, num_updates=42450, lr=9.43333e-05, gnorm=8.101, clip=64, loss_scale=256, train_wall=30, gb_free=17.9, wall=26449
2025-11-08 00:05:31 | INFO | train_inner | epoch 001:  42628 / 91072 loss=0.755859, wps=407.9, ups=1.63, wpb=249.8, bsz=16, num_updates=42500, lr=9.44444e-05, gnorm=8.467, clip=64, loss_scale=256, train_wall=30, gb_free=12.4, wall=26479
2025-11-08 00:06:02 | INFO | train_inner | epoch 001:  42678 / 91072 loss=0.768066, wps=402.8, ups=1.64, wpb=246, bsz=16, num_updates=42550, lr=9.45556e-05, gnorm=10.115, clip=74, loss_scale=512, train_wall=30, gb_free=13.9, wall=26510
2025-11-08 00:06:32 | INFO | train_inner | epoch 001:  42728 / 91072 loss=0.76709, wps=391.9, ups=1.65, wpb=238.1, bsz=16, num_updates=42600, lr=9.46667e-05, gnorm=8.287, clip=62, loss_scale=512, train_wall=30, gb_free=16.4, wall=26540
2025-11-08 00:07:03 | INFO | train_inner | epoch 001:  42778 / 91072 loss=0.756836, wps=416.9, ups=1.62, wpb=258, bsz=16, num_updates=42650, lr=9.47778e-05, gnorm=10.613, clip=80, loss_scale=512, train_wall=31, gb_free=15.1, wall=26571
2025-11-08 00:07:34 | INFO | train_inner | epoch 001:  42828 / 91072 loss=0.769043, wps=404.3, ups=1.64, wpb=247.2, bsz=16, num_updates=42700, lr=9.48889e-05, gnorm=8.295, clip=62, loss_scale=512, train_wall=30, gb_free=17.9, wall=26602
2025-11-08 00:07:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:08:05 | INFO | train_inner | epoch 001:  42879 / 91072 loss=0.82373, wps=394.9, ups=1.61, wpb=244.6, bsz=16, num_updates=42750, lr=9.5e-05, gnorm=8.676, clip=66, loss_scale=256, train_wall=31, gb_free=17.8, wall=26633
2025-11-08 00:08:35 | INFO | train_inner | epoch 001:  42929 / 91072 loss=0.752441, wps=395.9, ups=1.65, wpb=240.1, bsz=16, num_updates=42800, lr=9.51111e-05, gnorm=8.616, clip=62, loss_scale=256, train_wall=30, gb_free=17.5, wall=26663
2025-11-08 00:09:05 | INFO | train_inner | epoch 001:  42979 / 91072 loss=0.766113, wps=400.9, ups=1.64, wpb=244.9, bsz=16, num_updates=42850, lr=9.52222e-05, gnorm=9.927, clip=68, loss_scale=256, train_wall=30, gb_free=8.9, wall=26693
2025-11-08 00:09:36 | INFO | train_inner | epoch 001:  43029 / 91072 loss=0.72998, wps=408.3, ups=1.67, wpb=245.1, bsz=16, num_updates=42900, lr=9.53333e-05, gnorm=7.035, clip=50, loss_scale=256, train_wall=30, gb_free=17.7, wall=26723
2025-11-08 00:10:06 | INFO | train_inner | epoch 001:  43079 / 91072 loss=0.717285, wps=401.6, ups=1.62, wpb=247.2, bsz=16, num_updates=42950, lr=9.54444e-05, gnorm=8.91, clip=66, loss_scale=256, train_wall=31, gb_free=15.6, wall=26754
2025-11-08 00:10:36 | INFO | train_inner | epoch 001:  43129 / 91072 loss=0.793945, wps=400.2, ups=1.68, wpb=238.4, bsz=16, num_updates=43000, lr=9.55556e-05, gnorm=9.811, clip=72, loss_scale=512, train_wall=30, gb_free=16.4, wall=26784
2025-11-08 00:10:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:11:07 | INFO | train_inner | epoch 001:  43180 / 91072 loss=0.792969, wps=403.5, ups=1.59, wpb=253, bsz=16, num_updates=43050, lr=9.56667e-05, gnorm=10.65, clip=76, loss_scale=256, train_wall=31, gb_free=17.1, wall=26815
2025-11-08 00:11:38 | INFO | train_inner | epoch 001:  43230 / 91072 loss=0.763672, wps=400.3, ups=1.64, wpb=244.2, bsz=16, num_updates=43100, lr=9.57778e-05, gnorm=7.84, clip=64, loss_scale=256, train_wall=30, gb_free=10.8, wall=26846
2025-11-08 00:12:08 | INFO | train_inner | epoch 001:  43280 / 91072 loss=0.725098, wps=397.6, ups=1.64, wpb=242.6, bsz=16, num_updates=43150, lr=9.58889e-05, gnorm=9.109, clip=64, loss_scale=256, train_wall=30, gb_free=17.9, wall=26876
2025-11-08 00:12:39 | INFO | train_inner | epoch 001:  43330 / 91072 loss=0.725586, wps=402.5, ups=1.66, wpb=243.1, bsz=16, num_updates=43200, lr=9.6e-05, gnorm=7.296, clip=66, loss_scale=256, train_wall=30, gb_free=18.7, wall=26907
2025-11-08 00:13:09 | INFO | train_inner | epoch 001:  43380 / 91072 loss=0.782715, wps=404.9, ups=1.64, wpb=246.2, bsz=16, num_updates=43250, lr=9.61111e-05, gnorm=9.78, clip=66, loss_scale=256, train_wall=30, gb_free=18.5, wall=26937
2025-11-08 00:13:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:13:40 | INFO | train_inner | epoch 001:  43431 / 91072 loss=0.754883, wps=402.7, ups=1.59, wpb=252.6, bsz=16, num_updates=43300, lr=9.62222e-05, gnorm=10.021, clip=86, loss_scale=256, train_wall=31, gb_free=7.7, wall=26968
2025-11-08 00:14:11 | INFO | train_inner | epoch 001:  43481 / 91072 loss=0.706055, wps=402.4, ups=1.61, wpb=249.2, bsz=16, num_updates=43350, lr=9.63333e-05, gnorm=7.19, clip=54, loss_scale=256, train_wall=31, gb_free=18.2, wall=26999
2025-11-08 00:14:42 | INFO | train_inner | epoch 001:  43531 / 91072 loss=0.804199, wps=407.4, ups=1.63, wpb=249.9, bsz=16, num_updates=43400, lr=9.64444e-05, gnorm=10.233, clip=74, loss_scale=256, train_wall=31, gb_free=18.6, wall=27030
2025-11-08 00:15:13 | INFO | train_inner | epoch 001:  43581 / 91072 loss=0.782715, wps=410.1, ups=1.64, wpb=250.8, bsz=16, num_updates=43450, lr=9.65556e-05, gnorm=8.475, clip=70, loss_scale=256, train_wall=30, gb_free=18.2, wall=27061
2025-11-08 00:15:44 | INFO | train_inner | epoch 001:  43631 / 91072 loss=0.786133, wps=403.4, ups=1.62, wpb=249.3, bsz=16, num_updates=43500, lr=9.66667e-05, gnorm=10.611, clip=76, loss_scale=256, train_wall=31, gb_free=10.1, wall=27091
2025-11-08 00:16:15 | INFO | train_inner | epoch 001:  43681 / 91072 loss=0.79248, wps=408.6, ups=1.6, wpb=255.7, bsz=16, num_updates=43550, lr=9.67778e-05, gnorm=9.41, clip=72, loss_scale=512, train_wall=31, gb_free=14.5, wall=27123
2025-11-08 00:16:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:16:46 | INFO | train_inner | epoch 001:  43732 / 91072 loss=0.692383, wps=397.2, ups=1.59, wpb=249.3, bsz=16, num_updates=43600, lr=9.68889e-05, gnorm=8.851, clip=70, loss_scale=256, train_wall=31, gb_free=19.1, wall=27154
2025-11-08 00:17:16 | INFO | train_inner | epoch 001:  43782 / 91072 loss=0.783203, wps=393.3, ups=1.67, wpb=235.9, bsz=16, num_updates=43650, lr=9.7e-05, gnorm=9.64, clip=70, loss_scale=256, train_wall=30, gb_free=16.8, wall=27184
2025-11-08 00:17:47 | INFO | train_inner | epoch 001:  43832 / 91072 loss=0.723633, wps=405.8, ups=1.62, wpb=251.2, bsz=16, num_updates=43700, lr=9.71111e-05, gnorm=7.435, clip=56, loss_scale=256, train_wall=31, gb_free=16.9, wall=27215
2025-11-08 00:18:22 | INFO | train_inner | epoch 001:  43882 / 91072 loss=0.836914, wps=344.9, ups=1.43, wpb=240.7, bsz=16, num_updates=43750, lr=9.72222e-05, gnorm=8.556, clip=64, loss_scale=256, train_wall=35, gb_free=17.7, wall=27250
2025-11-08 00:18:52 | INFO | train_inner | epoch 001:  43932 / 91072 loss=0.830566, wps=388.6, ups=1.67, wpb=233.1, bsz=16, num_updates=43800, lr=9.73333e-05, gnorm=9.815, clip=70, loss_scale=256, train_wall=30, gb_free=17.9, wall=27280
2025-11-08 00:19:23 | INFO | train_inner | epoch 001:  43982 / 91072 loss=0.902344, wps=407.6, ups=1.63, wpb=249.8, bsz=16, num_updates=43850, lr=9.74444e-05, gnorm=10.473, clip=72, loss_scale=256, train_wall=30, gb_free=17.6, wall=27311
2025-11-08 00:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:19:55 | INFO | train_inner | epoch 001:  44033 / 91072 loss=0.789062, wps=362.7, ups=1.57, wpb=231.3, bsz=16, num_updates=43900, lr=9.75556e-05, gnorm=9.903, clip=70, loss_scale=256, train_wall=32, gb_free=16.1, wall=27342
2025-11-08 00:20:28 | INFO | train_inner | epoch 001:  44083 / 91072 loss=0.789062, wps=383.1, ups=1.51, wpb=254.2, bsz=16, num_updates=43950, lr=9.76667e-05, gnorm=8.459, clip=64, loss_scale=256, train_wall=33, gb_free=17.3, wall=27376
2025-11-08 00:20:58 | INFO | train_inner | epoch 001:  44133 / 91072 loss=0.786133, wps=409.3, ups=1.63, wpb=250.8, bsz=16, num_updates=44000, lr=9.77778e-05, gnorm=8.784, clip=58, loss_scale=256, train_wall=30, gb_free=16.8, wall=27406
2025-11-08 00:21:29 | INFO | train_inner | epoch 001:  44183 / 91072 loss=0.745117, wps=396.8, ups=1.65, wpb=240.6, bsz=16, num_updates=44050, lr=9.78889e-05, gnorm=7.241, clip=56, loss_scale=256, train_wall=30, gb_free=11.6, wall=27437
2025-11-08 00:22:03 | INFO | train_inner | epoch 001:  44233 / 91072 loss=0.777344, wps=367.4, ups=1.46, wpb=251.1, bsz=16, num_updates=44100, lr=9.8e-05, gnorm=8.631, clip=58, loss_scale=256, train_wall=34, gb_free=14.9, wall=27471
2025-11-08 00:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:22:37 | INFO | train_inner | epoch 001:  44284 / 91072 loss=0.791504, wps=377.8, ups=1.48, wpb=254.6, bsz=16, num_updates=44150, lr=9.81111e-05, gnorm=8.323, clip=52, loss_scale=256, train_wall=33, gb_free=17.3, wall=27505
2025-11-08 00:23:07 | INFO | train_inner | epoch 001:  44334 / 91072 loss=0.76123, wps=397.1, ups=1.65, wpb=240.1, bsz=16, num_updates=44200, lr=9.82222e-05, gnorm=8.914, clip=64, loss_scale=256, train_wall=30, gb_free=17.6, wall=27535
2025-11-08 00:23:38 | INFO | train_inner | epoch 001:  44384 / 91072 loss=0.744629, wps=409.7, ups=1.62, wpb=252.4, bsz=16, num_updates=44250, lr=9.83333e-05, gnorm=8.333, clip=70, loss_scale=256, train_wall=31, gb_free=17.4, wall=27566
2025-11-08 00:24:09 | INFO | train_inner | epoch 001:  44434 / 91072 loss=0.807129, wps=403.2, ups=1.58, wpb=254.6, bsz=16, num_updates=44300, lr=9.84444e-05, gnorm=9.185, clip=70, loss_scale=256, train_wall=31, gb_free=9.9, wall=27597
2025-11-08 00:24:40 | INFO | train_inner | epoch 001:  44484 / 91072 loss=0.730957, wps=413.6, ups=1.61, wpb=256.9, bsz=16, num_updates=44350, lr=9.85556e-05, gnorm=9.302, clip=74, loss_scale=256, train_wall=31, gb_free=14.6, wall=27628
2025-11-08 00:25:11 | INFO | train_inner | epoch 001:  44534 / 91072 loss=0.897949, wps=405.4, ups=1.65, wpb=245.5, bsz=16, num_updates=44400, lr=9.86667e-05, gnorm=9.312, clip=64, loss_scale=512, train_wall=30, gb_free=14.3, wall=27658
2025-11-08 00:25:41 | INFO | train_inner | epoch 001:  44584 / 91072 loss=0.8125, wps=405.9, ups=1.66, wpb=244.1, bsz=16, num_updates=44450, lr=9.87778e-05, gnorm=9.575, clip=70, loss_scale=512, train_wall=30, gb_free=16.5, wall=27689
2025-11-08 00:25:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:26:11 | INFO | train_inner | epoch 001:  44635 / 91072 loss=0.756836, wps=383.7, ups=1.64, wpb=234.6, bsz=16, num_updates=44500, lr=9.88889e-05, gnorm=7.3, clip=60, loss_scale=256, train_wall=30, gb_free=17.3, wall=27719
2025-11-08 00:26:41 | INFO | train_inner | epoch 001:  44685 / 91072 loss=0.818848, wps=408.5, ups=1.66, wpb=246.8, bsz=16, num_updates=44550, lr=9.9e-05, gnorm=9.921, clip=68, loss_scale=256, train_wall=30, gb_free=17.5, wall=27749
2025-11-08 00:27:11 | INFO | train_inner | epoch 001:  44735 / 91072 loss=0.793457, wps=398.5, ups=1.67, wpb=238.7, bsz=16, num_updates=44600, lr=9.91111e-05, gnorm=8.06, clip=68, loss_scale=256, train_wall=30, gb_free=17, wall=27779
2025-11-08 00:27:42 | INFO | train_inner | epoch 001:  44785 / 91072 loss=0.757324, wps=411.9, ups=1.65, wpb=250.2, bsz=16, num_updates=44650, lr=9.92222e-05, gnorm=8.721, clip=64, loss_scale=256, train_wall=30, gb_free=14.3, wall=27810
2025-11-08 00:28:12 | INFO | train_inner | epoch 001:  44835 / 91072 loss=0.810547, wps=406.1, ups=1.63, wpb=248.6, bsz=16, num_updates=44700, lr=9.93333e-05, gnorm=9.523, clip=74, loss_scale=256, train_wall=30, gb_free=15, wall=27840
2025-11-08 00:28:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:28:45 | INFO | train_inner | epoch 001:  44886 / 91072 loss=0.78125, wps=392, ups=1.55, wpb=252.4, bsz=16, num_updates=44750, lr=9.94444e-05, gnorm=8.535, clip=50, loss_scale=256, train_wall=32, gb_free=17.5, wall=27872
2025-11-08 00:29:16 | INFO | train_inner | epoch 001:  44936 / 91072 loss=0.741699, wps=396.7, ups=1.6, wpb=248.5, bsz=16, num_updates=44800, lr=9.95556e-05, gnorm=7.456, clip=64, loss_scale=256, train_wall=31, gb_free=18.2, wall=27904
2025-11-08 00:29:47 | INFO | train_inner | epoch 001:  44986 / 91072 loss=0.822266, wps=413.2, ups=1.6, wpb=258.9, bsz=16, num_updates=44850, lr=9.96667e-05, gnorm=8.618, clip=60, loss_scale=256, train_wall=31, gb_free=17.6, wall=27935
2025-11-08 00:30:19 | INFO | train_inner | epoch 001:  45036 / 91072 loss=0.71582, wps=378.2, ups=1.59, wpb=238.3, bsz=16, num_updates=44900, lr=9.97778e-05, gnorm=8.761, clip=64, loss_scale=256, train_wall=31, gb_free=17.7, wall=27967
2025-11-08 00:30:50 | INFO | train_inner | epoch 001:  45086 / 91072 loss=0.787598, wps=382.4, ups=1.58, wpb=242.2, bsz=16, num_updates=44950, lr=9.98889e-05, gnorm=9.222, clip=64, loss_scale=256, train_wall=31, gb_free=16.3, wall=27998
2025-11-08 00:31:20 | INFO | train_inner | epoch 001:  45136 / 91072 loss=0.814453, wps=396.6, ups=1.68, wpb=235.7, bsz=16, num_updates=45000, lr=0.0001, gnorm=8.647, clip=70, loss_scale=512, train_wall=30, gb_free=16.8, wall=28028
2025-11-08 00:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:31:54 | INFO | train_inner | epoch 001:  45187 / 91072 loss=0.768066, wps=354.2, ups=1.46, wpb=242.2, bsz=16, num_updates=45050, lr=9.99963e-05, gnorm=10.268, clip=62, loss_scale=256, train_wall=34, gb_free=16.8, wall=28062
2025-11-08 00:32:26 | INFO | train_inner | epoch 001:  45237 / 91072 loss=0.789551, wps=393.8, ups=1.58, wpb=248.6, bsz=16, num_updates=45100, lr=9.99926e-05, gnorm=8.915, clip=62, loss_scale=256, train_wall=31, gb_free=17.6, wall=28094
2025-11-08 00:32:57 | INFO | train_inner | epoch 001:  45287 / 91072 loss=0.803711, wps=393.6, ups=1.63, wpb=241.8, bsz=16, num_updates=45150, lr=9.99889e-05, gnorm=8.793, clip=62, loss_scale=256, train_wall=31, gb_free=18.5, wall=28124
2025-11-08 00:33:27 | INFO | train_inner | epoch 001:  45337 / 91072 loss=0.814941, wps=407.6, ups=1.63, wpb=250.7, bsz=16, num_updates=45200, lr=9.99852e-05, gnorm=10.389, clip=80, loss_scale=256, train_wall=31, gb_free=14.3, wall=28155
2025-11-08 00:33:58 | INFO | train_inner | epoch 001:  45387 / 91072 loss=0.788086, wps=388.4, ups=1.64, wpb=236.4, bsz=16, num_updates=45250, lr=9.99816e-05, gnorm=9.395, clip=66, loss_scale=256, train_wall=30, gb_free=18.1, wall=28186
2025-11-08 00:34:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:34:29 | INFO | train_inner | epoch 001:  45438 / 91072 loss=0.758301, wps=401, ups=1.63, wpb=246.6, bsz=16, num_updates=45300, lr=9.99779e-05, gnorm=7.882, clip=68, loss_scale=256, train_wall=31, gb_free=16.9, wall=28216
2025-11-08 00:34:59 | INFO | train_inner | epoch 001:  45488 / 91072 loss=0.77832, wps=395.2, ups=1.66, wpb=237.5, bsz=16, num_updates=45350, lr=9.99742e-05, gnorm=7.688, clip=62, loss_scale=256, train_wall=30, gb_free=14.9, wall=28246
2025-11-08 00:35:29 | INFO | train_inner | epoch 001:  45538 / 91072 loss=0.757812, wps=410.4, ups=1.62, wpb=253.3, bsz=16, num_updates=45400, lr=9.99705e-05, gnorm=9.476, clip=68, loss_scale=256, train_wall=31, gb_free=17.9, wall=28277
2025-11-08 00:36:00 | INFO | train_inner | epoch 001:  45588 / 91072 loss=0.711426, wps=407.2, ups=1.63, wpb=249.1, bsz=16, num_updates=45450, lr=9.99668e-05, gnorm=8.224, clip=64, loss_scale=256, train_wall=30, gb_free=17.2, wall=28308
2025-11-08 00:36:30 | INFO | train_inner | epoch 001:  45638 / 91072 loss=0.79541, wps=406.4, ups=1.66, wpb=244.9, bsz=16, num_updates=45500, lr=9.99631e-05, gnorm=9.319, clip=70, loss_scale=256, train_wall=30, gb_free=18.1, wall=28338
2025-11-08 00:37:00 | INFO | train_inner | epoch 001:  45688 / 91072 loss=0.746582, wps=402.5, ups=1.68, wpb=238.9, bsz=16, num_updates=45550, lr=9.99594e-05, gnorm=8.581, clip=68, loss_scale=512, train_wall=30, gb_free=17.8, wall=28368
2025-11-08 00:37:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:37:30 | INFO | train_inner | epoch 001:  45739 / 91072 loss=0.775879, wps=395.9, ups=1.63, wpb=242.8, bsz=16, num_updates=45600, lr=9.99557e-05, gnorm=8.264, clip=66, loss_scale=256, train_wall=31, gb_free=17.5, wall=28398
2025-11-08 00:38:01 | INFO | train_inner | epoch 001:  45789 / 91072 loss=0.740723, wps=393.2, ups=1.66, wpb=236.9, bsz=16, num_updates=45650, lr=9.9952e-05, gnorm=10.317, clip=72, loss_scale=256, train_wall=30, gb_free=14.7, wall=28429
2025-11-08 00:38:30 | INFO | train_inner | epoch 001:  45839 / 91072 loss=0.775879, wps=398.9, ups=1.68, wpb=237.2, bsz=16, num_updates=45700, lr=9.99483e-05, gnorm=7.975, clip=60, loss_scale=256, train_wall=30, gb_free=18.4, wall=28458
2025-11-08 00:39:01 | INFO | train_inner | epoch 001:  45889 / 91072 loss=0.723145, wps=403.3, ups=1.62, wpb=249.7, bsz=16, num_updates=45750, lr=9.99446e-05, gnorm=7.906, clip=68, loss_scale=256, train_wall=31, gb_free=18.1, wall=28489
2025-11-08 00:39:32 | INFO | train_inner | epoch 001:  45939 / 91072 loss=0.723633, wps=399.5, ups=1.62, wpb=246.7, bsz=16, num_updates=45800, lr=9.9941e-05, gnorm=9.529, clip=70, loss_scale=256, train_wall=31, gb_free=17.8, wall=28520
2025-11-08 00:40:04 | INFO | train_inner | epoch 001:  45989 / 91072 loss=0.75293, wps=390.4, ups=1.59, wpb=245.4, bsz=16, num_updates=45850, lr=9.99373e-05, gnorm=7.494, clip=66, loss_scale=512, train_wall=31, gb_free=16.3, wall=28552
2025-11-08 00:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:40:35 | INFO | train_inner | epoch 001:  46040 / 91072 loss=0.709473, wps=407.5, ups=1.58, wpb=257.6, bsz=16, num_updates=45900, lr=9.99336e-05, gnorm=8.703, clip=64, loss_scale=256, train_wall=31, gb_free=15, wall=28583
2025-11-08 00:41:05 | INFO | train_inner | epoch 001:  46090 / 91072 loss=0.803711, wps=391, ups=1.67, wpb=233.6, bsz=16, num_updates=45950, lr=9.99299e-05, gnorm=9.71, clip=66, loss_scale=256, train_wall=30, gb_free=18.9, wall=28613
2025-11-08 00:41:38 | INFO | train_inner | epoch 001:  46140 / 91072 loss=0.76416, wps=387.1, ups=1.51, wpb=256.1, bsz=16, num_updates=46000, lr=9.99262e-05, gnorm=9.356, clip=68, loss_scale=256, train_wall=33, gb_free=16.8, wall=28646
2025-11-08 00:42:09 | INFO | train_inner | epoch 001:  46190 / 91072 loss=0.748047, wps=405.9, ups=1.64, wpb=247.5, bsz=16, num_updates=46050, lr=9.99225e-05, gnorm=7.878, clip=56, loss_scale=256, train_wall=30, gb_free=17.9, wall=28677
2025-11-08 00:42:38 | INFO | train_inner | epoch 001:  46240 / 91072 loss=0.73291, wps=393.3, ups=1.68, wpb=234.5, bsz=16, num_updates=46100, lr=9.99188e-05, gnorm=9.176, clip=72, loss_scale=256, train_wall=30, gb_free=17.1, wall=28706
2025-11-08 00:42:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:43:10 | INFO | train_inner | epoch 001:  46291 / 91072 loss=0.730469, wps=411.1, ups=1.57, wpb=261.4, bsz=16, num_updates=46150, lr=9.99151e-05, gnorm=8.928, clip=72, loss_scale=256, train_wall=32, gb_free=8.8, wall=28738
2025-11-08 00:43:41 | INFO | train_inner | epoch 001:  46341 / 91072 loss=0.785156, wps=393.7, ups=1.65, wpb=239.3, bsz=16, num_updates=46200, lr=9.99114e-05, gnorm=9.779, clip=72, loss_scale=256, train_wall=30, gb_free=15.9, wall=28769
2025-11-08 00:44:11 | INFO | train_inner | epoch 001:  46391 / 91072 loss=0.780762, wps=393, ups=1.66, wpb=236.3, bsz=16, num_updates=46250, lr=9.99078e-05, gnorm=9.298, clip=64, loss_scale=256, train_wall=30, gb_free=15.2, wall=28799
2025-11-08 00:44:40 | INFO | train_inner | epoch 001:  46441 / 91072 loss=0.760254, wps=388.7, ups=1.68, wpb=231.3, bsz=16, num_updates=46300, lr=9.99041e-05, gnorm=9.006, clip=72, loss_scale=256, train_wall=30, gb_free=15.9, wall=28828
2025-11-08 00:45:11 | INFO | train_inner | epoch 001:  46491 / 91072 loss=0.794434, wps=418.9, ups=1.63, wpb=256.8, bsz=16, num_updates=46350, lr=9.99004e-05, gnorm=9.03, clip=74, loss_scale=256, train_wall=30, gb_free=17.9, wall=28859
2025-11-08 00:45:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:45:43 | INFO | train_inner | epoch 001:  46542 / 91072 loss=0.760742, wps=381.2, ups=1.57, wpb=242.2, bsz=16, num_updates=46400, lr=9.98967e-05, gnorm=9.181, clip=64, loss_scale=256, train_wall=32, gb_free=17.8, wall=28891
2025-11-08 00:46:13 | INFO | train_inner | epoch 001:  46592 / 91072 loss=0.817383, wps=398.1, ups=1.68, wpb=236.5, bsz=16, num_updates=46450, lr=9.9893e-05, gnorm=10.06, clip=60, loss_scale=256, train_wall=30, gb_free=18, wall=28921
2025-11-08 00:46:44 | INFO | train_inner | epoch 001:  46642 / 91072 loss=0.802246, wps=387.3, ups=1.61, wpb=239.9, bsz=16, num_updates=46500, lr=9.98893e-05, gnorm=9.19, clip=70, loss_scale=256, train_wall=31, gb_free=18.2, wall=28952
2025-11-08 00:47:15 | INFO | train_inner | epoch 001:  46692 / 91072 loss=0.743652, wps=400.5, ups=1.6, wpb=249.8, bsz=16, num_updates=46550, lr=9.98856e-05, gnorm=7.706, clip=66, loss_scale=256, train_wall=31, gb_free=17.6, wall=28983
2025-11-08 00:47:46 | INFO | train_inner | epoch 001:  46742 / 91072 loss=0.825195, wps=385.3, ups=1.61, wpb=239.4, bsz=16, num_updates=46600, lr=9.98819e-05, gnorm=9.337, clip=68, loss_scale=256, train_wall=31, gb_free=17.2, wall=29014
2025-11-08 00:48:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:48:17 | INFO | train_inner | epoch 001:  46793 / 91072 loss=0.771484, wps=391.7, ups=1.63, wpb=240.8, bsz=16, num_updates=46650, lr=9.98782e-05, gnorm=8.659, clip=66, loss_scale=256, train_wall=31, gb_free=19.1, wall=29045
2025-11-08 00:48:48 | INFO | train_inner | epoch 001:  46843 / 91072 loss=0.710938, wps=375.6, ups=1.6, wpb=235.1, bsz=16, num_updates=46700, lr=9.98745e-05, gnorm=9.697, clip=68, loss_scale=256, train_wall=31, gb_free=18.7, wall=29076
2025-11-08 00:49:18 | INFO | train_inner | epoch 001:  46893 / 91072 loss=0.67627, wps=405.4, ups=1.64, wpb=247.6, bsz=16, num_updates=46750, lr=9.98708e-05, gnorm=7.271, clip=62, loss_scale=256, train_wall=30, gb_free=19, wall=29106
2025-11-08 00:49:49 | INFO | train_inner | epoch 001:  46943 / 91072 loss=0.783203, wps=404.9, ups=1.62, wpb=249.2, bsz=16, num_updates=46800, lr=9.98672e-05, gnorm=9.496, clip=70, loss_scale=256, train_wall=31, gb_free=16.5, wall=29137
2025-11-08 00:50:19 | INFO | train_inner | epoch 001:  46993 / 91072 loss=0.766602, wps=405.3, ups=1.66, wpb=243.7, bsz=16, num_updates=46850, lr=9.98635e-05, gnorm=10.336, clip=64, loss_scale=256, train_wall=30, gb_free=12.8, wall=29167
2025-11-08 00:50:50 | INFO | train_inner | epoch 001:  47043 / 91072 loss=0.767578, wps=414.3, ups=1.63, wpb=253.8, bsz=16, num_updates=46900, lr=9.98598e-05, gnorm=8.241, clip=70, loss_scale=512, train_wall=30, gb_free=17.7, wall=29198
2025-11-08 00:51:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:51:21 | INFO | train_inner | epoch 001:  47094 / 91072 loss=0.739258, wps=404.9, ups=1.59, wpb=253.9, bsz=16, num_updates=46950, lr=9.98561e-05, gnorm=8.431, clip=66, loss_scale=256, train_wall=31, gb_free=16.5, wall=29229
2025-11-08 00:51:51 | INFO | train_inner | epoch 001:  47144 / 91072 loss=0.739258, wps=391.2, ups=1.7, wpb=230.7, bsz=16, num_updates=47000, lr=9.98524e-05, gnorm=9.592, clip=64, loss_scale=256, train_wall=29, gb_free=17.6, wall=29259
2025-11-08 00:52:21 | INFO | train_inner | epoch 001:  47194 / 91072 loss=0.791016, wps=410.1, ups=1.64, wpb=249.4, bsz=16, num_updates=47050, lr=9.98487e-05, gnorm=9.46, clip=70, loss_scale=256, train_wall=30, gb_free=15.8, wall=29289
2025-11-08 00:52:51 | INFO | train_inner | epoch 001:  47244 / 91072 loss=0.764648, wps=398.6, ups=1.68, wpb=237.2, bsz=16, num_updates=47100, lr=9.9845e-05, gnorm=9.879, clip=66, loss_scale=256, train_wall=30, gb_free=18.2, wall=29319
2025-11-08 00:53:21 | INFO | train_inner | epoch 001:  47294 / 91072 loss=0.741211, wps=394, ups=1.65, wpb=239.1, bsz=16, num_updates=47150, lr=9.98413e-05, gnorm=9.742, clip=66, loss_scale=256, train_wall=30, gb_free=10.5, wall=29349
2025-11-08 00:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:53:52 | INFO | train_inner | epoch 001:  47345 / 91072 loss=0.744629, wps=401.2, ups=1.62, wpb=247.7, bsz=16, num_updates=47200, lr=9.98376e-05, gnorm=8.386, clip=72, loss_scale=256, train_wall=31, gb_free=16.9, wall=29380
2025-11-08 00:54:22 | INFO | train_inner | epoch 001:  47395 / 91072 loss=0.768066, wps=399.1, ups=1.68, wpb=237.9, bsz=16, num_updates=47250, lr=9.9834e-05, gnorm=9.466, clip=64, loss_scale=256, train_wall=30, gb_free=14.8, wall=29410
2025-11-08 00:54:52 | INFO | train_inner | epoch 001:  47445 / 91072 loss=0.780273, wps=403.6, ups=1.67, wpb=241.4, bsz=16, num_updates=47300, lr=9.98303e-05, gnorm=7.918, clip=64, loss_scale=256, train_wall=30, gb_free=16.6, wall=29440
2025-11-08 00:55:22 | INFO | train_inner | epoch 001:  47495 / 91072 loss=0.811035, wps=399.2, ups=1.66, wpb=240, bsz=16, num_updates=47350, lr=9.98266e-05, gnorm=8.486, clip=66, loss_scale=256, train_wall=30, gb_free=16.9, wall=29470
2025-11-08 00:55:52 | INFO | train_inner | epoch 001:  47545 / 91072 loss=0.79541, wps=401.3, ups=1.67, wpb=240.6, bsz=16, num_updates=47400, lr=9.98229e-05, gnorm=9.528, clip=64, loss_scale=256, train_wall=30, gb_free=17.2, wall=29500
2025-11-08 00:56:22 | INFO | train_inner | epoch 001:  47595 / 91072 loss=0.740723, wps=400.2, ups=1.65, wpb=243.2, bsz=16, num_updates=47450, lr=9.98192e-05, gnorm=8.555, clip=70, loss_scale=512, train_wall=30, gb_free=17.8, wall=29530
2025-11-08 00:56:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 00:56:53 | INFO | train_inner | epoch 001:  47646 / 91072 loss=0.800293, wps=400.6, ups=1.64, wpb=244.7, bsz=16, num_updates=47500, lr=9.98155e-05, gnorm=9.149, clip=72, loss_scale=256, train_wall=30, gb_free=12.6, wall=29561
2025-11-08 00:57:23 | INFO | train_inner | epoch 001:  47696 / 91072 loss=0.716797, wps=392.1, ups=1.66, wpb=236.3, bsz=16, num_updates=47550, lr=9.98118e-05, gnorm=8.752, clip=50, loss_scale=256, train_wall=30, gb_free=16.2, wall=29591
2025-11-08 00:57:54 | INFO | train_inner | epoch 001:  47746 / 91072 loss=0.713379, wps=414.1, ups=1.64, wpb=253.2, bsz=16, num_updates=47600, lr=9.98081e-05, gnorm=8.404, clip=62, loss_scale=256, train_wall=30, gb_free=18.6, wall=29621
2025-11-08 00:58:24 | INFO | train_inner | epoch 001:  47796 / 91072 loss=0.790527, wps=405.9, ups=1.66, wpb=243.9, bsz=16, num_updates=47650, lr=9.98044e-05, gnorm=8.431, clip=60, loss_scale=256, train_wall=30, gb_free=16.9, wall=29651
2025-11-08 00:58:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 00:58:54 | INFO | train_inner | epoch 001:  47847 / 91072 loss=0.831543, wps=392.3, ups=1.66, wpb=236.5, bsz=16, num_updates=47700, lr=9.98007e-05, gnorm=10.975, clip=72, loss_scale=128, train_wall=30, gb_free=12.2, wall=29682
2025-11-08 00:59:24 | INFO | train_inner | epoch 001:  47897 / 91072 loss=0.78125, wps=393.8, ups=1.68, wpb=234.6, bsz=16, num_updates=47750, lr=9.9797e-05, gnorm=8.82, clip=66, loss_scale=128, train_wall=30, gb_free=15.6, wall=29711
2025-11-08 00:59:54 | INFO | train_inner | epoch 001:  47947 / 91072 loss=0.803711, wps=408.6, ups=1.64, wpb=249.1, bsz=16, num_updates=47800, lr=9.97934e-05, gnorm=7.769, clip=68, loss_scale=128, train_wall=30, gb_free=17.7, wall=29742
2025-11-08 01:00:24 | INFO | train_inner | epoch 001:  47997 / 91072 loss=0.744629, wps=400.6, ups=1.67, wpb=239.9, bsz=16, num_updates=47850, lr=9.97897e-05, gnorm=9.056, clip=62, loss_scale=128, train_wall=30, gb_free=14.2, wall=29772
2025-11-08 01:00:54 | INFO | train_inner | epoch 001:  48047 / 91072 loss=0.807617, wps=405.9, ups=1.65, wpb=246.1, bsz=16, num_updates=47900, lr=9.9786e-05, gnorm=9.002, clip=74, loss_scale=128, train_wall=30, gb_free=12.2, wall=29802
2025-11-08 01:01:25 | INFO | train_inner | epoch 001:  48097 / 91072 loss=0.732422, wps=400.3, ups=1.64, wpb=244.7, bsz=16, num_updates=47950, lr=9.97823e-05, gnorm=8.165, clip=58, loss_scale=256, train_wall=30, gb_free=18.6, wall=29833
2025-11-08 01:01:55 | INFO | train_inner | epoch 001:  48147 / 91072 loss=0.753418, wps=405.3, ups=1.63, wpb=248.2, bsz=16, num_updates=48000, lr=9.97786e-05, gnorm=7.262, clip=54, loss_scale=256, train_wall=30, gb_free=13.5, wall=29863
2025-11-08 01:02:28 | INFO | train_inner | epoch 001:  48197 / 91072 loss=0.768066, wps=404.8, ups=1.53, wpb=264.5, bsz=16, num_updates=48050, lr=9.97749e-05, gnorm=8.158, clip=60, loss_scale=256, train_wall=32, gb_free=15, wall=29896
2025-11-08 01:03:01 | INFO | train_inner | epoch 001:  48247 / 91072 loss=0.814941, wps=382.5, ups=1.53, wpb=249.5, bsz=16, num_updates=48100, lr=9.97712e-05, gnorm=8.447, clip=70, loss_scale=256, train_wall=32, gb_free=14, wall=29929
2025-11-08 01:03:31 | INFO | train_inner | epoch 001:  48297 / 91072 loss=0.766602, wps=401.1, ups=1.66, wpb=241.3, bsz=16, num_updates=48150, lr=9.97675e-05, gnorm=9.097, clip=72, loss_scale=256, train_wall=30, gb_free=19.4, wall=29959
2025-11-08 01:04:01 | INFO | train_inner | epoch 001:  48347 / 91072 loss=0.73291, wps=402.3, ups=1.66, wpb=242.7, bsz=16, num_updates=48200, lr=9.97638e-05, gnorm=8.121, clip=62, loss_scale=256, train_wall=30, gb_free=16.5, wall=29989
2025-11-08 01:04:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:04:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:04:33 | INFO | train_inner | epoch 001:  48399 / 91072 loss=0.78125, wps=395, ups=1.58, wpb=249.9, bsz=16, num_updates=48250, lr=9.97602e-05, gnorm=10.266, clip=78, loss_scale=128, train_wall=31, gb_free=17.7, wall=30021
2025-11-08 01:05:04 | INFO | train_inner | epoch 001:  48449 / 91072 loss=0.703125, wps=383, ups=1.58, wpb=242.7, bsz=16, num_updates=48300, lr=9.97565e-05, gnorm=10.816, clip=74, loss_scale=128, train_wall=32, gb_free=18.6, wall=30052
2025-11-08 01:05:35 | INFO | train_inner | epoch 001:  48499 / 91072 loss=0.733887, wps=416, ups=1.62, wpb=257.2, bsz=16, num_updates=48350, lr=9.97528e-05, gnorm=7.292, clip=50, loss_scale=128, train_wall=31, gb_free=14.7, wall=30083
2025-11-08 01:06:07 | INFO | train_inner | epoch 001:  48549 / 91072 loss=0.736328, wps=412.9, ups=1.59, wpb=260.3, bsz=16, num_updates=48400, lr=9.97491e-05, gnorm=9.418, clip=70, loss_scale=128, train_wall=31, gb_free=18, wall=30115
2025-11-08 01:06:37 | INFO | train_inner | epoch 001:  48599 / 91072 loss=0.730469, wps=382.6, ups=1.65, wpb=231.6, bsz=16, num_updates=48450, lr=9.97454e-05, gnorm=8.715, clip=56, loss_scale=128, train_wall=30, gb_free=10.8, wall=30145
2025-11-08 01:07:10 | INFO | train_inner | epoch 001:  48649 / 91072 loss=0.804688, wps=393.9, ups=1.54, wpb=256.6, bsz=16, num_updates=48500, lr=9.97417e-05, gnorm=8.211, clip=60, loss_scale=256, train_wall=32, gb_free=17.1, wall=30178
2025-11-08 01:07:40 | INFO | train_inner | epoch 001:  48699 / 91072 loss=0.753906, wps=412.2, ups=1.65, wpb=250.2, bsz=16, num_updates=48550, lr=9.9738e-05, gnorm=9.106, clip=74, loss_scale=256, train_wall=30, gb_free=14.4, wall=30208
2025-11-08 01:08:10 | INFO | train_inner | epoch 001:  48749 / 91072 loss=0.775391, wps=395.3, ups=1.67, wpb=237, bsz=16, num_updates=48600, lr=9.97343e-05, gnorm=8.302, clip=64, loss_scale=256, train_wall=30, gb_free=15.4, wall=30238
2025-11-08 01:08:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:08:43 | INFO | train_inner | epoch 001:  48800 / 91072 loss=0.842773, wps=382.5, ups=1.52, wpb=252.3, bsz=16, num_updates=48650, lr=9.97306e-05, gnorm=8.182, clip=58, loss_scale=128, train_wall=33, gb_free=16.5, wall=30271
2025-11-08 01:09:14 | INFO | train_inner | epoch 001:  48850 / 91072 loss=0.82666, wps=380.7, ups=1.62, wpb=235.5, bsz=16, num_updates=48700, lr=9.97269e-05, gnorm=10.559, clip=70, loss_scale=128, train_wall=31, gb_free=18.6, wall=30302
2025-11-08 01:09:44 | INFO | train_inner | epoch 001:  48900 / 91072 loss=0.766113, wps=389, ups=1.64, wpb=237.2, bsz=16, num_updates=48750, lr=9.97232e-05, gnorm=9.392, clip=62, loss_scale=128, train_wall=30, gb_free=18.5, wall=30332
2025-11-08 01:10:15 | INFO | train_inner | epoch 001:  48950 / 91072 loss=0.793457, wps=378.4, ups=1.62, wpb=233.7, bsz=16, num_updates=48800, lr=9.97196e-05, gnorm=8.4, clip=64, loss_scale=128, train_wall=31, gb_free=15.1, wall=30363
2025-11-08 01:10:45 | INFO | train_inner | epoch 001:  49000 / 91072 loss=0.793457, wps=392.9, ups=1.69, wpb=232.6, bsz=16, num_updates=48850, lr=9.97159e-05, gnorm=8.012, clip=66, loss_scale=128, train_wall=29, gb_free=17.7, wall=30393
2025-11-08 01:11:15 | INFO | train_inner | epoch 001:  49050 / 91072 loss=0.746094, wps=391.7, ups=1.66, wpb=236.3, bsz=16, num_updates=48900, lr=9.97122e-05, gnorm=7.715, clip=52, loss_scale=256, train_wall=30, gb_free=17.9, wall=30423
2025-11-08 01:11:45 | INFO | train_inner | epoch 001:  49100 / 91072 loss=0.707031, wps=406.5, ups=1.66, wpb=245.3, bsz=16, num_updates=48950, lr=9.97085e-05, gnorm=9.747, clip=76, loss_scale=256, train_wall=30, gb_free=17.3, wall=30453
2025-11-08 01:12:15 | INFO | train_inner | epoch 001:  49150 / 91072 loss=0.783203, wps=394.6, ups=1.67, wpb=236.2, bsz=16, num_updates=49000, lr=9.97048e-05, gnorm=9.508, clip=62, loss_scale=256, train_wall=30, gb_free=11.2, wall=30483
2025-11-08 01:12:46 | INFO | train_inner | epoch 001:  49200 / 91072 loss=0.757812, wps=413.4, ups=1.61, wpb=256.5, bsz=16, num_updates=49050, lr=9.97011e-05, gnorm=8.529, clip=68, loss_scale=256, train_wall=31, gb_free=14.6, wall=30514
2025-11-08 01:13:16 | INFO | train_inner | epoch 001:  49250 / 91072 loss=0.807617, wps=401, ups=1.66, wpb=242.2, bsz=16, num_updates=49100, lr=9.96974e-05, gnorm=8.986, clip=64, loss_scale=256, train_wall=30, gb_free=15.1, wall=30544
2025-11-08 01:13:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:13:47 | INFO | train_inner | epoch 001:  49301 / 91072 loss=0.768555, wps=400.9, ups=1.64, wpb=244.3, bsz=16, num_updates=49150, lr=9.96937e-05, gnorm=9.307, clip=74, loss_scale=256, train_wall=30, gb_free=16.2, wall=30575
2025-11-08 01:14:17 | INFO | train_inner | epoch 001:  49351 / 91072 loss=0.718262, wps=394, ups=1.67, wpb=236.5, bsz=16, num_updates=49200, lr=9.969e-05, gnorm=7.205, clip=56, loss_scale=256, train_wall=30, gb_free=16.5, wall=30605
2025-11-08 01:14:47 | INFO | train_inner | epoch 001:  49401 / 91072 loss=0.744629, wps=402.2, ups=1.63, wpb=247, bsz=16, num_updates=49250, lr=9.96864e-05, gnorm=10.519, clip=80, loss_scale=256, train_wall=31, gb_free=18.6, wall=30635
2025-11-08 01:15:18 | INFO | train_inner | epoch 001:  49451 / 91072 loss=0.850098, wps=406.7, ups=1.62, wpb=250.9, bsz=16, num_updates=49300, lr=9.96827e-05, gnorm=10.624, clip=80, loss_scale=256, train_wall=31, gb_free=14.2, wall=30666
2025-11-08 01:15:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:15:49 | INFO | train_inner | epoch 001:  49502 / 91072 loss=0.703125, wps=400.8, ups=1.61, wpb=249, bsz=16, num_updates=49350, lr=9.9679e-05, gnorm=9.234, clip=70, loss_scale=128, train_wall=31, gb_free=16.1, wall=30697
2025-11-08 01:16:19 | INFO | train_inner | epoch 001:  49552 / 91072 loss=0.773926, wps=394.5, ups=1.69, wpb=233.3, bsz=16, num_updates=49400, lr=9.96753e-05, gnorm=9.319, clip=74, loss_scale=128, train_wall=29, gb_free=16.5, wall=30727
2025-11-08 01:16:52 | INFO | train_inner | epoch 001:  49602 / 91072 loss=0.793945, wps=377.7, ups=1.51, wpb=250.2, bsz=16, num_updates=49450, lr=9.96716e-05, gnorm=9.088, clip=64, loss_scale=128, train_wall=33, gb_free=17.9, wall=30760
2025-11-08 01:17:24 | INFO | train_inner | epoch 001:  49652 / 91072 loss=0.818848, wps=393.9, ups=1.58, wpb=249.5, bsz=16, num_updates=49500, lr=9.96679e-05, gnorm=8.69, clip=62, loss_scale=128, train_wall=31, gb_free=15.4, wall=30792
2025-11-08 01:17:59 | INFO | train_inner | epoch 001:  49702 / 91072 loss=0.719727, wps=368.8, ups=1.44, wpb=256.6, bsz=16, num_updates=49550, lr=9.96642e-05, gnorm=8.887, clip=62, loss_scale=128, train_wall=35, gb_free=17.3, wall=30826
2025-11-08 01:18:29 | INFO | train_inner | epoch 001:  49752 / 91072 loss=0.773438, wps=411, ups=1.64, wpb=250.8, bsz=16, num_updates=49600, lr=9.96605e-05, gnorm=8.73, clip=58, loss_scale=128, train_wall=30, gb_free=18.3, wall=30857
2025-11-08 01:18:59 | INFO | train_inner | epoch 001:  49802 / 91072 loss=0.782715, wps=391.9, ups=1.67, wpb=234, bsz=16, num_updates=49650, lr=9.96568e-05, gnorm=10.024, clip=64, loss_scale=256, train_wall=30, gb_free=18.8, wall=30887
2025-11-08 01:19:29 | INFO | train_inner | epoch 001:  49852 / 91072 loss=0.821777, wps=398, ups=1.67, wpb=237.7, bsz=16, num_updates=49700, lr=9.96531e-05, gnorm=7.954, clip=64, loss_scale=256, train_wall=30, gb_free=17, wall=30917
2025-11-08 01:20:00 | INFO | train_inner | epoch 001:  49902 / 91072 loss=0.72168, wps=390.3, ups=1.59, wpb=245.9, bsz=16, num_updates=49750, lr=9.96494e-05, gnorm=6.966, clip=56, loss_scale=256, train_wall=31, gb_free=14, wall=30948
2025-11-08 01:20:31 | INFO | train_inner | epoch 001:  49952 / 91072 loss=0.845703, wps=402.1, ups=1.64, wpb=245.3, bsz=16, num_updates=49800, lr=9.96458e-05, gnorm=8.438, clip=60, loss_scale=256, train_wall=30, gb_free=17.7, wall=30979
2025-11-08 01:20:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:21:03 | INFO | train_inner | epoch 001:  50003 / 91072 loss=0.761719, wps=367, ups=1.57, wpb=233.7, bsz=16, num_updates=49850, lr=9.96421e-05, gnorm=8.743, clip=64, loss_scale=128, train_wall=32, gb_free=18.4, wall=31011
2025-11-08 01:21:34 | INFO | train_inner | epoch 001:  50053 / 91072 loss=0.783691, wps=398, ups=1.59, wpb=250.1, bsz=16, num_updates=49900, lr=9.96384e-05, gnorm=9.721, clip=68, loss_scale=128, train_wall=31, gb_free=16.3, wall=31042
2025-11-08 01:22:04 | INFO | train_inner | epoch 001:  50103 / 91072 loss=0.82959, wps=376.2, ups=1.67, wpb=224.9, bsz=16, num_updates=49950, lr=9.96347e-05, gnorm=7.889, clip=52, loss_scale=128, train_wall=30, gb_free=16.6, wall=31072
2025-11-08 01:22:38 | INFO | train_inner | epoch 001:  50153 / 91072 loss=0.880859, wps=347.5, ups=1.47, wpb=237.1, bsz=16, num_updates=50000, lr=9.9631e-05, gnorm=10.303, clip=72, loss_scale=128, train_wall=34, gb_free=18.8, wall=31106
2025-11-08 01:23:08 | INFO | train_inner | epoch 001:  50203 / 91072 loss=0.770996, wps=386.6, ups=1.68, wpb=230.3, bsz=16, num_updates=50050, lr=9.96273e-05, gnorm=8.586, clip=74, loss_scale=128, train_wall=30, gb_free=18.2, wall=31136
2025-11-08 01:23:38 | INFO | train_inner | epoch 001:  50253 / 91072 loss=0.874023, wps=406.2, ups=1.64, wpb=247, bsz=16, num_updates=50100, lr=9.96236e-05, gnorm=9.137, clip=62, loss_scale=256, train_wall=30, gb_free=18.2, wall=31166
2025-11-08 01:24:09 | INFO | train_inner | epoch 001:  50303 / 91072 loss=0.879883, wps=398.4, ups=1.62, wpb=246.1, bsz=16, num_updates=50150, lr=9.96199e-05, gnorm=9.665, clip=70, loss_scale=256, train_wall=31, gb_free=13.4, wall=31197
2025-11-08 01:24:41 | INFO | train_inner | epoch 001:  50353 / 91072 loss=0.822266, wps=398.2, ups=1.58, wpb=252.3, bsz=16, num_updates=50200, lr=9.96162e-05, gnorm=9.576, clip=72, loss_scale=256, train_wall=32, gb_free=14.2, wall=31229
2025-11-08 01:25:11 | INFO | train_inner | epoch 001:  50403 / 91072 loss=0.730469, wps=395.2, ups=1.64, wpb=240.9, bsz=16, num_updates=50250, lr=9.96126e-05, gnorm=8.801, clip=62, loss_scale=256, train_wall=30, gb_free=16.8, wall=31259
2025-11-08 01:25:42 | INFO | train_inner | epoch 001:  50453 / 91072 loss=0.756348, wps=397.1, ups=1.62, wpb=245.7, bsz=16, num_updates=50300, lr=9.96089e-05, gnorm=9.399, clip=72, loss_scale=256, train_wall=31, gb_free=18.5, wall=31290
2025-11-08 01:26:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:26:13 | INFO | train_inner | epoch 001:  50504 / 91072 loss=0.82666, wps=382.2, ups=1.61, wpb=237.9, bsz=16, num_updates=50350, lr=9.96052e-05, gnorm=8.868, clip=58, loss_scale=256, train_wall=31, gb_free=18.5, wall=31321
2025-11-08 01:26:46 | INFO | train_inner | epoch 001:  50554 / 91072 loss=0.748047, wps=362.9, ups=1.55, wpb=234.5, bsz=16, num_updates=50400, lr=9.96015e-05, gnorm=6.975, clip=58, loss_scale=256, train_wall=32, gb_free=16.8, wall=31354
2025-11-08 01:27:16 | INFO | train_inner | epoch 001:  50604 / 91072 loss=0.899902, wps=404.5, ups=1.65, wpb=245.3, bsz=16, num_updates=50450, lr=9.95978e-05, gnorm=10.454, clip=72, loss_scale=256, train_wall=30, gb_free=18.3, wall=31384
2025-11-08 01:27:48 | INFO | train_inner | epoch 001:  50654 / 91072 loss=0.764648, wps=385.9, ups=1.57, wpb=245.5, bsz=16, num_updates=50500, lr=9.95941e-05, gnorm=8.319, clip=58, loss_scale=256, train_wall=32, gb_free=18.4, wall=31416
2025-11-08 01:28:20 | INFO | train_inner | epoch 001:  50704 / 91072 loss=0.783691, wps=380.8, ups=1.55, wpb=246, bsz=16, num_updates=50550, lr=9.95904e-05, gnorm=9.985, clip=70, loss_scale=256, train_wall=32, gb_free=15.4, wall=31448
2025-11-08 01:28:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:28:53 | INFO | train_inner | epoch 001:  50755 / 91072 loss=0.712402, wps=368.5, ups=1.53, wpb=241.3, bsz=16, num_updates=50600, lr=9.95867e-05, gnorm=9.084, clip=70, loss_scale=256, train_wall=33, gb_free=18.4, wall=31481
2025-11-08 01:29:24 | INFO | train_inner | epoch 001:  50805 / 91072 loss=0.746582, wps=407.7, ups=1.61, wpb=252.6, bsz=16, num_updates=50650, lr=9.9583e-05, gnorm=7.308, clip=52, loss_scale=256, train_wall=31, gb_free=17.8, wall=31512
2025-11-08 01:29:54 | INFO | train_inner | epoch 001:  50855 / 91072 loss=0.806152, wps=406.3, ups=1.64, wpb=247.9, bsz=16, num_updates=50700, lr=9.95793e-05, gnorm=9.951, clip=72, loss_scale=256, train_wall=30, gb_free=15.9, wall=31542
2025-11-08 01:30:25 | INFO | train_inner | epoch 001:  50905 / 91072 loss=0.731934, wps=400.3, ups=1.64, wpb=243.6, bsz=16, num_updates=50750, lr=9.95756e-05, gnorm=7.879, clip=62, loss_scale=256, train_wall=30, gb_free=14.7, wall=31573
2025-11-08 01:30:56 | INFO | train_inner | epoch 001:  50955 / 91072 loss=0.740723, wps=414.9, ups=1.59, wpb=260.8, bsz=16, num_updates=50800, lr=9.9572e-05, gnorm=8.888, clip=64, loss_scale=256, train_wall=31, gb_free=17.4, wall=31604
2025-11-08 01:31:27 | INFO | train_inner | epoch 001:  51005 / 91072 loss=0.731445, wps=405, ups=1.63, wpb=247.8, bsz=16, num_updates=50850, lr=9.95683e-05, gnorm=10.634, clip=80, loss_scale=256, train_wall=30, gb_free=13.4, wall=31635
2025-11-08 01:31:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:31:58 | INFO | train_inner | epoch 001:  51056 / 91072 loss=0.748535, wps=392.6, ups=1.62, wpb=242.4, bsz=16, num_updates=50900, lr=9.95646e-05, gnorm=8.017, clip=62, loss_scale=256, train_wall=31, gb_free=11.8, wall=31666
2025-11-08 01:32:29 | INFO | train_inner | epoch 001:  51106 / 91072 loss=0.802734, wps=412.1, ups=1.62, wpb=254.9, bsz=16, num_updates=50950, lr=9.95609e-05, gnorm=8.351, clip=60, loss_scale=256, train_wall=31, gb_free=15.5, wall=31697
2025-11-08 01:32:59 | INFO | train_inner | epoch 001:  51156 / 91072 loss=0.681152, wps=401.9, ups=1.66, wpb=242.8, bsz=16, num_updates=51000, lr=9.95572e-05, gnorm=8.205, clip=64, loss_scale=256, train_wall=30, gb_free=18.3, wall=31727
2025-11-08 01:33:29 | INFO | train_inner | epoch 001:  51206 / 91072 loss=0.76416, wps=411.9, ups=1.63, wpb=252.4, bsz=16, num_updates=51050, lr=9.95535e-05, gnorm=9.784, clip=68, loss_scale=256, train_wall=30, gb_free=18.3, wall=31757
2025-11-08 01:34:00 | INFO | train_inner | epoch 001:  51256 / 91072 loss=0.795898, wps=404.3, ups=1.64, wpb=245.9, bsz=16, num_updates=51100, lr=9.95498e-05, gnorm=7.769, clip=58, loss_scale=256, train_wall=30, gb_free=16.4, wall=31788
2025-11-08 01:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:34:31 | INFO | train_inner | epoch 001:  51307 / 91072 loss=0.749023, wps=385, ups=1.61, wpb=238.9, bsz=16, num_updates=51150, lr=9.95461e-05, gnorm=8.769, clip=66, loss_scale=256, train_wall=31, gb_free=17.4, wall=31819
2025-11-08 01:35:01 | INFO | train_inner | epoch 001:  51357 / 91072 loss=0.797363, wps=401.5, ups=1.64, wpb=245.1, bsz=16, num_updates=51200, lr=9.95424e-05, gnorm=9.349, clip=66, loss_scale=256, train_wall=30, gb_free=14.9, wall=31849
2025-11-08 01:35:31 | INFO | train_inner | epoch 001:  51407 / 91072 loss=0.766113, wps=394.3, ups=1.67, wpb=235.4, bsz=16, num_updates=51250, lr=9.95388e-05, gnorm=7.766, clip=58, loss_scale=256, train_wall=30, gb_free=18, wall=31879
2025-11-08 01:36:02 | INFO | train_inner | epoch 001:  51457 / 91072 loss=0.761719, wps=414, ups=1.6, wpb=258.2, bsz=16, num_updates=51300, lr=9.95351e-05, gnorm=9.848, clip=78, loss_scale=256, train_wall=31, gb_free=17.3, wall=31910
2025-11-08 01:36:33 | INFO | train_inner | epoch 001:  51507 / 91072 loss=0.802246, wps=413, ups=1.61, wpb=256.3, bsz=16, num_updates=51350, lr=9.95314e-05, gnorm=10.343, clip=76, loss_scale=256, train_wall=31, gb_free=17.6, wall=31941
2025-11-08 01:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:37:04 | INFO | train_inner | epoch 001:  51558 / 91072 loss=0.754883, wps=387.4, ups=1.64, wpb=235.9, bsz=16, num_updates=51400, lr=9.95277e-05, gnorm=10.181, clip=56, loss_scale=256, train_wall=30, gb_free=17.5, wall=31972
2025-11-08 01:37:35 | INFO | train_inner | epoch 001:  51608 / 91072 loss=0.761719, wps=419.4, ups=1.6, wpb=262, bsz=16, num_updates=51450, lr=9.9524e-05, gnorm=9.077, clip=58, loss_scale=256, train_wall=31, gb_free=13, wall=32003
2025-11-08 01:38:05 | INFO | train_inner | epoch 001:  51658 / 91072 loss=0.740723, wps=405.5, ups=1.66, wpb=244, bsz=16, num_updates=51500, lr=9.95203e-05, gnorm=8.058, clip=56, loss_scale=256, train_wall=30, gb_free=15, wall=32033
2025-11-08 01:38:36 | INFO | train_inner | epoch 001:  51708 / 91072 loss=0.786621, wps=402.9, ups=1.65, wpb=244.1, bsz=16, num_updates=51550, lr=9.95166e-05, gnorm=10.204, clip=70, loss_scale=256, train_wall=30, gb_free=18, wall=32063
2025-11-08 01:39:06 | INFO | train_inner | epoch 001:  51758 / 91072 loss=0.826172, wps=404.8, ups=1.67, wpb=243, bsz=16, num_updates=51600, lr=9.95129e-05, gnorm=8.602, clip=60, loss_scale=256, train_wall=30, gb_free=17.9, wall=32093
2025-11-08 01:39:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:39:36 | INFO | train_inner | epoch 001:  51809 / 91072 loss=0.800293, wps=391.3, ups=1.62, wpb=241.4, bsz=16, num_updates=51650, lr=9.95092e-05, gnorm=10.735, clip=70, loss_scale=256, train_wall=31, gb_free=16.8, wall=32124
2025-11-08 01:40:07 | INFO | train_inner | epoch 001:  51859 / 91072 loss=0.739258, wps=412.1, ups=1.63, wpb=253.1, bsz=16, num_updates=51700, lr=9.95055e-05, gnorm=7.823, clip=64, loss_scale=256, train_wall=31, gb_free=18.6, wall=32155
2025-11-08 01:40:38 | INFO | train_inner | epoch 001:  51909 / 91072 loss=0.791504, wps=402.8, ups=1.64, wpb=245.2, bsz=16, num_updates=51750, lr=9.95019e-05, gnorm=8.725, clip=58, loss_scale=256, train_wall=30, gb_free=17.4, wall=32185
2025-11-08 01:41:08 | INFO | train_inner | epoch 001:  51959 / 91072 loss=0.715332, wps=402.3, ups=1.65, wpb=244, bsz=16, num_updates=51800, lr=9.94982e-05, gnorm=8.022, clip=54, loss_scale=256, train_wall=30, gb_free=17.1, wall=32216
2025-11-08 01:41:39 | INFO | train_inner | epoch 001:  52009 / 91072 loss=0.74707, wps=414.5, ups=1.63, wpb=254.3, bsz=16, num_updates=51850, lr=9.94945e-05, gnorm=8.643, clip=68, loss_scale=256, train_wall=31, gb_free=16.7, wall=32246
2025-11-08 01:42:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:42:10 | INFO | train_inner | epoch 001:  52060 / 91072 loss=0.763184, wps=391.4, ups=1.61, wpb=243.5, bsz=16, num_updates=51900, lr=9.94908e-05, gnorm=8.281, clip=66, loss_scale=256, train_wall=31, gb_free=17.4, wall=32278
2025-11-08 01:42:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:42:41 | INFO | train_inner | epoch 001:  52111 / 91072 loss=0.769531, wps=400.1, ups=1.61, wpb=249, bsz=16, num_updates=51950, lr=9.94871e-05, gnorm=7.483, clip=72, loss_scale=128, train_wall=31, gb_free=17.9, wall=32309
2025-11-08 01:43:11 | INFO | train_inner | epoch 001:  52161 / 91072 loss=0.793457, wps=415, ups=1.63, wpb=254.6, bsz=16, num_updates=52000, lr=9.94834e-05, gnorm=8.017, clip=62, loss_scale=128, train_wall=31, gb_free=12.2, wall=32339
2025-11-08 01:43:41 | INFO | train_inner | epoch 001:  52211 / 91072 loss=0.727051, wps=400, ups=1.67, wpb=239.7, bsz=16, num_updates=52050, lr=9.94797e-05, gnorm=7.665, clip=60, loss_scale=128, train_wall=30, gb_free=16.5, wall=32369
2025-11-08 01:44:12 | INFO | train_inner | epoch 001:  52261 / 91072 loss=0.741699, wps=400.1, ups=1.64, wpb=243.3, bsz=16, num_updates=52100, lr=9.9476e-05, gnorm=9.77, clip=80, loss_scale=128, train_wall=30, gb_free=18.4, wall=32400
2025-11-08 01:44:42 | INFO | train_inner | epoch 001:  52311 / 91072 loss=0.759277, wps=403.3, ups=1.67, wpb=241.9, bsz=16, num_updates=52150, lr=9.94723e-05, gnorm=10.089, clip=72, loss_scale=128, train_wall=30, gb_free=18, wall=32430
2025-11-08 01:45:12 | INFO | train_inner | epoch 001:  52361 / 91072 loss=0.658203, wps=400.1, ups=1.66, wpb=241.4, bsz=16, num_updates=52200, lr=9.94686e-05, gnorm=9.047, clip=64, loss_scale=256, train_wall=30, gb_free=16.9, wall=32460
2025-11-08 01:45:42 | INFO | train_inner | epoch 001:  52411 / 91072 loss=0.744629, wps=400.6, ups=1.67, wpb=240.1, bsz=16, num_updates=52250, lr=9.9465e-05, gnorm=9.576, clip=64, loss_scale=256, train_wall=30, gb_free=16.2, wall=32490
2025-11-08 01:46:12 | INFO | train_inner | epoch 001:  52461 / 91072 loss=0.792969, wps=393.4, ups=1.64, wpb=239.9, bsz=16, num_updates=52300, lr=9.94613e-05, gnorm=10.37, clip=70, loss_scale=256, train_wall=30, gb_free=18.3, wall=32520
2025-11-08 01:46:42 | INFO | train_inner | epoch 001:  52511 / 91072 loss=0.774902, wps=393.8, ups=1.67, wpb=235.2, bsz=16, num_updates=52350, lr=9.94576e-05, gnorm=10.162, clip=76, loss_scale=256, train_wall=30, gb_free=17.7, wall=32550
2025-11-08 01:47:13 | INFO | train_inner | epoch 001:  52561 / 91072 loss=0.789062, wps=410.4, ups=1.63, wpb=251.6, bsz=16, num_updates=52400, lr=9.94539e-05, gnorm=8.54, clip=68, loss_scale=256, train_wall=31, gb_free=18.2, wall=32581
2025-11-08 01:47:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 01:47:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:47:45 | INFO | train_inner | epoch 001:  52613 / 91072 loss=0.735352, wps=377.5, ups=1.55, wpb=242.8, bsz=16, num_updates=52450, lr=9.94502e-05, gnorm=9.601, clip=68, loss_scale=128, train_wall=32, gb_free=15.8, wall=32613
2025-11-08 01:48:17 | INFO | train_inner | epoch 001:  52663 / 91072 loss=0.747559, wps=372.4, ups=1.56, wpb=237.9, bsz=16, num_updates=52500, lr=9.94465e-05, gnorm=10.662, clip=74, loss_scale=128, train_wall=32, gb_free=17, wall=32645
2025-11-08 01:48:48 | INFO | train_inner | epoch 001:  52713 / 91072 loss=0.76416, wps=406.3, ups=1.64, wpb=248, bsz=16, num_updates=52550, lr=9.94428e-05, gnorm=9.824, clip=74, loss_scale=128, train_wall=30, gb_free=12.1, wall=32676
2025-11-08 01:49:18 | INFO | train_inner | epoch 001:  52763 / 91072 loss=0.71875, wps=403.2, ups=1.65, wpb=244.3, bsz=16, num_updates=52600, lr=9.94391e-05, gnorm=8.479, clip=66, loss_scale=128, train_wall=30, gb_free=16.7, wall=32706
2025-11-08 01:49:51 | INFO | train_inner | epoch 001:  52813 / 91072 loss=0.737305, wps=368.4, ups=1.51, wpb=243.4, bsz=16, num_updates=52650, lr=9.94354e-05, gnorm=10.369, clip=78, loss_scale=128, train_wall=33, gb_free=12.8, wall=32739
2025-11-08 01:50:23 | INFO | train_inner | epoch 001:  52863 / 91072 loss=0.755859, wps=369.4, ups=1.55, wpb=238, bsz=16, num_updates=52700, lr=9.94317e-05, gnorm=8.319, clip=68, loss_scale=128, train_wall=32, gb_free=19, wall=32771
2025-11-08 01:50:55 | INFO | train_inner | epoch 001:  52913 / 91072 loss=0.740234, wps=401.4, ups=1.55, wpb=259, bsz=16, num_updates=52750, lr=9.94281e-05, gnorm=8.41, clip=68, loss_scale=256, train_wall=32, gb_free=18.1, wall=32803
2025-11-08 01:51:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:51:28 | INFO | train_inner | epoch 001:  52964 / 91072 loss=0.767578, wps=378.2, ups=1.54, wpb=246.3, bsz=16, num_updates=52800, lr=9.94244e-05, gnorm=9.157, clip=60, loss_scale=128, train_wall=32, gb_free=16.3, wall=32836
2025-11-08 01:51:58 | INFO | train_inner | epoch 001:  53014 / 91072 loss=0.803223, wps=390.6, ups=1.67, wpb=234.6, bsz=16, num_updates=52850, lr=9.94207e-05, gnorm=10.228, clip=68, loss_scale=128, train_wall=30, gb_free=18.7, wall=32866
2025-11-08 01:52:29 | INFO | train_inner | epoch 001:  53064 / 91072 loss=0.755371, wps=406.9, ups=1.59, wpb=255.2, bsz=16, num_updates=52900, lr=9.9417e-05, gnorm=9.154, clip=60, loss_scale=128, train_wall=31, gb_free=14.7, wall=32897
2025-11-08 01:52:59 | INFO | train_inner | epoch 001:  53114 / 91072 loss=0.794922, wps=396.1, ups=1.68, wpb=236.1, bsz=16, num_updates=52950, lr=9.94133e-05, gnorm=7.431, clip=50, loss_scale=128, train_wall=30, gb_free=18.2, wall=32927
2025-11-08 01:53:30 | INFO | train_inner | epoch 001:  53164 / 91072 loss=0.650879, wps=415.3, ups=1.62, wpb=257.1, bsz=16, num_updates=53000, lr=9.94096e-05, gnorm=8.779, clip=62, loss_scale=128, train_wall=31, gb_free=14.9, wall=32958
2025-11-08 01:54:01 | INFO | train_inner | epoch 001:  53214 / 91072 loss=0.770508, wps=408.1, ups=1.62, wpb=251.2, bsz=16, num_updates=53050, lr=9.94059e-05, gnorm=7.762, clip=60, loss_scale=256, train_wall=31, gb_free=15.9, wall=32989
2025-11-08 01:54:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 01:54:32 | INFO | train_inner | epoch 001:  53265 / 91072 loss=0.758301, wps=395.9, ups=1.62, wpb=244.7, bsz=16, num_updates=53100, lr=9.94022e-05, gnorm=8.744, clip=74, loss_scale=128, train_wall=31, gb_free=11.7, wall=33020
2025-11-08 01:55:02 | INFO | train_inner | epoch 001:  53315 / 91072 loss=0.660156, wps=411.5, ups=1.65, wpb=250, bsz=16, num_updates=53150, lr=9.93985e-05, gnorm=8.013, clip=52, loss_scale=128, train_wall=30, gb_free=17.5, wall=33050
2025-11-08 01:55:32 | INFO | train_inner | epoch 001:  53365 / 91072 loss=0.828125, wps=397.1, ups=1.67, wpb=238.5, bsz=16, num_updates=53200, lr=9.93948e-05, gnorm=9.81, clip=60, loss_scale=128, train_wall=30, gb_free=15.4, wall=33080
2025-11-08 01:56:02 | INFO | train_inner | epoch 001:  53415 / 91072 loss=0.765137, wps=394.8, ups=1.66, wpb=237.9, bsz=16, num_updates=53250, lr=9.93912e-05, gnorm=9.387, clip=66, loss_scale=128, train_wall=30, gb_free=14.8, wall=33110
2025-11-08 01:56:33 | INFO | train_inner | epoch 001:  53465 / 91072 loss=0.708008, wps=402.1, ups=1.62, wpb=248.3, bsz=16, num_updates=53300, lr=9.93875e-05, gnorm=7.876, clip=68, loss_scale=128, train_wall=31, gb_free=12.2, wall=33141
2025-11-08 01:57:04 | INFO | train_inner | epoch 001:  53515 / 91072 loss=0.827637, wps=415.3, ups=1.64, wpb=253.6, bsz=16, num_updates=53350, lr=9.93838e-05, gnorm=10.934, clip=78, loss_scale=256, train_wall=30, gb_free=16.8, wall=33172
2025-11-08 01:57:34 | INFO | train_inner | epoch 001:  53565 / 91072 loss=0.749512, wps=399.8, ups=1.66, wpb=240.7, bsz=16, num_updates=53400, lr=9.93801e-05, gnorm=7.224, clip=44, loss_scale=256, train_wall=30, gb_free=17, wall=33202
2025-11-08 01:58:05 | INFO | train_inner | epoch 001:  53615 / 91072 loss=0.783691, wps=409.1, ups=1.58, wpb=258.3, bsz=16, num_updates=53450, lr=9.93764e-05, gnorm=7.952, clip=48, loss_scale=256, train_wall=31, gb_free=17, wall=33233
2025-11-08 01:58:36 | INFO | train_inner | epoch 001:  53665 / 91072 loss=0.737305, wps=394.2, ups=1.66, wpb=236.8, bsz=16, num_updates=53500, lr=9.93727e-05, gnorm=7.873, clip=62, loss_scale=256, train_wall=30, gb_free=17.1, wall=33263
2025-11-08 01:59:06 | INFO | train_inner | epoch 001:  53715 / 91072 loss=0.757324, wps=407.6, ups=1.65, wpb=246.5, bsz=16, num_updates=53550, lr=9.9369e-05, gnorm=8.048, clip=62, loss_scale=256, train_wall=30, gb_free=15.2, wall=33294
2025-11-08 01:59:36 | INFO | train_inner | epoch 001:  53765 / 91072 loss=0.815918, wps=400, ups=1.66, wpb=241.4, bsz=16, num_updates=53600, lr=9.93653e-05, gnorm=8.17, clip=62, loss_scale=256, train_wall=30, gb_free=18, wall=33324
2025-11-08 01:59:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 02:00:10 | INFO | train_inner | epoch 001:  53816 / 91072 loss=0.755859, wps=367.9, ups=1.47, wpb=251, bsz=16, num_updates=53650, lr=9.93616e-05, gnorm=9.704, clip=64, loss_scale=256, train_wall=34, gb_free=17.9, wall=33358
2025-11-08 02:00:40 | INFO | train_inner | epoch 001:  53866 / 91072 loss=0.780762, wps=392.4, ups=1.69, wpb=232.1, bsz=16, num_updates=53700, lr=9.93579e-05, gnorm=8.498, clip=74, loss_scale=256, train_wall=29, gb_free=14.3, wall=33388
2025-11-08 02:01:10 | INFO | train_inner | epoch 001:  53916 / 91072 loss=0.772949, wps=403.4, ups=1.65, wpb=244.8, bsz=16, num_updates=53750, lr=9.93543e-05, gnorm=9.057, clip=68, loss_scale=256, train_wall=30, gb_free=17.1, wall=33418
2025-11-08 02:01:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 02:01:42 | INFO | train_inner | epoch 001:  53967 / 91072 loss=0.70752, wps=392.1, ups=1.57, wpb=249.1, bsz=16, num_updates=53800, lr=9.93506e-05, gnorm=9.29, clip=76, loss_scale=128, train_wall=32, gb_free=16.7, wall=33450
2025-11-08 02:02:12 | INFO | train_inner | epoch 001:  54017 / 91072 loss=0.758301, wps=393.2, ups=1.64, wpb=240.1, bsz=16, num_updates=53850, lr=9.93469e-05, gnorm=9.188, clip=68, loss_scale=128, train_wall=30, gb_free=16.6, wall=33480
2025-11-08 02:02:43 | INFO | train_inner | epoch 001:  54067 / 91072 loss=0.830078, wps=396, ups=1.61, wpb=246, bsz=16, num_updates=53900, lr=9.93432e-05, gnorm=7.761, clip=52, loss_scale=128, train_wall=31, gb_free=17.7, wall=33511
2025-11-08 02:03:15 | INFO | train_inner | epoch 001:  54117 / 91072 loss=0.787109, wps=383.2, ups=1.57, wpb=244.4, bsz=16, num_updates=53950, lr=9.93395e-05, gnorm=8.774, clip=60, loss_scale=128, train_wall=32, gb_free=18.2, wall=33543
2025-11-08 02:03:47 | INFO | train_inner | epoch 001:  54167 / 91072 loss=0.783203, wps=391.9, ups=1.58, wpb=247.7, bsz=16, num_updates=54000, lr=9.93358e-05, gnorm=9.295, clip=74, loss_scale=128, train_wall=31, gb_free=16.6, wall=33575
2025-11-08 02:04:17 | INFO | train_inner | epoch 001:  54217 / 91072 loss=0.811523, wps=398.9, ups=1.64, wpb=243.2, bsz=16, num_updates=54050, lr=9.93321e-05, gnorm=9.133, clip=64, loss_scale=128, train_wall=30, gb_free=16.8, wall=33605
2025-11-08 02:04:48 | INFO | train_inner | epoch 001:  54267 / 91072 loss=0.715332, wps=400.1, ups=1.65, wpb=243, bsz=16, num_updates=54100, lr=9.93284e-05, gnorm=7.797, clip=64, loss_scale=256, train_wall=30, gb_free=13.5, wall=33636
2025-11-08 02:05:18 | INFO | train_inner | epoch 001:  54317 / 91072 loss=0.737305, wps=401.6, ups=1.64, wpb=245, bsz=16, num_updates=54150, lr=9.93247e-05, gnorm=9.844, clip=66, loss_scale=256, train_wall=30, gb_free=18.4, wall=33666
2025-11-08 02:05:49 | INFO | train_inner | epoch 001:  54367 / 91072 loss=0.717285, wps=387.9, ups=1.64, wpb=236.5, bsz=16, num_updates=54200, lr=9.9321e-05, gnorm=9.292, clip=72, loss_scale=256, train_wall=30, gb_free=14.3, wall=33697
2025-11-08 02:06:20 | INFO | train_inner | epoch 001:  54417 / 91072 loss=0.774902, wps=378.9, ups=1.58, wpb=239.5, bsz=16, num_updates=54250, lr=9.93174e-05, gnorm=7.29, clip=56, loss_scale=256, train_wall=31, gb_free=19.3, wall=33728
2025-11-08 02:06:56 | INFO | train_inner | epoch 001:  54467 / 91072 loss=0.773438, wps=343.3, ups=1.39, wpb=247.1, bsz=16, num_updates=54300, lr=9.93137e-05, gnorm=11.684, clip=82, loss_scale=256, train_wall=36, gb_free=17.9, wall=33764
2025-11-08 02:07:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 02:07:28 | INFO | train_inner | epoch 001:  54518 / 91072 loss=0.735352, wps=397, ups=1.56, wpb=255.1, bsz=16, num_updates=54350, lr=9.931e-05, gnorm=8.092, clip=66, loss_scale=256, train_wall=32, gb_free=14.7, wall=33796
2025-11-08 02:08:01 | INFO | train_inner | epoch 001:  54568 / 91072 loss=0.76123, wps=395.7, ups=1.54, wpb=256.4, bsz=16, num_updates=54400, lr=9.93063e-05, gnorm=10.542, clip=76, loss_scale=256, train_wall=32, gb_free=18.6, wall=33829
2025-11-08 02:08:32 | INFO | train_inner | epoch 001:  54618 / 91072 loss=0.781738, wps=397.4, ups=1.62, wpb=244.9, bsz=16, num_updates=54450, lr=9.93026e-05, gnorm=8.402, clip=72, loss_scale=256, train_wall=31, gb_free=17.3, wall=33860
2025-11-08 02:09:03 | INFO | train_inner | epoch 001:  54668 / 91072 loss=0.734863, wps=388.4, ups=1.58, wpb=246, bsz=16, num_updates=54500, lr=9.92989e-05, gnorm=7.761, clip=54, loss_scale=256, train_wall=31, gb_free=12.8, wall=33891
2025-11-08 02:09:34 | INFO | train_inner | epoch 001:  54718 / 91072 loss=0.780273, wps=409.3, ups=1.63, wpb=250.6, bsz=16, num_updates=54550, lr=9.92952e-05, gnorm=9.453, clip=70, loss_scale=256, train_wall=30, gb_free=14, wall=33922
2025-11-08 02:09:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-08 02:10:06 | INFO | train_inner | epoch 001:  54769 / 91072 loss=0.722168, wps=378.1, ups=1.55, wpb=244.4, bsz=16, num_updates=54600, lr=9.92915e-05, gnorm=7.32, clip=60, loss_scale=128, train_wall=32, gb_free=10.7, wall=33954
2025-11-08 02:10:37 | INFO | train_inner | epoch 001:  54819 / 91072 loss=0.797852, wps=400.4, ups=1.63, wpb=245.4, bsz=16, num_updates=54650, lr=9.92878e-05, gnorm=9.117, clip=70, loss_scale=128, train_wall=30, gb_free=17.9, wall=33985
2025-11-08 02:11:08 | INFO | train_inner | epoch 001:  54869 / 91072 loss=0.743164, wps=399, ups=1.63, wpb=245.3, bsz=16, num_updates=54700, lr=9.92841e-05, gnorm=8.48, clip=66, loss_scale=128, train_wall=31, gb_free=16.2, wall=34016
2025-11-08 02:11:39 | INFO | train_inner | epoch 001:  54919 / 91072 loss=0.785645, wps=412.5, ups=1.61, wpb=256.8, bsz=16, num_updates=54750, lr=9.92805e-05, gnorm=8.518, clip=50, loss_scale=128, train_wall=31, gb_free=17.5, wall=34047
2025-11-08 02:12:09 | INFO | train_inner | epoch 001:  54969 / 91072 loss=0.84668, wps=396.7, ups=1.63, wpb=243.4, bsz=16, num_updates=54800, lr=9.92768e-05, gnorm=12.397, clip=66, loss_scale=128, train_wall=31, gb_free=18.3, wall=34077
2025-11-08 02:12:40 | INFO | train_inner | epoch 001:  55019 / 91072 loss=0.927734, wps=392.2, ups=1.62, wpb=242.6, bsz=16, num_updates=54850, lr=9.92731e-05, gnorm=17.993, clip=84, loss_scale=256, train_wall=31, gb_free=17.9, wall=34108
2025-11-08 02:13:11 | INFO | train_inner | epoch 001:  55069 / 91072 loss=0.752441, wps=389.4, ups=1.63, wpb=238.9, bsz=16, num_updates=54900, lr=9.92694e-05, gnorm=10.653, clip=68, loss_scale=256, train_wall=31, gb_free=17.5, wall=34139
2025-11-08 02:13:42 | INFO | train_inner | epoch 001:  55119 / 91072 loss=0.810547, wps=389.7, ups=1.63, wpb=238.8, bsz=16, num_updates=54950, lr=9.92657e-05, gnorm=11.815, clip=68, loss_scale=256, train_wall=30, gb_free=16, wall=34170
2025-11-08 02:14:13 | INFO | train_inner | epoch 001:  55169 / 91072 loss=0.736328, wps=395.2, ups=1.59, wpb=249.1, bsz=16, num_updates=55000, lr=9.9262e-05, gnorm=9.014, clip=60, loss_scale=256, train_wall=31, gb_free=17.6, wall=34201
2025-11-08 02:14:43 | INFO | train_inner | epoch 001:  55219 / 91072 loss=0.76416, wps=383.8, ups=1.66, wpb=231.7, bsz=16, num_updates=55050, lr=9.92583e-05, gnorm=10.197, clip=66, loss_scale=256, train_wall=30, gb_free=18.7, wall=34231
2025-11-08 02:15:15 | INFO | train_inner | epoch 001:  55269 / 91072 loss=0.75, wps=396.6, ups=1.6, wpb=248.3, bsz=16, num_updates=55100, lr=9.92546e-05, gnorm=7.728, clip=52, loss_scale=512, train_wall=31, gb_free=18.1, wall=34263
2025-11-08 02:15:48 | INFO | train_inner | epoch 001:  55319 / 91072 loss=0.820801, wps=383, ups=1.51, wpb=253.6, bsz=16, num_updates=55150, lr=9.92509e-05, gnorm=10.336, clip=76, loss_scale=512, train_wall=33, gb_free=18.9, wall=34296
2025-11-08 02:16:20 | INFO | train_inner | epoch 001:  55369 / 91072 loss=0.842773, wps=391.2, ups=1.56, wpb=250.6, bsz=16, num_updates=55200, lr=9.92472e-05, gnorm=11.002, clip=74, loss_scale=512, train_wall=32, gb_free=16.1, wall=34328
2025-11-08 02:16:50 | INFO | train_inner | epoch 001:  55419 / 91072 loss=0.825195, wps=400.1, ups=1.64, wpb=243.8, bsz=16, num_updates=55250, lr=9.92436e-05, gnorm=10.142, clip=72, loss_scale=512, train_wall=30, gb_free=17.3, wall=34358
2025-11-08 02:17:23 | INFO | train_inner | epoch 001:  55469 / 91072 loss=0.762695, wps=391.3, ups=1.55, wpb=252.5, bsz=16, num_updates=55300, lr=9.92399e-05, gnorm=10.972, clip=78, loss_scale=512, train_wall=32, gb_free=17.9, wall=34390
2025-11-08 02:17:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-08 02:17:55 | INFO | train_inner | epoch 001:  55520 / 91072 loss=0.758789, wps=378.4, ups=1.53, wpb=246.7, bsz=16, num_updates=55350, lr=9.92362e-05, gnorm=9.703, clip=68, loss_scale=512, train_wall=32, gb_free=18, wall=34423
2025-11-08 02:18:27 | INFO | train_inner | epoch 001:  55570 / 91072 loss=0.803711, wps=390.4, ups=1.57, wpb=248.4, bsz=16, num_updates=55400, lr=9.92325e-05, gnorm=9.354, clip=68, loss_scale=512, train_wall=32, gb_free=13.2, wall=34455
2025-11-08 02:18:59 | INFO | train_inner | epoch 001:  55620 / 91072 loss=0.809082, wps=365.2, ups=1.58, wpb=231.2, bsz=16, num_updates=55450, lr=9.92288e-05, gnorm=11.046, clip=72, loss_scale=512, train_wall=31, gb_free=17.6, wall=34487
2025-11-08 02:19:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2025-11-08 02:19:30 | INFO | train_inner | epoch 001:  55671 / 91072 loss=0.898926, wps=379.4, ups=1.61, wpb=235.7, bsz=16, num_updates=55500, lr=9.92251e-05, gnorm=9.361, clip=64, loss_scale=256, train_wall=31, gb_free=12, wall=34518
2025-11-08 02:20:01 | INFO | train_inner | epoch 001:  55721 / 91072 loss=0.773926, wps=407.4, ups=1.6, wpb=254.8, bsz=16, num_updates=55550, lr=9.92214e-05, gnorm=9.698, clip=70, loss_scale=256, train_wall=31, gb_free=15.5, wall=34549
2025-11-08 02:20:31 | INFO | train_inner | epoch 001:  55771 / 91072 loss=0.82959, wps=400.6, ups=1.66, wpb=240.7, bsz=16, num_updates=55600, lr=9.92177e-05, gnorm=8.652, clip=66, loss_scale=256, train_wall=30, gb_free=17.4, wall=34579
2025-11-08 02:21:01 | INFO | train_inner | epoch 001:  55821 / 91072 loss=0.74707, wps=406.4, ups=1.65, wpb=246.4, bsz=16, num_updates=55650, lr=9.9214e-05, gnorm=9.724, clip=70, loss_scale=256, train_wall=30, gb_free=10.6, wall=34609
2025-11-08 02:21:31 | INFO | train_inner | epoch 001:  55871 / 91072 loss=0.790527, wps=407, ups=1.66, wpb=245.6, bsz=16, num_updates=55700, lr=9.92103e-05, gnorm=9.593, clip=64, loss_scale=256, train_wall=30, gb_free=16.6, wall=34639
2025-11-08 02:22:01 | INFO | train_inner | epoch 001:  55921 / 91072 loss=0.764648, wps=389, ups=1.68, wpb=232.2, bsz=16, num_updates=55750, lr=9.92067e-05, gnorm=9.9, clip=58, loss_scale=256, train_wall=30, gb_free=18.5, wall=34669
2025-11-08 02:22:31 | INFO | train_inner | epoch 001:  55971 / 91072 loss=0.872559, wps=389.8, ups=1.68, wpb=231.5, bsz=16, num_updates=55800, lr=9.9203e-05, gnorm=9.329, clip=66, loss_scale=512, train_wall=30, gb_free=13.3, wall=34699
2025-11-08 02:23:02 | INFO | train_inner | epoch 001:  56021 / 91072 loss=0.861328, wps=407.7, ups=1.6, wpb=255.3, bsz=16, num_updates=55850, lr=9.91993e-05, gnorm=11.524, clip=72, loss_scale=512, train_wall=31, gb_free=16.6, wall=34730
2025-11-08 02:23:33 | INFO | train_inner | epoch 001:  56071 / 91072 loss=0.828125, wps=409.7, ups=1.62, wpb=253.1, bsz=16, num_updates=55900, lr=9.91956e-05, gnorm=10.13, clip=68, loss_scale=512, train_wall=31, gb_free=11.7, wall=34761
2025-11-08 02:24:04 | INFO | train_inner | epoch 001:  56121 / 91072 loss=0.825195, wps=404.9, ups=1.62, wpb=250.3, bsz=16, num_updates=55950, lr=9.91919e-05, gnorm=8.509, clip=70, loss_scale=512, train_wall=31, gb_free=16.5, wall=34792
2025-11-08 02:24:35 | INFO | train_inner | epoch 001:  56171 / 91072 loss=0.741211, wps=399.6, ups=1.6, wpb=250.2, bsz=16, num_updates=56000, lr=9.91882e-05, gnorm=7.354, clip=54, loss_scale=512, train_wall=31, gb_free=2.5, wall=34823
2025-11-08 02:24:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-08 02:25:08 | INFO | train_inner | epoch 001:  56222 / 91072 loss=0.772949, wps=387, ups=1.56, wpb=248.8, bsz=16, num_updates=56050, lr=9.91845e-05, gnorm=8.686, clip=66, loss_scale=512, train_wall=32, gb_free=14.9, wall=34856
2025-11-08 02:25:43 | INFO | train_inner | epoch 001:  56272 / 91072 loss=0.753418, wps=337.1, ups=1.42, wpb=237.8, bsz=16, num_updates=56100, lr=9.91808e-05, gnorm=7.945, clip=58, loss_scale=512, train_wall=35, gb_free=17.1, wall=34891
2025-11-08 02:26:13 | INFO | train_inner | epoch 001:  56322 / 91072 loss=0.732422, wps=391.3, ups=1.65, wpb=237.2, bsz=16, num_updates=56150, lr=9.91771e-05, gnorm=9.126, clip=72, loss_scale=512, train_wall=30, gb_free=16.6, wall=34921
2025-11-08 02:26:44 | INFO | train_inner | epoch 001:  56372 / 91072 loss=0.718262, wps=400.9, ups=1.64, wpb=245.1, bsz=16, num_updates=56200, lr=9.91734e-05, gnorm=8.949, clip=66, loss_scale=512, train_wall=30, gb_free=17, wall=34952
2025-11-08 02:27:14 | INFO | train_inner | epoch 001:  56422 / 91072 loss=0.743164, wps=401.5, ups=1.65, wpb=242.8, bsz=16, num_updates=56250, lr=9.91697e-05, gnorm=9.964, clip=68, loss_scale=512, train_wall=30, gb_free=18.5, wall=34982
2025-11-08 02:27:47 | INFO | train_inner | epoch 001:  56472 / 91072 loss=0.812012, wps=364.6, ups=1.5, wpb=243.5, bsz=16, num_updates=56300, lr=9.91661e-05, gnorm=8.146, clip=64, loss_scale=1024, train_wall=33, gb_free=16.7, wall=35015
2025-11-08 02:27:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-08 02:28:20 | INFO | train_inner | epoch 001:  56523 / 91072 loss=0.804688, wps=391.3, ups=1.55, wpb=252.6, bsz=16, num_updates=56350, lr=9.91624e-05, gnorm=9.504, clip=70, loss_scale=512, train_wall=32, gb_free=17.9, wall=35048
2025-11-08 02:28:50 | INFO | train_inner | epoch 001:  56573 / 91072 loss=0.819336, wps=407.6, ups=1.64, wpb=248.4, bsz=16, num_updates=56400, lr=9.91587e-05, gnorm=8.988, clip=70, loss_scale=512, train_wall=30, gb_free=16.7, wall=35078
2025-11-08 02:29:21 | INFO | train_inner | epoch 001:  56623 / 91072 loss=0.785645, wps=399.8, ups=1.64, wpb=243.8, bsz=16, num_updates=56450, lr=9.9155e-05, gnorm=7.996, clip=66, loss_scale=512, train_wall=30, gb_free=17.3, wall=35109
2025-11-08 02:29:55 | INFO | train_inner | epoch 001:  56673 / 91072 loss=0.752441, wps=361.5, ups=1.47, wpb=246.7, bsz=16, num_updates=56500, lr=9.91513e-05, gnorm=8.275, clip=66, loss_scale=512, train_wall=34, gb_free=18.5, wall=35143
2025-11-08 02:30:27 | INFO | train_inner | epoch 001:  56723 / 91072 loss=0.73584, wps=389.7, ups=1.56, wpb=249.2, bsz=16, num_updates=56550, lr=9.91476e-05, gnorm=8.069, clip=64, loss_scale=512, train_wall=32, gb_free=11.8, wall=35175
2025-11-08 02:30:57 | INFO | train_inner | epoch 001:  56773 / 91072 loss=0.715332, wps=407.7, ups=1.65, wpb=246.6, bsz=16, num_updates=56600, lr=9.91439e-05, gnorm=8.197, clip=64, loss_scale=1024, train_wall=30, gb_free=17.7, wall=35205
2025-11-08 02:31:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-08 02:31:28 | INFO | train_inner | epoch 001:  56824 / 91072 loss=0.832031, wps=393.4, ups=1.61, wpb=244.5, bsz=16, num_updates=56650, lr=9.91402e-05, gnorm=9.271, clip=72, loss_scale=512, train_wall=31, gb_free=15.3, wall=35236
2025-11-08 02:31:59 | INFO | train_inner | epoch 001:  56874 / 91072 loss=0.850586, wps=385.8, ups=1.62, wpb=238.1, bsz=16, num_updates=56700, lr=9.91365e-05, gnorm=10.571, clip=80, loss_scale=512, train_wall=31, gb_free=16.8, wall=35267
2025-11-08 02:32:30 | INFO | train_inner | epoch 001:  56924 / 91072 loss=0.814941, wps=405.1, ups=1.63, wpb=248.8, bsz=16, num_updates=56750, lr=9.91329e-05, gnorm=9.113, clip=74, loss_scale=512, train_wall=31, gb_free=16.1, wall=35298
2025-11-08 02:33:00 | INFO | train_inner | epoch 001:  56974 / 91072 loss=0.793457, wps=406.3, ups=1.63, wpb=249.5, bsz=16, num_updates=56800, lr=9.91292e-05, gnorm=8.29, clip=68, loss_scale=512, train_wall=31, gb_free=15.9, wall=35328
2025-11-08 02:33:31 | INFO | train_inner | epoch 001:  57024 / 91072 loss=0.727539, wps=393.4, ups=1.61, wpb=244.5, bsz=16, num_updates=56850, lr=9.91255e-05, gnorm=10.451, clip=78, loss_scale=512, train_wall=31, gb_free=18.3, wall=35359
2025-11-08 02:34:02 | INFO | train_inner | epoch 001:  57074 / 91072 loss=0.775391, wps=379.2, ups=1.64, wpb=231.2, bsz=16, num_updates=56900, lr=9.91218e-05, gnorm=8.214, clip=64, loss_scale=1024, train_wall=30, gb_free=18.9, wall=35390
2025-11-08 02:34:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-08 02:34:34 | INFO | train_inner | epoch 001:  57125 / 91072 loss=0.808105, wps=378, ups=1.58, wpb=238.9, bsz=16, num_updates=56950, lr=9.91181e-05, gnorm=8.737, clip=60, loss_scale=512, train_wall=31, gb_free=19.2, wall=35421
2025-11-08 02:35:04 | INFO | train_inner | epoch 001:  57175 / 91072 loss=0.740723, wps=403.1, ups=1.63, wpb=247.6, bsz=16, num_updates=57000, lr=9.91144e-05, gnorm=6.922, clip=54, loss_scale=512, train_wall=31, gb_free=19.4, wall=35452
2025-11-08 02:35:36 | INFO | train_inner | epoch 001:  57225 / 91072 loss=0.699219, wps=386.2, ups=1.56, wpb=246.8, bsz=16, num_updates=57050, lr=9.91107e-05, gnorm=7.615, clip=58, loss_scale=512, train_wall=32, gb_free=16.5, wall=35484
2025-11-08 02:36:08 | INFO | train_inner | epoch 001:  57275 / 91072 loss=0.726074, wps=410.9, ups=1.58, wpb=259.4, bsz=16, num_updates=57100, lr=9.9107e-05, gnorm=8.161, clip=58, loss_scale=512, train_wall=31, gb_free=17.5, wall=35516
2025-11-08 02:36:38 | INFO | train_inner | epoch 001:  57325 / 91072 loss=0.789551, wps=400.6, ups=1.64, wpb=244.2, bsz=16, num_updates=57150, lr=9.91033e-05, gnorm=11.361, clip=74, loss_scale=512, train_wall=30, gb_free=16.2, wall=35546
2025-11-08 02:36:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2025-11-08 02:37:11 | INFO | train_inner | epoch 001:  57376 / 91072 loss=0.710449, wps=385.2, ups=1.52, wpb=254, bsz=16, num_updates=57200, lr=9.90996e-05, gnorm=8.124, clip=68, loss_scale=512, train_wall=33, gb_free=17.5, wall=35579
2025-11-08 02:37:42 | INFO | train_inner | epoch 001:  57426 / 91072 loss=0.768066, wps=384.9, ups=1.61, wpb=239.4, bsz=16, num_updates=57250, lr=9.90959e-05, gnorm=8.605, clip=62, loss_scale=512, train_wall=31, gb_free=18.1, wall=35610
==========================================
 ‚úÖ ‰ªªÂä°ÂÆåÊàê‰∫é: Sat Nov  8 02:38:47 CST 2025
==========================================
