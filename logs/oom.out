[INFO] Job starting at Sun Oct 26 19:26:29 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä® (LMDBÊ†ºÂºè)
 ËäÇÁÇπ:        g0109
 ‰Ωú‰∏öID:      4495938
 GPUs:        0,1,2,3,4,5,6,7
 ÂêØÂä®Êó∂Èó¥:    Sun Oct 26 19:26:30 CST 2025
==========================================
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - Â§öGPUÂàÜÂ∏ÉÂºèÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           8 GPUs √ó 1 node(s)
DataLoader workers: 8 per GPU
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/lmdb/valid.lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     ./affincraft_pretrain_ckpts_lmdb_multi_gpu
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   160
===================================================================
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:29:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-26 19:30:03 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2025-10-26 19:30:03 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 0
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 7
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 4
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 2
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 5
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 3
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 6
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2025-10-26 19:30:04 | INFO | fairseq.distributed.utils | initialized host g0109 as rank 1
2025-10-26 19:30:05 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 1, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 100, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 20, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 150, 'max_update': 1875000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './affincraft_pretrain_ckpts_lmdb_multi_gpu', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=1, fp16_scale_window=128, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=8, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=20, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=20, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=150, max_update=1875000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts_lmdb_multi_gpu', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=512, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/lmdb/valid.lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=75000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1875000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.1, act_dropout=0.1, dropout=0.1, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 512, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/lmdb/valid.lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 75000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 1875000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb





Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129





2025-10-26 19:30:05 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/lmdb/valid.lmdb





Ê†∑Êú¨ÊÄªÊï∞: 160,000
Ê†∑Êú¨ÊÄªÊï∞: 160,000Ê†∑Êú¨ÊÄªÊï∞: 160,000Ê†∑Êú¨ÊÄªÊï∞: 160,000Ê†∑Êú¨ÊÄªÊï∞: 160,000Ê†∑Êú¨ÊÄªÊï∞: 160,000Ê†∑Êú¨ÊÄªÊï∞: 160,000
Ê†∑Êú¨ÊÄªÊï∞: 160,000






2025-10-26 19:30:05 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå160000 ‰∏™Ê†∑Êú¨
2025-10-26 19:30:05 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=1, fp16_scale_window=128, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=8, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=20, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=20, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=150, max_update=1875000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts_lmdb_multi_gpu', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=512, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/lmdb/valid.lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=75000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1875000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.1, act_dropout=0.1, dropout=0.1, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-10-26 19:30:06 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-10-26 19:30:06 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-10-26 19:30:06 | INFO | fairseq_cli.train | model: GraphormerModel
2025-10-26 19:30:06 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-10-26 19:30:06 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-10-26 19:30:06 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-10-26 19:30:06 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 160000
2025-10-26 19:30:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   4: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   5: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   6: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | rank   7: capabilities =  8.9  ; total memory = 23.643 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-26 19:30:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-10-26 19:30:06 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2025-10-26 19:30:06 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 20
2025-10-26 19:30:06 | INFO | fairseq.trainer | Preparing to load checkpoint ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint_last.pt
2025-10-26 19:30:06 | INFO | fairseq.trainer | No existing checkpoint found ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint_last.pt
2025-10-26 19:30:06 | INFO | fairseq.trainer | loading train data for epoch 1
2025-10-26 19:30:06 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-10-26 19:30:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9108
2025-10-26 19:30:12 | INFO | fairseq.trainer | begin training epoch 1
2025-10-26 19:30:12 | INFO | fairseq_cli.train | Start iterating over samples
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 9535 (pdbid: 3chq_frame24)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 9535 (pdbid: 3chq_frame24)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 893502 (pdbid: 3ztx_frame31)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 893502 (pdbid: 3ztx_frame31)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 707850 (pdbid: 3cho_frame18)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 707850 (pdbid: 3cho_frame18)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 732310 (pdbid: 3lpf_frame46)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 732310 (pdbid: 3lpf_frame46)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 42971 (pdbid: 1x6u_frame96)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 42971 (pdbid: 1x6u_frame96)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 904421 (pdbid: 2xyd_frame15)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 904421 (pdbid: 2xyd_frame15)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 508567 (pdbid: 3ow3_frame25)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 508567 (pdbid: 3ow3_frame25)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 585969 (pdbid: 5gn9_frame74)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 585969 (pdbid: 5gn9_frame74)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 956209 (pdbid: 4zxy_frame79)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 956209 (pdbid: 4zxy_frame79)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 762588 (pdbid: 3lp7_frame78)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 762588 (pdbid: 3lp7_frame78)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 692359 (pdbid: 6q7w_frame86)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 692359 (pdbid: 6q7w_frame86)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 609385 (pdbid: 3v0p_frame18)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 609385 (pdbid: 3v0p_frame18)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 933311 (pdbid: 3saz_frame83)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 933311 (pdbid: 3saz_frame83)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 901936 (pdbid: 1h1b_frame51)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 901936 (pdbid: 1h1b_frame51)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 480891 (pdbid: 4y6m_frame1)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 480891 (pdbid: 4y6m_frame1)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 625601 (pdbid: 3ogq_frame98)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 625601 (pdbid: 3ogq_frame98)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1403552 (pdbid: 6c5q_frame43)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1403552 (pdbid: 6c5q_frame43)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 100486 (pdbid: 3q44_frame48)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 100486 (pdbid: 3q44_frame48)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 857667 (pdbid: 2w1f_frame66)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 857667 (pdbid: 2w1f_frame66)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1400118 (pdbid: 5knr_frame68)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1400118 (pdbid: 5knr_frame68)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 489827 (pdbid: 4anx_frame29)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 489827 (pdbid: 4anx_frame29)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1450112 (pdbid: 4ea3_frame39)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1450112 (pdbid: 4ea3_frame39)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 515114 (pdbid: 4mse_frame85)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 515114 (pdbid: 4mse_frame85)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 950277 (pdbid: 6qre_frame75)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 950277 (pdbid: 6qre_frame75)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 659975 (pdbid: 2qbp_frame6)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 659975 (pdbid: 2qbp_frame6)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 988479 (pdbid: 4w9e_frame79)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 988479 (pdbid: 4w9e_frame79)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 161323 (pdbid: 4pni_frame84)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 161323 (pdbid: 4pni_frame84)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 593132 (pdbid: 5alt_frame18)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 593132 (pdbid: 5alt_frame18)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1064355 (pdbid: 3kqp_frame59)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1064355 (pdbid: 3kqp_frame59)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1164243 (pdbid: 4dkt_frame62)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1164243 (pdbid: 4dkt_frame62)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 286901 (pdbid: 2rcu_frame64)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 286901 (pdbid: 2rcu_frame64)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 790738 (pdbid: 4m2v_frame78)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 790738 (pdbid: 4m2v_frame78)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1451674 (pdbid: 5m39_frame96)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1451674 (pdbid: 5m39_frame96)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1420055 (pdbid: 5voj_frame72)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1420055 (pdbid: 5voj_frame72)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 707979 (pdbid: 4nal_frame26)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 707979 (pdbid: 4nal_frame26)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 82569 (pdbid: 2bqw_frame76)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 82569 (pdbid: 2bqw_frame76)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1413130 (pdbid: 5mys_frame94)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 1413130 (pdbid: 5mys_frame94)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 514704 (pdbid: 1f9g_frame41)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 514704 (pdbid: 1f9g_frame41)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 187683 (pdbid: 5aol_frame16)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 187683 (pdbid: 5aol_frame16)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 624464 (pdbid: 6oja_frame66)
Ë≠¶Âëä: Ë∑≥ËøáÂåÖÂê´NaNÁöÑÊ†∑Êú¨ 624464 (pdbid: 6oja_frame66)
2025-10-26 19:36:02 | ERROR | graphormer.criterions.l2_loss | ERROR during forward pass: CUDA out of memory. Tried to allocate 614.00 MiB. GPU 4 has a total capacity of 23.64 GiB of which 455.69 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 634.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-26 19:36:02 | ERROR | graphormer.criterions.l2_loss | Sample ID: None
2025-10-26 19:36:02 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 614.00 MiB. GPU 4 has a total capacity of 23.64 GiB of which 455.69 MiB is free. Including non-PyTorch memory, this process has 23.14 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 634.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 3         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  22451 MiB |  22451 MiB |  11498 GiB |  11476 GiB |
|       from large pool |  22392 MiB |  22392 MiB |  11390 GiB |  11368 GiB |
|       from small pool |     58 MiB |     59 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  22451 MiB |  22451 MiB |  11498 GiB |  11476 GiB |
|       from large pool |  22392 MiB |  22392 MiB |  11390 GiB |  11368 GiB |
|       from small pool |     58 MiB |     59 MiB |    108 GiB |    108 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  22446 MiB |  22446 MiB |  11471 GiB |  11449 GiB |
|       from large pool |  22388 MiB |  22388 MiB |  11363 GiB |  11341 GiB |
|       from small pool |     58 MiB |     59 MiB |    107 GiB |    107 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  23086 MiB |  23498 MiB |  64596 MiB |  41510 MiB |
|       from large pool |  23024 MiB |  23414 MiB |  64500 MiB |  41476 MiB |
|       from small pool |     62 MiB |     84 MiB |     96 MiB |     34 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 649694 KiB |   4559 MiB |  10383 GiB |  10383 GiB |
|       from large pool | 646336 KiB |   4519 MiB |  10272 GiB |  10271 GiB |
|       from small pool |   3358 KiB |     49 MiB |    111 GiB |    111 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3116    |    3116    |    3215 K  |    3212 K  |
|       from large pool |     374    |     374    |     320 K  |     320 K  |
|       from small pool |    2742    |    2743    |    2894 K  |    2892 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3116    |    3116    |    3215 K  |    3212 K  |
|       from large pool |     374    |     374    |     320 K  |     320 K  |
|       from small pool |    2742    |    2743    |    2894 K  |    2892 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      91    |     115    |     305    |     214    |
|       from large pool |      60    |      73    |     257    |     197    |
|       from small pool |      31    |      42    |      48    |      17    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     555    |     555    |    2054 K  |    2054 K  |
|       from large pool |      49    |      54    |     125 K  |     125 K  |
|       from small pool |     506    |     506    |    1929 K  |    1928 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2025-10-26 19:36:02 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
