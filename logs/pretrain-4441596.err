gcc-12.2.0 loaded successful
WARNING: underlay of /etc/localtime required more than 50 (88) bind mounts
WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (410) bind mounts
W1018 13:58:08.476398 22560 torch/distributed/run.py:792] 
W1018 13:58:08.476398 22560 torch/distributed/run.py:792] *****************************************
W1018 13:58:08.476398 22560 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1018 13:58:08.476398 22560 torch/distributed/run.py:792] *****************************************
2025-10-18 13:58:33.607595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607636: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607639: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-18 13:58:33.607590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760767114.880396   22571 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760767114.880441   22568 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760767114.880407   22569 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760767114.880461   22566 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760767114.880408   22565 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760767114.880418   22570 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760767114.880416   22564 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760767114.880401   22567 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760767115.529874   22567 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529875   22564 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529880   22568 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529876   22570 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529880   22571 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529951   22569 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529965   22565 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1760767115.529876   22566 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1760767120.913616   22567 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913621   22564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913618   22568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913622   22565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913628   22569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913623   22570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913702   22567 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913730   22564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913776   22568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913803   22565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913833   22569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913863   22570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913868   22567 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913874   22564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913883   22568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913888   22565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913894   22569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913903   22570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913908   22567 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913923   22564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913932   22568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913937   22565 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913942   22569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913952   22570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913983   22566 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.914096   22566 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.914105   22566 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.914113   22566 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.913995   22571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.914160   22571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.914171   22571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760767120.914177   22571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-18 13:58:41.036603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036690: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 13:58:41.036602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[rank5]: Traceback (most recent call last):
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank5]:     sys.exit(cli_main())
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank5]:     distributed_utils.call_main(cfg, main)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank5]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank5]:     main(cfg, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank5]:     task = tasks.setup_task(cfg.task)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank5]:     return task.setup_task(cfg, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank5]:     return cls(cfg)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank5]:     self._setup_affincraft_dataset(cfg)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank5]:     raise e
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank5]:     dataset_train = LMDBAffinCraftDataset(
[rank5]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank3]:     sys.exit(cli_main())
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank3]:     distributed_utils.call_main(cfg, main)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank3]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank3]:     main(cfg, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank3]:     task = tasks.setup_task(cfg.task)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank3]:     return task.setup_task(cfg, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank3]:     return cls(cfg)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank3]:     self._setup_affincraft_dataset(cfg)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank3]:     raise e
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank3]:     dataset_train = LMDBAffinCraftDataset(
[rank3]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank7]: Traceback (most recent call last):
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank7]:     sys.exit(cli_main())
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank7]:     distributed_utils.call_main(cfg, main)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank7]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank7]:     main(cfg, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank7]:     task = tasks.setup_task(cfg.task)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank7]:     return task.setup_task(cfg, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank7]:     return cls(cfg)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank7]:     self._setup_affincraft_dataset(cfg)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank7]:     raise e
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank7]:     dataset_train = LMDBAffinCraftDataset(
[rank7]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank6]: Traceback (most recent call last):
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank6]:     sys.exit(cli_main())
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank6]:     distributed_utils.call_main(cfg, main)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank6]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank6]:     main(cfg, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank6]:     task = tasks.setup_task(cfg.task)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank6]:     return task.setup_task(cfg, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank6]:     return cls(cfg)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank6]:     self._setup_affincraft_dataset(cfg)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank6]:     raise e
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank6]:     dataset_train = LMDBAffinCraftDataset(
[rank6]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank2]:     sys.exit(cli_main())
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank2]:     distributed_utils.call_main(cfg, main)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank2]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank2]:     main(cfg, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank2]:     task = tasks.setup_task(cfg.task)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank2]:     return task.setup_task(cfg, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank2]:     return cls(cfg)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank2]:     self._setup_affincraft_dataset(cfg)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank2]:     raise e
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank2]:     dataset_train = LMDBAffinCraftDataset(
[rank2]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank1]:     sys.exit(cli_main())
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank1]:     distributed_utils.call_main(cfg, main)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank1]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank1]:     main(cfg, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank1]:     task = tasks.setup_task(cfg.task)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank1]:     return task.setup_task(cfg, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank1]:     return cls(cfg)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank1]:     self._setup_affincraft_dataset(cfg)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank1]:     raise e
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank1]:     dataset_train = LMDBAffinCraftDataset(
[rank1]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank0]:     sys.exit(cli_main())
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank0]:     distributed_utils.call_main(cfg, main)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank0]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank0]:     main(cfg, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank0]:     task = tasks.setup_task(cfg.task)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank0]:     return task.setup_task(cfg, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank0]:     return cls(cfg)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank0]:     self._setup_affincraft_dataset(cfg)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank0]:     raise e
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank0]:     dataset_train = LMDBAffinCraftDataset(
[rank0]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank4]: Traceback (most recent call last):
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank4]:     sys.exit(cli_main())
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank4]:     distributed_utils.call_main(cfg, main)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank4]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank4]:     main(cfg, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 87, in main
[rank4]:     task = tasks.setup_task(cfg.task)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
[rank4]:     return task.setup_task(cfg, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 406, in setup_task
[rank4]:     return cls(cfg)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 279, in __init__
[rank4]:     self._setup_affincraft_dataset(cfg)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 386, in _setup_affincraft_dataset
[rank4]:     raise e
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/tasks/graph_prediction.py", line 317, in _setup_affincraft_dataset
[rank4]:     dataset_train = LMDBAffinCraftDataset(
[rank4]: UnboundLocalError: local variable 'LMDBAffinCraftDataset' referenced before assignment
[rank0]:[W1018 14:00:56.951787332 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1018 14:01:00.341948 22560 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 22564 closing signal SIGTERM
W1018 14:01:00.342496 22560 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 22565 closing signal SIGTERM
W1018 14:01:00.342650 22560 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 22566 closing signal SIGTERM
W1018 14:01:00.342783 22560 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 22569 closing signal SIGTERM
W1018 14:01:00.342916 22560 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 22570 closing signal SIGTERM
E1018 14:01:00.495215 22560 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 22567) of binary: /data/run01/scw6f3q/zncao/affincraft/bin/python
Traceback (most recent call last):
  File "/data/run01/scw6f3q/zncao/affincraft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-18_14:01:00
  host      : g0109.para.ai
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 22568)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-10-18_14:01:00
  host      : g0109.para.ai
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 22571)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-18_14:01:00
  host      : g0109.para.ai
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 22567)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
