[INFO] Job starting at Fri Oct 31 22:22:40 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä® (LMDBÊ†ºÂºè)
 ËäÇÁÇπ:        g0499
 ‰Ωú‰∏öID:      4503582
 GPUs:        0,1,2,3,4,5,6,7
 ÂêØÂä®Êó∂Èó¥:    Fri Oct 31 22:22:41 CST 2025
==========================================
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - Â§öGPUÂàÜÂ∏ÉÂºèÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           8 GPUs √ó 1 node(s)
DataLoader workers: 6 per GPU
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/valid_lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     ./affincraft_pretrain_ckpts
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   128
-------------------------------------------------------------------
ÁõÆÊ†áËÆ≠ÁªÉËΩÆÊï∞:       100
‰º∞ÁÆóÊÄªÊõ¥Êñ∞Ê≠•Êï∞:     1250000
Â≠¶‰π†ÁéáÈ¢ÑÁÉ≠Ê≠•Êï∞:     50000
===================================================================
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:26:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-31 22:27:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2025-10-31 22:27:15 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 0
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 2
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 6
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 3
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 4
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 5
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 7
2025-10-31 22:27:16 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 1
2025-10-31 22:27:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 100, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 1250000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './affincraft_pretrain_ckpts', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=1250000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[5e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=474, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=50000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1250000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 474, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/valid_lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 50000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 1250000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb


Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129


LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129

LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb

Ê†∑Êú¨ÊÄªÊï∞: 80,568LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb

Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568

Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129



2025-10-31 22:27:17 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 80,568
2025-10-31 22:27:17 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå80568 ‰∏™Ê†∑Êú¨
2025-10-31 22:27:17 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=1250000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[5e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=474, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=50000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1250000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-10-31 22:27:18 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-10-31 22:27:18 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-10-31 22:27:18 | INFO | fairseq_cli.train | model: GraphormerModel
2025-10-31 22:27:18 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-10-31 22:27:18 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-10-31 22:27:18 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-10-31 22:27:18 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 80568
2025-10-31 22:27:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   4: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   5: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   6: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | rank   7: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-31 22:27:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-10-31 22:27:18 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2025-10-31 22:27:18 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 16
2025-10-31 22:27:18 | INFO | fairseq.trainer | Preparing to load checkpoint ./affincraft_pretrain_ckpts/checkpoint_last.pt
2025-10-31 22:27:27 | INFO | fairseq.trainer | Loaded checkpoint ./affincraft_pretrain_ckpts/checkpoint_last.pt (epoch 5 @ 45272 updates)
2025-10-31 22:27:27 | INFO | fairseq.trainer | loading train data for epoch 5
2025-10-31 22:27:27 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-10-31 22:27:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-10-31 22:27:30 | INFO | fairseq.trainer | begin training epoch 5
2025-10-31 22:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2025-10-31 22:28:14 | INFO | train_inner | epoch 005:     28 / 11384 loss=0.088873, wps=1642.7, ups=0.83, wpb=1966.9, bsz=128, num_updates=45300, lr=4.53e-05, gnorm=12.165, clip=100, loss_scale=16, train_wall=37, gb_free=17.3, wall=56
2025-10-31 22:29:05 | INFO | train_inner | epoch 005:     78 / 11384 loss=0.080564, wps=1928.2, ups=0.99, wpb=1954.1, bsz=128, num_updates=45350, lr=4.535e-05, gnorm=15.793, clip=100, loss_scale=16, train_wall=50, gb_free=13.7, wall=107
2025-10-31 22:29:53 | INFO | train_inner | epoch 005:    128 / 11384 loss=0.072514, wps=2025.2, ups=1.04, wpb=1954.6, bsz=128, num_updates=45400, lr=4.54e-05, gnorm=12.516, clip=98, loss_scale=16, train_wall=48, gb_free=10.5, wall=155
2025-10-31 22:30:41 | INFO | train_inner | epoch 005:    178 / 11384 loss=0.064483, wps=1982.8, ups=1.04, wpb=1908.6, bsz=128, num_updates=45450, lr=4.545e-05, gnorm=10.224, clip=100, loss_scale=16, train_wall=48, gb_free=15.4, wall=203
2025-10-31 22:31:29 | INFO | train_inner | epoch 005:    228 / 11384 loss=0.062154, wps=2047, ups=1.04, wpb=1964.4, bsz=128, num_updates=45500, lr=4.55e-05, gnorm=10.059, clip=98, loss_scale=16, train_wall=48, gb_free=16.6, wall=251
2025-10-31 22:32:18 | INFO | train_inner | epoch 005:    278 / 11384 loss=0.07245, wps=2018.6, ups=1.03, wpb=1953.5, bsz=128, num_updates=45550, lr=4.555e-05, gnorm=11.249, clip=100, loss_scale=32, train_wall=48, gb_free=13.4, wall=300
2025-10-31 22:32:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 22:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 22:33:09 | INFO | train_inner | epoch 005:    330 / 11384 loss=0.072471, wps=1929.7, ups=0.98, wpb=1974, bsz=128, num_updates=45600, lr=4.56e-05, gnorm=11.073, clip=100, loss_scale=8, train_wall=51, gb_free=13.4, wall=351
2025-10-31 22:33:59 | INFO | train_inner | epoch 005:    380 / 11384 loss=0.072439, wps=1980.8, ups=1, wpb=1976.5, bsz=128, num_updates=45650, lr=4.565e-05, gnorm=12.218, clip=92, loss_scale=8, train_wall=50, gb_free=12.9, wall=401
2025-10-31 22:34:48 | INFO | train_inner | epoch 005:    430 / 11384 loss=0.065318, wps=2003.4, ups=1.01, wpb=1980.5, bsz=128, num_updates=45700, lr=4.57e-05, gnorm=11.253, clip=98, loss_scale=8, train_wall=49, gb_free=13.2, wall=450
2025-10-31 22:35:36 | INFO | train_inner | epoch 005:    480 / 11384 loss=0.05679, wps=2010.3, ups=1.03, wpb=1945.3, bsz=128, num_updates=45750, lr=4.575e-05, gnorm=8.939, clip=96, loss_scale=8, train_wall=48, gb_free=15.4, wall=498
2025-10-31 22:36:25 | INFO | train_inner | epoch 005:    530 / 11384 loss=0.061307, wps=2021.8, ups=1.02, wpb=1979.7, bsz=128, num_updates=45800, lr=4.58e-05, gnorm=9.06, clip=96, loss_scale=8, train_wall=49, gb_free=15.5, wall=547
2025-10-31 22:37:14 | INFO | train_inner | epoch 005:    580 / 11384 loss=0.063779, wps=1999.6, ups=1.03, wpb=1941.1, bsz=128, num_updates=45850, lr=4.585e-05, gnorm=11.471, clip=98, loss_scale=8, train_wall=48, gb_free=13.3, wall=596
2025-10-31 22:38:10 | INFO | train_inner | epoch 005:    630 / 11384 loss=0.062297, wps=1748.4, ups=0.89, wpb=1972, bsz=128, num_updates=45900, lr=4.59e-05, gnorm=9.568, clip=98, loss_scale=16, train_wall=56, gb_free=16.3, wall=652
2025-10-31 22:43:20 | INFO | train_inner | epoch 005:    680 / 11384 loss=0.061903, wps=323.4, ups=0.16, wpb=2003.4, bsz=128, num_updates=45950, lr=4.595e-05, gnorm=10.549, clip=98, loss_scale=16, train_wall=285, gb_free=14, wall=962
2025-10-31 22:44:33 | INFO | train_inner | epoch 005:    730 / 11384 loss=0.058172, wps=1360, ups=0.69, wpb=1969.5, bsz=128, num_updates=46000, lr=4.6e-05, gnorm=10.791, clip=98, loss_scale=16, train_wall=50, gb_free=14.2, wall=1035
2025-10-31 22:45:27 | INFO | train_inner | epoch 005:    780 / 11384 loss=0.065623, wps=1771.2, ups=0.92, wpb=1928.9, bsz=128, num_updates=46050, lr=4.605e-05, gnorm=12.199, clip=98, loss_scale=16, train_wall=54, gb_free=16, wall=1089
2025-10-31 22:46:50 | INFO | train_inner | epoch 005:    830 / 11384 loss=0.063847, wps=1169.8, ups=0.6, wpb=1934, bsz=128, num_updates=46100, lr=4.61e-05, gnorm=11.834, clip=100, loss_scale=16, train_wall=82, gb_free=16.6, wall=1172
2025-10-31 22:46:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 22:48:02 | INFO | train_inner | epoch 005:    881 / 11384 loss=0.062394, wps=1351, ups=0.69, wpb=1963.4, bsz=128, num_updates=46150, lr=4.615e-05, gnorm=11.319, clip=100, loss_scale=8, train_wall=55, gb_free=16.2, wall=1244
2025-10-31 22:49:28 | INFO | train_inner | epoch 005:    931 / 11384 loss=0.067022, wps=1144.3, ups=0.59, wpb=1948.3, bsz=128, num_updates=46200, lr=4.62e-05, gnorm=12.45, clip=100, loss_scale=8, train_wall=85, gb_free=15.8, wall=1330
2025-10-31 22:50:19 | INFO | train_inner | epoch 005:    981 / 11384 loss=0.060019, wps=1887.7, ups=0.98, wpb=1932.8, bsz=128, num_updates=46250, lr=4.625e-05, gnorm=10.309, clip=98, loss_scale=8, train_wall=51, gb_free=14.7, wall=1381
2025-10-31 22:51:29 | INFO | train_inner | epoch 005:   1031 / 11384 loss=0.066342, wps=1395.7, ups=0.71, wpb=1967.1, bsz=128, num_updates=46300, lr=4.63e-05, gnorm=11.283, clip=98, loss_scale=8, train_wall=59, gb_free=16.4, wall=1451
2025-10-31 22:52:48 | INFO | train_inner | epoch 005:   1081 / 11384 loss=0.061057, wps=1232, ups=0.64, wpb=1937.2, bsz=128, num_updates=46350, lr=4.635e-05, gnorm=10.396, clip=98, loss_scale=8, train_wall=78, gb_free=15.8, wall=1530
2025-10-31 22:55:17 | INFO | train_inner | epoch 005:   1131 / 11384 loss=0.063594, wps=646.9, ups=0.33, wpb=1931.2, bsz=128, num_updates=46400, lr=4.64e-05, gnorm=17.956, clip=100, loss_scale=16, train_wall=61, gb_free=13.2, wall=1679
2025-10-31 22:56:59 | INFO | train_inner | epoch 005:   1181 / 11384 loss=0.062475, wps=962, ups=0.49, wpb=1969.7, bsz=128, num_updates=46450, lr=4.645e-05, gnorm=12.235, clip=98, loss_scale=16, train_wall=96, gb_free=15.9, wall=1781
2025-10-31 22:57:50 | INFO | train_inner | epoch 005:   1231 / 11384 loss=0.061661, wps=1922.9, ups=0.99, wpb=1943.7, bsz=127.9, num_updates=46500, lr=4.65e-05, gnorm=11.637, clip=98, loss_scale=16, train_wall=50, gb_free=17, wall=1832
2025-10-31 22:59:17 | INFO | train_inner | epoch 005:   1281 / 11384 loss=0.072916, wps=1121, ups=0.57, wpb=1955.8, bsz=128, num_updates=46550, lr=4.655e-05, gnorm=10.523, clip=100, loss_scale=16, train_wall=55, gb_free=13.4, wall=1919
2025-10-31 23:01:09 | INFO | train_inner | epoch 005:   1331 / 11384 loss=0.060342, wps=870.6, ups=0.45, wpb=1952.4, bsz=128, num_updates=46600, lr=4.66e-05, gnorm=15.055, clip=96, loss_scale=16, train_wall=104, gb_free=13.5, wall=2031
2025-10-31 23:01:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 23:03:02 | INFO | train_inner | epoch 005:   1382 / 11384 loss=0.062315, wps=867.6, ups=0.44, wpb=1952.6, bsz=128, num_updates=46650, lr=4.665e-05, gnorm=9.48, clip=94, loss_scale=16, train_wall=112, gb_free=14.6, wall=2144
2025-10-31 23:05:00 | INFO | train_inner | epoch 005:   1432 / 11384 loss=0.060655, wps=838.6, ups=0.42, wpb=1973.2, bsz=128, num_updates=46700, lr=4.67e-05, gnorm=10.615, clip=98, loss_scale=16, train_wall=117, gb_free=14.9, wall=2262
2025-10-31 23:06:22 | INFO | train_inner | epoch 005:   1482 / 11384 loss=0.062687, wps=1171.3, ups=0.61, wpb=1921.8, bsz=128, num_updates=46750, lr=4.675e-05, gnorm=12.291, clip=98, loss_scale=16, train_wall=82, gb_free=17.1, wall=2344
2025-10-31 23:07:14 | INFO | train_inner | epoch 005:   1532 / 11384 loss=0.061401, wps=1871.9, ups=0.96, wpb=1953.4, bsz=128, num_updates=46800, lr=4.68e-05, gnorm=11.042, clip=98, loss_scale=16, train_wall=52, gb_free=12.3, wall=2396
2025-10-31 23:10:07 | INFO | train_inner | epoch 005:   1582 / 11384 loss=0.062646, wps=565.4, ups=0.29, wpb=1953.4, bsz=128, num_updates=46850, lr=4.685e-05, gnorm=13.064, clip=100, loss_scale=16, train_wall=173, gb_free=11.4, wall=2568
2025-10-31 23:11:58 | INFO | train_inner | epoch 005:   1632 / 11384 loss=0.058128, wps=879.5, ups=0.45, wpb=1953.3, bsz=128, num_updates=46900, lr=4.69e-05, gnorm=9.657, clip=94, loss_scale=32, train_wall=111, gb_free=16.5, wall=2680
2025-10-31 23:13:17 | INFO | train_inner | epoch 005:   1682 / 11384 loss=0.063009, wps=1251.1, ups=0.63, wpb=1979.8, bsz=128, num_updates=46950, lr=4.695e-05, gnorm=10.055, clip=96, loss_scale=32, train_wall=57, gb_free=12.5, wall=2759
2025-10-31 23:14:09 | INFO | train_inner | epoch 005:   1732 / 11384 loss=0.060749, wps=1866, ups=0.95, wpb=1960.8, bsz=128, num_updates=47000, lr=4.7e-05, gnorm=10.132, clip=98, loss_scale=32, train_wall=52, gb_free=7.1, wall=2811
2025-10-31 23:14:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 23:15:35 | INFO | train_inner | epoch 005:   1783 / 11384 loss=0.060341, wps=1133.8, ups=0.58, wpb=1952.7, bsz=128, num_updates=47050, lr=4.705e-05, gnorm=9.963, clip=96, loss_scale=16, train_wall=86, gb_free=16.4, wall=2897
2025-10-31 23:16:57 | INFO | train_inner | epoch 005:   1833 / 11384 loss=0.059107, wps=1198, ups=0.61, wpb=1966, bsz=128, num_updates=47100, lr=4.71e-05, gnorm=9.212, clip=94, loss_scale=16, train_wall=82, gb_free=13.8, wall=2979
2025-10-31 23:19:08 | INFO | train_inner | epoch 005:   1883 / 11384 loss=0.058491, wps=766.9, ups=0.38, wpb=1996.2, bsz=128, num_updates=47150, lr=4.715e-05, gnorm=10.492, clip=96, loss_scale=16, train_wall=130, gb_free=14.3, wall=3110
2025-10-31 23:20:56 | INFO | train_inner | epoch 005:   1933 / 11384 loss=0.05756, wps=905.4, ups=0.46, wpb=1971.5, bsz=128, num_updates=47200, lr=4.72e-05, gnorm=9.41, clip=94, loss_scale=16, train_wall=64, gb_free=16.3, wall=3218
2025-10-31 23:23:53 | INFO | train_inner | epoch 005:   1983 / 11384 loss=0.065411, wps=556.5, ups=0.28, wpb=1961, bsz=128, num_updates=47250, lr=4.725e-05, gnorm=11.924, clip=100, loss_scale=16, train_wall=56, gb_free=15.9, wall=3395
2025-10-31 23:23:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 23:25:58 | INFO | train_inner | epoch 005:   2034 / 11384 loss=0.060694, wps=789.5, ups=0.4, wpb=1980.3, bsz=128, num_updates=47300, lr=4.73e-05, gnorm=11.758, clip=98, loss_scale=8, train_wall=53, gb_free=8.4, wall=3520
2025-10-31 23:26:51 | INFO | train_inner | epoch 005:   2084 / 11384 loss=0.065308, wps=1880, ups=0.95, wpb=1978.9, bsz=128, num_updates=47350, lr=4.735e-05, gnorm=10.892, clip=96, loss_scale=8, train_wall=52, gb_free=16.1, wall=3573
2025-10-31 23:28:46 | INFO | train_inner | epoch 005:   2134 / 11384 loss=0.05884, wps=834, ups=0.43, wpb=1931.3, bsz=128, num_updates=47400, lr=4.74e-05, gnorm=9.429, clip=96, loss_scale=8, train_wall=116, gb_free=15.1, wall=3688
2025-10-31 23:30:08 | INFO | train_inner | epoch 005:   2184 / 11384 loss=0.057547, wps=1187.1, ups=0.61, wpb=1938, bsz=128, num_updates=47450, lr=4.745e-05, gnorm=11.903, clip=92, loss_scale=8, train_wall=81, gb_free=13.4, wall=3770
2025-10-31 23:31:31 | INFO | train_inner | epoch 005:   2234 / 11384 loss=0.060232, wps=1193.9, ups=0.61, wpb=1970.9, bsz=128, num_updates=47500, lr=4.75e-05, gnorm=11.003, clip=94, loss_scale=8, train_wall=82, gb_free=8.9, wall=3853
2025-10-31 23:32:57 | INFO | train_inner | epoch 005:   2284 / 11384 loss=0.070185, wps=1124.5, ups=0.58, wpb=1936.6, bsz=128, num_updates=47550, lr=4.755e-05, gnorm=14.402, clip=100, loss_scale=16, train_wall=86, gb_free=16.6, wall=3939
2025-10-31 23:33:51 | INFO | train_inner | epoch 005:   2334 / 11384 loss=0.079178, wps=1822.9, ups=0.92, wpb=1971.9, bsz=128, num_updates=47600, lr=4.76e-05, gnorm=10.802, clip=98, loss_scale=16, train_wall=54, gb_free=13.2, wall=3993
2025-10-31 23:36:07 | INFO | train_inner | epoch 005:   2384 / 11384 loss=0.073779, wps=720.5, ups=0.37, wpb=1968.7, bsz=128, num_updates=47650, lr=4.765e-05, gnorm=12.953, clip=100, loss_scale=16, train_wall=136, gb_free=16, wall=4129
2025-10-31 23:38:14 | INFO | train_inner | epoch 005:   2434 / 11384 loss=0.062386, wps=799.3, ups=0.39, wpb=2025.6, bsz=128, num_updates=47700, lr=4.77e-05, gnorm=10.996, clip=100, loss_scale=16, train_wall=126, gb_free=16.4, wall=4256
2025-10-31 23:38:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 23:39:05 | INFO | train_inner | epoch 005:   2485 / 11384 loss=0.070802, wps=1904.4, ups=0.98, wpb=1950, bsz=128, num_updates=47750, lr=4.775e-05, gnorm=15.284, clip=98, loss_scale=8, train_wall=51, gb_free=14, wall=4307
2025-10-31 23:40:30 | INFO | train_inner | epoch 005:   2535 / 11384 loss=0.065999, wps=1131, ups=0.59, wpb=1924.9, bsz=128, num_updates=47800, lr=4.78e-05, gnorm=12.092, clip=98, loss_scale=8, train_wall=52, gb_free=15.1, wall=4392
2025-10-31 23:42:30 | INFO | train_inner | epoch 005:   2585 / 11384 loss=0.067261, wps=824.3, ups=0.42, wpb=1970.4, bsz=128, num_updates=47850, lr=4.785e-05, gnorm=10.849, clip=100, loss_scale=8, train_wall=119, gb_free=13.4, wall=4512
2025-10-31 23:43:54 | INFO | train_inner | epoch 005:   2635 / 11384 loss=0.061592, wps=1163.9, ups=0.6, wpb=1950, bsz=128, num_updates=47900, lr=4.79e-05, gnorm=11.232, clip=94, loss_scale=8, train_wall=51, gb_free=14.7, wall=4596
2025-10-31 23:45:27 | INFO | train_inner | epoch 005:   2685 / 11384 loss=0.068859, wps=1043.4, ups=0.54, wpb=1946.1, bsz=128, num_updates=47950, lr=4.795e-05, gnorm=10.722, clip=100, loss_scale=8, train_wall=93, gb_free=10.4, wall=4689
2025-10-31 23:47:41 | INFO | train_inner | epoch 005:   2735 / 11384 loss=0.061487, wps=726, ups=0.37, wpb=1947.9, bsz=128, num_updates=48000, lr=4.8e-05, gnorm=12, clip=100, loss_scale=16, train_wall=134, gb_free=15.6, wall=4823
2025-10-31 23:49:13 | INFO | train_inner | epoch 005:   2785 / 11384 loss=0.056836, wps=1057.5, ups=0.54, wpb=1944.2, bsz=128, num_updates=48050, lr=4.805e-05, gnorm=12.371, clip=92, loss_scale=16, train_wall=92, gb_free=14.9, wall=4915
2025-10-31 23:51:41 | INFO | train_inner | epoch 005:   2835 / 11384 loss=0.064626, wps=657.8, ups=0.34, wpb=1945.4, bsz=128, num_updates=48100, lr=4.81e-05, gnorm=12.545, clip=100, loss_scale=16, train_wall=148, gb_free=11, wall=5063
2025-10-31 23:52:37 | INFO | train_inner | epoch 005:   2885 / 11384 loss=0.069902, wps=1739.3, ups=0.89, wpb=1961.1, bsz=128, num_updates=48150, lr=4.815e-05, gnorm=13.979, clip=98, loss_scale=16, train_wall=56, gb_free=15.5, wall=5119
2025-10-31 23:53:58 | INFO | train_inner | epoch 005:   2935 / 11384 loss=0.067813, wps=1192.9, ups=0.62, wpb=1916.7, bsz=128, num_updates=48200, lr=4.82e-05, gnorm=16.13, clip=100, loss_scale=16, train_wall=80, gb_free=16.6, wall=5200
2025-10-31 23:55:27 | INFO | train_inner | epoch 005:   2985 / 11384 loss=0.062767, wps=1110.4, ups=0.56, wpb=1992.3, bsz=128, num_updates=48250, lr=4.825e-05, gnorm=10.185, clip=94, loss_scale=32, train_wall=51, gb_free=15.9, wall=5289
2025-10-31 23:57:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 23:57:16 | INFO | train_inner | epoch 005:   3036 / 11384 loss=0.060114, wps=903, ups=0.46, wpb=1969.2, bsz=128, num_updates=48300, lr=4.83e-05, gnorm=11.174, clip=94, loss_scale=16, train_wall=109, gb_free=15.3, wall=5398
2025-10-31 23:58:08 | INFO | train_inner | epoch 005:   3086 / 11384 loss=0.065271, wps=1919.6, ups=0.97, wpb=1981, bsz=128, num_updates=48350, lr=4.835e-05, gnorm=12.365, clip=98, loss_scale=16, train_wall=51, gb_free=15.2, wall=5450
2025-11-01 00:00:29 | INFO | train_inner | epoch 005:   3136 / 11384 loss=0.058732, wps=695, ups=0.36, wpb=1955.6, bsz=128, num_updates=48400, lr=4.84e-05, gnorm=8.529, clip=94, loss_scale=16, train_wall=140, gb_free=15.7, wall=5591
2025-11-01 00:02:41 | INFO | train_inner | epoch 005:   3186 / 11384 loss=0.056783, wps=753.3, ups=0.38, wpb=1985.2, bsz=128, num_updates=48450, lr=4.845e-05, gnorm=9.227, clip=96, loss_scale=16, train_wall=56, gb_free=13.4, wall=5723
2025-11-01 00:04:21 | INFO | train_inner | epoch 005:   3236 / 11384 loss=0.062145, wps=968.3, ups=0.5, wpb=1940.9, bsz=128, num_updates=48500, lr=4.85e-05, gnorm=14.128, clip=100, loss_scale=16, train_wall=100, gb_free=15.2, wall=5823
2025-11-01 00:06:18 | INFO | train_inner | epoch 005:   3286 / 11384 loss=0.061296, wps=837.2, ups=0.43, wpb=1957.3, bsz=128, num_updates=48550, lr=4.855e-05, gnorm=11.434, clip=98, loss_scale=32, train_wall=117, gb_free=13.9, wall=5940
2025-11-01 00:07:10 | INFO | train_inner | epoch 005:   3336 / 11384 loss=0.057088, wps=1850.4, ups=0.96, wpb=1931.8, bsz=128, num_updates=48600, lr=4.86e-05, gnorm=9.074, clip=92, loss_scale=32, train_wall=52, gb_free=16.7, wall=5992
2025-11-01 00:08:37 | INFO | train_inner | epoch 005:   3386 / 11384 loss=0.061661, wps=1115.4, ups=0.58, wpb=1939.2, bsz=128, num_updates=48650, lr=4.865e-05, gnorm=11.36, clip=100, loss_scale=32, train_wall=87, gb_free=15.7, wall=6079
2025-11-01 00:10:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 00:11:20 | INFO | train_inner | epoch 005:   3437 / 11384 loss=0.066284, wps=601, ups=0.31, wpb=1961.1, bsz=128, num_updates=48700, lr=4.87e-05, gnorm=10.64, clip=98, loss_scale=16, train_wall=94, gb_free=17.1, wall=6242
2025-11-01 00:12:44 | INFO | train_inner | epoch 005:   3487 / 11384 loss=0.064685, wps=1176.2, ups=0.6, wpb=1976.5, bsz=128, num_updates=48750, lr=4.875e-05, gnorm=10.101, clip=96, loss_scale=16, train_wall=84, gb_free=15.2, wall=6326
2025-11-01 00:14:56 | INFO | train_inner | epoch 005:   3537 / 11384 loss=0.057946, wps=743.6, ups=0.38, wpb=1961, bsz=128, num_updates=48800, lr=4.88e-05, gnorm=9.954, clip=96, loss_scale=16, train_wall=66, gb_free=16.6, wall=6458
2025-11-01 00:15:48 | INFO | train_inner | epoch 005:   3587 / 11384 loss=0.057522, wps=1855, ups=0.95, wpb=1945.4, bsz=128, num_updates=48850, lr=4.885e-05, gnorm=9.624, clip=98, loss_scale=16, train_wall=52, gb_free=15.7, wall=6510
2025-11-01 00:17:31 | INFO | train_inner | epoch 005:   3637 / 11384 loss=0.057341, wps=966.5, ups=0.49, wpb=1976.9, bsz=128, num_updates=48900, lr=4.89e-05, gnorm=9.418, clip=94, loss_scale=16, train_wall=102, gb_free=15.5, wall=6613
2025-11-01 00:19:22 | INFO | train_inner | epoch 005:   3687 / 11384 loss=0.062362, wps=877, ups=0.45, wpb=1959.1, bsz=128, num_updates=48950, lr=4.895e-05, gnorm=13.942, clip=96, loss_scale=32, train_wall=111, gb_free=15.6, wall=6724
2025-11-01 00:21:00 | INFO | train_inner | epoch 005:   3737 / 11384 loss=0.052606, wps=1011.4, ups=0.51, wpb=1965.7, bsz=128, num_updates=49000, lr=4.9e-05, gnorm=8.357, clip=86, loss_scale=32, train_wall=97, gb_free=15.2, wall=6822
2025-11-01 00:21:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 00:22:02 | INFO | train_inner | epoch 005:   3788 / 11384 loss=0.055988, wps=1555.5, ups=0.8, wpb=1939.1, bsz=128, num_updates=49050, lr=4.905e-05, gnorm=10.487, clip=90, loss_scale=16, train_wall=62, gb_free=15.9, wall=6884
2025-11-01 00:23:43 | INFO | train_inner | epoch 005:   3838 / 11384 loss=0.051764, wps=969.3, ups=0.5, wpb=1957.4, bsz=128, num_updates=49100, lr=4.91e-05, gnorm=9.003, clip=96, loss_scale=16, train_wall=101, gb_free=14.2, wall=6985
2025-11-01 00:25:09 | INFO | train_inner | epoch 005:   3888 / 11384 loss=0.056404, wps=1146.8, ups=0.58, wpb=1970.6, bsz=128, num_updates=49150, lr=4.915e-05, gnorm=12.071, clip=100, loss_scale=16, train_wall=54, gb_free=16.5, wall=7071
2025-11-01 00:26:53 | INFO | train_inner | epoch 005:   3938 / 11384 loss=0.05622, wps=950.9, ups=0.48, wpb=1983.6, bsz=128, num_updates=49200, lr=4.92e-05, gnorm=10.016, clip=90, loss_scale=16, train_wall=104, gb_free=5.2, wall=7175
2025-11-01 00:27:50 | INFO | train_inner | epoch 005:   3988 / 11384 loss=0.053797, wps=1707.3, ups=0.89, wpb=1927.7, bsz=128, num_updates=49250, lr=4.925e-05, gnorm=10.065, clip=90, loss_scale=16, train_wall=56, gb_free=16.7, wall=7232
2025-11-01 00:29:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 00:29:22 | INFO | train_inner | epoch 005:   4039 / 11384 loss=0.049019, wps=1048.3, ups=0.54, wpb=1927.8, bsz=128, num_updates=49300, lr=4.93e-05, gnorm=9.473, clip=86, loss_scale=16, train_wall=61, gb_free=9.1, wall=7324
2025-11-01 00:30:40 | INFO | train_inner | epoch 005:   4089 / 11384 loss=0.052181, wps=1257.3, ups=0.65, wpb=1942.3, bsz=128, num_updates=49350, lr=4.935e-05, gnorm=11.858, clip=96, loss_scale=16, train_wall=77, gb_free=16.5, wall=7402
2025-11-01 00:31:35 | INFO | train_inner | epoch 005:   4139 / 11384 loss=0.053366, wps=1746.9, ups=0.9, wpb=1941.8, bsz=128, num_updates=49400, lr=4.94e-05, gnorm=13.117, clip=96, loss_scale=16, train_wall=55, gb_free=17.5, wall=7457
2025-11-01 00:32:30 | INFO | train_inner | epoch 005:   4189 / 11384 loss=0.057661, wps=1796.2, ups=0.91, wpb=1966.2, bsz=128, num_updates=49450, lr=4.945e-05, gnorm=10.4, clip=94, loss_scale=16, train_wall=55, gb_free=16.9, wall=7512
2025-11-01 00:33:27 | INFO | train_inner | epoch 005:   4239 / 11384 loss=0.058723, wps=1705.1, ups=0.87, wpb=1955.6, bsz=128, num_updates=49500, lr=4.95e-05, gnorm=11.387, clip=96, loss_scale=16, train_wall=57, gb_free=10.5, wall=7569
2025-11-01 00:34:51 | INFO | train_inner | epoch 005:   4289 / 11384 loss=0.054903, wps=1175.6, ups=0.6, wpb=1958.3, bsz=128, num_updates=49550, lr=4.955e-05, gnorm=9.507, clip=92, loss_scale=16, train_wall=83, gb_free=13.8, wall=7653
2025-11-01 00:35:58 | INFO | train_inner | epoch 005:   4339 / 11384 loss=0.056531, wps=1434.5, ups=0.75, wpb=1917, bsz=128, num_updates=49600, lr=4.96e-05, gnorm=10.047, clip=96, loss_scale=32, train_wall=67, gb_free=15.4, wall=7719
2025-11-01 00:37:07 | INFO | train_inner | epoch 005:   4389 / 11384 loss=0.05261, wps=1411.3, ups=0.72, wpb=1968.9, bsz=128, num_updates=49650, lr=4.965e-05, gnorm=9.865, clip=92, loss_scale=32, train_wall=70, gb_free=15.8, wall=7789
2025-11-01 00:38:04 | INFO | train_inner | epoch 005:   4439 / 11384 loss=0.060529, wps=1722, ups=0.88, wpb=1947.6, bsz=128, num_updates=49700, lr=4.97e-05, gnorm=9.729, clip=92, loss_scale=32, train_wall=56, gb_free=14.2, wall=7846
2025-11-01 00:39:05 | INFO | train_inner | epoch 005:   4489 / 11384 loss=0.058949, wps=1600.5, ups=0.81, wpb=1970, bsz=128, num_updates=49750, lr=4.975e-05, gnorm=8.954, clip=96, loss_scale=32, train_wall=61, gb_free=15.5, wall=7907
2025-11-01 00:40:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 00:40:14 | INFO | train_inner | epoch 005:   4540 / 11384 loss=0.052765, wps=1446.9, ups=0.73, wpb=1972.4, bsz=128, num_updates=49800, lr=4.98e-05, gnorm=9.29, clip=92, loss_scale=16, train_wall=68, gb_free=17.2, wall=7976
2025-11-01 00:41:09 | INFO | train_inner | epoch 005:   4590 / 11384 loss=0.0551, wps=1750.5, ups=0.91, wpb=1928.8, bsz=128, num_updates=49850, lr=4.985e-05, gnorm=10.526, clip=94, loss_scale=16, train_wall=55, gb_free=16.3, wall=8031
2025-11-01 00:42:09 | INFO | train_inner | epoch 005:   4640 / 11384 loss=0.056126, wps=1626, ups=0.82, wpb=1975, bsz=128, num_updates=49900, lr=4.99e-05, gnorm=8.843, clip=92, loss_scale=16, train_wall=61, gb_free=16.8, wall=8091
2025-11-01 00:43:13 | INFO | train_inner | epoch 005:   4690 / 11384 loss=0.054196, wps=1500.5, ups=0.79, wpb=1904.9, bsz=128, num_updates=49950, lr=4.995e-05, gnorm=9.865, clip=96, loss_scale=16, train_wall=61, gb_free=17.1, wall=8155
2025-11-01 00:44:07 | INFO | train_inner | epoch 005:   4740 / 11384 loss=0.066467, wps=1802, ups=0.92, wpb=1960.2, bsz=128, num_updates=50000, lr=5e-05, gnorm=18.891, clip=100, loss_scale=16, train_wall=54, gb_free=8.7, wall=8209
2025-11-01 00:45:13 | INFO | train_inner | epoch 005:   4790 / 11384 loss=0.060705, wps=1483, ups=0.76, wpb=1954.3, bsz=128, num_updates=50050, lr=4.99979e-05, gnorm=12.789, clip=94, loss_scale=32, train_wall=66, gb_free=15.1, wall=8275
2025-11-01 00:45:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 00:46:10 | INFO | train_inner | epoch 005:   4841 / 11384 loss=0.05868, wps=1719.4, ups=0.88, wpb=1964.8, bsz=128, num_updates=50100, lr=4.99958e-05, gnorm=11.464, clip=96, loss_scale=16, train_wall=55, gb_free=11.9, wall=8332
2025-11-01 00:47:21 | INFO | train_inner | epoch 005:   4891 / 11384 loss=0.058065, wps=1373.2, ups=0.71, wpb=1944, bsz=128, num_updates=50150, lr=4.99938e-05, gnorm=9.738, clip=94, loss_scale=16, train_wall=68, gb_free=15.9, wall=8403
2025-11-01 00:48:16 | INFO | train_inner | epoch 005:   4941 / 11384 loss=0.05858, wps=1787.4, ups=0.91, wpb=1956, bsz=128, num_updates=50200, lr=4.99917e-05, gnorm=12.072, clip=90, loss_scale=16, train_wall=54, gb_free=13.8, wall=8458
2025-11-01 00:49:12 | INFO | train_inner | epoch 005:   4991 / 11384 loss=0.103244, wps=1746.5, ups=0.9, wpb=1944.3, bsz=128, num_updates=50250, lr=4.99896e-05, gnorm=18.843, clip=98, loss_scale=16, train_wall=55, gb_free=16.1, wall=8513
2025-11-01 00:50:12 | INFO | train_inner | epoch 005:   5041 / 11384 loss=0.152142, wps=1607.4, ups=0.82, wpb=1950.4, bsz=128, num_updates=50300, lr=4.99875e-05, gnorm=18.497, clip=100, loss_scale=16, train_wall=60, gb_free=16.9, wall=8574
2025-11-01 00:51:14 | INFO | train_inner | epoch 005:   5091 / 11384 loss=0.063963, wps=1617.5, ups=0.81, wpb=1993, bsz=128, num_updates=50350, lr=4.99854e-05, gnorm=13.164, clip=100, loss_scale=32, train_wall=61, gb_free=16.5, wall=8636
2025-11-01 00:52:27 | INFO | train_inner | epoch 005:   5141 / 11384 loss=0.06208, wps=1345.9, ups=0.68, wpb=1968.1, bsz=128, num_updates=50400, lr=4.99833e-05, gnorm=10.418, clip=98, loss_scale=32, train_wall=73, gb_free=9.7, wall=8709
2025-11-01 00:53:23 | INFO | train_inner | epoch 005:   5191 / 11384 loss=0.063212, wps=1779, ups=0.9, wpb=1979.3, bsz=128, num_updates=50450, lr=4.99813e-05, gnorm=12.04, clip=98, loss_scale=32, train_wall=55, gb_free=11.1, wall=8765
2025-11-01 00:54:37 | INFO | train_inner | epoch 005:   5241 / 11384 loss=0.062353, wps=1304.2, ups=0.67, wpb=1943.8, bsz=128, num_updates=50500, lr=4.99792e-05, gnorm=9.348, clip=88, loss_scale=32, train_wall=74, gb_free=6.8, wall=8839
2025-11-01 00:56:19 | INFO | train_inner | epoch 005:   5291 / 11384 loss=0.062872, wps=963.7, ups=0.49, wpb=1955.2, bsz=128, num_updates=50550, lr=4.99771e-05, gnorm=11.121, clip=94, loss_scale=32, train_wall=101, gb_free=15.5, wall=8941
2025-11-01 00:57:19 | INFO | train_inner | epoch 005:   5341 / 11384 loss=0.058225, wps=1610.9, ups=0.83, wpb=1935.7, bsz=128, num_updates=50600, lr=4.9975e-05, gnorm=11.652, clip=88, loss_scale=64, train_wall=60, gb_free=10, wall=9001
2025-11-01 00:58:21 | INFO | train_inner | epoch 005:   5391 / 11384 loss=0.059954, wps=1580.6, ups=0.8, wpb=1970, bsz=128, num_updates=50650, lr=4.99729e-05, gnorm=10.198, clip=92, loss_scale=64, train_wall=62, gb_free=15.2, wall=9063
2025-11-01 00:59:44 | INFO | train_inner | epoch 005:   5441 / 11384 loss=0.071745, wps=1189.5, ups=0.6, wpb=1975.8, bsz=128, num_updates=50700, lr=4.99708e-05, gnorm=10.911, clip=96, loss_scale=64, train_wall=74, gb_free=6.7, wall=9146
2025-11-01 01:00:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 01:01:00 | INFO | train_inner | epoch 005:   5492 / 11384 loss=0.063433, wps=1301.5, ups=0.66, wpb=1984.1, bsz=128, num_updates=50750, lr=4.99688e-05, gnorm=10.444, clip=94, loss_scale=32, train_wall=76, gb_free=15.5, wall=9222
2025-11-01 01:02:01 | INFO | train_inner | epoch 005:   5542 / 11384 loss=0.059817, wps=1620.2, ups=0.83, wpb=1962.6, bsz=128, num_updates=50800, lr=4.99667e-05, gnorm=10.675, clip=96, loss_scale=32, train_wall=60, gb_free=14.9, wall=9283
2025-11-01 01:02:56 | INFO | train_inner | epoch 005:   5592 / 11384 loss=0.058955, wps=1773.6, ups=0.9, wpb=1962.5, bsz=128, num_updates=50850, lr=4.99646e-05, gnorm=10.904, clip=94, loss_scale=32, train_wall=55, gb_free=15.2, wall=9338
2025-11-01 01:03:54 | INFO | train_inner | epoch 005:   5642 / 11384 loss=0.054066, wps=1730.4, ups=0.87, wpb=1989.5, bsz=128, num_updates=50900, lr=4.99625e-05, gnorm=8.869, clip=88, loss_scale=32, train_wall=57, gb_free=17.5, wall=9396
2025-11-01 01:04:54 | INFO | train_inner | epoch 005:   5692 / 11384 loss=0.056817, wps=1643.4, ups=0.84, wpb=1964.3, bsz=128, num_updates=50950, lr=4.99604e-05, gnorm=9.749, clip=92, loss_scale=32, train_wall=60, gb_free=15.4, wall=9456
2025-11-01 01:06:00 | INFO | train_inner | epoch 005:   5742 / 11384 loss=0.052356, wps=1446.7, ups=0.75, wpb=1935.8, bsz=128, num_updates=51000, lr=4.99583e-05, gnorm=10.052, clip=94, loss_scale=64, train_wall=67, gb_free=13.1, wall=9522
2025-11-01 01:06:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 01:07:15 | INFO | train_inner | epoch 005:   5793 / 11384 loss=0.054465, wps=1335.7, ups=0.68, wpb=1975.4, bsz=128, num_updates=51050, lr=4.99563e-05, gnorm=9.189, clip=82, loss_scale=32, train_wall=74, gb_free=12.6, wall=9596
2025-11-01 01:07:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 01:07:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-01 01:08:16 | INFO | train_inner | epoch 005:   5845 / 11384 loss=0.073024, wps=1631.7, ups=0.81, wpb=2011, bsz=128, num_updates=51100, lr=4.99542e-05, gnorm=10.532, clip=92, loss_scale=8, train_wall=61, gb_free=17.3, wall=9658
2025-11-01 01:09:11 | INFO | train_inner | epoch 005:   5895 / 11384 loss=0.06232, wps=1795.6, ups=0.91, wpb=1965.1, bsz=128, num_updates=51150, lr=4.99521e-05, gnorm=8.385, clip=94, loss_scale=8, train_wall=55, gb_free=16.7, wall=9713
2025-11-01 01:10:18 | INFO | train_inner | epoch 005:   5945 / 11384 loss=0.067676, wps=1467, ups=0.75, wpb=1964.9, bsz=128, num_updates=51200, lr=4.995e-05, gnorm=10.847, clip=88, loss_scale=8, train_wall=63, gb_free=15.4, wall=9780
2025-11-01 01:11:48 | INFO | train_inner | epoch 005:   5995 / 11384 loss=0.063793, wps=1084.2, ups=0.55, wpb=1953.9, bsz=128, num_updates=51250, lr=4.99479e-05, gnorm=10.996, clip=92, loss_scale=8, train_wall=90, gb_free=11.4, wall=9870
2025-11-01 01:13:00 | INFO | train_inner | epoch 005:   6045 / 11384 loss=0.058229, wps=1380.3, ups=0.7, wpb=1973.7, bsz=128, num_updates=51300, lr=4.99458e-05, gnorm=12.024, clip=90, loss_scale=8, train_wall=71, gb_free=14, wall=9941
2025-11-01 01:14:04 | INFO | train_inner | epoch 005:   6095 / 11384 loss=0.061563, wps=1497.8, ups=0.77, wpb=1943.7, bsz=128, num_updates=51350, lr=4.99438e-05, gnorm=10.932, clip=90, loss_scale=16, train_wall=60, gb_free=14.7, wall=10006
2025-11-01 01:15:33 | INFO | train_inner | epoch 005:   6145 / 11384 loss=0.069911, wps=1101.5, ups=0.57, wpb=1942.7, bsz=128, num_updates=51400, lr=4.99417e-05, gnorm=9.42, clip=94, loss_scale=16, train_wall=61, gb_free=13.2, wall=10095
2025-11-01 01:16:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-01 01:16:57 | INFO | train_inner | epoch 005:   6196 / 11384 loss=0.057886, wps=1156.4, ups=0.6, wpb=1937.8, bsz=128, num_updates=51450, lr=4.99396e-05, gnorm=10.356, clip=92, loss_scale=8, train_wall=84, gb_free=8.4, wall=10179
2025-11-01 01:17:57 | INFO | train_inner | epoch 005:   6246 / 11384 loss=0.061737, wps=1617.5, ups=0.83, wpb=1951.6, bsz=128, num_updates=51500, lr=4.99375e-05, gnorm=11.31, clip=92, loss_scale=8, train_wall=60, gb_free=13.7, wall=10239
2025-11-01 01:18:54 | INFO | train_inner | epoch 005:   6296 / 11384 loss=0.059018, wps=1695.1, ups=0.87, wpb=1942.4, bsz=128, num_updates=51550, lr=4.99354e-05, gnorm=12.182, clip=96, loss_scale=8, train_wall=57, gb_free=12.7, wall=10296
2025-11-01 01:19:55 | INFO | train_inner | epoch 005:   6346 / 11384 loss=0.056711, wps=1625.5, ups=0.82, wpb=1979.3, bsz=128, num_updates=51600, lr=4.99333e-05, gnorm=9.81, clip=90, loss_scale=8, train_wall=61, gb_free=14, wall=10357
2025-11-01 01:21:00 | INFO | train_inner | epoch 005:   6396 / 11384 loss=0.060142, wps=1535.5, ups=0.78, wpb=1970, bsz=128, num_updates=51650, lr=4.99313e-05, gnorm=9.927, clip=92, loss_scale=8, train_wall=64, gb_free=17.3, wall=10422
2025-11-01 01:22:05 | INFO | train_inner | epoch 005:   6446 / 11384 loss=0.057455, wps=1514.3, ups=0.77, wpb=1971.1, bsz=128, num_updates=51700, lr=4.99292e-05, gnorm=10.779, clip=94, loss_scale=16, train_wall=65, gb_free=16.6, wall=10487
2025-11-01 01:23:06 | INFO | train_inner | epoch 005:   6496 / 11384 loss=0.058531, wps=1610.9, ups=0.82, wpb=1964.8, bsz=128, num_updates=51750, lr=4.99271e-05, gnorm=11.483, clip=96, loss_scale=16, train_wall=61, gb_free=16.7, wall=10548
2025-11-01 01:24:05 | INFO | train_inner | epoch 005:   6546 / 11384 loss=0.056436, wps=1634.8, ups=0.85, wpb=1925.9, bsz=128, num_updates=51800, lr=4.9925e-05, gnorm=8.941, clip=98, loss_scale=16, train_wall=59, gb_free=12.6, wall=10607
2025-11-01 01:25:01 | INFO | train_inner | epoch 005:   6596 / 11384 loss=0.051588, wps=1762.1, ups=0.89, wpb=1978.5, bsz=128, num_updates=51850, lr=4.99229e-05, gnorm=9.506, clip=92, loss_scale=16, train_wall=56, gb_free=14.2, wall=10663
2025-11-01 01:26:07 | INFO | train_inner | epoch 005:   6646 / 11384 loss=0.055908, wps=1477.3, ups=0.77, wpb=1928.6, bsz=128, num_updates=51900, lr=4.99208e-05, gnorm=10.955, clip=92, loss_scale=16, train_wall=65, gb_free=15.8, wall=10729
2025-11-01 01:27:10 | INFO | train_inner | epoch 005:   6696 / 11384 loss=0.054337, wps=1525.6, ups=0.78, wpb=1944.3, bsz=128, num_updates=51950, lr=4.99188e-05, gnorm=8.739, clip=88, loss_scale=32, train_wall=64, gb_free=9.3, wall=10792
2025-11-01 01:28:19 | INFO | train_inner | epoch 005:   6746 / 11384 loss=0.053854, wps=1435.1, ups=0.72, wpb=1981.2, bsz=128, num_updates=52000, lr=4.99167e-05, gnorm=8.886, clip=88, loss_scale=32, train_wall=69, gb_free=14.9, wall=10861
2025-11-01 01:29:44 | INFO | train_inner | epoch 005:   6796 / 11384 loss=0.055584, wps=1158.1, ups=0.59, wpb=1956.6, bsz=128, num_updates=52050, lr=4.99146e-05, gnorm=10.299, clip=94, loss_scale=32, train_wall=84, gb_free=10.6, wall=10946
2025-11-01 01:30:52 | INFO | train_inner | epoch 005:   6846 / 11384 loss=0.052966, wps=1419.7, ups=0.73, wpb=1935.2, bsz=128, num_updates=52100, lr=4.99125e-05, gnorm=9.233, clip=90, loss_scale=32, train_wall=68, gb_free=14.3, wall=11014
2025-11-01 01:32:04 | INFO | train_inner | epoch 005:   6896 / 11384 loss=0.052784, wps=1355.8, ups=0.7, wpb=1946.8, bsz=128, num_updates=52150, lr=4.99104e-05, gnorm=8.895, clip=88, loss_scale=32, train_wall=72, gb_free=15.7, wall=11086
2025-11-01 01:33:14 | INFO | train_inner | epoch 005:   6946 / 11384 loss=0.052613, wps=1367.2, ups=0.71, wpb=1927.8, bsz=128, num_updates=52200, lr=4.99083e-05, gnorm=10.371, clip=94, loss_scale=64, train_wall=70, gb_free=16.1, wall=11156
2025-11-01 01:34:32 | INFO | train_inner | epoch 005:   6996 / 11384 loss=0.054424, wps=1264.6, ups=0.64, wpb=1971.3, bsz=128, num_updates=52250, lr=4.99063e-05, gnorm=10.291, clip=88, loss_scale=64, train_wall=78, gb_free=15.8, wall=11234
2025-11-01 01:35:31 | INFO | train_inner | epoch 005:   7046 / 11384 loss=0.050018, wps=1677.7, ups=0.85, wpb=1975.5, bsz=128, num_updates=52300, lr=4.99042e-05, gnorm=8.916, clip=82, loss_scale=64, train_wall=59, gb_free=16.2, wall=11293
2025-11-01 01:36:26 | INFO | train_inner | epoch 005:   7096 / 11384 loss=0.052648, wps=1761.7, ups=0.91, wpb=1942.2, bsz=128, num_updates=52350, lr=4.99021e-05, gnorm=10.683, clip=94, loss_scale=64, train_wall=55, gb_free=14.8, wall=11348
2025-11-01 01:36:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 01:37:31 | INFO | train_inner | epoch 005:   7147 / 11384 loss=0.051426, wps=1488.6, ups=0.78, wpb=1913.7, bsz=128, num_updates=52400, lr=4.99e-05, gnorm=9.151, clip=84, loss_scale=32, train_wall=64, gb_free=12.6, wall=11413
2025-11-01 01:38:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 01:38:31 | INFO | train_inner | epoch 005:   7198 / 11384 loss=0.059096, wps=1620.3, ups=0.84, wpb=1939.5, bsz=128, num_updates=52450, lr=4.98979e-05, gnorm=11.196, clip=96, loss_scale=16, train_wall=60, gb_free=16.3, wall=11473
2025-11-01 01:39:24 | INFO | train_inner | epoch 005:   7248 / 11384 loss=0.049175, wps=1816.5, ups=0.93, wpb=1956.8, bsz=128, num_updates=52500, lr=4.98958e-05, gnorm=9.441, clip=100, loss_scale=16, train_wall=54, gb_free=15.9, wall=11526
2025-11-01 01:40:35 | INFO | train_inner | epoch 005:   7298 / 11384 loss=0.050739, wps=1384.4, ups=0.71, wpb=1958.7, bsz=128, num_updates=52550, lr=4.98938e-05, gnorm=8.024, clip=90, loss_scale=16, train_wall=71, gb_free=14.9, wall=11597
2025-11-01 01:41:29 | INFO | train_inner | epoch 005:   7348 / 11384 loss=0.054017, wps=1796.9, ups=0.92, wpb=1950.8, bsz=128, num_updates=52600, lr=4.98917e-05, gnorm=8.677, clip=90, loss_scale=16, train_wall=54, gb_free=15.3, wall=11651
2025-11-01 01:42:52 | INFO | train_inner | epoch 005:   7398 / 11384 loss=0.047, wps=1182.5, ups=0.61, wpb=1949.6, bsz=128, num_updates=52650, lr=4.98896e-05, gnorm=9.181, clip=88, loss_scale=16, train_wall=82, gb_free=14.7, wall=11734
2025-11-01 01:43:50 | INFO | train_inner | epoch 005:   7448 / 11384 loss=0.056835, wps=1702, ups=0.86, wpb=1973.1, bsz=128, num_updates=52700, lr=4.98875e-05, gnorm=8.566, clip=92, loss_scale=32, train_wall=58, gb_free=14.1, wall=11792
2025-11-01 01:44:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 01:44:54 | INFO | train_inner | epoch 005:   7499 / 11384 loss=0.05124, wps=1551.1, ups=0.78, wpb=1994.9, bsz=128, num_updates=52750, lr=4.98854e-05, gnorm=10.164, clip=90, loss_scale=16, train_wall=62, gb_free=14.5, wall=11856
2025-11-01 01:46:07 | INFO | train_inner | epoch 005:   7549 / 11384 loss=0.052435, wps=1349.9, ups=0.68, wpb=1973.6, bsz=128, num_updates=52800, lr=4.98833e-05, gnorm=13.589, clip=96, loss_scale=16, train_wall=67, gb_free=16.3, wall=11929
2025-11-01 01:47:13 | INFO | train_inner | epoch 005:   7599 / 11384 loss=0.057868, wps=1489.8, ups=0.76, wpb=1958, bsz=128, num_updates=52850, lr=4.98813e-05, gnorm=8.349, clip=88, loss_scale=16, train_wall=66, gb_free=15.1, wall=11995
2025-11-01 01:48:20 | INFO | train_inner | epoch 005:   7649 / 11384 loss=0.056104, wps=1415.7, ups=0.75, wpb=1896.7, bsz=128, num_updates=52900, lr=4.98792e-05, gnorm=10.089, clip=90, loss_scale=16, train_wall=61, gb_free=15.7, wall=12062
2025-11-01 01:49:31 | INFO | train_inner | epoch 005:   7699 / 11384 loss=0.051413, wps=1372.9, ups=0.71, wpb=1942, bsz=128, num_updates=52950, lr=4.98771e-05, gnorm=9.443, clip=90, loss_scale=16, train_wall=71, gb_free=11.8, wall=12133
2025-11-01 01:50:37 | INFO | train_inner | epoch 005:   7749 / 11384 loss=0.052772, wps=1515, ups=0.76, wpb=1990.5, bsz=128, num_updates=53000, lr=4.9875e-05, gnorm=10.757, clip=96, loss_scale=32, train_wall=63, gb_free=15.6, wall=12198
2025-11-01 01:51:46 | INFO | train_inner | epoch 005:   7799 / 11384 loss=0.054468, wps=1458, ups=0.72, wpb=2022.9, bsz=128, num_updates=53050, lr=4.98729e-05, gnorm=10.725, clip=94, loss_scale=32, train_wall=65, gb_free=9.6, wall=12268
2025-11-01 01:52:59 | INFO | train_inner | epoch 005:   7849 / 11384 loss=0.054836, wps=1347.2, ups=0.68, wpb=1967.2, bsz=128, num_updates=53100, lr=4.98708e-05, gnorm=11.25, clip=94, loss_scale=32, train_wall=61, gb_free=16.7, wall=12341
2025-11-01 01:54:12 | INFO | train_inner | epoch 005:   7899 / 11384 loss=0.052887, wps=1346.2, ups=0.69, wpb=1964.4, bsz=128, num_updates=53150, lr=4.98688e-05, gnorm=9.83, clip=78, loss_scale=32, train_wall=73, gb_free=12.2, wall=12414
2025-11-01 01:54:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 01:55:11 | INFO | train_inner | epoch 005:   7950 / 11384 loss=0.059606, wps=1657.7, ups=0.85, wpb=1942.9, bsz=128, num_updates=53200, lr=4.98667e-05, gnorm=10.212, clip=88, loss_scale=16, train_wall=58, gb_free=11.3, wall=12473
2025-11-01 01:56:09 | INFO | train_inner | epoch 005:   8000 / 11384 loss=0.051351, wps=1674.2, ups=0.86, wpb=1948.3, bsz=128, num_updates=53250, lr=4.98646e-05, gnorm=8.892, clip=84, loss_scale=16, train_wall=58, gb_free=15.4, wall=12531
2025-11-01 01:57:13 | INFO | train_inner | epoch 005:   8050 / 11384 loss=0.05244, wps=1487.9, ups=0.78, wpb=1904.4, bsz=128, num_updates=53300, lr=4.98625e-05, gnorm=10.858, clip=82, loss_scale=16, train_wall=64, gb_free=14.9, wall=12595
2025-11-01 01:58:14 | INFO | train_inner | epoch 005:   8100 / 11384 loss=0.052984, wps=1606.7, ups=0.82, wpb=1970.2, bsz=128, num_updates=53350, lr=4.98604e-05, gnorm=9.643, clip=90, loss_scale=16, train_wall=61, gb_free=13.2, wall=12656
2025-11-01 01:58:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-01 01:59:22 | INFO | train_inner | epoch 005:   8151 / 11384 loss=0.049695, wps=1444.9, ups=0.73, wpb=1969.7, bsz=128, num_updates=53400, lr=4.98583e-05, gnorm=11.763, clip=88, loss_scale=8, train_wall=68, gb_free=13.4, wall=12724
2025-11-01 02:00:27 | INFO | train_inner | epoch 005:   8201 / 11384 loss=0.043749, wps=1518.4, ups=0.78, wpb=1949.1, bsz=128, num_updates=53450, lr=4.98563e-05, gnorm=7.147, clip=72, loss_scale=8, train_wall=64, gb_free=16.6, wall=12789
2025-11-01 02:01:28 | INFO | train_inner | epoch 005:   8251 / 11384 loss=0.057786, wps=1598.5, ups=0.81, wpb=1964.8, bsz=128, num_updates=53500, lr=4.98542e-05, gnorm=10.725, clip=96, loss_scale=8, train_wall=61, gb_free=15.1, wall=12850
2025-11-01 02:02:44 | INFO | train_inner | epoch 005:   8301 / 11384 loss=0.049219, wps=1286.2, ups=0.66, wpb=1950.7, bsz=128, num_updates=53550, lr=4.98521e-05, gnorm=8.37, clip=80, loss_scale=8, train_wall=76, gb_free=17.5, wall=12926
2025-11-01 02:03:48 | INFO | train_inner | epoch 005:   8351 / 11384 loss=0.049898, wps=1536.5, ups=0.78, wpb=1974.7, bsz=128, num_updates=53600, lr=4.985e-05, gnorm=7.328, clip=82, loss_scale=8, train_wall=64, gb_free=12.4, wall=12990
2025-11-01 02:05:05 | INFO | train_inner | epoch 005:   8401 / 11384 loss=0.048953, wps=1361.2, ups=0.69, wpb=1969, bsz=128, num_updates=53650, lr=4.98479e-05, gnorm=9.012, clip=78, loss_scale=16, train_wall=70, gb_free=14.8, wall=13067
2025-11-01 02:06:12 | INFO | train_inner | epoch 005:   8451 / 11384 loss=0.051697, wps=1475.2, ups=0.75, wpb=1969.2, bsz=128, num_updates=53700, lr=4.98458e-05, gnorm=9.558, clip=90, loss_scale=16, train_wall=67, gb_free=11.2, wall=13134
2025-11-01 02:07:30 | INFO | train_inner | epoch 005:   8501 / 11384 loss=0.046398, wps=1256.6, ups=0.64, wpb=1976.3, bsz=128, num_updates=53750, lr=4.98438e-05, gnorm=10.821, clip=76, loss_scale=16, train_wall=75, gb_free=10.7, wall=13212
2025-11-01 02:08:54 | INFO | train_inner | epoch 005:   8551 / 11384 loss=0.051344, wps=1168, ups=0.6, wpb=1959.1, bsz=128, num_updates=53800, lr=4.98417e-05, gnorm=12.038, clip=78, loss_scale=16, train_wall=80, gb_free=17.2, wall=13296
2025-11-01 02:10:01 | INFO | train_inner | epoch 005:   8601 / 11384 loss=0.050899, wps=1486.9, ups=0.75, wpb=1977.2, bsz=128, num_updates=53850, lr=4.98396e-05, gnorm=8.261, clip=90, loss_scale=16, train_wall=66, gb_free=17.3, wall=13363
2025-11-01 02:11:06 | INFO | train_inner | epoch 005:   8651 / 11384 loss=0.044065, wps=1501.5, ups=0.76, wpb=1973.5, bsz=128, num_updates=53900, lr=4.98375e-05, gnorm=7.899, clip=76, loss_scale=32, train_wall=66, gb_free=14.9, wall=13428
2025-11-01 02:12:11 | INFO | train_inner | epoch 005:   8701 / 11384 loss=0.047763, wps=1517.7, ups=0.78, wpb=1956.2, bsz=128, num_updates=53950, lr=4.98354e-05, gnorm=10.006, clip=84, loss_scale=32, train_wall=64, gb_free=15.8, wall=13493
2025-11-01 02:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 02:13:16 | INFO | train_inner | epoch 005:   8752 / 11384 loss=0.048623, wps=1469.5, ups=0.77, wpb=1919.2, bsz=128, num_updates=54000, lr=4.98333e-05, gnorm=8.243, clip=82, loss_scale=16, train_wall=65, gb_free=14.1, wall=13558
2025-11-01 02:14:26 | INFO | train_inner | epoch 005:   8802 / 11384 loss=0.050074, wps=1418.2, ups=0.72, wpb=1982.2, bsz=128, num_updates=54050, lr=4.98313e-05, gnorm=9.665, clip=90, loss_scale=16, train_wall=70, gb_free=5.4, wall=13628
2025-11-01 02:15:34 | INFO | train_inner | epoch 005:   8852 / 11384 loss=0.053796, wps=1429.5, ups=0.73, wpb=1952.5, bsz=128, num_updates=54100, lr=4.98292e-05, gnorm=8.846, clip=88, loss_scale=16, train_wall=68, gb_free=16.5, wall=13696
2025-11-01 02:16:36 | INFO | train_inner | epoch 005:   8902 / 11384 loss=0.046116, wps=1610.2, ups=0.82, wpb=1970.7, bsz=128, num_updates=54150, lr=4.98271e-05, gnorm=8.366, clip=86, loss_scale=16, train_wall=61, gb_free=13.9, wall=13758
2025-11-01 02:16:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-01 02:17:49 | INFO | train_inner | epoch 005:   8953 / 11384 loss=0.044225, wps=1360.7, ups=0.69, wpb=1983.1, bsz=128, num_updates=54200, lr=4.9825e-05, gnorm=7.967, clip=80, loss_scale=8, train_wall=73, gb_free=16.3, wall=13831
2025-11-01 02:18:48 | INFO | train_inner | epoch 005:   9003 / 11384 loss=0.050051, wps=1668.5, ups=0.84, wpb=1991.9, bsz=128, num_updates=54250, lr=4.98229e-05, gnorm=11.103, clip=88, loss_scale=8, train_wall=59, gb_free=15.9, wall=13890
2025-11-01 02:19:49 | INFO | train_inner | epoch 005:   9053 / 11384 loss=0.050579, wps=1632.8, ups=0.83, wpb=1967.6, bsz=128, num_updates=54300, lr=4.98208e-05, gnorm=8.819, clip=86, loss_scale=8, train_wall=60, gb_free=9.6, wall=13951
2025-11-01 02:20:55 | INFO | train_inner | epoch 005:   9103 / 11384 loss=0.051702, wps=1449.9, ups=0.76, wpb=1920, bsz=128, num_updates=54350, lr=4.98188e-05, gnorm=9.903, clip=82, loss_scale=8, train_wall=66, gb_free=16.6, wall=14017
2025-11-01 02:22:05 | INFO | train_inner | epoch 005:   9153 / 11384 loss=0.04744, wps=1389.1, ups=0.72, wpb=1938.6, bsz=128, num_updates=54400, lr=4.98167e-05, gnorm=10.38, clip=78, loss_scale=8, train_wall=67, gb_free=9.8, wall=14087
2025-11-01 02:23:34 | INFO | train_inner | epoch 005:   9203 / 11384 loss=0.043094, wps=1115.1, ups=0.56, wpb=1995.8, bsz=128, num_updates=54450, lr=4.98146e-05, gnorm=7.787, clip=68, loss_scale=16, train_wall=89, gb_free=14, wall=14176
2025-11-01 02:24:59 | INFO | train_inner | epoch 005:   9253 / 11384 loss=0.052887, wps=1146, ups=0.59, wpb=1938.5, bsz=128, num_updates=54500, lr=4.98125e-05, gnorm=10.258, clip=90, loss_scale=16, train_wall=84, gb_free=15.6, wall=14261
2025-11-01 02:26:15 | INFO | train_inner | epoch 005:   9303 / 11384 loss=0.046455, wps=1300.4, ups=0.66, wpb=1978.2, bsz=128, num_updates=54550, lr=4.98104e-05, gnorm=8.125, clip=84, loss_scale=16, train_wall=76, gb_free=10.3, wall=14337
2025-11-01 02:27:22 | INFO | train_inner | epoch 005:   9353 / 11384 loss=0.045582, wps=1478.1, ups=0.74, wpb=1985.5, bsz=128, num_updates=54600, lr=4.98083e-05, gnorm=8.101, clip=78, loss_scale=16, train_wall=67, gb_free=15.5, wall=14404
2025-11-01 02:28:29 | INFO | train_inner | epoch 005:   9403 / 11384 loss=0.04662, wps=1467.6, ups=0.75, wpb=1964.9, bsz=128, num_updates=54650, lr=4.98063e-05, gnorm=9.157, clip=78, loss_scale=16, train_wall=67, gb_free=13.1, wall=14471
2025-11-01 02:29:26 | INFO | train_inner | epoch 005:   9453 / 11384 loss=0.049967, wps=1701.5, ups=0.87, wpb=1960.3, bsz=128, num_updates=54700, lr=4.98042e-05, gnorm=9.819, clip=86, loss_scale=32, train_wall=57, gb_free=13.6, wall=14528
2025-11-01 02:30:29 | INFO | train_inner | epoch 005:   9503 / 11384 loss=0.044056, wps=1611.7, ups=0.8, wpb=2026.2, bsz=128, num_updates=54750, lr=4.98021e-05, gnorm=7.706, clip=70, loss_scale=32, train_wall=63, gb_free=14.2, wall=14591
2025-11-01 02:30:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 02:31:33 | INFO | train_inner | epoch 005:   9554 / 11384 loss=0.044316, wps=1575.4, ups=0.79, wpb=1995.7, bsz=128, num_updates=54800, lr=4.98e-05, gnorm=9.139, clip=78, loss_scale=16, train_wall=63, gb_free=15.8, wall=14655
2025-11-01 02:32:30 | INFO | train_inner | epoch 005:   9604 / 11384 loss=0.051106, wps=1680.3, ups=0.87, wpb=1933.9, bsz=128, num_updates=54850, lr=4.97979e-05, gnorm=11.375, clip=88, loss_scale=16, train_wall=57, gb_free=17.1, wall=14712
2025-11-01 02:33:52 | INFO | train_inner | epoch 005:   9654 / 11384 loss=0.045501, wps=1224.5, ups=0.61, wpb=1998.7, bsz=128, num_updates=54900, lr=4.97958e-05, gnorm=8.209, clip=70, loss_scale=16, train_wall=81, gb_free=16.7, wall=14794
2025-11-01 02:34:58 | INFO | train_inner | epoch 005:   9704 / 11384 loss=0.048336, wps=1484.2, ups=0.76, wpb=1951.2, bsz=128, num_updates=54950, lr=4.97938e-05, gnorm=9.948, clip=82, loss_scale=16, train_wall=66, gb_free=14.4, wall=14860
2025-11-01 02:35:59 | INFO | train_inner | epoch 005:   9754 / 11384 loss=0.047714, wps=1576, ups=0.81, wpb=1936.7, bsz=128, num_updates=55000, lr=4.97917e-05, gnorm=8.832, clip=84, loss_scale=16, train_wall=61, gb_free=15.6, wall=14921
2025-11-01 02:37:05 | INFO | train_inner | epoch 005:   9804 / 11384 loss=0.046108, wps=1455.7, ups=0.75, wpb=1928.1, bsz=128, num_updates=55050, lr=4.97896e-05, gnorm=9.406, clip=76, loss_scale=32, train_wall=65, gb_free=15.9, wall=14987
2025-11-01 02:38:45 | INFO | train_inner | epoch 005:   9854 / 11384 loss=0.049505, wps=986.4, ups=0.5, wpb=1968.9, bsz=128, num_updates=55100, lr=4.97875e-05, gnorm=8.797, clip=84, loss_scale=32, train_wall=97, gb_free=14.6, wall=15087
2025-11-01 02:39:47 | INFO | train_inner | epoch 005:   9904 / 11384 loss=0.05257, wps=1566.5, ups=0.81, wpb=1925.2, bsz=128, num_updates=55150, lr=4.97854e-05, gnorm=13.621, clip=86, loss_scale=32, train_wall=61, gb_free=11.6, wall=15148
2025-11-01 02:41:16 | INFO | train_inner | epoch 005:   9954 / 11384 loss=0.050892, wps=1093.1, ups=0.56, wpb=1950, bsz=128, num_updates=55200, lr=4.97833e-05, gnorm=7.779, clip=88, loss_scale=32, train_wall=89, gb_free=16.6, wall=15238
2025-11-01 02:42:24 | INFO | train_inner | epoch 005:  10004 / 11384 loss=0.053083, wps=1422.9, ups=0.74, wpb=1934.8, bsz=128, num_updates=55250, lr=4.97813e-05, gnorm=10.012, clip=80, loss_scale=32, train_wall=68, gb_free=17.1, wall=15306
2025-11-01 02:43:25 | INFO | train_inner | epoch 005:  10054 / 11384 loss=0.050919, wps=1637.3, ups=0.82, wpb=1998.6, bsz=128, num_updates=55300, lr=4.97792e-05, gnorm=8.847, clip=84, loss_scale=64, train_wall=61, gb_free=16.5, wall=15367
2025-11-01 02:44:21 | INFO | train_inner | epoch 005:  10104 / 11384 loss=0.042764, wps=1764.8, ups=0.9, wpb=1966.8, bsz=128, num_updates=55350, lr=4.97771e-05, gnorm=7.042, clip=70, loss_scale=64, train_wall=56, gb_free=16.6, wall=15423
2025-11-01 02:45:29 | INFO | train_inner | epoch 005:  10154 / 11384 loss=0.049675, wps=1445.8, ups=0.73, wpb=1970.5, bsz=128, num_updates=55400, lr=4.9775e-05, gnorm=9.714, clip=86, loss_scale=64, train_wall=58, gb_free=11.2, wall=15491
2025-11-01 02:46:48 | INFO | train_inner | epoch 005:  10204 / 11384 loss=0.041744, wps=1220.9, ups=0.63, wpb=1923.3, bsz=128, num_updates=55450, lr=4.97729e-05, gnorm=7.894, clip=74, loss_scale=64, train_wall=79, gb_free=17.4, wall=15570
2025-11-01 02:47:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 02:47:42 | INFO | train_inner | epoch 005:  10255 / 11384 loss=0.044229, wps=1819.5, ups=0.92, wpb=1974.4, bsz=128, num_updates=55500, lr=4.97708e-05, gnorm=8.485, clip=74, loss_scale=32, train_wall=54, gb_free=12.2, wall=15624
2025-11-01 02:48:58 | INFO | train_inner | epoch 005:  10305 / 11384 loss=0.047297, wps=1299.2, ups=0.66, wpb=1965.2, bsz=128, num_updates=55550, lr=4.97688e-05, gnorm=6.789, clip=70, loss_scale=32, train_wall=74, gb_free=17, wall=15700
2025-11-01 02:50:05 | INFO | train_inner | epoch 005:  10355 / 11384 loss=0.044409, wps=1449.5, ups=0.74, wpb=1960.3, bsz=128, num_updates=55600, lr=4.97667e-05, gnorm=7.847, clip=76, loss_scale=32, train_wall=67, gb_free=16.4, wall=15767
2025-11-01 02:51:14 | INFO | train_inner | epoch 005:  10405 / 11384 loss=0.042677, wps=1437.5, ups=0.73, wpb=1957.4, bsz=128, num_updates=55650, lr=4.97646e-05, gnorm=6.668, clip=66, loss_scale=32, train_wall=68, gb_free=16.6, wall=15835
2025-11-01 02:52:09 | INFO | train_inner | epoch 005:  10455 / 11384 loss=0.04951, wps=1752.3, ups=0.9, wpb=1955.4, bsz=128, num_updates=55700, lr=4.97625e-05, gnorm=7.838, clip=88, loss_scale=32, train_wall=56, gb_free=16.5, wall=15891
2025-11-01 02:52:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 02:53:19 | INFO | train_inner | epoch 005:  10506 / 11384 loss=0.049568, wps=1415, ups=0.72, wpb=1973.1, bsz=128, num_updates=55750, lr=4.97604e-05, gnorm=9.015, clip=82, loss_scale=32, train_wall=70, gb_free=16.7, wall=15961
2025-11-01 02:54:22 | INFO | train_inner | epoch 005:  10556 / 11384 loss=0.045626, wps=1561.8, ups=0.8, wpb=1953.6, bsz=128, num_updates=55800, lr=4.97583e-05, gnorm=8.407, clip=80, loss_scale=32, train_wall=62, gb_free=16.4, wall=16024
2025-11-01 02:55:25 | INFO | train_inner | epoch 005:  10606 / 11384 loss=0.045279, wps=1542.8, ups=0.78, wpb=1967.3, bsz=128, num_updates=55850, lr=4.97563e-05, gnorm=8.528, clip=76, loss_scale=32, train_wall=64, gb_free=16.6, wall=16087
2025-11-01 02:56:46 | INFO | train_inner | epoch 005:  10656 / 11384 loss=0.044603, wps=1209.1, ups=0.62, wpb=1939.7, bsz=128, num_updates=55900, lr=4.97542e-05, gnorm=7.96, clip=70, loss_scale=32, train_wall=80, gb_free=14.7, wall=16168
2025-11-01 02:57:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 02:57:53 | INFO | train_inner | epoch 005:  10707 / 11384 loss=0.045787, wps=1610.3, ups=0.82, wpb=1956, bsz=128, num_updates=55950, lr=4.97521e-05, gnorm=9.372, clip=82, loss_scale=16, train_wall=60, gb_free=15.9, wall=16235
2025-11-01 02:59:08 | INFO | train_inner | epoch 005:  10757 / 11384 loss=0.045364, wps=1324.9, ups=0.67, wpb=1989.7, bsz=128, num_updates=56000, lr=4.975e-05, gnorm=8.91, clip=74, loss_scale=16, train_wall=75, gb_free=14.3, wall=16310
2025-11-01 03:00:28 | INFO | train_inner | epoch 005:  10807 / 11384 loss=0.050315, wps=1214.8, ups=0.62, wpb=1946.2, bsz=128, num_updates=56050, lr=4.97479e-05, gnorm=8.891, clip=80, loss_scale=16, train_wall=80, gb_free=14.9, wall=16390
2025-11-01 03:01:43 | INFO | train_inner | epoch 005:  10857 / 11384 loss=0.045209, wps=1336.5, ups=0.67, wpb=2003.7, bsz=128, num_updates=56100, lr=4.97458e-05, gnorm=9.667, clip=74, loss_scale=16, train_wall=59, gb_free=15.4, wall=16465
2025-11-01 03:02:42 | INFO | train_inner | epoch 005:  10907 / 11384 loss=0.048612, wps=1693.8, ups=0.85, wpb=1984.4, bsz=128, num_updates=56150, lr=4.97438e-05, gnorm=9.028, clip=74, loss_scale=16, train_wall=58, gb_free=13.7, wall=16524
2025-11-01 03:03:57 | INFO | train_inner | epoch 005:  10957 / 11384 loss=0.048132, wps=1286.6, ups=0.66, wpb=1942.5, bsz=128, num_updates=56200, lr=4.97417e-05, gnorm=8.286, clip=86, loss_scale=32, train_wall=75, gb_free=16.7, wall=16599
2025-11-01 03:04:56 | INFO | train_inner | epoch 005:  11007 / 11384 loss=0.04183, wps=1665, ups=0.85, wpb=1965.6, bsz=128, num_updates=56250, lr=4.97396e-05, gnorm=7.169, clip=72, loss_scale=32, train_wall=59, gb_free=13.2, wall=16658
2025-11-01 03:05:52 | INFO | train_inner | epoch 005:  11057 / 11384 loss=0.047625, wps=1746.3, ups=0.89, wpb=1966, bsz=128, num_updates=56300, lr=4.97375e-05, gnorm=8.584, clip=82, loss_scale=32, train_wall=56, gb_free=16.2, wall=16714
2025-11-01 03:07:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 03:07:07 | INFO | train_inner | epoch 005:  11108 / 11384 loss=0.054958, wps=1319.8, ups=0.67, wpb=1976.5, bsz=128, num_updates=56350, lr=4.97354e-05, gnorm=9.189, clip=80, loss_scale=16, train_wall=75, gb_free=16.7, wall=16789
2025-11-01 03:08:11 | INFO | train_inner | epoch 005:  11158 / 11384 loss=0.047071, wps=1536.6, ups=0.78, wpb=1962.1, bsz=128, num_updates=56400, lr=4.97333e-05, gnorm=10.579, clip=78, loss_scale=16, train_wall=64, gb_free=14.4, wall=16853
2025-11-01 03:09:30 | INFO | train_inner | epoch 005:  11208 / 11384 loss=0.046756, wps=1249, ups=0.64, wpb=1965.7, bsz=128, num_updates=56450, lr=4.97313e-05, gnorm=9.787, clip=84, loss_scale=16, train_wall=78, gb_free=15.2, wall=16932
2025-11-01 03:10:35 | INFO | train_inner | epoch 005:  11258 / 11384 loss=0.051242, wps=1502.7, ups=0.77, wpb=1957.5, bsz=128, num_updates=56500, lr=4.97292e-05, gnorm=7.363, clip=70, loss_scale=16, train_wall=65, gb_free=16.1, wall=16997
2025-11-01 03:11:36 | INFO | train_inner | epoch 005:  11308 / 11384 loss=0.044155, wps=1596.3, ups=0.82, wpb=1940.5, bsz=128, num_updates=56550, lr=4.97271e-05, gnorm=7.933, clip=74, loss_scale=16, train_wall=61, gb_free=13.9, wall=17058
2025-11-01 03:12:51 | INFO | train_inner | epoch 005:  11358 / 11384 loss=0.04759, wps=1298.3, ups=0.67, wpb=1945.2, bsz=128, num_updates=56600, lr=4.9725e-05, gnorm=8.675, clip=82, loss_scale=32, train_wall=75, gb_free=15.6, wall=17133
2025-11-01 03:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-01 03:31:07 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 0.042055 | wps 1308.7 | wpb 1948.3 | bsz 127.9 | num_updates 56626 | best_loss 0.042055
2025-11-01 03:31:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 56626 updates
2025-11-01 03:31:07 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts/checkpoint5.pt
2025-11-01 03:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts/checkpoint5.pt
2025-11-01 03:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./affincraft_pretrain_ckpts/checkpoint5.pt (epoch 5 @ 56626 updates, score 0.042055) (writing took 142.87748574302532 seconds)
2025-11-01 03:33:30 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2025-11-01 03:33:30 | INFO | train | epoch 005 | loss 0.057121 | wps 1212.1 | ups 0.62 | wpb 1958.9 | bsz 128 | num_updates 56626 | lr 4.97239e-05 | gnorm 10.359 | clip 90.4 | loss_scale 32 | train_wall 16105 | gb_free 16.8 | wall 18372
2025-11-01 03:33:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-11-01 03:33:36 | INFO | fairseq.trainer | begin training epoch 6
2025-11-01 03:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-01 03:35:56 | INFO | train_inner | epoch 006:     24 / 11384 loss=0.046765, wps=70.7, ups=0.04, wpb=1959.7, bsz=127.7, num_updates=56650, lr=4.97229e-05, gnorm=7.427, clip=70, loss_scale=32, train_wall=114, gb_free=16.7, wall=18518
2025-11-01 03:36:47 | INFO | train_inner | epoch 006:     74 / 11384 loss=0.048178, wps=1958.5, ups=0.99, wpb=1980, bsz=128, num_updates=56700, lr=4.97208e-05, gnorm=8.056, clip=74, loss_scale=32, train_wall=50, gb_free=12.7, wall=18569
2025-11-01 03:38:13 | INFO | train_inner | epoch 006:    124 / 11384 loss=0.050057, wps=1129, ups=0.58, wpb=1949.2, bsz=128, num_updates=56750, lr=4.97188e-05, gnorm=9.026, clip=88, loss_scale=32, train_wall=86, gb_free=16.5, wall=18655
2025-11-01 03:39:09 | INFO | train_inner | epoch 006:    174 / 11384 loss=0.042872, wps=1750.2, ups=0.89, wpb=1966.5, bsz=128, num_updates=56800, lr=4.97167e-05, gnorm=7.974, clip=80, loss_scale=32, train_wall=56, gb_free=15.2, wall=18711
2025-11-01 03:40:16 | INFO | train_inner | epoch 006:    224 / 11384 loss=0.042394, wps=1481.4, ups=0.75, wpb=1975.7, bsz=128, num_updates=56850, lr=4.97146e-05, gnorm=5.885, clip=62, loss_scale=32, train_wall=66, gb_free=15.6, wall=18778
2025-11-01 03:42:32 | INFO | train_inner | epoch 006:    274 / 11384 loss=0.04679, wps=726.6, ups=0.37, wpb=1971.7, bsz=128, num_updates=56900, lr=4.97125e-05, gnorm=8.819, clip=82, loss_scale=64, train_wall=73, gb_free=13.9, wall=18914
2025-11-01 03:44:51 | INFO | train_inner | epoch 006:    324 / 11384 loss=0.041433, wps=702.8, ups=0.36, wpb=1951.8, bsz=128, num_updates=56950, lr=4.97104e-05, gnorm=8.193, clip=74, loss_scale=64, train_wall=139, gb_free=13.3, wall=19053
2025-11-01 03:46:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 03:46:11 | INFO | train_inner | epoch 006:    375 / 11384 loss=0.048774, wps=1220.9, ups=0.62, wpb=1967.4, bsz=128, num_updates=57000, lr=4.97083e-05, gnorm=10.286, clip=80, loss_scale=32, train_wall=80, gb_free=10.5, wall=19133
2025-11-01 03:47:05 | INFO | train_inner | epoch 006:    425 / 11384 loss=0.043583, wps=1854.6, ups=0.94, wpb=1981, bsz=128, num_updates=57050, lr=4.97063e-05, gnorm=8.516, clip=86, loss_scale=32, train_wall=53, gb_free=15, wall=19187
2025-11-01 03:48:21 | INFO | train_inner | epoch 006:    475 / 11384 loss=0.043107, wps=1285.9, ups=0.66, wpb=1954.8, bsz=128, num_updates=57100, lr=4.97042e-05, gnorm=7.149, clip=74, loss_scale=32, train_wall=76, gb_free=16.3, wall=19263
2025-11-01 03:50:08 | INFO | train_inner | epoch 006:    525 / 11384 loss=0.039021, wps=910.5, ups=0.47, wpb=1955.7, bsz=128, num_updates=57150, lr=4.97021e-05, gnorm=8.211, clip=62, loss_scale=32, train_wall=102, gb_free=16.1, wall=19370
2025-11-01 03:52:20 | INFO | train_inner | epoch 006:    575 / 11384 loss=0.038678, wps=742.5, ups=0.38, wpb=1966.6, bsz=128, num_updates=57200, lr=4.97e-05, gnorm=6.724, clip=56, loss_scale=32, train_wall=132, gb_free=12.3, wall=19502
2025-11-01 03:54:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 03:54:33 | INFO | train_inner | epoch 006:    626 / 11384 loss=0.044341, wps=745.6, ups=0.38, wpb=1976.8, bsz=128, num_updates=57250, lr=4.96979e-05, gnorm=7.409, clip=68, loss_scale=16, train_wall=132, gb_free=13.6, wall=19635
2025-11-01 03:55:40 | INFO | train_inner | epoch 006:    676 / 11384 loss=0.047664, wps=1486.9, ups=0.75, wpb=1983.2, bsz=127.9, num_updates=57300, lr=4.96958e-05, gnorm=8.576, clip=74, loss_scale=16, train_wall=66, gb_free=12.1, wall=19702
2025-11-01 03:57:17 | INFO | train_inner | epoch 006:    726 / 11384 loss=0.046325, wps=1002, ups=0.51, wpb=1948.5, bsz=128, num_updates=57350, lr=4.96938e-05, gnorm=8.314, clip=72, loss_scale=16, train_wall=97, gb_free=15.8, wall=19799
2025-11-01 03:58:54 | INFO | train_inner | epoch 006:    776 / 11384 loss=0.045258, wps=1007, ups=0.52, wpb=1952.8, bsz=128, num_updates=57400, lr=4.96917e-05, gnorm=10.986, clip=76, loss_scale=16, train_wall=97, gb_free=14.7, wall=19896
2025-11-01 04:00:42 | INFO | train_inner | epoch 006:    826 / 11384 loss=0.048116, wps=901.1, ups=0.46, wpb=1944, bsz=128, num_updates=57450, lr=4.96896e-05, gnorm=10.147, clip=84, loss_scale=16, train_wall=108, gb_free=17, wall=20004
2025-11-01 04:03:18 | INFO | train_inner | epoch 006:    876 / 11384 loss=0.042254, wps=615.6, ups=0.32, wpb=1925.4, bsz=128, num_updates=57500, lr=4.96875e-05, gnorm=7.416, clip=64, loss_scale=16, train_wall=156, gb_free=16.5, wall=20160
2025-11-01 04:05:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 04:05:52 | INFO | train_inner | epoch 006:    927 / 11384 loss=0.044417, wps=638.7, ups=0.33, wpb=1964.2, bsz=128, num_updates=57550, lr=4.96854e-05, gnorm=8.696, clip=66, loss_scale=16, train_wall=139, gb_free=15.5, wall=20314
2025-11-01 04:08:32 | INFO | train_inner | epoch 006:    977 / 11384 loss=0.045031, wps=597.3, ups=0.31, wpb=1913.3, bsz=128, num_updates=57600, lr=4.96833e-05, gnorm=8.881, clip=80, loss_scale=16, train_wall=160, gb_free=14.1, wall=20474
2025-11-01 04:10:02 | INFO | train_inner | epoch 006:   1027 / 11384 loss=0.048269, wps=1104.5, ups=0.56, wpb=1979.2, bsz=128, num_updates=57650, lr=4.96813e-05, gnorm=9.918, clip=76, loss_scale=16, train_wall=89, gb_free=15.1, wall=20564
2025-11-01 04:11:54 | INFO | train_inner | epoch 006:   1077 / 11384 loss=0.045268, wps=880.5, ups=0.45, wpb=1974.2, bsz=128, num_updates=57700, lr=4.96792e-05, gnorm=7.661, clip=68, loss_scale=16, train_wall=72, gb_free=15.2, wall=20676
2025-11-01 04:13:07 | INFO | train_inner | epoch 006:   1127 / 11384 loss=0.0519, wps=1326, ups=0.68, wpb=1948.8, bsz=128, num_updates=57750, lr=4.96771e-05, gnorm=11.487, clip=86, loss_scale=16, train_wall=73, gb_free=17.6, wall=20749
2025-11-01 04:15:05 | INFO | train_inner | epoch 006:   1177 / 11384 loss=0.044283, wps=831, ups=0.43, wpb=1955, bsz=128, num_updates=57800, lr=4.9675e-05, gnorm=8.893, clip=78, loss_scale=32, train_wall=117, gb_free=15.8, wall=20867
2025-11-01 04:17:23 | INFO | train_inner | epoch 006:   1227 / 11384 loss=0.041159, wps=699.4, ups=0.36, wpb=1938.8, bsz=128, num_updates=57850, lr=4.96729e-05, gnorm=7.914, clip=74, loss_scale=32, train_wall=80, gb_free=15.9, wall=21005
2025-11-01 04:19:28 | INFO | train_inner | epoch 006:   1277 / 11384 loss=0.045401, wps=771.5, ups=0.4, wpb=1927.2, bsz=128, num_updates=57900, lr=4.96708e-05, gnorm=9.371, clip=84, loss_scale=32, train_wall=125, gb_free=15.9, wall=21130
==========================================
 ‚úÖ ‰ªªÂä°ÂÆåÊàê‰∫é: Sat Nov  1 04:22:41 CST 2025
==========================================
