[INFO] Job starting at Tue Nov 11 22:31:27 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä® (LMDBÊ†ºÂºè)
 ËäÇÁÇπ:        g0068
 ‰Ωú‰∏öID:      4521930
 GPUs:        0,1,2,3,4,5,6,7
 ÂêØÂä®Êó∂Èó¥:    Tue Nov 11 22:31:27 CST 2025
==========================================
CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - Â§öGPUÂàÜÂ∏ÉÂºèÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           8 GPUs √ó 1 node(s)
DataLoader workers: 3 per GPU
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/valid_lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   64
-------------------------------------------------------------------
ÁõÆÊ†áËÆ≠ÁªÉËΩÆÊï∞:       100
‰º∞ÁÆóÊÄªÊõ¥Êñ∞Ê≠•Êï∞:     2277000
Â≠¶‰π†ÁéáÈ¢ÑÁÉ≠Ê≠•Êï∞:     91000
===================================================================
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 3
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 3: setting device to 3
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 4
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 4: setting device to 4
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 0
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 0: setting device to 0
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 1
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 1: setting device to 1
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 2
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 2: setting device to 2
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 7
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 7: setting device to 7
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 5
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 5: setting device to 5
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | initialized host g0068 as rank 6
2025-11-11 22:32:22 | INFO | fairseq.distributed.utils | [DEBUG] Rank 6: setting device to 6
2025-11-11 22:32:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 20, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 2277000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [8e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=200, log_format=None, log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='graph_prediction', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=8, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=20, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=8, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=2277000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[8e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', restore_file='checkpoint_last.pt', finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=460, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=91000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='2277000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 460, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/valid_lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [8e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 91000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 2277000.0, 'lr': [8e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbÊ†∑Êú¨ÊÄªÊï∞: 1,457,129‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb






Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129





‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
2025-11-11 22:32:23 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbÊ†∑Êú¨ÊÄªÊï∞: 80,568‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb‚úÖ LMDB Êï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb







Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568






2025-11-11 22:32:23 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå80568 ‰∏™Ê†∑Êú¨
2025-11-11 22:32:23 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=200, log_format=None, log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='graph_prediction', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=8, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=20, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=8, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=2277000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[8e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', restore_file='checkpoint_last.pt', finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=460, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=91000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='2277000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-11-11 22:32:23 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-11-11 22:32:23 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-11-11 22:32:23 | INFO | fairseq_cli.train | model: GraphormerModel
2025-11-11 22:32:23 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-11-11 22:32:23 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-11-11 22:32:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-11-11 22:32:23 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 80568
2025-11-11 22:32:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   4: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   5: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   6: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | rank   7: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-11 22:32:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-11-11 22:32:24 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2025-11-11 22:32:24 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 8
2025-11-11 22:32:24 | INFO | fairseq.trainer | Preparing to load checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint_last.pt
2025-11-11 22:32:24 | INFO | fairseq.trainer | No existing checkpoint found /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint_last.pt
2025-11-11 22:32:24 | INFO | fairseq.trainer | loading train data for epoch 1
2025-11-11 22:32:24 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-11-11 22:32:27 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2025-11-11 22:32:27 | INFO | fairseq.trainer | begin training epoch 1
2025-11-11 22:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-11 22:32:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22768
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
[TRAINER] Registering gradient clamp hooks for all model parameters
2025-11-11 22:36:50 | INFO | train_inner | epoch 001:    200 / 22768 loss=0.751536, wps=1344.4, ups=0.77, wpb=1734.9, bsz=64, num_updates=200, lr=1.75824e-07, gnorm=134.915, clip=100, train_wall=260, gb_free=17.7, wall=266
2025-11-11 22:41:06 | INFO | train_inner | epoch 001:    400 / 22768 loss=0.646573, wps=1350.2, ups=0.78, wpb=1732.3, bsz=64, num_updates=400, lr=3.51648e-07, gnorm=97.495, clip=100, train_wall=256, gb_free=18.4, wall=523
2025-11-11 22:45:25 | INFO | train_inner | epoch 001:    600 / 22768 loss=0.621922, wps=1356.8, ups=0.77, wpb=1755.2, bsz=64, num_updates=600, lr=5.27473e-07, gnorm=103.802, clip=100, train_wall=258, gb_free=18.4, wall=781
2025-11-11 22:49:39 | INFO | train_inner | epoch 001:    800 / 22768 loss=0.576351, wps=1359.6, ups=0.79, wpb=1723.9, bsz=64, num_updates=800, lr=7.03297e-07, gnorm=113.825, clip=100, train_wall=253, gb_free=17.5, wall=1035
2025-11-11 22:53:55 | INFO | train_inner | epoch 001:   1000 / 22768 loss=0.559498, wps=1362.2, ups=0.78, wpb=1747.3, bsz=64, num_updates=1000, lr=8.79121e-07, gnorm=109.734, clip=100, train_wall=256, gb_free=18.2, wall=1292
2025-11-11 22:58:12 | INFO | train_inner | epoch 001:   1200 / 22768 loss=0.51103, wps=1364.1, ups=0.78, wpb=1751.2, bsz=64, num_updates=1200, lr=1.05495e-06, gnorm=105.508, clip=100, train_wall=256, gb_free=17.6, wall=1548
2025-11-11 23:02:29 | INFO | train_inner | epoch 001:   1400 / 22768 loss=0.517333, wps=1356.5, ups=0.78, wpb=1742.7, bsz=64, num_updates=1400, lr=1.23077e-06, gnorm=104.339, clip=100, train_wall=256, gb_free=15.8, wall=1805
2025-11-11 23:06:44 | INFO | train_inner | epoch 001:   1600 / 22768 loss=0.492777, wps=1365.6, ups=0.79, wpb=1739.2, bsz=64, num_updates=1600, lr=1.40659e-06, gnorm=78.37, clip=100, train_wall=254, gb_free=17.8, wall=2060
2025-11-11 23:10:57 | INFO | train_inner | epoch 001:   1800 / 22768 loss=0.47908, wps=1371.9, ups=0.79, wpb=1736.4, bsz=64, num_updates=1800, lr=1.58242e-06, gnorm=76.363, clip=100, train_wall=252, gb_free=16.7, wall=2313
2025-11-11 23:16:18 | INFO | train_inner | epoch 001:   2000 / 22768 loss=0.490641, wps=1077.3, ups=0.62, wpb=1732, bsz=64, num_updates=2000, lr=1.75824e-06, gnorm=63.385, clip=100, train_wall=320, gb_free=16.1, wall=2635
2025-11-11 23:20:42 | INFO | train_inner | epoch 001:   2200 / 22768 loss=0.476103, wps=1337.9, ups=0.76, wpb=1765.6, bsz=64, num_updates=2200, lr=1.93407e-06, gnorm=59.882, clip=100, train_wall=263, gb_free=16.8, wall=2899
2025-11-11 23:26:10 | INFO | train_inner | epoch 001:   2400 / 22768 loss=0.468765, wps=1063.8, ups=0.61, wpb=1742.9, bsz=64, num_updates=2400, lr=2.10989e-06, gnorm=53.381, clip=100, train_wall=322, gb_free=18.9, wall=3226
2025-11-11 23:30:27 | INFO | train_inner | epoch 001:   2600 / 22768 loss=0.469383, wps=1346.9, ups=0.78, wpb=1734.3, bsz=64, num_updates=2600, lr=2.28571e-06, gnorm=49.952, clip=100, train_wall=257, gb_free=18.4, wall=3484
2025-11-11 23:34:45 | INFO | train_inner | epoch 001:   2800 / 22768 loss=0.449474, wps=1353.8, ups=0.78, wpb=1740.5, bsz=64, num_updates=2800, lr=2.46154e-06, gnorm=46.544, clip=100, train_wall=256, gb_free=15.5, wall=3741
2025-11-11 23:39:04 | INFO | train_inner | epoch 001:   3000 / 22768 loss=0.457473, wps=1347, ups=0.77, wpb=1750.2, bsz=64, num_updates=3000, lr=2.63736e-06, gnorm=45.722, clip=100, train_wall=259, gb_free=18.8, wall=4001
2025-11-11 23:43:22 | INFO | train_inner | epoch 001:   3200 / 22768 loss=0.448003, wps=1347.9, ups=0.78, wpb=1732.9, bsz=64, num_updates=3200, lr=2.81319e-06, gnorm=37.994, clip=100, train_wall=256, gb_free=17.6, wall=4258
2025-11-11 23:47:39 | INFO | train_inner | epoch 001:   3400 / 22768 loss=0.440346, wps=1353.8, ups=0.78, wpb=1742.7, bsz=64, num_updates=3400, lr=2.98901e-06, gnorm=36.951, clip=100, train_wall=257, gb_free=18.1, wall=4515
2025-11-11 23:51:57 | INFO | train_inner | epoch 001:   3600 / 22768 loss=0.45422, wps=1354.1, ups=0.77, wpb=1747.8, bsz=64, num_updates=3600, lr=3.16484e-06, gnorm=39.825, clip=100, train_wall=257, gb_free=17.9, wall=4774
2025-11-11 23:56:09 | INFO | train_inner | epoch 001:   3800 / 22768 loss=0.440422, wps=1362.9, ups=0.79, wpb=1717.5, bsz=64, num_updates=3800, lr=3.34066e-06, gnorm=37.291, clip=100, train_wall=251, gb_free=18.4, wall=5026
2025-11-12 00:00:36 | INFO | train_inner | epoch 001:   4000 / 22768 loss=0.419584, wps=1292.7, ups=0.75, wpb=1726.1, bsz=64, num_updates=4000, lr=3.51648e-06, gnorm=34.673, clip=100, train_wall=257, gb_free=15.1, wall=5293
2025-11-12 00:04:52 | INFO | train_inner | epoch 001:   4200 / 22768 loss=0.433738, wps=1372.2, ups=0.78, wpb=1755.2, bsz=64, num_updates=4200, lr=3.69231e-06, gnorm=40.027, clip=100, train_wall=255, gb_free=17.8, wall=5548
2025-11-12 00:09:18 | INFO | train_inner | epoch 001:   4400 / 22768 loss=0.419548, wps=1305.6, ups=0.75, wpb=1737.6, bsz=64, num_updates=4400, lr=3.86813e-06, gnorm=35.103, clip=100, train_wall=256, gb_free=14.1, wall=5815
2025-11-12 00:14:12 | INFO | train_inner | epoch 001:   4600 / 22768 loss=0.433224, wps=1180.6, ups=0.68, wpb=1735.2, bsz=64, num_updates=4600, lr=4.04396e-06, gnorm=36.225, clip=100, train_wall=293, gb_free=18.4, wall=6109
2025-11-12 00:18:29 | INFO | train_inner | epoch 001:   4800 / 22768 loss=0.428211, wps=1347.9, ups=0.78, wpb=1732.9, bsz=64, num_updates=4800, lr=4.21978e-06, gnorm=36.743, clip=100, train_wall=255, gb_free=16.3, wall=6366
2025-11-12 00:22:48 | INFO | train_inner | epoch 001:   5000 / 22768 loss=0.405592, wps=1354.8, ups=0.77, wpb=1751.8, bsz=64, num_updates=5000, lr=4.3956e-06, gnorm=35.595, clip=100, train_wall=257, gb_free=18, wall=6624
2025-11-12 00:27:12 | INFO | train_inner | epoch 001:   5200 / 22768 loss=0.424058, wps=1329.3, ups=0.76, wpb=1755.7, bsz=64, num_updates=5200, lr=4.57143e-06, gnorm=36.966, clip=100, train_wall=263, gb_free=17.2, wall=6888
2025-11-12 00:31:31 | INFO | train_inner | epoch 001:   5400 / 22768 loss=0.418216, wps=1339.3, ups=0.77, wpb=1732.8, bsz=64, num_updates=5400, lr=4.74725e-06, gnorm=36.455, clip=100, train_wall=258, gb_free=18.5, wall=7147
2025-11-12 00:35:47 | INFO | train_inner | epoch 001:   5600 / 22768 loss=0.423378, wps=1354.8, ups=0.78, wpb=1731.7, bsz=64, num_updates=5600, lr=4.92308e-06, gnorm=35.155, clip=100, train_wall=255, gb_free=16.1, wall=7403
2025-11-12 00:40:11 | INFO | train_inner | epoch 001:   5800 / 22768 loss=0.406171, wps=1319.8, ups=0.76, wpb=1747.9, bsz=64, num_updates=5800, lr=5.0989e-06, gnorm=36.126, clip=100, train_wall=264, gb_free=18.2, wall=7668
2025-11-12 00:44:29 | INFO | train_inner | epoch 001:   6000 / 22768 loss=0.41513, wps=1362.9, ups=0.78, wpb=1752.7, bsz=64, num_updates=6000, lr=5.27473e-06, gnorm=35.261, clip=100, train_wall=256, gb_free=17.2, wall=7925
2025-11-12 00:48:48 | INFO | train_inner | epoch 001:   6200 / 22768 loss=0.405362, wps=1352.1, ups=0.77, wpb=1753.7, bsz=64, num_updates=6200, lr=5.45055e-06, gnorm=35.674, clip=100, train_wall=259, gb_free=17.7, wall=8184
2025-11-12 00:53:38 | INFO | train_inner | epoch 001:   6400 / 22768 loss=0.401191, wps=1200.3, ups=0.69, wpb=1742.9, bsz=64, num_updates=6400, lr=5.62637e-06, gnorm=36.792, clip=100, train_wall=283, gb_free=17.6, wall=8475
2025-11-12 00:57:57 | INFO | train_inner | epoch 001:   6600 / 22768 loss=0.40631, wps=1334.7, ups=0.77, wpb=1727.1, bsz=64, num_updates=6600, lr=5.8022e-06, gnorm=36.47, clip=100, train_wall=258, gb_free=17.6, wall=8734
2025-11-12 01:02:22 | INFO | train_inner | epoch 001:   6800 / 22768 loss=0.409587, wps=1307.5, ups=0.76, wpb=1730.2, bsz=64, num_updates=6800, lr=5.97802e-06, gnorm=37.505, clip=100, train_wall=264, gb_free=18.3, wall=8998
2025-11-12 01:06:38 | INFO | train_inner | epoch 001:   7000 / 22768 loss=0.40809, wps=1361.3, ups=0.78, wpb=1740.9, bsz=64, num_updates=7000, lr=6.15385e-06, gnorm=39.609, clip=100, train_wall=255, gb_free=18.2, wall=9254
2025-11-12 01:10:53 | INFO | train_inner | epoch 001:   7200 / 22768 loss=0.393333, wps=1362.8, ups=0.78, wpb=1739.3, bsz=64, num_updates=7200, lr=6.32967e-06, gnorm=38.658, clip=100, train_wall=254, gb_free=17.5, wall=9509
2025-11-12 01:15:12 | INFO | train_inner | epoch 001:   7400 / 22768 loss=0.388401, wps=1339.9, ups=0.77, wpb=1738.3, bsz=64, num_updates=7400, lr=6.50549e-06, gnorm=38.881, clip=100, train_wall=259, gb_free=17.7, wall=9769
2025-11-12 01:19:31 | INFO | train_inner | epoch 001:   7600 / 22768 loss=0.387514, wps=1356.3, ups=0.77, wpb=1754.8, bsz=64, num_updates=7600, lr=6.68132e-06, gnorm=36.041, clip=100, train_wall=258, gb_free=16.6, wall=10028
2025-11-12 01:23:43 | INFO | train_inner | epoch 001:   7800 / 22768 loss=0.395591, wps=1377.6, ups=0.79, wpb=1734.2, bsz=64, num_updates=7800, lr=6.85714e-06, gnorm=35.974, clip=100, train_wall=251, gb_free=16.8, wall=10279
2025-11-12 01:28:03 | INFO | train_inner | epoch 001:   8000 / 22768 loss=0.391332, wps=1341.4, ups=0.77, wpb=1740.8, bsz=64, num_updates=8000, lr=7.03297e-06, gnorm=37.024, clip=100, train_wall=259, gb_free=18.6, wall=10539
2025-11-12 01:32:18 | INFO | train_inner | epoch 001:   8200 / 22768 loss=0.397152, wps=1359.5, ups=0.78, wpb=1734.6, bsz=64, num_updates=8200, lr=7.20879e-06, gnorm=41.501, clip=100, train_wall=254, gb_free=17.2, wall=10794
2025-11-12 01:36:40 | INFO | train_inner | epoch 001:   8400 / 22768 loss=0.385054, wps=1335, ups=0.76, wpb=1751.2, bsz=64, num_updates=8400, lr=7.38462e-06, gnorm=38.132, clip=100, train_wall=262, gb_free=17.8, wall=11056
2025-11-12 01:40:57 | INFO | train_inner | epoch 001:   8600 / 22768 loss=0.375717, wps=1367.2, ups=0.78, wpb=1756.1, bsz=64, num_updates=8600, lr=7.56044e-06, gnorm=40.182, clip=100, train_wall=256, gb_free=18.5, wall=11313
2025-11-12 01:45:25 | INFO | train_inner | epoch 001:   8800 / 22768 loss=0.384873, wps=1297.2, ups=0.75, wpb=1738.4, bsz=64, num_updates=8800, lr=7.73626e-06, gnorm=36.016, clip=100, train_wall=267, gb_free=18.8, wall=11581
2025-11-12 01:49:54 | INFO | train_inner | epoch 001:   9000 / 22768 loss=0.372536, wps=1279, ups=0.74, wpb=1721.5, bsz=64, num_updates=9000, lr=7.91209e-06, gnorm=38.072, clip=100, train_wall=268, gb_free=18.8, wall=11851
2025-11-12 01:54:19 | INFO | train_inner | epoch 001:   9200 / 22768 loss=0.378143, wps=1312.6, ups=0.75, wpb=1739.2, bsz=64, num_updates=9200, lr=8.08791e-06, gnorm=36.087, clip=100, train_wall=264, gb_free=17.8, wall=12116
2025-11-12 01:58:38 | INFO | train_inner | epoch 001:   9400 / 22768 loss=0.383105, wps=1335.7, ups=0.77, wpb=1726.1, bsz=64, num_updates=9400, lr=8.26374e-06, gnorm=39.472, clip=100, train_wall=258, gb_free=19, wall=12374
2025-11-12 02:02:58 | INFO | train_inner | epoch 001:   9600 / 22768 loss=0.382967, wps=1351, ups=0.77, wpb=1759.4, bsz=64, num_updates=9600, lr=8.43956e-06, gnorm=38.209, clip=100, train_wall=260, gb_free=16.8, wall=12634
2025-11-12 02:07:18 | INFO | train_inner | epoch 001:   9800 / 22768 loss=0.373247, wps=1338.7, ups=0.77, wpb=1739.4, bsz=64, num_updates=9800, lr=8.61538e-06, gnorm=35.7, clip=100, train_wall=259, gb_free=18.4, wall=12894
2025-11-12 02:11:37 | INFO | train_inner | epoch 001:  10000 / 22768 loss=0.374506, wps=1354.2, ups=0.77, wpb=1754.6, bsz=64, num_updates=10000, lr=8.79121e-06, gnorm=37.399, clip=100, train_wall=258, gb_free=17.3, wall=13153
2025-11-12 02:15:55 | INFO | train_inner | epoch 001:  10200 / 22768 loss=0.373684, wps=1360.2, ups=0.78, wpb=1751.5, bsz=64, num_updates=10200, lr=8.96703e-06, gnorm=38.12, clip=100, train_wall=257, gb_free=17, wall=13411
2025-11-12 02:20:16 | INFO | train_inner | epoch 001:  10400 / 22768 loss=0.362, wps=1334.6, ups=0.76, wpb=1744.7, bsz=64, num_updates=10400, lr=9.14286e-06, gnorm=36.046, clip=100, train_wall=261, gb_free=17.9, wall=13672
2025-11-12 02:24:36 | INFO | train_inner | epoch 001:  10600 / 22768 loss=0.364191, wps=1352.6, ups=0.77, wpb=1754.5, bsz=64, num_updates=10600, lr=9.31868e-06, gnorm=38.512, clip=100, train_wall=259, gb_free=16.9, wall=13932
2025-11-12 02:28:54 | INFO | train_inner | epoch 001:  10800 / 22768 loss=0.365449, wps=1347.5, ups=0.77, wpb=1743.8, bsz=64, num_updates=10800, lr=9.49451e-06, gnorm=38.721, clip=100, train_wall=258, gb_free=18.2, wall=14191
2025-11-12 02:33:22 | INFO | train_inner | epoch 001:  11000 / 22768 loss=0.353973, wps=1300.1, ups=0.75, wpb=1737.8, bsz=64, num_updates=11000, lr=9.67033e-06, gnorm=38.414, clip=100, train_wall=266, gb_free=17.5, wall=14458
2025-11-12 02:37:52 | INFO | train_inner | epoch 001:  11200 / 22768 loss=0.366062, wps=1289.3, ups=0.74, wpb=1744.6, bsz=64, num_updates=11200, lr=9.84615e-06, gnorm=39.366, clip=100, train_wall=270, gb_free=18.2, wall=14729
2025-11-12 02:42:21 | INFO | train_inner | epoch 001:  11400 / 22768 loss=0.363077, wps=1308, ups=0.75, wpb=1753.8, bsz=64, num_updates=11400, lr=1.0022e-05, gnorm=38.645, clip=100, train_wall=267, gb_free=18.6, wall=14997
2025-11-12 02:46:43 | INFO | train_inner | epoch 001:  11600 / 22768 loss=0.359505, wps=1306.7, ups=0.76, wpb=1714.5, bsz=64, num_updates=11600, lr=1.01978e-05, gnorm=38.182, clip=100, train_wall=262, gb_free=17.6, wall=15259
2025-11-12 02:51:01 | INFO | train_inner | epoch 001:  11800 / 22768 loss=0.358706, wps=1354.4, ups=0.78, wpb=1745.8, bsz=64, num_updates=11800, lr=1.03736e-05, gnorm=40.116, clip=100, train_wall=257, gb_free=18, wall=15517
2025-11-12 02:55:27 | INFO | train_inner | epoch 001:  12000 / 22768 loss=0.353446, wps=1305.3, ups=0.75, wpb=1733.9, bsz=64, num_updates=12000, lr=1.05495e-05, gnorm=39.339, clip=100, train_wall=265, gb_free=17.8, wall=15783
2025-11-12 02:59:59 | INFO | train_inner | epoch 001:  12200 / 22768 loss=0.345626, wps=1274.3, ups=0.73, wpb=1734, bsz=64, num_updates=12200, lr=1.07253e-05, gnorm=39.154, clip=100, train_wall=271, gb_free=11.1, wall=16055
2025-11-12 03:04:29 | INFO | train_inner | epoch 001:  12400 / 22768 loss=0.361871, wps=1288.3, ups=0.74, wpb=1738.4, bsz=64, num_updates=12400, lr=1.09011e-05, gnorm=41.339, clip=100, train_wall=269, gb_free=18.3, wall=16325
2025-11-12 03:09:01 | INFO | train_inner | epoch 001:  12600 / 22768 loss=0.34301, wps=1285.8, ups=0.74, wpb=1748.4, bsz=64, num_updates=12600, lr=1.10769e-05, gnorm=38.107, clip=100, train_wall=271, gb_free=18.1, wall=16597
2025-11-12 03:13:21 | INFO | train_inner | epoch 001:  12800 / 22768 loss=0.349183, wps=1350.1, ups=0.77, wpb=1759.7, bsz=64, num_updates=12800, lr=1.12527e-05, gnorm=38.501, clip=100, train_wall=260, gb_free=11.1, wall=16858
2025-11-12 03:17:51 | INFO | train_inner | epoch 001:  13000 / 22768 loss=0.345125, wps=1295.7, ups=0.74, wpb=1746, bsz=64, num_updates=13000, lr=1.14286e-05, gnorm=36.545, clip=100, train_wall=269, gb_free=17.9, wall=17127
2025-11-12 03:22:17 | INFO | train_inner | epoch 001:  13200 / 22768 loss=0.350533, wps=1306.3, ups=0.75, wpb=1738.4, bsz=64, num_updates=13200, lr=1.16044e-05, gnorm=41.783, clip=100, train_wall=265, gb_free=18.4, wall=17393
2025-11-12 03:26:37 | INFO | train_inner | epoch 001:  13400 / 22768 loss=0.338584, wps=1337.7, ups=0.77, wpb=1735.1, bsz=64, num_updates=13400, lr=1.17802e-05, gnorm=38.305, clip=100, train_wall=259, gb_free=16.9, wall=17653
2025-11-12 03:30:57 | INFO | train_inner | epoch 001:  13600 / 22768 loss=0.335798, wps=1336.4, ups=0.77, wpb=1743.5, bsz=64, num_updates=13600, lr=1.1956e-05, gnorm=38.213, clip=100, train_wall=260, gb_free=18.3, wall=17914
2025-11-12 03:35:24 | INFO | train_inner | epoch 001:  13800 / 22768 loss=0.344767, wps=1307.6, ups=0.75, wpb=1743.5, bsz=64, num_updates=13800, lr=1.21319e-05, gnorm=40.291, clip=100, train_wall=266, gb_free=18.3, wall=18180
2025-11-12 03:39:46 | INFO | train_inner | epoch 001:  14000 / 22768 loss=0.337065, wps=1334.8, ups=0.76, wpb=1746.6, bsz=64, num_updates=14000, lr=1.23077e-05, gnorm=39.214, clip=100, train_wall=261, gb_free=18.3, wall=18442
2025-11-12 03:44:26 | INFO | train_inner | epoch 001:  14200 / 22768 loss=0.337014, wps=1256.9, ups=0.71, wpb=1759.3, bsz=64, num_updates=14200, lr=1.24835e-05, gnorm=36.449, clip=100, train_wall=279, gb_free=18.1, wall=18722
2025-11-12 03:49:04 | INFO | train_inner | epoch 001:  14400 / 22768 loss=0.339222, wps=1255.6, ups=0.72, wpb=1745.9, bsz=64, num_updates=14400, lr=1.26593e-05, gnorm=39.295, clip=100, train_wall=277, gb_free=16.4, wall=19000
2025-11-12 03:53:29 | INFO | train_inner | epoch 001:  14600 / 22768 loss=0.340815, wps=1329.4, ups=0.75, wpb=1764.2, bsz=64, num_updates=14600, lr=1.28352e-05, gnorm=39.656, clip=100, train_wall=265, gb_free=18, wall=19266
2025-11-12 03:57:50 | INFO | train_inner | epoch 001:  14800 / 22768 loss=0.331819, wps=1345.1, ups=0.77, wpb=1755, bsz=64, num_updates=14800, lr=1.3011e-05, gnorm=41.356, clip=100, train_wall=260, gb_free=16.9, wall=19527
2025-11-12 04:02:14 | INFO | train_inner | epoch 001:  15000 / 22768 loss=0.325226, wps=1324.8, ups=0.76, wpb=1743.3, bsz=64, num_updates=15000, lr=1.31868e-05, gnorm=38.687, clip=100, train_wall=262, gb_free=17.5, wall=19790
2025-11-12 04:06:33 | INFO | train_inner | epoch 001:  15200 / 22768 loss=0.319533, wps=1320.7, ups=0.77, wpb=1714.4, bsz=64, num_updates=15200, lr=1.33626e-05, gnorm=39.865, clip=100, train_wall=259, gb_free=11.1, wall=20049
2025-11-12 04:11:01 | INFO | train_inner | epoch 001:  15400 / 22768 loss=0.311155, wps=1302.4, ups=0.75, wpb=1741.6, bsz=64, num_updates=15400, lr=1.35385e-05, gnorm=39.585, clip=100, train_wall=267, gb_free=17.8, wall=20317
2025-11-12 04:15:30 | INFO | train_inner | epoch 001:  15600 / 22768 loss=0.325398, wps=1293.4, ups=0.74, wpb=1741.5, bsz=64, num_updates=15600, lr=1.37143e-05, gnorm=39.636, clip=100, train_wall=268, gb_free=17.4, wall=20586
2025-11-12 04:19:55 | INFO | train_inner | epoch 001:  15800 / 22768 loss=0.323178, wps=1325.7, ups=0.76, wpb=1755.6, bsz=64, num_updates=15800, lr=1.38901e-05, gnorm=41.473, clip=100, train_wall=264, gb_free=18.6, wall=20851
2025-11-12 04:24:13 | INFO | train_inner | epoch 001:  16000 / 22768 loss=0.312999, wps=1343.5, ups=0.77, wpb=1736.2, bsz=64, num_updates=16000, lr=1.40659e-05, gnorm=41.946, clip=100, train_wall=258, gb_free=17.6, wall=21110
2025-11-12 04:28:36 | INFO | train_inner | epoch 001:  16200 / 22768 loss=0.318833, wps=1329.3, ups=0.76, wpb=1748, bsz=64, num_updates=16200, lr=1.42418e-05, gnorm=40.631, clip=100, train_wall=262, gb_free=17.4, wall=21373
2025-11-12 04:33:08 | INFO | train_inner | epoch 001:  16400 / 22768 loss=0.309396, wps=1287.8, ups=0.74, wpb=1746.5, bsz=64, num_updates=16400, lr=1.44176e-05, gnorm=40.696, clip=100, train_wall=270, gb_free=18.1, wall=21644
2025-11-12 04:37:42 | INFO | train_inner | epoch 001:  16600 / 22768 loss=0.319971, wps=1248.7, ups=0.73, wpb=1715, bsz=64, num_updates=16600, lr=1.45934e-05, gnorm=41.248, clip=100, train_wall=274, gb_free=18.7, wall=21919
2025-11-12 04:42:06 | INFO | train_inner | epoch 001:  16800 / 22768 loss=0.306909, wps=1315.7, ups=0.76, wpb=1734.4, bsz=64, num_updates=16800, lr=1.47692e-05, gnorm=42.568, clip=100, train_wall=263, gb_free=17.7, wall=22182
2025-11-12 04:46:25 | INFO | train_inner | epoch 001:  17000 / 22768 loss=0.303328, wps=1347.2, ups=0.77, wpb=1746.8, bsz=64, num_updates=17000, lr=1.49451e-05, gnorm=42.17, clip=100, train_wall=259, gb_free=17.3, wall=22442
2025-11-12 04:50:46 | INFO | train_inner | epoch 001:  17200 / 22768 loss=0.313176, wps=1346.4, ups=0.77, wpb=1757, bsz=64, num_updates=17200, lr=1.51209e-05, gnorm=41.593, clip=100, train_wall=260, gb_free=16.6, wall=22703
2025-11-12 04:55:27 | INFO | train_inner | epoch 001:  17400 / 22768 loss=0.305669, wps=1239.3, ups=0.71, wpb=1740, bsz=64, num_updates=17400, lr=1.52967e-05, gnorm=41.063, clip=100, train_wall=280, gb_free=18.1, wall=22983
2025-11-12 04:59:56 | INFO | train_inner | epoch 001:  17600 / 22768 loss=0.307476, wps=1308, ups=0.74, wpb=1759.3, bsz=64, num_updates=17600, lr=1.54725e-05, gnorm=41.494, clip=100, train_wall=268, gb_free=18.3, wall=23252
2025-11-12 05:04:23 | INFO | train_inner | epoch 001:  17800 / 22768 loss=0.298273, wps=1296.8, ups=0.75, wpb=1732.5, bsz=64, num_updates=17800, lr=1.56484e-05, gnorm=39.531, clip=100, train_wall=266, gb_free=17.6, wall=23520
2025-11-12 05:08:48 | INFO | train_inner | epoch 001:  18000 / 22768 loss=0.295949, wps=1300.8, ups=0.76, wpb=1722.3, bsz=64, num_updates=18000, lr=1.58242e-05, gnorm=42.744, clip=100, train_wall=264, gb_free=18.3, wall=23784
2025-11-12 05:13:18 | INFO | train_inner | epoch 001:  18200 / 22768 loss=0.297619, wps=1292.5, ups=0.74, wpb=1742.5, bsz=64, num_updates=18200, lr=1.6e-05, gnorm=41.152, clip=100, train_wall=269, gb_free=18.1, wall=24054
2025-11-12 05:17:37 | INFO | train_inner | epoch 001:  18400 / 22768 loss=0.302726, wps=1349, ups=0.77, wpb=1749.6, bsz=64, num_updates=18400, lr=1.61758e-05, gnorm=42.309, clip=100, train_wall=259, gb_free=18.2, wall=24314
2025-11-12 05:21:56 | INFO | train_inner | epoch 001:  18600 / 22768 loss=0.310015, wps=1349.3, ups=0.77, wpb=1743.4, bsz=64, num_updates=18600, lr=1.63516e-05, gnorm=40.124, clip=100, train_wall=258, gb_free=16.6, wall=24572
2025-11-12 05:26:17 | INFO | train_inner | epoch 001:  18800 / 22768 loss=0.291892, wps=1333.9, ups=0.77, wpb=1740, bsz=64, num_updates=18800, lr=1.65275e-05, gnorm=38.803, clip=100, train_wall=260, gb_free=15.1, wall=24833
2025-11-12 05:30:40 | INFO | train_inner | epoch 001:  19000 / 22768 loss=0.295572, wps=1318.1, ups=0.76, wpb=1736.3, bsz=64, num_updates=19000, lr=1.67033e-05, gnorm=40.806, clip=100, train_wall=263, gb_free=18.1, wall=25096
2025-11-12 05:35:04 | INFO | train_inner | epoch 001:  19200 / 22768 loss=0.291635, wps=1314.1, ups=0.76, wpb=1735.6, bsz=64, num_updates=19200, lr=1.68791e-05, gnorm=40.488, clip=100, train_wall=263, gb_free=17.7, wall=25361
2025-11-12 05:39:28 | INFO | train_inner | epoch 001:  19400 / 22768 loss=0.288586, wps=1316.6, ups=0.76, wpb=1737.3, bsz=64, num_updates=19400, lr=1.70549e-05, gnorm=40.283, clip=100, train_wall=263, gb_free=18.4, wall=25624
2025-11-12 05:43:56 | INFO | train_inner | epoch 001:  19600 / 22768 loss=0.2879, wps=1305.9, ups=0.75, wpb=1745.4, bsz=64, num_updates=19600, lr=1.72308e-05, gnorm=39.654, clip=100, train_wall=266, gb_free=16.5, wall=25892
2025-11-12 05:48:12 | INFO | train_inner | epoch 001:  19800 / 22768 loss=0.282233, wps=1360.1, ups=0.78, wpb=1742, bsz=64, num_updates=19800, lr=1.74066e-05, gnorm=40.526, clip=100, train_wall=255, gb_free=17.4, wall=26148
2025-11-12 05:52:35 | INFO | train_inner | epoch 001:  20000 / 22768 loss=0.284405, wps=1332.4, ups=0.76, wpb=1751, bsz=64, num_updates=20000, lr=1.75824e-05, gnorm=41.858, clip=100, train_wall=262, gb_free=18.5, wall=26411
2025-11-12 05:56:53 | INFO | train_inner | epoch 001:  20200 / 22768 loss=0.286917, wps=1346.5, ups=0.77, wpb=1742.9, bsz=64, num_updates=20200, lr=1.77582e-05, gnorm=44.257, clip=100, train_wall=258, gb_free=18.1, wall=26670
2025-11-12 06:01:14 | INFO | train_inner | epoch 001:  20400 / 22768 loss=0.285305, wps=1331.2, ups=0.77, wpb=1734.3, bsz=64, num_updates=20400, lr=1.79341e-05, gnorm=41.397, clip=100, train_wall=260, gb_free=17.4, wall=26930
2025-11-12 06:05:39 | INFO | train_inner | epoch 001:  20600 / 22768 loss=0.280288, wps=1323.8, ups=0.75, wpb=1756.2, bsz=64, num_updates=20600, lr=1.81099e-05, gnorm=43.855, clip=100, train_wall=265, gb_free=18.2, wall=27196
2025-11-12 06:10:01 | INFO | train_inner | epoch 001:  20800 / 22768 loss=0.279337, wps=1331.3, ups=0.76, wpb=1743.5, bsz=64, num_updates=20800, lr=1.82857e-05, gnorm=43.525, clip=100, train_wall=261, gb_free=14.7, wall=27458
2025-11-12 06:14:39 | INFO | train_inner | epoch 001:  21000 / 22768 loss=0.27016, wps=1256.6, ups=0.72, wpb=1745.4, bsz=64, num_updates=21000, lr=1.84615e-05, gnorm=43.909, clip=100, train_wall=277, gb_free=17.8, wall=27735
2025-11-12 06:19:11 | INFO | train_inner | epoch 001:  21200 / 22768 loss=0.279877, wps=1292.3, ups=0.74, wpb=1754.9, bsz=64, num_updates=21200, lr=1.86374e-05, gnorm=44.691, clip=100, train_wall=271, gb_free=17.3, wall=28007
2025-11-12 06:23:41 | INFO | train_inner | epoch 001:  21400 / 22768 loss=0.272121, wps=1292.5, ups=0.74, wpb=1746.3, bsz=64, num_updates=21400, lr=1.88132e-05, gnorm=41.358, clip=100, train_wall=269, gb_free=15.6, wall=28277
2025-11-12 06:28:04 | INFO | train_inner | epoch 001:  21600 / 22768 loss=0.271429, wps=1323.1, ups=0.76, wpb=1741.3, bsz=64, num_updates=21600, lr=1.8989e-05, gnorm=42.27, clip=100, train_wall=262, gb_free=16.5, wall=28541
2025-11-12 06:32:29 | INFO | train_inner | epoch 001:  21800 / 22768 loss=0.275384, wps=1302.5, ups=0.75, wpb=1726.5, bsz=64, num_updates=21800, lr=1.91648e-05, gnorm=41.801, clip=100, train_wall=264, gb_free=17.6, wall=28806
2025-11-12 06:36:50 | INFO | train_inner | epoch 001:  22000 / 22768 loss=0.270626, wps=1339.9, ups=0.77, wpb=1748.3, bsz=64, num_updates=22000, lr=1.93407e-05, gnorm=43.15, clip=100, train_wall=260, gb_free=17.8, wall=29067
2025-11-12 06:41:12 | INFO | train_inner | epoch 001:  22200 / 22768 loss=0.259737, wps=1335, ups=0.77, wpb=1744.8, bsz=64, num_updates=22200, lr=1.95165e-05, gnorm=44.374, clip=100, train_wall=261, gb_free=15.8, wall=29328
2025-11-12 06:45:42 | INFO | train_inner | epoch 001:  22400 / 22768 loss=0.282383, wps=1280.9, ups=0.74, wpb=1732.6, bsz=64, num_updates=22400, lr=1.96923e-05, gnorm=45.847, clip=100, train_wall=270, gb_free=18.4, wall=29599
2025-11-12 06:50:14 | INFO | train_inner | epoch 001:  22600 / 22768 loss=0.274502, wps=1278.5, ups=0.74, wpb=1739.4, bsz=64, num_updates=22600, lr=1.98681e-05, gnorm=41.005, clip=100, train_wall=271, gb_free=16.7, wall=29871
[TRAINER SKIP] Zero loss detected, sample was skipped by criterion
[TRAINER SKIP] Zero loss detected, sample was skipped by criterion
