gcc-12.2.0 loaded successful
WARNING: underlay of /etc/localtime required more than 50 (88) bind mounts
WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (410) bind mounts
W1028 16:42:20.598363 1649 torch/distributed/run.py:792] 
W1028 16:42:20.598363 1649 torch/distributed/run.py:792] *****************************************
W1028 16:42:20.598363 1649 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1028 16:42:20.598363 1649 torch/distributed/run.py:792] *****************************************
2025-10-28 16:42:58.759385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-10-28 16:42:58.759381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1761640979.179772    1704 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179773    1713 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179813    1702 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179772    1714 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179773    1716 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179770    1707 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179789    1715 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.179774    1703 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761640979.807790    1704 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807799    1715 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807798    1714 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807793    1703 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807808    1713 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807820    1707 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807807    1702 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1761640979.807817    1716 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1761640984.884407    1704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884409    1714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884400    1715 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884435    1702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884400    1713 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884447    1707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884453    1703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884552    1704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884614    1714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884724    1715 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884793    1702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884844    1713 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884901    1707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884956    1703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884975    1704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884998    1714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885017    1715 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885035    1702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885048    1713 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885069    1707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885110    1703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885128    1704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885148    1714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885166    1715 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885183    1702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885195    1713 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885214    1707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885230    1703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.884446    1716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885430    1716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885466    1716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761640984.885480    1716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-28 16:43:05.176526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176523: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176557: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176878: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-28 16:43:05.176541: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank1]:     sys.exit(cli_main())
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank1]:     distributed_utils.call_main(cfg, main)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank1]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank1]:     main(cfg, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank1]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank1]:     return func(*args, **kwds)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank1]:     log_output = trainer.train_step(samples)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank1]:     return func(*args, **kwds)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank1]:     raise e
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank1]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank1]:     loss, sample_size, logging_output = criterion(model, sample)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank1]:     raise e
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank1]:     logits = model(**sample["net_input"])
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank1]:     return self.module(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank1]:     return self.encoder(batched_data, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank1]:     inner_states, graph_rep = self.graph_encoder(
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank1]:     attn_bias = self.graph_attn_bias(batched_data)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank1]:     self._update_attn_bias_vectorized(
[rank1]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank1]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank1]: RuntimeError: expected scalar type Float but found Half
[rank6]: Traceback (most recent call last):
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank6]:     sys.exit(cli_main())
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank6]:     distributed_utils.call_main(cfg, main)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank6]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank6]:     main(cfg, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank6]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank6]:     return func(*args, **kwds)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank6]:     log_output = trainer.train_step(samples)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank6]:     return func(*args, **kwds)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank6]:     raise e
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank6]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank6]:     loss, sample_size, logging_output = criterion(model, sample)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank6]:     raise e
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank6]:     logits = model(**sample["net_input"])
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank6]:     return self.module(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank6]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank6]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank6]:     return self.encoder(batched_data, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank6]:     inner_states, graph_rep = self.graph_encoder(
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank6]:     attn_bias = self.graph_attn_bias(batched_data)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank6]:     self._update_attn_bias_vectorized(
[rank6]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank6]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank6]: RuntimeError: expected scalar type Float but found Half
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank2]:     sys.exit(cli_main())
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank2]:     distributed_utils.call_main(cfg, main)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank2]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank2]:     main(cfg, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank2]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank2]:     return func(*args, **kwds)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank2]:     log_output = trainer.train_step(samples)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank2]:     return func(*args, **kwds)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank2]:     raise e
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank2]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank2]:     loss, sample_size, logging_output = criterion(model, sample)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank2]:     raise e
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank2]:     logits = model(**sample["net_input"])
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank2]:     return self.module(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank2]:     return self.encoder(batched_data, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank2]:     inner_states, graph_rep = self.graph_encoder(
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank2]:     attn_bias = self.graph_attn_bias(batched_data)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank2]:     self._update_attn_bias_vectorized(
[rank2]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank2]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank2]: RuntimeError: expected scalar type Float but found Half
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank3]:     sys.exit(cli_main())
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank3]:     distributed_utils.call_main(cfg, main)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank3]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank3]:     main(cfg, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank3]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank3]:     return func(*args, **kwds)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank3]:     log_output = trainer.train_step(samples)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank3]:     return func(*args, **kwds)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank3]:     raise e
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank3]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank3]:     loss, sample_size, logging_output = criterion(model, sample)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank3]:     raise e
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank3]:     logits = model(**sample["net_input"])
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank3]:     return self.module(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank3]:     return self.encoder(batched_data, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank3]:     inner_states, graph_rep = self.graph_encoder(
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank3]:     attn_bias = self.graph_attn_bias(batched_data)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank3]:     self._update_attn_bias_vectorized(
[rank3]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank3]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank3]: RuntimeError: expected scalar type Float but found Half
[rank7]: Traceback (most recent call last):
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank7]:     sys.exit(cli_main())
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank7]:     distributed_utils.call_main(cfg, main)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank7]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank7]:     main(cfg, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank7]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank7]:     return func(*args, **kwds)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank7]:     log_output = trainer.train_step(samples)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank7]:     return func(*args, **kwds)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank7]:     raise e
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank7]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank7]:     loss, sample_size, logging_output = criterion(model, sample)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank7]:     raise e
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank7]:     logits = model(**sample["net_input"])
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank7]:     return self.module(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank7]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank7]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank7]:     return self.encoder(batched_data, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank7]:     inner_states, graph_rep = self.graph_encoder(
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank7]:     attn_bias = self.graph_attn_bias(batched_data)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank7]:     self._update_attn_bias_vectorized(
[rank7]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank7]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank7]: RuntimeError: expected scalar type Float but found Half
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank0]:     sys.exit(cli_main())
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank0]:     distributed_utils.call_main(cfg, main)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank0]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank0]:     main(cfg, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank0]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank0]:     return func(*args, **kwds)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank0]:     log_output = trainer.train_step(samples)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank0]:     return func(*args, **kwds)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank0]:     raise e
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank0]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank0]:     loss, sample_size, logging_output = criterion(model, sample)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank0]:     raise e
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank0]:     logits = model(**sample["net_input"])
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank0]:     return self.module(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank0]:     return self.encoder(batched_data, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank0]:     inner_states, graph_rep = self.graph_encoder(
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank0]:     attn_bias = self.graph_attn_bias(batched_data)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank0]:     self._update_attn_bias_vectorized(
[rank0]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank0]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank0]: RuntimeError: expected scalar type Float but found Half
[rank4]: Traceback (most recent call last):
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank4]:     sys.exit(cli_main())
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank4]:     distributed_utils.call_main(cfg, main)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank4]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank4]:     main(cfg, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank4]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank4]:     return func(*args, **kwds)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank4]:     log_output = trainer.train_step(samples)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank4]:     return func(*args, **kwds)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank4]:     raise e
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank4]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank4]:     loss, sample_size, logging_output = criterion(model, sample)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank4]:     raise e
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank4]:     logits = model(**sample["net_input"])
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank4]:     return self.module(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank4]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank4]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank4]:     return self.encoder(batched_data, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank4]:     inner_states, graph_rep = self.graph_encoder(
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank4]:     attn_bias = self.graph_attn_bias(batched_data)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank4]:     self._update_attn_bias_vectorized(
[rank4]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank4]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank4]: RuntimeError: expected scalar type Float but found Half
[rank5]: Traceback (most recent call last):
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train", line 8, in <module>
[rank5]:     sys.exit(cli_main())
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 557, in cli_main
[rank5]:     distributed_utils.call_main(cfg, main)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 354, in call_main
[rank5]:     distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/utils.py", line 328, in distributed_main
[rank5]:     main(cfg, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 190, in main
[rank5]:     valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank5]:     return func(*args, **kwds)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq_cli/train.py", line 316, in train
[rank5]:     log_output = trainer.train_step(samples)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/contextlib.py", line 79, in inner
[rank5]:     return func(*args, **kwds)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 857, in train_step
[rank5]:     raise e
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/trainer.py", line 824, in train_step
[rank5]:     loss, sample_size_i, logging_output = self.task.train_step(
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py", line 515, in train_step
[rank5]:     loss, sample_size, logging_output = criterion(model, sample)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 207, in forward
[rank5]:     raise e
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/criterions/l2_loss.py", line 114, in forward
[rank5]:     logits = model(**sample["net_input"])
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/fairseq/distributed/module_proxy_wrapper.py", line 56, in forward
[rank5]:     return self.module(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank5]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank5]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 174, in forward
[rank5]:     return self.encoder(batched_data, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/models/graphormer.py", line 243, in forward
[rank5]:     inner_states, graph_rep = self.graph_encoder(
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/affincraft_graph_encoder.py", line 182, in forward
[rank5]:     attn_bias = self.graph_attn_bias(batched_data)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 276, in forward
[rank5]:     self._update_attn_bias_vectorized(
[rank5]:   File "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer/modules/graphormer_layers.py", line 399, in _update_attn_bias_vectorized
[rank5]:     graph_attn_bias[b, h].index_put_((src, tgt), emb, accumulate=True)
[rank5]: RuntimeError: expected scalar type Float but found Half
[rank0]:[W1028 16:46:42.068504850 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1028 16:46:51.768296 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1702 closing signal SIGTERM
W1028 16:46:51.770557 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1703 closing signal SIGTERM
W1028 16:46:51.770908 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1707 closing signal SIGTERM
W1028 16:46:51.771203 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1713 closing signal SIGTERM
W1028 16:46:51.771490 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1714 closing signal SIGTERM
W1028 16:46:51.771793 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1715 closing signal SIGTERM
W1028 16:46:51.772077 1649 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1716 closing signal SIGTERM
E1028 16:46:57.398102 1649 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 2 (pid: 1704) of binary: /data/run01/scw6f3q/zncao/affincraft/bin/python
Traceback (most recent call last):
  File "/data/run01/scw6f3q/zncao/affincraft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/run01/scw6f3q/zncao/affincraft/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/data/run01/scw6f3q/zncao/affincraft/bin/fairseq-train FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-28_16:46:51
  host      : g0939
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 1704)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
