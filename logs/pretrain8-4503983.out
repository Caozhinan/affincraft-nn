[INFO] Job starting at Sat Nov  1 12:37:18 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä® (LMDBÊ†ºÂºè)
 ËäÇÁÇπ:        g0499
 ‰Ωú‰∏öID:      4503983
 GPUs:        0,1,2,3,4,5,6,7
 ÂêØÂä®Êó∂Èó¥:    Sat Nov  1 12:37:18 CST 2025
==========================================
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - Â§öGPUÂàÜÂ∏ÉÂºèÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           8 GPUs √ó 1 node(s)
DataLoader workers: 6 per GPU
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/valid_lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   128
-------------------------------------------------------------------
ÁõÆÊ†áËÆ≠ÁªÉËΩÆÊï∞:       100
‰º∞ÁÆóÊÄªÊõ¥Êñ∞Ê≠•Êï∞:     1250000
Â≠¶‰π†ÁéáÈ¢ÑÁÉ≠Ê≠•Êï∞:     50000
===================================================================
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:40:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-11-01 12:41:02 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2025-11-01 12:41:02 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 0
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 1
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 5
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 2
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 3
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 6
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 7
2025-11-01 12:41:03 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 4
2025-11-01 12:41:04 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 64, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 100, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 1250000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=64, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=1250000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[5e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=474, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=50000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1250000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 474, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/valid_lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 50000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 1250000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbÊ†∑Êú¨ÊÄªÊï∞: 1,457,129
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129


Ê†∑Êú¨ÊÄªÊï∞: 1,457,129

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129




2025-11-01 12:41:04 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb


Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568
Ê†∑Êú¨ÊÄªÊï∞: 80,568





2025-11-01 12:41:04 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå80568 ‰∏™Ê†∑Êú¨
Ê†∑Êú¨ÊÄªÊï∞: 80,568
2025-11-01 12:41:04 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=64, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=1.0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=100, max_update=1250000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[5e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=474, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=50000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1250000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.05, act_dropout=0.05, dropout=0.05, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-11-01 12:41:04 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-11-01 12:41:04 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-11-01 12:41:04 | INFO | fairseq_cli.train | model: GraphormerModel
2025-11-01 12:41:04 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-11-01 12:41:04 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-11-01 12:41:04 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-11-01 12:41:04 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 80568
2025-11-01 12:41:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   4: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   5: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   6: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | rank   7: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-11-01 12:41:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-11-01 12:41:05 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2025-11-01 12:41:05 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 16
2025-11-01 12:41:05 | INFO | fairseq.trainer | Preparing to load checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint_last.pt
2025-11-01 12:41:05 | INFO | fairseq.trainer | No existing checkpoint found /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint_last.pt
2025-11-01 12:41:05 | INFO | fairseq.trainer | loading train data for epoch 1
2025-11-01 12:41:05 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-11-01 12:41:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-11-01 12:41:10 | INFO | fairseq.trainer | begin training epoch 1
2025-11-01 12:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-01 12:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 12:42:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 12:42:33 | INFO | train_inner | epoch 001:     52 / 11384 loss=0.883306, wps=1304.6, ups=0.67, wpb=1950.7, bsz=128, num_updates=50, lr=5e-08, gnorm=160.621, clip=100, loss_scale=16, train_wall=77, gb_free=15.8, wall=88
2025-11-01 12:43:32 | INFO | train_inner | epoch 001:    102 / 11384 loss=0.807167, wps=1656.2, ups=0.85, wpb=1955.8, bsz=128, num_updates=100, lr=1e-07, gnorm=163.853, clip=100, loss_scale=16, train_wall=59, gb_free=12.5, wall=147
2025-11-01 12:44:31 | INFO | train_inner | epoch 001:    152 / 11384 loss=0.707058, wps=1674.3, ups=0.84, wpb=1983.6, bsz=128, num_updates=150, lr=1.5e-07, gnorm=120.122, clip=100, loss_scale=16, train_wall=59, gb_free=11.4, wall=207
2025-11-01 12:45:30 | INFO | train_inner | epoch 001:    202 / 11384 loss=0.66319, wps=1648.2, ups=0.85, wpb=1928.2, bsz=128, num_updates=200, lr=2e-07, gnorm=85.475, clip=100, loss_scale=16, train_wall=58, gb_free=16.8, wall=265
2025-11-01 12:46:28 | INFO | train_inner | epoch 001:    252 / 11384 loss=0.654096, wps=1665.1, ups=0.86, wpb=1938.6, bsz=128, num_updates=250, lr=2.5e-07, gnorm=79.521, clip=100, loss_scale=16, train_wall=58, gb_free=15.5, wall=323
2025-11-01 12:47:27 | INFO | train_inner | epoch 001:    302 / 11384 loss=0.607521, wps=1692.8, ups=0.85, wpb=1993.6, bsz=128, num_updates=300, lr=3e-07, gnorm=90.167, clip=100, loss_scale=32, train_wall=59, gb_free=16.6, wall=382
2025-11-01 12:47:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 12:48:28 | INFO | train_inner | epoch 001:    353 / 11384 loss=0.617602, wps=1619.6, ups=0.81, wpb=1987.4, bsz=128, num_updates=350, lr=3.5e-07, gnorm=83.903, clip=100, loss_scale=16, train_wall=61, gb_free=15.2, wall=444
2025-11-01 12:49:30 | INFO | train_inner | epoch 001:    403 / 11384 loss=0.674746, wps=1592.3, ups=0.81, wpb=1959.8, bsz=128, num_updates=400, lr=4e-07, gnorm=118.987, clip=100, loss_scale=16, train_wall=61, gb_free=16.2, wall=505
2025-11-01 12:50:40 | INFO | train_inner | epoch 001:    453 / 11384 loss=0.587486, wps=1377.1, ups=0.71, wpb=1937, bsz=128, num_updates=450, lr=4.5e-07, gnorm=88.92, clip=100, loss_scale=16, train_wall=70, gb_free=15.3, wall=576
2025-11-01 12:52:12 | INFO | train_inner | epoch 001:    503 / 11384 loss=0.594729, wps=1057.2, ups=0.54, wpb=1941.5, bsz=128, num_updates=500, lr=5e-07, gnorm=107.431, clip=100, loss_scale=16, train_wall=91, gb_free=10.1, wall=667
2025-11-01 12:53:15 | INFO | train_inner | epoch 001:    553 / 11384 loss=0.584598, wps=1545.2, ups=0.8, wpb=1938.9, bsz=128, num_updates=550, lr=5.5e-07, gnorm=124.62, clip=100, loss_scale=16, train_wall=62, gb_free=14.8, wall=730
2025-11-01 12:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 12:54:18 | INFO | train_inner | epoch 001:    604 / 11384 loss=0.559796, wps=1539.4, ups=0.79, wpb=1953.9, bsz=128, num_updates=600, lr=6e-07, gnorm=103.203, clip=100, loss_scale=16, train_wall=63, gb_free=15.9, wall=794
2025-11-01 12:55:21 | INFO | train_inner | epoch 001:    654 / 11384 loss=0.559493, wps=1544.1, ups=0.8, wpb=1941.4, bsz=128, num_updates=650, lr=6.5e-07, gnorm=114.39, clip=100, loss_scale=16, train_wall=63, gb_free=15.3, wall=856
2025-11-01 12:56:24 | INFO | train_inner | epoch 001:    704 / 11384 loss=0.565618, wps=1563.7, ups=0.8, wpb=1961.5, bsz=128, num_updates=700, lr=7e-07, gnorm=98, clip=100, loss_scale=16, train_wall=62, gb_free=16.9, wall=919
2025-11-01 12:57:27 | INFO | train_inner | epoch 001:    754 / 11384 loss=0.536112, wps=1557.6, ups=0.8, wpb=1951.5, bsz=128, num_updates=750, lr=7.5e-07, gnorm=111.547, clip=100, loss_scale=16, train_wall=62, gb_free=14.6, wall=982
2025-11-01 12:58:42 | INFO | train_inner | epoch 001:    804 / 11384 loss=0.570072, wps=1307.1, ups=0.67, wpb=1959.9, bsz=128, num_updates=800, lr=8e-07, gnorm=116.16, clip=100, loss_scale=16, train_wall=74, gb_free=16.4, wall=1057
2025-11-01 13:00:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 13:01:06 | INFO | train_inner | epoch 001:    855 / 11384 loss=0.516963, wps=686.5, ups=0.35, wpb=1976.4, bsz=128, num_updates=850, lr=8.5e-07, gnorm=115.225, clip=100, loss_scale=16, train_wall=144, gb_free=13.3, wall=1201
2025-11-01 13:03:09 | INFO | train_inner | epoch 001:    905 / 11384 loss=0.546347, wps=792.1, ups=0.4, wpb=1961.9, bsz=128, num_updates=900, lr=9e-07, gnorm=130.433, clip=100, loss_scale=16, train_wall=123, gb_free=16.4, wall=1325
2025-11-01 13:04:11 | INFO | train_inner | epoch 001:    955 / 11384 loss=0.538288, wps=1586.4, ups=0.81, wpb=1967.6, bsz=128, num_updates=950, lr=9.5e-07, gnorm=141.899, clip=100, loss_scale=16, train_wall=62, gb_free=13.7, wall=1387
2025-11-01 13:05:31 | INFO | train_inner | epoch 001:   1005 / 11384 loss=0.510348, wps=1225, ups=0.62, wpb=1962, bsz=128, num_updates=1000, lr=1e-06, gnorm=82.709, clip=100, loss_scale=16, train_wall=72, gb_free=16.5, wall=1467
2025-11-01 13:07:15 | INFO | train_inner | epoch 001:   1055 / 11384 loss=0.503606, wps=940.8, ups=0.48, wpb=1946.2, bsz=128, num_updates=1050, lr=1.05e-06, gnorm=110.152, clip=100, loss_scale=16, train_wall=64, gb_free=16.6, wall=1570
2025-11-01 13:07:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 13:09:02 | INFO | train_inner | epoch 001:   1106 / 11384 loss=0.512392, wps=896.6, ups=0.47, wpb=1914.2, bsz=128, num_updates=1100, lr=1.1e-06, gnorm=136.667, clip=100, loss_scale=16, train_wall=77, gb_free=15.3, wall=1677
2025-11-01 13:10:02 | INFO | train_inner | epoch 001:   1156 / 11384 loss=0.489047, wps=1612.7, ups=0.83, wpb=1937.4, bsz=128, num_updates=1150, lr=1.15e-06, gnorm=114.684, clip=100, loss_scale=16, train_wall=60, gb_free=15.7, wall=1737
2025-11-01 13:11:27 | INFO | train_inner | epoch 001:   1206 / 11384 loss=0.493442, wps=1147.7, ups=0.59, wpb=1961.6, bsz=128, num_updates=1200, lr=1.2e-06, gnorm=133.506, clip=100, loss_scale=16, train_wall=85, gb_free=10.4, wall=1822
2025-11-01 13:13:09 | INFO | train_inner | epoch 001:   1256 / 11384 loss=0.492168, wps=954.5, ups=0.49, wpb=1941, bsz=128, num_updates=1250, lr=1.25e-06, gnorm=92.965, clip=100, loss_scale=16, train_wall=101, gb_free=16.5, wall=1924
2025-11-01 13:15:30 | INFO | train_inner | epoch 001:   1306 / 11384 loss=0.484272, wps=693.3, ups=0.35, wpb=1964, bsz=128, num_updates=1300, lr=1.3e-06, gnorm=109.423, clip=100, loss_scale=16, train_wall=141, gb_free=10.7, wall=2066
2025-11-01 13:16:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 13:16:53 | INFO | train_inner | epoch 001:   1357 / 11384 loss=0.499717, wps=1190.6, ups=0.61, wpb=1962.5, bsz=128, num_updates=1350, lr=1.35e-06, gnorm=144.944, clip=100, loss_scale=16, train_wall=82, gb_free=12.8, wall=2148
2025-11-01 13:17:53 | INFO | train_inner | epoch 001:   1407 / 11384 loss=0.493644, wps=1593.3, ups=0.84, wpb=1906.8, bsz=128, num_updates=1400, lr=1.4e-06, gnorm=98.854, clip=100, loss_scale=16, train_wall=60, gb_free=16.2, wall=2208
2025-11-01 13:19:59 | INFO | train_inner | epoch 001:   1457 / 11384 loss=0.480652, wps=775.9, ups=0.4, wpb=1954.8, bsz=128, num_updates=1450, lr=1.45e-06, gnorm=87.498, clip=100, loss_scale=16, train_wall=126, gb_free=15.8, wall=2334
2025-11-01 13:21:28 | INFO | train_inner | epoch 001:   1507 / 11384 loss=0.478457, wps=1060.2, ups=0.56, wpb=1893.3, bsz=128, num_updates=1500, lr=1.5e-06, gnorm=87.924, clip=100, loss_scale=16, train_wall=89, gb_free=16.3, wall=2423
2025-11-01 13:23:13 | INFO | train_inner | epoch 001:   1557 / 11384 loss=0.450593, wps=915, ups=0.47, wpb=1928.5, bsz=128, num_updates=1550, lr=1.55e-06, gnorm=73.284, clip=100, loss_scale=16, train_wall=105, gb_free=8.6, wall=2529
2025-11-01 13:25:22 | INFO | train_inner | epoch 001:   1607 / 11384 loss=0.492414, wps=762.5, ups=0.39, wpb=1956.4, bsz=128, num_updates=1600, lr=1.6e-06, gnorm=100.317, clip=100, loss_scale=32, train_wall=128, gb_free=14.2, wall=2657
2025-11-01 13:26:40 | INFO | train_inner | epoch 001:   1657 / 11384 loss=0.455642, wps=1272, ups=0.64, wpb=1993.2, bsz=128, num_updates=1650, lr=1.65e-06, gnorm=76.967, clip=100, loss_scale=32, train_wall=78, gb_free=15.9, wall=2735
2025-11-01 13:28:14 | INFO | train_inner | epoch 001:   1707 / 11384 loss=0.471786, wps=1053.7, ups=0.54, wpb=1959.4, bsz=128, num_updates=1700, lr=1.7e-06, gnorm=65.423, clip=100, loss_scale=32, train_wall=93, gb_free=14.2, wall=2829
2025-11-01 13:29:42 | INFO | train_inner | epoch 001:   1757 / 11384 loss=0.463854, wps=1116.3, ups=0.56, wpb=1980.9, bsz=128, num_updates=1750, lr=1.75e-06, gnorm=70.612, clip=100, loss_scale=32, train_wall=89, gb_free=16.8, wall=2918
2025-11-01 13:30:57 | INFO | train_inner | epoch 001:   1807 / 11384 loss=0.459774, wps=1285.7, ups=0.67, wpb=1918.1, bsz=128, num_updates=1800, lr=1.8e-06, gnorm=68.407, clip=100, loss_scale=32, train_wall=69, gb_free=9.8, wall=2992
2025-11-01 13:32:50 | INFO | train_inner | epoch 001:   1857 / 11384 loss=0.473517, wps=872, ups=0.44, wpb=1970, bsz=128, num_updates=1850, lr=1.85e-06, gnorm=54.967, clip=100, loss_scale=32, train_wall=113, gb_free=14.9, wall=3105
2025-11-01 13:33:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 13:33:54 | INFO | train_inner | epoch 001:   1908 / 11384 loss=0.445569, wps=1546.7, ups=0.78, wpb=1975.7, bsz=128, num_updates=1900, lr=1.9e-06, gnorm=56.804, clip=100, loss_scale=32, train_wall=63, gb_free=14.4, wall=3169
2025-11-01 13:35:55 | INFO | train_inner | epoch 001:   1958 / 11384 loss=0.453611, wps=811.8, ups=0.41, wpb=1969.1, bsz=128, num_updates=1950, lr=1.95e-06, gnorm=64.125, clip=100, loss_scale=32, train_wall=120, gb_free=16.3, wall=3290
2025-11-01 13:37:15 | INFO | train_inner | epoch 001:   2008 / 11384 loss=0.457671, wps=1211.9, ups=0.63, wpb=1938.8, bsz=128, num_updates=2000, lr=2e-06, gnorm=68.262, clip=100, loss_scale=32, train_wall=74, gb_free=16.4, wall=3370
2025-11-01 13:40:29 | INFO | train_inner | epoch 001:   2058 / 11384 loss=0.433133, wps=500.1, ups=0.26, wpb=1940.3, bsz=128, num_updates=2050, lr=2.05e-06, gnorm=53.038, clip=100, loss_scale=32, train_wall=187, gb_free=17.5, wall=3564
2025-11-01 13:42:14 | INFO | train_inner | epoch 001:   2108 / 11384 loss=0.469194, wps=948.2, ups=0.48, wpb=1991.1, bsz=128, num_updates=2100, lr=2.1e-06, gnorm=55.969, clip=100, loss_scale=32, train_wall=105, gb_free=14.5, wall=3669
2025-11-01 13:43:15 | INFO | train_inner | epoch 001:   2158 / 11384 loss=0.44935, wps=1577.7, ups=0.82, wpb=1917.9, bsz=128, num_updates=2150, lr=2.15e-06, gnorm=58.62, clip=100, loss_scale=64, train_wall=60, gb_free=13.1, wall=3730
2025-11-01 13:43:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 13:44:45 | INFO | train_inner | epoch 001:   2209 / 11384 loss=0.467611, wps=1072.9, ups=0.55, wpb=1940.8, bsz=128, num_updates=2200, lr=2.2e-06, gnorm=56.532, clip=100, loss_scale=32, train_wall=77, gb_free=15.8, wall=3821
2025-11-01 13:46:38 | INFO | train_inner | epoch 001:   2259 / 11384 loss=0.452329, wps=861.6, ups=0.44, wpb=1949.2, bsz=128, num_updates=2250, lr=2.25e-06, gnorm=43.389, clip=100, loss_scale=32, train_wall=113, gb_free=15.9, wall=3934
2025-11-01 13:48:57 | INFO | train_inner | epoch 001:   2309 / 11384 loss=0.443188, wps=691.3, ups=0.36, wpb=1916.8, bsz=128, num_updates=2300, lr=2.3e-06, gnorm=46.337, clip=100, loss_scale=32, train_wall=96, gb_free=16.7, wall=4072
2025-11-01 13:49:59 | INFO | train_inner | epoch 001:   2359 / 11384 loss=0.463249, wps=1596.6, ups=0.81, wpb=1983.3, bsz=128, num_updates=2350, lr=2.35e-06, gnorm=50.827, clip=100, loss_scale=32, train_wall=62, gb_free=14.4, wall=4134
2025-11-01 13:51:58 | INFO | train_inner | epoch 001:   2409 / 11384 loss=0.429447, wps=815.6, ups=0.42, wpb=1934.4, bsz=128, num_updates=2400, lr=2.4e-06, gnorm=43.521, clip=100, loss_scale=32, train_wall=118, gb_free=15.8, wall=4253
2025-11-01 13:53:50 | INFO | train_inner | epoch 001:   2459 / 11384 loss=0.461525, wps=870.9, ups=0.45, wpb=1953.9, bsz=128, num_updates=2450, lr=2.45e-06, gnorm=46.889, clip=100, loss_scale=64, train_wall=112, gb_free=16.5, wall=4365
2025-11-01 13:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 13:55:18 | INFO | train_inner | epoch 001:   2510 / 11384 loss=0.431825, wps=1131.1, ups=0.57, wpb=1990.7, bsz=128, num_updates=2500, lr=2.5e-06, gnorm=41.88, clip=100, loss_scale=32, train_wall=88, gb_free=17.3, wall=4453
2025-11-01 13:56:19 | INFO | train_inner | epoch 001:   2560 / 11384 loss=0.445707, wps=1612.9, ups=0.82, wpb=1961.7, bsz=128, num_updates=2550, lr=2.55e-06, gnorm=46.773, clip=100, loss_scale=32, train_wall=61, gb_free=8.2, wall=4514
2025-11-01 13:58:57 | INFO | train_inner | epoch 001:   2610 / 11384 loss=0.436012, wps=623.5, ups=0.32, wpb=1970.5, bsz=128, num_updates=2600, lr=2.6e-06, gnorm=39.81, clip=100, loss_scale=32, train_wall=68, gb_free=13, wall=4672
2025-11-01 14:00:29 | INFO | train_inner | epoch 001:   2660 / 11384 loss=0.44805, wps=1065.3, ups=0.54, wpb=1959.4, bsz=128, num_updates=2650, lr=2.65e-06, gnorm=46.325, clip=100, loss_scale=32, train_wall=92, gb_free=15.4, wall=4764
2025-11-01 14:02:13 | INFO | train_inner | epoch 001:   2710 / 11384 loss=0.438653, wps=938.1, ups=0.48, wpb=1959.3, bsz=128, num_updates=2700, lr=2.7e-06, gnorm=41.321, clip=100, loss_scale=32, train_wall=62, gb_free=12.8, wall=4868
2025-11-01 14:03:13 | INFO | train_inner | epoch 001:   2760 / 11384 loss=0.445161, wps=1609.3, ups=0.83, wpb=1930.3, bsz=128, num_updates=2750, lr=2.75e-06, gnorm=49.803, clip=100, loss_scale=64, train_wall=60, gb_free=16.1, wall=4928
2025-11-01 14:05:05 | INFO | train_inner | epoch 001:   2810 / 11384 loss=0.434792, wps=889.2, ups=0.45, wpb=1981.7, bsz=128, num_updates=2800, lr=2.8e-06, gnorm=45.969, clip=100, loss_scale=64, train_wall=85, gb_free=13.6, wall=5040
2025-11-01 14:06:31 | INFO | train_inner | epoch 001:   2860 / 11384 loss=0.423345, wps=1122.1, ups=0.58, wpb=1945.4, bsz=128, num_updates=2850, lr=2.85e-06, gnorm=39.22, clip=100, loss_scale=64, train_wall=79, gb_free=16.4, wall=5126
2025-11-01 14:07:32 | INFO | train_inner | epoch 001:   2910 / 11384 loss=0.443671, wps=1593.3, ups=0.82, wpb=1935.2, bsz=128, num_updates=2900, lr=2.9e-06, gnorm=42.88, clip=100, loss_scale=64, train_wall=61, gb_free=17.4, wall=5187
2025-11-01 14:09:52 | INFO | train_inner | epoch 001:   2960 / 11384 loss=0.428504, wps=712.9, ups=0.36, wpb=1990.3, bsz=128, num_updates=2950, lr=2.95e-06, gnorm=49.509, clip=100, loss_scale=64, train_wall=139, gb_free=7.2, wall=5327
2025-11-01 14:11:58 | INFO | train_inner | epoch 001:   3010 / 11384 loss=0.420007, wps=773, ups=0.39, wpb=1957.5, bsz=128, num_updates=3000, lr=3e-06, gnorm=45.694, clip=100, loss_scale=128, train_wall=103, gb_free=14.1, wall=5453
2025-11-01 14:13:00 | INFO | train_inner | epoch 001:   3060 / 11384 loss=0.411149, wps=1632.4, ups=0.81, wpb=2012.1, bsz=128, num_updates=3050, lr=3.05e-06, gnorm=40.8, clip=100, loss_scale=128, train_wall=61, gb_free=14.6, wall=5515
2025-11-01 14:13:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 14:15:11 | INFO | train_inner | epoch 001:   3111 / 11384 loss=0.442893, wps=742.7, ups=0.38, wpb=1949.5, bsz=128, num_updates=3100, lr=3.1e-06, gnorm=39.394, clip=100, loss_scale=64, train_wall=131, gb_free=16.9, wall=5646
2025-11-01 14:18:03 | INFO | train_inner | epoch 001:   3161 / 11384 loss=0.410015, wps=560.3, ups=0.29, wpb=1922.3, bsz=128, num_updates=3150, lr=3.15e-06, gnorm=41.992, clip=100, loss_scale=64, train_wall=85, gb_free=15.9, wall=5818
2025-11-01 14:19:02 | INFO | train_inner | epoch 001:   3211 / 11384 loss=0.428968, wps=1657, ups=0.84, wpb=1970.9, bsz=128, num_updates=3200, lr=3.2e-06, gnorm=44.103, clip=100, loss_scale=64, train_wall=59, gb_free=11.1, wall=5877
2025-11-01 14:20:41 | INFO | train_inner | epoch 001:   3261 / 11384 loss=0.42385, wps=986.9, ups=0.5, wpb=1960.7, bsz=127.9, num_updates=3250, lr=3.25e-06, gnorm=46.69, clip=100, loss_scale=64, train_wall=99, gb_free=16.9, wall=5977
2025-11-01 14:22:15 | INFO | train_inner | epoch 001:   3311 / 11384 loss=0.416184, wps=1037.5, ups=0.54, wpb=1938.5, bsz=128, num_updates=3300, lr=3.3e-06, gnorm=37.123, clip=100, loss_scale=64, train_wall=93, gb_free=16.7, wall=6070
2025-11-01 14:24:45 | INFO | train_inner | epoch 001:   3361 / 11384 loss=0.419434, wps=654.4, ups=0.33, wpb=1964.6, bsz=128, num_updates=3350, lr=3.35e-06, gnorm=36.58, clip=100, loss_scale=128, train_wall=150, gb_free=16.8, wall=6220
2025-11-01 14:26:39 | INFO | train_inner | epoch 001:   3411 / 11384 loss=0.419432, wps=862.5, ups=0.44, wpb=1969.6, bsz=128, num_updates=3400, lr=3.4e-06, gnorm=40.502, clip=100, loss_scale=128, train_wall=114, gb_free=16.9, wall=6334
2025-11-01 14:27:39 | INFO | train_inner | epoch 001:   3461 / 11384 loss=0.402645, wps=1599.3, ups=0.83, wpb=1924.2, bsz=128, num_updates=3450, lr=3.45e-06, gnorm=34.188, clip=100, loss_scale=128, train_wall=60, gb_free=16.5, wall=6395
2025-11-01 14:28:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 14:29:36 | INFO | train_inner | epoch 001:   3512 / 11384 loss=0.428129, wps=846.1, ups=0.43, wpb=1966.7, bsz=128, num_updates=3500, lr=3.5e-06, gnorm=45.493, clip=100, loss_scale=64, train_wall=74, gb_free=15, wall=6511
2025-11-01 14:31:36 | INFO | train_inner | epoch 001:   3562 / 11384 loss=0.437623, wps=811, ups=0.42, wpb=1949.9, bsz=128, num_updates=3550, lr=3.55e-06, gnorm=37.71, clip=100, loss_scale=64, train_wall=120, gb_free=15.4, wall=6631
2025-11-01 14:33:23 | INFO | train_inner | epoch 001:   3612 / 11384 loss=0.425295, wps=920.9, ups=0.47, wpb=1979.8, bsz=128, num_updates=3600, lr=3.6e-06, gnorm=46.723, clip=100, loss_scale=64, train_wall=107, gb_free=13.5, wall=6739
2025-11-01 14:35:01 | INFO | train_inner | epoch 001:   3662 / 11384 loss=0.410331, wps=995.3, ups=0.51, wpb=1939.7, bsz=128, num_updates=3650, lr=3.65e-06, gnorm=33.356, clip=100, loss_scale=64, train_wall=97, gb_free=13.9, wall=6836
2025-11-01 14:36:06 | INFO | train_inner | epoch 001:   3712 / 11384 loss=0.405584, wps=1541.9, ups=0.77, wpb=1994.4, bsz=128, num_updates=3700, lr=3.7e-06, gnorm=37.385, clip=100, loss_scale=64, train_wall=64, gb_free=15.3, wall=6901
2025-11-01 14:37:23 | INFO | train_inner | epoch 001:   3762 / 11384 loss=0.41874, wps=1279.2, ups=0.65, wpb=1973.9, bsz=128, num_updates=3750, lr=3.75e-06, gnorm=36.241, clip=100, loss_scale=128, train_wall=77, gb_free=16.8, wall=6978
2025-11-01 14:38:26 | INFO | train_inner | epoch 001:   3812 / 11384 loss=0.387273, wps=1553.9, ups=0.79, wpb=1974.8, bsz=128, num_updates=3800, lr=3.8e-06, gnorm=31.498, clip=100, loss_scale=128, train_wall=63, gb_free=16.7, wall=7042
2025-11-01 14:39:39 | INFO | train_inner | epoch 001:   3862 / 11384 loss=0.401409, wps=1332.8, ups=0.69, wpb=1934.3, bsz=128, num_updates=3850, lr=3.85e-06, gnorm=33.58, clip=100, loss_scale=128, train_wall=72, gb_free=10.7, wall=7114
2025-11-01 14:40:47 | INFO | train_inner | epoch 001:   3912 / 11384 loss=0.416065, wps=1437.9, ups=0.73, wpb=1960.5, bsz=128, num_updates=3900, lr=3.9e-06, gnorm=38.753, clip=100, loss_scale=128, train_wall=68, gb_free=17.1, wall=7182
2025-11-01 14:42:01 | INFO | train_inner | epoch 001:   3962 / 11384 loss=0.402931, wps=1354.7, ups=0.68, wpb=1992.8, bsz=128, num_updates=3950, lr=3.95e-06, gnorm=37.808, clip=100, loss_scale=128, train_wall=73, gb_free=15.7, wall=7256
2025-11-01 14:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-01 14:43:22 | INFO | train_inner | epoch 001:   4013 / 11384 loss=0.40193, wps=1198, ups=0.62, wpb=1939.4, bsz=128, num_updates=4000, lr=4e-06, gnorm=40.148, clip=100, loss_scale=128, train_wall=81, gb_free=16.8, wall=7337
2025-11-01 14:44:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 14:44:28 | INFO | train_inner | epoch 001:   4064 / 11384 loss=0.390653, wps=1465.5, ups=0.75, wpb=1948.8, bsz=128, num_updates=4050, lr=4.05e-06, gnorm=33.76, clip=100, loss_scale=64, train_wall=66, gb_free=13.8, wall=7403
2025-11-01 14:45:31 | INFO | train_inner | epoch 001:   4114 / 11384 loss=0.4004, wps=1546.3, ups=0.8, wpb=1942.4, bsz=128, num_updates=4100, lr=4.1e-06, gnorm=38.041, clip=100, loss_scale=64, train_wall=63, gb_free=15.8, wall=7466
2025-11-01 14:46:35 | INFO | train_inner | epoch 001:   4164 / 11384 loss=0.389397, wps=1519.1, ups=0.78, wpb=1955.5, bsz=128, num_updates=4150, lr=4.15e-06, gnorm=37.292, clip=100, loss_scale=64, train_wall=64, gb_free=5.4, wall=7531
2025-11-01 14:47:43 | INFO | train_inner | epoch 001:   4214 / 11384 loss=0.393759, wps=1448.8, ups=0.74, wpb=1958.8, bsz=128, num_updates=4200, lr=4.2e-06, gnorm=41.718, clip=100, loss_scale=64, train_wall=67, gb_free=14.1, wall=7598
2025-11-01 14:48:54 | INFO | train_inner | epoch 001:   4264 / 11384 loss=0.413003, wps=1377.7, ups=0.7, wpb=1969.5, bsz=128, num_updates=4250, lr=4.25e-06, gnorm=41.012, clip=100, loss_scale=64, train_wall=71, gb_free=15.3, wall=7670
2025-11-01 14:49:56 | INFO | train_inner | epoch 001:   4314 / 11384 loss=0.393013, wps=1585.5, ups=0.81, wpb=1951.4, bsz=128, num_updates=4300, lr=4.3e-06, gnorm=41.677, clip=100, loss_scale=128, train_wall=61, gb_free=15.6, wall=7731
2025-11-01 14:51:01 | INFO | train_inner | epoch 001:   4364 / 11384 loss=0.423987, wps=1527.5, ups=0.77, wpb=1993, bsz=128, num_updates=4350, lr=4.35e-06, gnorm=45.323, clip=100, loss_scale=128, train_wall=65, gb_free=16.7, wall=7796
2025-11-01 14:52:07 | INFO | train_inner | epoch 001:   4414 / 11384 loss=0.407179, wps=1482.1, ups=0.76, wpb=1946.6, bsz=128, num_updates=4400, lr=4.4e-06, gnorm=38.545, clip=100, loss_scale=128, train_wall=65, gb_free=16.8, wall=7862
2025-11-01 14:53:21 | INFO | train_inner | epoch 001:   4464 / 11384 loss=0.398073, wps=1343.2, ups=0.68, wpb=1983.8, bsz=128, num_updates=4450, lr=4.45e-06, gnorm=39.064, clip=100, loss_scale=128, train_wall=74, gb_free=15.2, wall=7936
2025-11-01 14:54:32 | INFO | train_inner | epoch 001:   4514 / 11384 loss=0.415295, wps=1379.2, ups=0.71, wpb=1954.7, bsz=128, num_updates=4500, lr=4.5e-06, gnorm=41.156, clip=100, loss_scale=128, train_wall=71, gb_free=15.2, wall=8007
2025-11-01 14:55:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-01 14:55:50 | INFO | train_inner | epoch 001:   4565 / 11384 loss=0.407385, wps=1260.3, ups=0.64, wpb=1971.7, bsz=128, num_updates=4550, lr=4.55e-06, gnorm=44.285, clip=100, loss_scale=128, train_wall=77, gb_free=17.1, wall=8085
2025-11-01 14:56:56 | INFO | train_inner | epoch 001:   4615 / 11384 loss=0.380535, wps=1490.9, ups=0.76, wpb=1972.6, bsz=128, num_updates=4600, lr=4.6e-06, gnorm=37.039, clip=100, loss_scale=128, train_wall=66, gb_free=15.2, wall=8151
2025-11-01 14:58:06 | INFO | train_inner | epoch 001:   4665 / 11384 loss=0.39953, wps=1409.3, ups=0.72, wpb=1959.5, bsz=128, num_updates=4650, lr=4.65e-06, gnorm=41.73, clip=100, loss_scale=128, train_wall=69, gb_free=16.2, wall=8221
2025-11-01 14:59:10 | INFO | train_inner | epoch 001:   4715 / 11384 loss=0.406768, wps=1506.8, ups=0.78, wpb=1935.4, bsz=128, num_updates=4700, lr=4.7e-06, gnorm=34.479, clip=100, loss_scale=128, train_wall=64, gb_free=8, wall=8285
2025-11-01 15:00:22 | INFO | train_inner | epoch 001:   4765 / 11384 loss=0.387028, wps=1384.9, ups=0.69, wpb=2010.1, bsz=128, num_updates=4750, lr=4.75e-06, gnorm=40.507, clip=100, loss_scale=128, train_wall=72, gb_free=15.9, wall=8358
2025-11-01 15:01:27 | INFO | train_inner | epoch 001:   4815 / 11384 loss=0.395411, wps=1483.6, ups=0.77, wpb=1923.3, bsz=128, num_updates=4800, lr=4.8e-06, gnorm=41.139, clip=100, loss_scale=256, train_wall=61, gb_free=15, wall=8422
2025-11-01 15:01:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-01 15:02:30 | INFO | train_inner | epoch 001:   4866 / 11384 loss=0.406323, wps=1515.4, ups=0.8, wpb=1905, bsz=128, num_updates=4850, lr=4.85e-06, gnorm=40.998, clip=100, loss_scale=128, train_wall=63, gb_free=16.1, wall=8485
2025-11-01 15:03:41 | INFO | train_inner | epoch 001:   4916 / 11384 loss=0.401953, wps=1383.9, ups=0.71, wpb=1947.3, bsz=128, num_updates=4900, lr=4.9e-06, gnorm=39.877, clip=100, loss_scale=128, train_wall=70, gb_free=16.2, wall=8556
2025-11-01 15:04:44 | INFO | train_inner | epoch 001:   4966 / 11384 loss=0.391745, wps=1535.8, ups=0.79, wpb=1945.4, bsz=128, num_updates=4950, lr=4.95e-06, gnorm=36.037, clip=100, loss_scale=128, train_wall=63, gb_free=15.8, wall=8619
2025-11-01 15:05:47 | INFO | train_inner | epoch 001:   5016 / 11384 loss=0.387202, wps=1536.3, ups=0.79, wpb=1938.3, bsz=128, num_updates=5000, lr=5e-06, gnorm=39.719, clip=100, loss_scale=128, train_wall=63, gb_free=17.3, wall=8682
2025-11-01 15:06:55 | INFO | train_inner | epoch 001:   5066 / 11384 loss=0.385521, wps=1411.6, ups=0.73, wpb=1923.1, bsz=128, num_updates=5050, lr=5.05e-06, gnorm=36.293, clip=100, loss_scale=128, train_wall=68, gb_free=16, wall=8750
2025-11-01 15:07:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 15:08:06 | INFO | train_inner | epoch 001:   5117 / 11384 loss=0.386398, wps=1387, ups=0.71, wpb=1966.7, bsz=128, num_updates=5100, lr=5.1e-06, gnorm=40.836, clip=100, loss_scale=64, train_wall=71, gb_free=14.8, wall=8821
2025-11-01 15:09:29 | INFO | train_inner | epoch 001:   5167 / 11384 loss=0.394524, wps=1191.3, ups=0.6, wpb=1970.7, bsz=128, num_updates=5150, lr=5.15e-06, gnorm=36.805, clip=100, loss_scale=64, train_wall=82, gb_free=14.7, wall=8904
2025-11-01 15:10:48 | INFO | train_inner | epoch 001:   5217 / 11384 loss=0.392154, wps=1241.9, ups=0.63, wpb=1963.6, bsz=128, num_updates=5200, lr=5.2e-06, gnorm=36.806, clip=100, loss_scale=64, train_wall=72, gb_free=13.3, wall=8983
2025-11-01 15:11:57 | INFO | train_inner | epoch 001:   5267 / 11384 loss=0.40216, wps=1406.3, ups=0.72, wpb=1951.8, bsz=128, num_updates=5250, lr=5.25e-06, gnorm=38.276, clip=100, loss_scale=64, train_wall=68, gb_free=15, wall=9052
2025-11-01 15:13:14 | INFO | train_inner | epoch 001:   5317 / 11384 loss=0.381251, wps=1281, ups=0.65, wpb=1972.7, bsz=128, num_updates=5300, lr=5.3e-06, gnorm=39.286, clip=100, loss_scale=64, train_wall=76, gb_free=14.2, wall=9130
2025-11-01 15:14:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 15:14:27 | INFO | train_inner | epoch 001:   5368 / 11384 loss=0.396127, wps=1357.5, ups=0.69, wpb=1961.9, bsz=128, num_updates=5350, lr=5.35e-06, gnorm=47.173, clip=100, loss_scale=64, train_wall=72, gb_free=16.1, wall=9202
2025-11-01 15:15:38 | INFO | train_inner | epoch 001:   5418 / 11384 loss=0.381962, wps=1359.6, ups=0.7, wpb=1938.7, bsz=128, num_updates=5400, lr=5.4e-06, gnorm=43.173, clip=100, loss_scale=64, train_wall=71, gb_free=15.3, wall=9273
2025-11-01 15:16:44 | INFO | train_inner | epoch 001:   5468 / 11384 loss=0.392787, wps=1521.2, ups=0.76, wpb=1995.4, bsz=128, num_updates=5450, lr=5.45e-06, gnorm=48.546, clip=100, loss_scale=64, train_wall=65, gb_free=15.8, wall=9339
2025-11-01 15:17:49 | INFO | train_inner | epoch 001:   5518 / 11384 loss=0.390522, wps=1486.1, ups=0.76, wpb=1944.9, bsz=128, num_updates=5500, lr=5.5e-06, gnorm=41.846, clip=100, loss_scale=64, train_wall=65, gb_free=15.2, wall=9404
2025-11-01 15:18:53 | INFO | train_inner | epoch 001:   5568 / 11384 loss=0.376131, wps=1530.4, ups=0.78, wpb=1956.5, bsz=128, num_updates=5550, lr=5.55e-06, gnorm=38.733, clip=100, loss_scale=64, train_wall=64, gb_free=17.3, wall=9468
2025-11-01 15:20:03 | INFO | train_inner | epoch 001:   5618 / 11384 loss=0.393665, wps=1399.2, ups=0.71, wpb=1967.2, bsz=128, num_updates=5600, lr=5.6e-06, gnorm=38.148, clip=100, loss_scale=128, train_wall=70, gb_free=13.9, wall=9538
2025-11-01 15:21:09 | INFO | train_inner | epoch 001:   5668 / 11384 loss=0.382813, wps=1475.6, ups=0.76, wpb=1944.7, bsz=128, num_updates=5650, lr=5.65e-06, gnorm=36.061, clip=100, loss_scale=128, train_wall=66, gb_free=7.3, wall=9604
2025-11-01 15:22:14 | INFO | train_inner | epoch 001:   5718 / 11384 loss=0.377072, wps=1505.7, ups=0.78, wpb=1940.9, bsz=128, num_updates=5700, lr=5.7e-06, gnorm=41.618, clip=100, loss_scale=128, train_wall=64, gb_free=15.1, wall=9669
2025-11-01 15:22:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 15:23:23 | INFO | train_inner | epoch 001:   5769 / 11384 loss=0.387811, wps=1392.3, ups=0.72, wpb=1945.8, bsz=128, num_updates=5750, lr=5.75e-06, gnorm=39.619, clip=100, loss_scale=64, train_wall=70, gb_free=11.6, wall=9739
2025-11-01 15:24:32 | INFO | train_inner | epoch 001:   5819 / 11384 loss=0.373299, wps=1411.9, ups=0.73, wpb=1924.6, bsz=128, num_updates=5800, lr=5.8e-06, gnorm=38.366, clip=100, loss_scale=64, train_wall=68, gb_free=15, wall=9807
2025-11-01 15:25:45 | INFO | train_inner | epoch 001:   5869 / 11384 loss=0.388209, wps=1325.6, ups=0.68, wpb=1947.3, bsz=128, num_updates=5850, lr=5.85e-06, gnorm=39.009, clip=100, loss_scale=64, train_wall=73, gb_free=14.3, wall=9880
2025-11-01 15:26:58 | INFO | train_inner | epoch 001:   5919 / 11384 loss=0.365804, wps=1325.9, ups=0.68, wpb=1936, bsz=128, num_updates=5900, lr=5.9e-06, gnorm=40.551, clip=100, loss_scale=64, train_wall=73, gb_free=12.2, wall=9953
2025-11-01 15:28:08 | INFO | train_inner | epoch 001:   5969 / 11384 loss=0.362616, wps=1389.5, ups=0.71, wpb=1944, bsz=128, num_updates=5950, lr=5.95e-06, gnorm=42.67, clip=100, loss_scale=64, train_wall=68, gb_free=15, wall=10023
2025-11-01 15:28:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 15:30:19 | INFO | train_inner | epoch 001:   6020 / 11384 loss=0.373021, wps=737.5, ups=0.38, wpb=1934.5, bsz=128, num_updates=6000, lr=6e-06, gnorm=44.111, clip=100, loss_scale=64, train_wall=95, gb_free=17, wall=10154
2025-11-01 15:31:36 | INFO | train_inner | epoch 001:   6070 / 11384 loss=0.360624, wps=1287.9, ups=0.65, wpb=1975.3, bsz=128, num_updates=6050, lr=6.05e-06, gnorm=39.816, clip=100, loss_scale=64, train_wall=71, gb_free=16.4, wall=10231
2025-11-01 15:32:51 | INFO | train_inner | epoch 001:   6120 / 11384 loss=0.358507, wps=1286.3, ups=0.67, wpb=1930.4, bsz=128, num_updates=6100, lr=6.1e-06, gnorm=44.153, clip=100, loss_scale=64, train_wall=75, gb_free=15.8, wall=10306
2025-11-01 15:33:57 | INFO | train_inner | epoch 001:   6170 / 11384 loss=0.374978, wps=1449.8, ups=0.75, wpb=1928, bsz=128, num_updates=6150, lr=6.15e-06, gnorm=40.155, clip=100, loss_scale=64, train_wall=66, gb_free=15.3, wall=10373
2025-11-01 15:35:06 | INFO | train_inner | epoch 001:   6220 / 11384 loss=0.380088, wps=1447.6, ups=0.73, wpb=1996.5, bsz=128, num_updates=6200, lr=6.2e-06, gnorm=41.393, clip=100, loss_scale=64, train_wall=69, gb_free=13.5, wall=10442
2025-11-01 15:36:19 | INFO | train_inner | epoch 001:   6270 / 11384 loss=0.386365, wps=1325, ups=0.69, wpb=1921.1, bsz=128, num_updates=6250, lr=6.25e-06, gnorm=39.138, clip=100, loss_scale=128, train_wall=72, gb_free=16, wall=10514
2025-11-01 15:37:21 | INFO | train_inner | epoch 001:   6320 / 11384 loss=0.369566, wps=1586.2, ups=0.81, wpb=1968.5, bsz=128, num_updates=6300, lr=6.3e-06, gnorm=40.361, clip=100, loss_scale=128, train_wall=62, gb_free=16.8, wall=10576
2025-11-01 15:38:30 | INFO | train_inner | epoch 001:   6370 / 11384 loss=0.383339, wps=1404.3, ups=0.72, wpb=1940.6, bsz=128, num_updates=6350, lr=6.35e-06, gnorm=41.754, clip=100, loss_scale=128, train_wall=69, gb_free=15.8, wall=10645
2025-11-01 15:39:33 | INFO | train_inner | epoch 001:   6420 / 11384 loss=0.351679, wps=1554.5, ups=0.79, wpb=1959.1, bsz=128, num_updates=6400, lr=6.4e-06, gnorm=35.226, clip=100, loss_scale=128, train_wall=63, gb_free=15.9, wall=10708
2025-11-01 15:40:45 | INFO | train_inner | epoch 001:   6470 / 11384 loss=0.358697, wps=1387.7, ups=0.7, wpb=1987.7, bsz=128, num_updates=6450, lr=6.45e-06, gnorm=40.375, clip=100, loss_scale=128, train_wall=71, gb_free=15.1, wall=10780
2025-11-01 15:41:52 | INFO | train_inner | epoch 001:   6520 / 11384 loss=0.351699, wps=1443.7, ups=0.74, wpb=1949.3, bsz=128, num_updates=6500, lr=6.5e-06, gnorm=33.915, clip=100, loss_scale=256, train_wall=67, gb_free=16.4, wall=10847
2025-11-01 15:41:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-11-01 15:43:13 | INFO | train_inner | epoch 001:   6571 / 11384 loss=0.351946, wps=1208.4, ups=0.62, wpb=1954.7, bsz=128, num_updates=6550, lr=6.55e-06, gnorm=39.961, clip=100, loss_scale=128, train_wall=81, gb_free=17.1, wall=10928
2025-11-01 15:44:39 | INFO | train_inner | epoch 001:   6621 / 11384 loss=0.381266, wps=1137.9, ups=0.58, wpb=1951, bsz=128, num_updates=6600, lr=6.6e-06, gnorm=45.243, clip=100, loss_scale=128, train_wall=85, gb_free=16.2, wall=11014
2025-11-01 15:45:47 | INFO | train_inner | epoch 001:   6671 / 11384 loss=0.360163, wps=1443.1, ups=0.73, wpb=1979.4, bsz=128, num_updates=6650, lr=6.65e-06, gnorm=41.692, clip=100, loss_scale=128, train_wall=68, gb_free=14.4, wall=11083
2025-11-01 15:47:01 | INFO | train_inner | epoch 001:   6721 / 11384 loss=0.346021, wps=1361.6, ups=0.68, wpb=1994.7, bsz=128, num_updates=6700, lr=6.7e-06, gnorm=41.439, clip=100, loss_scale=128, train_wall=73, gb_free=14.5, wall=11156
2025-11-01 15:47:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 15:48:20 | INFO | train_inner | epoch 001:   6772 / 11384 loss=0.36478, wps=1243.1, ups=0.63, wpb=1967.2, bsz=128, num_updates=6750, lr=6.75e-06, gnorm=46.162, clip=100, loss_scale=64, train_wall=79, gb_free=16.5, wall=11235
2025-11-01 15:49:33 | INFO | train_inner | epoch 001:   6822 / 11384 loss=0.366198, wps=1314.8, ups=0.68, wpb=1933.8, bsz=128, num_updates=6800, lr=6.8e-06, gnorm=41.398, clip=100, loss_scale=64, train_wall=73, gb_free=11.6, wall=11309
2025-11-01 15:50:47 | INFO | train_inner | epoch 001:   6872 / 11384 loss=0.373134, wps=1342.1, ups=0.68, wpb=1966.8, bsz=128, num_updates=6850, lr=6.85e-06, gnorm=41.863, clip=100, loss_scale=64, train_wall=73, gb_free=15.6, wall=11382
2025-11-01 15:51:55 | INFO | train_inner | epoch 001:   6922 / 11384 loss=0.366822, wps=1419.4, ups=0.73, wpb=1931.8, bsz=128, num_updates=6900, lr=6.9e-06, gnorm=40.037, clip=100, loss_scale=64, train_wall=68, gb_free=15.6, wall=11450
2025-11-01 15:53:07 | INFO | train_inner | epoch 001:   6972 / 11384 loss=0.396944, wps=1350.3, ups=0.7, wpb=1940.6, bsz=128, num_updates=6950, lr=6.95e-06, gnorm=47.797, clip=100, loss_scale=64, train_wall=72, gb_free=9.2, wall=11522
2025-11-01 15:53:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 15:54:20 | INFO | train_inner | epoch 001:   7023 / 11384 loss=0.384341, wps=1343, ups=0.69, wpb=1956.2, bsz=128, num_updates=7000, lr=7e-06, gnorm=44.531, clip=100, loss_scale=64, train_wall=73, gb_free=16.1, wall=11595
2025-11-01 15:55:36 | INFO | train_inner | epoch 001:   7073 / 11384 loss=0.355095, wps=1272.4, ups=0.66, wpb=1940.3, bsz=128, num_updates=7050, lr=7.05e-06, gnorm=37.642, clip=100, loss_scale=64, train_wall=76, gb_free=16.5, wall=11671
2025-11-01 15:56:39 | INFO | train_inner | epoch 001:   7123 / 11384 loss=0.367154, wps=1543.4, ups=0.79, wpb=1960.8, bsz=128, num_updates=7100, lr=7.1e-06, gnorm=39.13, clip=100, loss_scale=64, train_wall=63, gb_free=15.6, wall=11735
2025-11-01 15:57:43 | INFO | train_inner | epoch 001:   7173 / 11384 loss=0.354776, wps=1512.6, ups=0.78, wpb=1939.3, bsz=128, num_updates=7150, lr=7.15e-06, gnorm=43.665, clip=100, loss_scale=64, train_wall=64, gb_free=15.2, wall=11799
2025-11-01 15:58:54 | INFO | train_inner | epoch 001:   7223 / 11384 loss=0.362367, wps=1389.1, ups=0.71, wpb=1958.3, bsz=128, num_updates=7200, lr=7.2e-06, gnorm=37.139, clip=100, loss_scale=64, train_wall=70, gb_free=16.2, wall=11869
2025-11-01 16:00:03 | INFO | train_inner | epoch 001:   7273 / 11384 loss=0.360245, wps=1422.4, ups=0.73, wpb=1953, bsz=128, num_updates=7250, lr=7.25e-06, gnorm=36.252, clip=100, loss_scale=128, train_wall=68, gb_free=14.1, wall=11938
2025-11-01 16:01:07 | INFO | train_inner | epoch 001:   7323 / 11384 loss=0.370906, wps=1536.3, ups=0.78, wpb=1964.7, bsz=128, num_updates=7300, lr=7.3e-06, gnorm=51.771, clip=100, loss_scale=128, train_wall=64, gb_free=16, wall=12002
2025-11-01 16:02:16 | INFO | train_inner | epoch 001:   7373 / 11384 loss=0.344603, wps=1434.8, ups=0.72, wpb=1990.4, bsz=128, num_updates=7350, lr=7.35e-06, gnorm=39.315, clip=100, loss_scale=128, train_wall=69, gb_free=16.4, wall=12071
2025-11-01 16:02:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:03:29 | INFO | train_inner | epoch 001:   7424 / 11384 loss=0.357381, wps=1356.7, ups=0.68, wpb=1985.3, bsz=128, num_updates=7400, lr=7.4e-06, gnorm=39.482, clip=100, loss_scale=64, train_wall=73, gb_free=15.1, wall=12144
2025-11-01 16:04:43 | INFO | train_inner | epoch 001:   7474 / 11384 loss=0.362873, wps=1355, ups=0.68, wpb=1989.2, bsz=128, num_updates=7450, lr=7.45e-06, gnorm=43.053, clip=100, loss_scale=64, train_wall=73, gb_free=17.6, wall=12218
2025-11-01 16:05:55 | INFO | train_inner | epoch 001:   7524 / 11384 loss=0.360689, wps=1373.9, ups=0.69, wpb=1997.9, bsz=128, num_updates=7500, lr=7.5e-06, gnorm=44.014, clip=100, loss_scale=64, train_wall=72, gb_free=15.9, wall=12290
2025-11-01 16:07:07 | INFO | train_inner | epoch 001:   7574 / 11384 loss=0.386928, wps=1375.8, ups=0.7, wpb=1961.7, bsz=128, num_updates=7550, lr=7.55e-06, gnorm=43.332, clip=100, loss_scale=64, train_wall=71, gb_free=17.4, wall=12362
2025-11-01 16:08:17 | INFO | train_inner | epoch 001:   7624 / 11384 loss=0.364064, wps=1400.4, ups=0.71, wpb=1960.7, bsz=128, num_updates=7600, lr=7.6e-06, gnorm=40.977, clip=100, loss_scale=64, train_wall=70, gb_free=13.4, wall=12432
2025-11-01 16:09:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:09:44 | INFO | train_inner | epoch 001:   7675 / 11384 loss=0.352401, wps=1140.9, ups=0.57, wpb=1990.2, bsz=128, num_updates=7650, lr=7.65e-06, gnorm=38.948, clip=100, loss_scale=64, train_wall=87, gb_free=15.6, wall=12519
2025-11-01 16:11:03 | INFO | train_inner | epoch 001:   7725 / 11384 loss=0.363257, wps=1235.1, ups=0.63, wpb=1960.7, bsz=128, num_updates=7700, lr=7.7e-06, gnorm=47.528, clip=100, loss_scale=64, train_wall=79, gb_free=14.1, wall=12598
2025-11-01 16:12:17 | INFO | train_inner | epoch 001:   7775 / 11384 loss=0.366457, wps=1314.4, ups=0.67, wpb=1949.1, bsz=128, num_updates=7750, lr=7.75e-06, gnorm=42.743, clip=100, loss_scale=64, train_wall=74, gb_free=12.6, wall=12672
2025-11-01 16:13:26 | INFO | train_inner | epoch 001:   7825 / 11384 loss=0.321897, wps=1419.2, ups=0.73, wpb=1951.1, bsz=128, num_updates=7800, lr=7.8e-06, gnorm=38.53, clip=100, loss_scale=64, train_wall=68, gb_free=12, wall=12741
2025-11-01 16:14:35 | INFO | train_inner | epoch 001:   7875 / 11384 loss=0.354549, wps=1438.8, ups=0.72, wpb=1997.9, bsz=128, num_updates=7850, lr=7.85e-06, gnorm=36.478, clip=100, loss_scale=64, train_wall=69, gb_free=16.5, wall=12811
2025-11-01 16:15:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:15:42 | INFO | train_inner | epoch 001:   7926 / 11384 loss=0.339576, wps=1485.9, ups=0.75, wpb=1972.6, bsz=128, num_updates=7900, lr=7.9e-06, gnorm=41.508, clip=100, loss_scale=64, train_wall=66, gb_free=16.4, wall=12877
2025-11-01 16:16:53 | INFO | train_inner | epoch 001:   7976 / 11384 loss=0.365803, wps=1483.3, ups=0.74, wpb=1997.9, bsz=128, num_updates=7950, lr=7.95e-06, gnorm=43.266, clip=100, loss_scale=64, train_wall=67, gb_free=15.7, wall=12948
2025-11-01 16:17:58 | INFO | train_inner | epoch 001:   8026 / 11384 loss=0.34534, wps=1494.7, ups=0.77, wpb=1941.4, bsz=128, num_updates=8000, lr=8e-06, gnorm=42.702, clip=100, loss_scale=64, train_wall=65, gb_free=16.2, wall=13013
2025-11-01 16:19:09 | INFO | train_inner | epoch 001:   8076 / 11384 loss=0.347789, wps=1397.6, ups=0.71, wpb=1978.2, bsz=128, num_updates=8050, lr=8.05e-06, gnorm=43.589, clip=100, loss_scale=64, train_wall=71, gb_free=16.8, wall=13084
2025-11-01 16:20:17 | INFO | train_inner | epoch 001:   8126 / 11384 loss=0.343114, wps=1429.6, ups=0.74, wpb=1938.8, bsz=128, num_updates=8100, lr=8.1e-06, gnorm=40.304, clip=100, loss_scale=64, train_wall=68, gb_free=11.5, wall=13152
2025-11-01 16:21:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:21:22 | INFO | train_inner | epoch 001:   8177 / 11384 loss=0.379373, wps=1490.1, ups=0.77, wpb=1941.4, bsz=128, num_updates=8150, lr=8.15e-06, gnorm=47.329, clip=100, loss_scale=64, train_wall=65, gb_free=13.5, wall=13217
2025-11-01 16:22:40 | INFO | train_inner | epoch 001:   8227 / 11384 loss=0.334712, wps=1275.4, ups=0.64, wpb=1991.2, bsz=128, num_updates=8200, lr=8.2e-06, gnorm=39.168, clip=100, loss_scale=64, train_wall=78, gb_free=14.3, wall=13295
2025-11-01 16:23:43 | INFO | train_inner | epoch 001:   8277 / 11384 loss=0.34973, wps=1558.1, ups=0.79, wpb=1970, bsz=128, num_updates=8250, lr=8.25e-06, gnorm=44.889, clip=100, loss_scale=64, train_wall=63, gb_free=15.8, wall=13358
2025-11-01 16:24:58 | INFO | train_inner | epoch 001:   8327 / 11384 loss=0.342983, wps=1315.2, ups=0.67, wpb=1965.5, bsz=128, num_updates=8300, lr=8.3e-06, gnorm=39.016, clip=100, loss_scale=64, train_wall=74, gb_free=14.9, wall=13433
2025-11-01 16:26:24 | INFO | train_inner | epoch 001:   8377 / 11384 loss=0.326651, wps=1135.1, ups=0.58, wpb=1958.7, bsz=128, num_updates=8350, lr=8.35e-06, gnorm=42.99, clip=100, loss_scale=64, train_wall=86, gb_free=11.9, wall=13519
2025-11-01 16:27:52 | INFO | train_inner | epoch 001:   8427 / 11384 loss=0.349038, wps=1121.7, ups=0.57, wpb=1964, bsz=128, num_updates=8400, lr=8.4e-06, gnorm=51.548, clip=100, loss_scale=64, train_wall=87, gb_free=16.7, wall=13607
2025-11-01 16:28:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:28:59 | INFO | train_inner | epoch 001:   8478 / 11384 loss=0.345356, wps=1463.5, ups=0.74, wpb=1974.6, bsz=128, num_updates=8450, lr=8.45e-06, gnorm=40.574, clip=100, loss_scale=64, train_wall=67, gb_free=15.9, wall=13674
2025-11-01 16:30:17 | INFO | train_inner | epoch 001:   8528 / 11384 loss=0.34328, wps=1262.3, ups=0.65, wpb=1952.1, bsz=128, num_updates=8500, lr=8.5e-06, gnorm=36.404, clip=100, loss_scale=64, train_wall=76, gb_free=16.9, wall=13752
2025-11-01 16:31:20 | INFO | train_inner | epoch 001:   8578 / 11384 loss=0.340101, wps=1492.3, ups=0.79, wpb=1884.7, bsz=128, num_updates=8550, lr=8.55e-06, gnorm=37.715, clip=100, loss_scale=64, train_wall=63, gb_free=14.6, wall=13815
2025-11-01 16:32:41 | INFO | train_inner | epoch 001:   8628 / 11384 loss=0.347938, wps=1224.3, ups=0.62, wpb=1977, bsz=128, num_updates=8600, lr=8.6e-06, gnorm=45.165, clip=100, loss_scale=64, train_wall=80, gb_free=15.7, wall=13896
2025-11-01 16:33:47 | INFO | train_inner | epoch 001:   8678 / 11384 loss=0.345471, wps=1476.7, ups=0.75, wpb=1972.9, bsz=128, num_updates=8650, lr=8.65e-06, gnorm=42.769, clip=100, loss_scale=64, train_wall=67, gb_free=13, wall=13963
2025-11-01 16:34:52 | INFO | train_inner | epoch 001:   8728 / 11384 loss=0.337554, wps=1530.1, ups=0.78, wpb=1971.3, bsz=128, num_updates=8700, lr=8.7e-06, gnorm=41.441, clip=100, loss_scale=128, train_wall=64, gb_free=16.4, wall=14027
2025-11-01 16:35:55 | INFO | train_inner | epoch 001:   8778 / 11384 loss=0.33367, wps=1547.6, ups=0.79, wpb=1961.4, bsz=128, num_updates=8750, lr=8.75e-06, gnorm=40.813, clip=100, loss_scale=128, train_wall=63, gb_free=14.1, wall=14090
2025-11-01 16:36:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:36:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 16:37:02 | INFO | train_inner | epoch 001:   8830 / 11384 loss=0.362196, wps=1441.1, ups=0.75, wpb=1931.7, bsz=128, num_updates=8800, lr=8.8e-06, gnorm=52.904, clip=100, loss_scale=32, train_wall=67, gb_free=15.6, wall=14157
2025-11-01 16:38:15 | INFO | train_inner | epoch 001:   8880 / 11384 loss=0.341217, wps=1337.3, ups=0.68, wpb=1957.6, bsz=128, num_updates=8850, lr=8.85e-06, gnorm=41.654, clip=100, loss_scale=32, train_wall=73, gb_free=16.1, wall=14231
2025-11-01 16:39:28 | INFO | train_inner | epoch 001:   8930 / 11384 loss=0.333343, wps=1384.3, ups=0.69, wpb=2004.9, bsz=128, num_updates=8900, lr=8.9e-06, gnorm=36.66, clip=100, loss_scale=32, train_wall=72, gb_free=11.2, wall=14303
2025-11-01 16:40:45 | INFO | train_inner | epoch 001:   8980 / 11384 loss=0.336937, wps=1293.9, ups=0.65, wpb=1991.7, bsz=128, num_updates=8950, lr=8.95e-06, gnorm=40.047, clip=100, loss_scale=32, train_wall=77, gb_free=15.8, wall=14380
2025-11-01 16:41:49 | INFO | train_inner | epoch 001:   9030 / 11384 loss=0.337219, wps=1506.7, ups=0.78, wpb=1936, bsz=128, num_updates=9000, lr=9e-06, gnorm=39.441, clip=100, loss_scale=32, train_wall=64, gb_free=15.8, wall=14444
2025-11-01 16:43:02 | INFO | train_inner | epoch 001:   9080 / 11384 loss=0.348927, wps=1339.9, ups=0.69, wpb=1943.8, bsz=128, num_updates=9050, lr=9.05e-06, gnorm=43.44, clip=100, loss_scale=64, train_wall=72, gb_free=16.5, wall=14517
2025-11-01 16:44:43 | INFO | train_inner | epoch 001:   9130 / 11384 loss=0.341839, wps=985.4, ups=0.5, wpb=1988.6, bsz=128, num_updates=9100, lr=9.1e-06, gnorm=38.448, clip=100, loss_scale=64, train_wall=101, gb_free=14.4, wall=14618
2025-11-01 16:46:08 | INFO | train_inner | epoch 001:   9180 / 11384 loss=0.330466, wps=1154.8, ups=0.58, wpb=1977.8, bsz=128, num_updates=9150, lr=9.15e-06, gnorm=43.356, clip=100, loss_scale=64, train_wall=84, gb_free=16.8, wall=14703
2025-11-01 16:47:18 | INFO | train_inner | epoch 001:   9230 / 11384 loss=0.342512, wps=1392, ups=0.72, wpb=1944.3, bsz=128, num_updates=9200, lr=9.2e-06, gnorm=41.248, clip=100, loss_scale=64, train_wall=70, gb_free=14, wall=14773
2025-11-01 16:48:24 | INFO | train_inner | epoch 001:   9280 / 11384 loss=0.331484, wps=1497.5, ups=0.76, wpb=1974.8, bsz=128, num_updates=9250, lr=9.25e-06, gnorm=45.4, clip=100, loss_scale=64, train_wall=66, gb_free=15.2, wall=14839
2025-11-01 16:49:31 | INFO | train_inner | epoch 001:   9330 / 11384 loss=0.325607, wps=1497, ups=0.75, wpb=1998.1, bsz=128, num_updates=9300, lr=9.3e-06, gnorm=37.026, clip=100, loss_scale=128, train_wall=67, gb_free=16.8, wall=14906
2025-11-01 16:49:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:50:40 | INFO | train_inner | epoch 001:   9381 / 11384 loss=0.348179, wps=1424.8, ups=0.72, wpb=1968.2, bsz=128, num_updates=9350, lr=9.35e-06, gnorm=42.978, clip=100, loss_scale=64, train_wall=69, gb_free=14.4, wall=14975
2025-11-01 16:51:56 | INFO | train_inner | epoch 001:   9431 / 11384 loss=0.337034, wps=1294.9, ups=0.66, wpb=1972.9, bsz=128, num_updates=9400, lr=9.4e-06, gnorm=39.61, clip=100, loss_scale=64, train_wall=76, gb_free=16.2, wall=15051
2025-11-01 16:52:59 | INFO | train_inner | epoch 001:   9481 / 11384 loss=0.345102, wps=1540.8, ups=0.8, wpb=1933.5, bsz=128, num_updates=9450, lr=9.45e-06, gnorm=43.209, clip=100, loss_scale=64, train_wall=62, gb_free=12, wall=15114
2025-11-01 16:54:03 | INFO | train_inner | epoch 001:   9531 / 11384 loss=0.329125, wps=1527.6, ups=0.77, wpb=1975.4, bsz=128, num_updates=9500, lr=9.5e-06, gnorm=43.438, clip=100, loss_scale=64, train_wall=64, gb_free=15.8, wall=15179
2025-11-01 16:55:08 | INFO | train_inner | epoch 001:   9581 / 11384 loss=0.347668, wps=1492.3, ups=0.77, wpb=1926, bsz=128, num_updates=9550, lr=9.55e-06, gnorm=43.499, clip=100, loss_scale=64, train_wall=64, gb_free=15.2, wall=15243
2025-11-01 16:55:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 16:56:21 | INFO | train_inner | epoch 001:   9632 / 11384 loss=0.329131, wps=1353.3, ups=0.69, wpb=1966.7, bsz=128, num_updates=9600, lr=9.6e-06, gnorm=39.215, clip=100, loss_scale=64, train_wall=72, gb_free=16.6, wall=15316
2025-11-01 16:57:28 | INFO | train_inner | epoch 001:   9682 / 11384 loss=0.310466, wps=1491.3, ups=0.75, wpb=1997.3, bsz=128, num_updates=9650, lr=9.65e-06, gnorm=36.725, clip=100, loss_scale=64, train_wall=67, gb_free=10.8, wall=15383
2025-11-01 16:58:45 | INFO | train_inner | epoch 001:   9732 / 11384 loss=0.328441, wps=1277.9, ups=0.65, wpb=1968.2, bsz=128, num_updates=9700, lr=9.7e-06, gnorm=44.729, clip=100, loss_scale=64, train_wall=77, gb_free=17.4, wall=15460
2025-11-01 17:00:15 | INFO | train_inner | epoch 001:   9782 / 11384 loss=0.321369, wps=1091.8, ups=0.55, wpb=1969.1, bsz=128, num_updates=9750, lr=9.75e-06, gnorm=45.365, clip=100, loss_scale=64, train_wall=71, gb_free=15.5, wall=15550
2025-11-01 17:01:25 | INFO | train_inner | epoch 001:   9832 / 11384 loss=0.339977, wps=1370.8, ups=0.71, wpb=1926.7, bsz=128, num_updates=9800, lr=9.8e-06, gnorm=45.188, clip=100, loss_scale=64, train_wall=70, gb_free=14, wall=15620
2025-11-01 17:02:36 | INFO | train_inner | epoch 001:   9882 / 11384 loss=0.321831, wps=1357.2, ups=0.7, wpb=1936.8, bsz=128, num_updates=9850, lr=9.85e-06, gnorm=39.411, clip=100, loss_scale=128, train_wall=71, gb_free=15.9, wall=15692
2025-11-01 17:02:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 17:03:41 | INFO | train_inner | epoch 001:   9933 / 11384 loss=0.337076, wps=1509.8, ups=0.78, wpb=1947.5, bsz=128, num_updates=9900, lr=9.9e-06, gnorm=37.238, clip=100, loss_scale=64, train_wall=64, gb_free=13.8, wall=15756
2025-11-01 17:04:58 | INFO | train_inner | epoch 001:   9983 / 11384 loss=0.325748, wps=1281.3, ups=0.65, wpb=1982.1, bsz=128, num_updates=9950, lr=9.95e-06, gnorm=43.424, clip=100, loss_scale=64, train_wall=77, gb_free=15.8, wall=15833
2025-11-01 17:06:01 | INFO | train_inner | epoch 001:  10033 / 11384 loss=0.343917, wps=1554.4, ups=0.79, wpb=1957.2, bsz=128, num_updates=10000, lr=1e-05, gnorm=53.575, clip=100, loss_scale=64, train_wall=63, gb_free=16.1, wall=15896
2025-11-01 17:07:14 | INFO | train_inner | epoch 001:  10083 / 11384 loss=0.325141, wps=1320, ups=0.69, wpb=1922.7, bsz=128, num_updates=10050, lr=1.005e-05, gnorm=43.425, clip=100, loss_scale=64, train_wall=73, gb_free=8.5, wall=15969
2025-11-01 17:08:31 | INFO | train_inner | epoch 001:  10133 / 11384 loss=0.330712, wps=1257.2, ups=0.65, wpb=1946.3, bsz=128, num_updates=10100, lr=1.01e-05, gnorm=37.295, clip=100, loss_scale=64, train_wall=76, gb_free=9.5, wall=16047
2025-11-01 17:08:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 17:09:42 | INFO | train_inner | epoch 001:  10184 / 11384 loss=0.314632, wps=1411.4, ups=0.71, wpb=1974, bsz=128, num_updates=10150, lr=1.015e-05, gnorm=40.492, clip=100, loss_scale=32, train_wall=70, gb_free=16.6, wall=16117
2025-11-01 17:10:52 | INFO | train_inner | epoch 001:  10234 / 11384 loss=0.327191, wps=1390, ups=0.71, wpb=1949.2, bsz=128, num_updates=10200, lr=1.02e-05, gnorm=36.412, clip=100, loss_scale=32, train_wall=70, gb_free=15, wall=16187
2025-11-01 17:12:12 | INFO | train_inner | epoch 001:  10284 / 11384 loss=0.320001, wps=1294.6, ups=0.65, wpb=1981.9, bsz=128, num_updates=10250, lr=1.025e-05, gnorm=44.491, clip=100, loss_scale=32, train_wall=76, gb_free=16.3, wall=16268
2025-11-01 17:13:15 | INFO | train_inner | epoch 001:  10334 / 11384 loss=0.324975, wps=1542.6, ups=0.8, wpb=1920.5, bsz=128, num_updates=10300, lr=1.03e-05, gnorm=45.139, clip=100, loss_scale=32, train_wall=62, gb_free=14.9, wall=16330
2025-11-01 17:14:29 | INFO | train_inner | epoch 001:  10384 / 11384 loss=0.317452, wps=1321.6, ups=0.67, wpb=1974.1, bsz=128, num_updates=10350, lr=1.035e-05, gnorm=39.765, clip=100, loss_scale=32, train_wall=74, gb_free=13.3, wall=16405
2025-11-01 17:15:48 | INFO | train_inner | epoch 001:  10434 / 11384 loss=0.325232, wps=1240.7, ups=0.63, wpb=1961, bsz=128, num_updates=10400, lr=1.04e-05, gnorm=44.037, clip=100, loss_scale=64, train_wall=79, gb_free=16.1, wall=16484
2025-11-01 17:16:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 17:17:06 | INFO | train_inner | epoch 001:  10485 / 11384 loss=0.317868, wps=1261.6, ups=0.65, wpb=1955.3, bsz=128, num_updates=10450, lr=1.045e-05, gnorm=40.038, clip=100, loss_scale=32, train_wall=77, gb_free=14.7, wall=16561
2025-11-01 17:18:19 | INFO | train_inner | epoch 001:  10535 / 11384 loss=0.325055, wps=1345.4, ups=0.68, wpb=1970.3, bsz=128, num_updates=10500, lr=1.05e-05, gnorm=42.4, clip=100, loss_scale=32, train_wall=73, gb_free=11.4, wall=16634
2025-11-01 17:19:32 | INFO | train_inner | epoch 001:  10585 / 11384 loss=0.316149, wps=1327.9, ups=0.68, wpb=1943.8, bsz=128, num_updates=10550, lr=1.055e-05, gnorm=42.78, clip=100, loss_scale=32, train_wall=73, gb_free=16.3, wall=16708
2025-11-01 17:20:56 | INFO | train_inner | epoch 001:  10635 / 11384 loss=0.316546, wps=1179.1, ups=0.6, wpb=1976.1, bsz=128, num_updates=10600, lr=1.06e-05, gnorm=38.776, clip=100, loss_scale=32, train_wall=84, gb_free=16.8, wall=16791
2025-11-01 17:22:10 | INFO | train_inner | epoch 001:  10685 / 11384 loss=0.328699, wps=1313.1, ups=0.68, wpb=1945.1, bsz=128, num_updates=10650, lr=1.065e-05, gnorm=40.469, clip=100, loss_scale=32, train_wall=74, gb_free=10.3, wall=16865
2025-11-01 17:22:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 17:23:18 | INFO | train_inner | epoch 001:  10736 / 11384 loss=0.314933, wps=1480.3, ups=0.74, wpb=2011.9, bsz=128, num_updates=10700, lr=1.07e-05, gnorm=44.028, clip=100, loss_scale=32, train_wall=68, gb_free=15.1, wall=16933
2025-11-01 17:24:30 | INFO | train_inner | epoch 001:  10786 / 11384 loss=0.319093, wps=1388.2, ups=0.7, wpb=1984.4, bsz=128, num_updates=10750, lr=1.075e-05, gnorm=35.833, clip=100, loss_scale=32, train_wall=71, gb_free=13.9, wall=17005
2025-11-01 17:25:32 | INFO | train_inner | epoch 001:  10836 / 11384 loss=0.3209, wps=1590.8, ups=0.81, wpb=1971.9, bsz=128, num_updates=10800, lr=1.08e-05, gnorm=51.881, clip=100, loss_scale=32, train_wall=62, gb_free=16.2, wall=17067
2025-11-01 17:27:04 | INFO | train_inner | epoch 001:  10886 / 11384 loss=0.337445, wps=1063.4, ups=0.54, wpb=1963.5, bsz=128, num_updates=10850, lr=1.085e-05, gnorm=42.085, clip=100, loss_scale=32, train_wall=92, gb_free=12.7, wall=17159
2025-11-01 17:28:13 | INFO | train_inner | epoch 001:  10936 / 11384 loss=0.312411, wps=1424.9, ups=0.72, wpb=1980.4, bsz=128, num_updates=10900, lr=1.09e-05, gnorm=40.429, clip=100, loss_scale=32, train_wall=69, gb_free=16, wall=17229
2025-11-01 17:29:20 | INFO | train_inner | epoch 001:  10986 / 11384 loss=0.312535, wps=1477.2, ups=0.75, wpb=1958.5, bsz=128, num_updates=10950, lr=1.095e-05, gnorm=34.785, clip=100, loss_scale=64, train_wall=66, gb_free=14.7, wall=17295
2025-11-01 17:30:23 | INFO | train_inner | epoch 001:  11036 / 11384 loss=0.303702, wps=1537.3, ups=0.79, wpb=1950.4, bsz=128, num_updates=11000, lr=1.1e-05, gnorm=38.649, clip=100, loss_scale=64, train_wall=63, gb_free=16.4, wall=17358
2025-11-01 17:31:38 | INFO | train_inner | epoch 001:  11086 / 11384 loss=0.30948, wps=1324.1, ups=0.67, wpb=1968.7, bsz=128, num_updates=11050, lr=1.105e-05, gnorm=41.242, clip=100, loss_scale=64, train_wall=74, gb_free=10.1, wall=17433
2025-11-01 17:32:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 17:33:02 | INFO | train_inner | epoch 001:  11137 / 11384 loss=0.313287, wps=1148.5, ups=0.59, wpb=1948.1, bsz=128, num_updates=11100, lr=1.11e-05, gnorm=40.057, clip=100, loss_scale=32, train_wall=85, gb_free=16.8, wall=17518
2025-11-01 17:34:06 | INFO | train_inner | epoch 001:  11187 / 11384 loss=0.321106, wps=1511.6, ups=0.78, wpb=1935.3, bsz=128, num_updates=11150, lr=1.115e-05, gnorm=39.208, clip=100, loss_scale=32, train_wall=64, gb_free=14.6, wall=17582
2025-11-01 17:35:10 | INFO | train_inner | epoch 001:  11237 / 11384 loss=0.307812, wps=1542.3, ups=0.78, wpb=1971.3, bsz=128, num_updates=11200, lr=1.12e-05, gnorm=38.941, clip=100, loss_scale=32, train_wall=64, gb_free=12.8, wall=17646
2025-11-01 17:36:14 | INFO | train_inner | epoch 001:  11287 / 11384 loss=0.333885, wps=1538.8, ups=0.79, wpb=1951.1, bsz=128, num_updates=11250, lr=1.125e-05, gnorm=44.674, clip=100, loss_scale=32, train_wall=63, gb_free=14.9, wall=17709
2025-11-01 17:37:32 | INFO | train_inner | epoch 001:  11337 / 11384 loss=0.31759, wps=1260.7, ups=0.64, wpb=1962, bsz=128, num_updates=11300, lr=1.13e-05, gnorm=39.604, clip=100, loss_scale=32, train_wall=78, gb_free=11, wall=17787
2025-11-01 17:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 17:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-01 17:56:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.30016 | wps 1434.8 | wpb 1948.3 | bsz 127.9 | num_updates 11346
2025-11-01 17:56:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 11346 updates
2025-11-01 17:56:10 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint1.pt
2025-11-01 17:56:13 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint1.pt
2025-11-01 17:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint1.pt (epoch 1 @ 11346 updates, score 0.30016) (writing took 12.592627470032312 seconds)
2025-11-01 17:56:23 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2025-11-01 17:56:23 | INFO | train | epoch 001 | loss 0.402665 | wps 1175.3 | ups 0.6 | wpb 1958.2 | bsz 128 | num_updates 11346 | lr 1.1346e-05 | gnorm 52.119 | clip 100 | loss_scale 32 | train_wall 17219 | gb_free 16.7 | wall 18918
2025-11-01 17:56:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-11-01 17:56:45 | INFO | fairseq.trainer | begin training epoch 2
2025-11-01 17:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-01 17:59:36 | INFO | train_inner | epoch 002:      4 / 11384 loss=0.311834, wps=74, ups=0.04, wpb=1960.4, bsz=127.7, num_updates=11350, lr=1.135e-05, gnorm=38.514, clip=100, loss_scale=32, train_wall=99, gb_free=10.4, wall=19112
2025-11-01 18:01:59 | INFO | train_inner | epoch 002:     54 / 11384 loss=0.309146, wps=696.1, ups=0.35, wpb=1982.4, bsz=128, num_updates=11400, lr=1.14e-05, gnorm=41.114, clip=100, loss_scale=32, train_wall=142, gb_free=16.1, wall=19254
2025-11-01 18:03:00 | INFO | train_inner | epoch 002:    104 / 11384 loss=0.324906, wps=1587.1, ups=0.82, wpb=1946.6, bsz=128, num_updates=11450, lr=1.145e-05, gnorm=44.029, clip=100, loss_scale=32, train_wall=61, gb_free=11.9, wall=19315
2025-11-01 18:05:33 | INFO | train_inner | epoch 002:    154 / 11384 loss=0.305435, wps=654.7, ups=0.33, wpb=2005.7, bsz=128, num_updates=11500, lr=1.15e-05, gnorm=37.959, clip=100, loss_scale=32, train_wall=153, gb_free=10.7, wall=19468
2025-11-01 18:07:04 | INFO | train_inner | epoch 002:    204 / 11384 loss=0.311768, wps=1088, ups=0.55, wpb=1983.8, bsz=128, num_updates=11550, lr=1.155e-05, gnorm=43.574, clip=100, loss_scale=32, train_wall=91, gb_free=16.7, wall=19560
2025-11-01 18:08:16 | INFO | train_inner | epoch 002:    254 / 11384 loss=0.32325, wps=1363.9, ups=0.7, wpb=1943.7, bsz=128, num_updates=11600, lr=1.16e-05, gnorm=40.859, clip=100, loss_scale=64, train_wall=71, gb_free=16.6, wall=19631
2025-11-01 18:10:26 | INFO | train_inner | epoch 002:    304 / 11384 loss=0.317927, wps=751.5, ups=0.38, wpb=1957.8, bsz=128, num_updates=11650, lr=1.165e-05, gnorm=41.174, clip=100, loss_scale=64, train_wall=130, gb_free=16, wall=19761
2025-11-01 18:13:02 | INFO | train_inner | epoch 002:    354 / 11384 loss=0.320178, wps=629.3, ups=0.32, wpb=1964.5, bsz=128, num_updates=11700, lr=1.17e-05, gnorm=42.448, clip=100, loss_scale=64, train_wall=156, gb_free=15.8, wall=19917
2025-11-01 18:13:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 18:14:38 | INFO | train_inner | epoch 002:    405 / 11384 loss=0.31653, wps=1011.8, ups=0.52, wpb=1938.5, bsz=128, num_updates=11750, lr=1.175e-05, gnorm=41.659, clip=100, loss_scale=32, train_wall=82, gb_free=10.7, wall=20013
2025-11-01 18:16:02 | INFO | train_inner | epoch 002:    455 / 11384 loss=0.29729, wps=1141.5, ups=0.6, wpb=1915.4, bsz=128, num_updates=11800, lr=1.18e-05, gnorm=37.335, clip=100, loss_scale=32, train_wall=84, gb_free=16, wall=20097
2025-11-01 18:17:42 | INFO | train_inner | epoch 002:    505 / 11384 loss=0.299862, wps=946, ups=0.5, wpb=1896.4, bsz=128, num_updates=11850, lr=1.185e-05, gnorm=38.87, clip=100, loss_scale=32, train_wall=100, gb_free=14.6, wall=20197
2025-11-01 18:20:08 | INFO | train_inner | epoch 002:    555 / 11384 loss=0.301384, wps=670.7, ups=0.34, wpb=1963, bsz=128, num_updates=11900, lr=1.19e-05, gnorm=41.497, clip=100, loss_scale=32, train_wall=146, gb_free=14.8, wall=20343
2025-11-01 18:22:06 | INFO | train_inner | epoch 002:    605 / 11384 loss=0.306919, wps=828.8, ups=0.42, wpb=1954.9, bsz=128, num_updates=11950, lr=1.195e-05, gnorm=36.27, clip=100, loss_scale=32, train_wall=118, gb_free=16.4, wall=20461
2025-11-01 18:24:55 | INFO | train_inner | epoch 002:    655 / 11384 loss=0.299702, wps=580, ups=0.3, wpb=1957.5, bsz=128, num_updates=12000, lr=1.2e-05, gnorm=40.821, clip=100, loss_scale=64, train_wall=83, gb_free=16.6, wall=20630
2025-11-01 18:26:03 | INFO | train_inner | epoch 002:    705 / 11384 loss=0.299865, wps=1412.5, ups=0.74, wpb=1915.1, bsz=128, num_updates=12050, lr=1.205e-05, gnorm=41.692, clip=100, loss_scale=64, train_wall=68, gb_free=12.8, wall=20698
2025-11-01 18:28:28 | INFO | train_inner | epoch 002:    755 / 11384 loss=0.304609, wps=663.1, ups=0.34, wpb=1925.8, bsz=128, num_updates=12100, lr=1.21e-05, gnorm=45.012, clip=100, loss_scale=64, train_wall=138, gb_free=15.4, wall=20843
2025-11-01 18:30:29 | INFO | train_inner | epoch 002:    805 / 11384 loss=0.290867, wps=824, ups=0.41, wpb=1988.3, bsz=128, num_updates=12150, lr=1.215e-05, gnorm=35.963, clip=100, loss_scale=64, train_wall=120, gb_free=12.4, wall=20964
2025-11-01 18:32:25 | INFO | train_inner | epoch 002:    855 / 11384 loss=0.301163, wps=845.2, ups=0.43, wpb=1964.2, bsz=128, num_updates=12200, lr=1.22e-05, gnorm=37.75, clip=100, loss_scale=64, train_wall=116, gb_free=16, wall=21080
2025-11-01 18:34:22 | INFO | train_inner | epoch 002:    905 / 11384 loss=0.306791, wps=836.1, ups=0.43, wpb=1966.3, bsz=128, num_updates=12250, lr=1.225e-05, gnorm=38.782, clip=100, loss_scale=128, train_wall=117, gb_free=17.1, wall=21198
2025-11-01 18:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-11-01 18:35:34 | INFO | train_inner | epoch 002:    956 / 11384 loss=0.290206, wps=1374.3, ups=0.7, wpb=1958.7, bsz=128, num_updates=12300, lr=1.23e-05, gnorm=37.497, clip=100, loss_scale=64, train_wall=71, gb_free=16.2, wall=21269
2025-11-01 18:36:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 18:37:55 | INFO | train_inner | epoch 002:   1007 / 11384 loss=0.284409, wps=678.6, ups=0.35, wpb=1921.9, bsz=128, num_updates=12350, lr=1.235e-05, gnorm=40.461, clip=100, loss_scale=32, train_wall=141, gb_free=12.6, wall=21411
2025-11-01 18:40:25 | INFO | train_inner | epoch 002:   1057 / 11384 loss=0.291789, wps=646, ups=0.33, wpb=1933.5, bsz=128, num_updates=12400, lr=1.24e-05, gnorm=43.094, clip=100, loss_scale=32, train_wall=149, gb_free=13.7, wall=21560
2025-11-01 18:43:05 | INFO | train_inner | epoch 002:   1107 / 11384 loss=0.296591, wps=612.4, ups=0.31, wpb=1960.9, bsz=128, num_updates=12450, lr=1.245e-05, gnorm=43.514, clip=100, loss_scale=32, train_wall=160, gb_free=14.1, wall=21720
2025-11-01 18:45:10 | INFO | train_inner | epoch 002:   1157 / 11384 loss=0.285175, wps=781.3, ups=0.4, wpb=1947.9, bsz=128, num_updates=12500, lr=1.25e-05, gnorm=40.389, clip=100, loss_scale=32, train_wall=81, gb_free=16.1, wall=21845
2025-11-01 18:47:23 | INFO | train_inner | epoch 002:   1207 / 11384 loss=0.299008, wps=737.5, ups=0.38, wpb=1966.4, bsz=128, num_updates=12550, lr=1.255e-05, gnorm=38.839, clip=100, loss_scale=32, train_wall=133, gb_free=15.2, wall=21978
2025-11-01 18:48:36 | INFO | train_inner | epoch 002:   1257 / 11384 loss=0.28459, wps=1360.9, ups=0.68, wpb=1987.1, bsz=128, num_updates=12600, lr=1.26e-05, gnorm=40.163, clip=100, loss_scale=64, train_wall=73, gb_free=14.9, wall=22051
2025-11-01 18:50:49 | INFO | train_inner | epoch 002:   1307 / 11384 loss=0.29748, wps=721.5, ups=0.38, wpb=1912.6, bsz=128, num_updates=12650, lr=1.265e-05, gnorm=39.486, clip=100, loss_scale=64, train_wall=132, gb_free=15.1, wall=22184
2025-11-01 18:53:16 | INFO | train_inner | epoch 002:   1357 / 11384 loss=0.289834, wps=654.8, ups=0.34, wpb=1932, bsz=128, num_updates=12700, lr=1.27e-05, gnorm=38.042, clip=100, loss_scale=64, train_wall=147, gb_free=8.1, wall=22331
2025-11-01 18:55:27 | INFO | train_inner | epoch 002:   1407 / 11384 loss=0.297726, wps=738, ups=0.38, wpb=1935.1, bsz=128, num_updates=12750, lr=1.275e-05, gnorm=42.574, clip=100, loss_scale=64, train_wall=110, gb_free=16, wall=22462
2025-11-01 18:58:31 | INFO | train_inner | epoch 002:   1457 / 11384 loss=0.285539, wps=542.9, ups=0.27, wpb=1997.6, bsz=128, num_updates=12800, lr=1.28e-05, gnorm=38.997, clip=100, loss_scale=64, train_wall=139, gb_free=17.2, wall=22646
2025-11-01 18:58:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 18:59:46 | INFO | train_inner | epoch 002:   1508 / 11384 loss=0.301175, wps=1353.3, ups=0.67, wpb=2012.8, bsz=128, num_updates=12850, lr=1.285e-05, gnorm=42.86, clip=100, loss_scale=32, train_wall=74, gb_free=12.1, wall=22721
2025-11-01 19:01:47 | INFO | train_inner | epoch 002:   1558 / 11384 loss=0.295803, wps=807, ups=0.41, wpb=1957.3, bsz=128, num_updates=12900, lr=1.29e-05, gnorm=40.26, clip=100, loss_scale=32, train_wall=121, gb_free=16.9, wall=22843
2025-11-01 19:02:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 19:04:12 | INFO | train_inner | epoch 002:   1609 / 11384 loss=0.28309, wps=675.5, ups=0.34, wpb=1960.4, bsz=128, num_updates=12950, lr=1.295e-05, gnorm=42.235, clip=100, loss_scale=16, train_wall=145, gb_free=16.4, wall=22988
2025-11-01 19:07:14 | INFO | train_inner | epoch 002:   1659 / 11384 loss=0.297155, wps=536.7, ups=0.28, wpb=1943.5, bsz=128, num_updates=13000, lr=1.3e-05, gnorm=42.862, clip=100, loss_scale=16, train_wall=181, gb_free=14.1, wall=23169
2025-11-01 19:08:37 | INFO | train_inner | epoch 002:   1709 / 11384 loss=0.274887, wps=1184, ups=0.6, wpb=1970.6, bsz=128, num_updates=13050, lr=1.305e-05, gnorm=42.719, clip=100, loss_scale=16, train_wall=83, gb_free=10.5, wall=23252
2025-11-01 19:10:24 | INFO | train_inner | epoch 002:   1759 / 11384 loss=0.282621, wps=921.2, ups=0.46, wpb=1984.1, bsz=128, num_updates=13100, lr=1.31e-05, gnorm=40.246, clip=100, loss_scale=16, train_wall=69, gb_free=4.4, wall=23360
2025-11-01 19:12:18 | INFO | train_inner | epoch 002:   1809 / 11384 loss=0.293294, wps=863.2, ups=0.44, wpb=1965.6, bsz=128, num_updates=13150, lr=1.315e-05, gnorm=44.026, clip=100, loss_scale=16, train_wall=114, gb_free=13.9, wall=23474
2025-11-01 19:15:20 | INFO | train_inner | epoch 002:   1859 / 11384 loss=0.288309, wps=536.7, ups=0.27, wpb=1954.2, bsz=128, num_updates=13200, lr=1.32e-05, gnorm=51.652, clip=100, loss_scale=32, train_wall=104, gb_free=15.4, wall=23656
2025-11-01 19:16:47 | INFO | train_inner | epoch 002:   1909 / 11384 loss=0.284177, wps=1128.5, ups=0.58, wpb=1958.1, bsz=128, num_updates=13250, lr=1.325e-05, gnorm=38.579, clip=100, loss_scale=32, train_wall=86, gb_free=9.8, wall=23742
2025-11-01 19:18:45 | INFO | train_inner | epoch 002:   1959 / 11384 loss=0.282219, wps=836.9, ups=0.43, wpb=1967.9, bsz=128, num_updates=13300, lr=1.33e-05, gnorm=38.003, clip=100, loss_scale=32, train_wall=117, gb_free=17, wall=23860
2025-11-01 19:21:08 | INFO | train_inner | epoch 002:   2009 / 11384 loss=0.281287, wps=697.2, ups=0.35, wpb=1991.4, bsz=128, num_updates=13350, lr=1.335e-05, gnorm=35.788, clip=100, loss_scale=32, train_wall=143, gb_free=12.5, wall=24003
2025-11-01 19:23:18 | INFO | train_inner | epoch 002:   2059 / 11384 loss=0.29257, wps=756.9, ups=0.38, wpb=1976, bsz=128, num_updates=13400, lr=1.34e-05, gnorm=39.881, clip=100, loss_scale=32, train_wall=130, gb_free=14.3, wall=24133
2025-11-01 19:23:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 19:24:35 | INFO | train_inner | epoch 002:   2110 / 11384 loss=0.281817, wps=1278.2, ups=0.65, wpb=1970.9, bsz=128, num_updates=13450, lr=1.345e-05, gnorm=39.86, clip=100, loss_scale=32, train_wall=77, gb_free=14.6, wall=24211
2025-11-01 19:26:35 | INFO | train_inner | epoch 002:   2160 / 11384 loss=0.293756, wps=822.2, ups=0.42, wpb=1961.7, bsz=128, num_updates=13500, lr=1.35e-05, gnorm=45.385, clip=100, loss_scale=32, train_wall=119, gb_free=17, wall=24330
2025-11-01 19:29:27 | INFO | train_inner | epoch 002:   2210 / 11384 loss=0.28002, wps=570.2, ups=0.29, wpb=1967.6, bsz=128, num_updates=13550, lr=1.355e-05, gnorm=39.226, clip=100, loss_scale=32, train_wall=94, gb_free=10.9, wall=24502
2025-11-01 19:31:48 | INFO | train_inner | epoch 002:   2260 / 11384 loss=0.276224, wps=685.8, ups=0.35, wpb=1933.7, bsz=128, num_updates=13600, lr=1.36e-05, gnorm=41.987, clip=100, loss_scale=32, train_wall=141, gb_free=8.3, wall=24643
2025-11-01 19:34:27 | INFO | train_inner | epoch 002:   2310 / 11384 loss=0.276574, wps=614.8, ups=0.32, wpb=1951.5, bsz=128, num_updates=13650, lr=1.365e-05, gnorm=40.558, clip=100, loss_scale=32, train_wall=87, gb_free=16.8, wall=24802
2025-11-01 19:35:43 | INFO | train_inner | epoch 002:   2360 / 11384 loss=0.276918, wps=1291.7, ups=0.65, wpb=1973.1, bsz=128, num_updates=13700, lr=1.37e-05, gnorm=37.028, clip=100, loss_scale=64, train_wall=76, gb_free=16.8, wall=24878
2025-11-01 19:37:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 19:38:12 | INFO | train_inner | epoch 002:   2411 / 11384 loss=0.279865, wps=664.8, ups=0.34, wpb=1972, bsz=128, num_updates=13750, lr=1.375e-05, gnorm=38.544, clip=100, loss_scale=32, train_wall=148, gb_free=15.1, wall=25027
2025-11-01 19:40:29 | INFO | train_inner | epoch 002:   2461 / 11384 loss=0.277883, wps=738.9, ups=0.36, wpb=2027.5, bsz=128, num_updates=13800, lr=1.38e-05, gnorm=39.054, clip=100, loss_scale=32, train_wall=137, gb_free=11.2, wall=25164
2025-11-01 19:42:46 | INFO | train_inner | epoch 002:   2511 / 11384 loss=0.265891, wps=713.5, ups=0.36, wpb=1960.4, bsz=128, num_updates=13850, lr=1.385e-05, gnorm=37.501, clip=100, loss_scale=32, train_wall=137, gb_free=15.8, wall=25302
2025-11-01 19:44:08 | INFO | train_inner | epoch 002:   2561 / 11384 loss=0.279428, wps=1190.2, ups=0.61, wpb=1945.9, bsz=128, num_updates=13900, lr=1.39e-05, gnorm=40.01, clip=100, loss_scale=32, train_wall=82, gb_free=15.7, wall=25383
2025-11-01 19:46:18 | INFO | train_inner | epoch 002:   2611 / 11384 loss=0.273682, wps=753.6, ups=0.38, wpb=1960.9, bsz=128, num_updates=13950, lr=1.395e-05, gnorm=38.101, clip=100, loss_scale=32, train_wall=130, gb_free=16.1, wall=25513
2025-11-01 19:48:37 | INFO | train_inner | epoch 002:   2661 / 11384 loss=0.27189, wps=708.2, ups=0.36, wpb=1961.7, bsz=128, num_updates=14000, lr=1.4e-05, gnorm=39.979, clip=100, loss_scale=64, train_wall=138, gb_free=16.8, wall=25652
2025-11-01 19:49:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 19:50:51 | INFO | train_inner | epoch 002:   2712 / 11384 loss=0.268949, wps=726.7, ups=0.37, wpb=1954.3, bsz=128, num_updates=14050, lr=1.405e-05, gnorm=39.206, clip=100, loss_scale=32, train_wall=134, gb_free=11.6, wall=25786
2025-11-01 19:53:09 | INFO | train_inner | epoch 002:   2762 / 11384 loss=0.274925, wps=718.2, ups=0.36, wpb=1982.9, bsz=128, num_updates=14100, lr=1.41e-05, gnorm=42.239, clip=100, loss_scale=32, train_wall=120, gb_free=13.2, wall=25924
2025-11-01 19:54:51 | INFO | train_inner | epoch 002:   2812 / 11384 loss=0.28057, wps=975.3, ups=0.49, wpb=1974.1, bsz=128, num_updates=14150, lr=1.415e-05, gnorm=43.521, clip=100, loss_scale=32, train_wall=101, gb_free=13.5, wall=26026
2025-11-01 19:56:18 | INFO | train_inner | epoch 002:   2862 / 11384 loss=0.269195, wps=1117.1, ups=0.57, wpb=1964.1, bsz=128, num_updates=14200, lr=1.42e-05, gnorm=37.775, clip=100, loss_scale=32, train_wall=88, gb_free=16.4, wall=26114
2025-11-01 19:57:48 | INFO | train_inner | epoch 002:   2912 / 11384 loss=0.269672, wps=1114.2, ups=0.56, wpb=1989.9, bsz=128, num_updates=14250, lr=1.425e-05, gnorm=38.742, clip=100, loss_scale=32, train_wall=89, gb_free=16.2, wall=26203
2025-11-01 19:58:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 19:59:23 | INFO | train_inner | epoch 002:   2963 / 11384 loss=0.272866, wps=1013, ups=0.52, wpb=1934.5, bsz=128, num_updates=14300, lr=1.43e-05, gnorm=37.759, clip=100, loss_scale=32, train_wall=95, gb_free=15.8, wall=26298
2025-11-01 20:01:00 | INFO | train_inner | epoch 002:   3013 / 11384 loss=0.266363, wps=999.8, ups=0.52, wpb=1940.2, bsz=128, num_updates=14350, lr=1.435e-05, gnorm=36.459, clip=100, loss_scale=32, train_wall=97, gb_free=14.5, wall=26396
2025-11-01 20:02:25 | INFO | train_inner | epoch 002:   3063 / 11384 loss=0.270394, wps=1142.5, ups=0.59, wpb=1944.1, bsz=128, num_updates=14400, lr=1.44e-05, gnorm=36.433, clip=100, loss_scale=32, train_wall=85, gb_free=15.1, wall=26481
2025-11-01 20:04:18 | INFO | train_inner | epoch 002:   3113 / 11384 loss=0.273039, wps=862.3, ups=0.45, wpb=1937, bsz=128, num_updates=14450, lr=1.445e-05, gnorm=40.469, clip=100, loss_scale=32, train_wall=112, gb_free=16.2, wall=26593
2025-11-01 20:06:22 | INFO | train_inner | epoch 002:   3163 / 11384 loss=0.272792, wps=800.1, ups=0.4, wpb=1994.2, bsz=128, num_updates=14500, lr=1.45e-05, gnorm=38.339, clip=100, loss_scale=32, train_wall=124, gb_free=17, wall=26718
2025-11-01 20:07:43 | INFO | train_inner | epoch 002:   3213 / 11384 loss=0.259471, wps=1224.1, ups=0.62, wpb=1980.7, bsz=128, num_updates=14550, lr=1.455e-05, gnorm=37.945, clip=100, loss_scale=64, train_wall=81, gb_free=15.9, wall=26798
2025-11-01 20:09:17 | INFO | train_inner | epoch 002:   3263 / 11384 loss=0.267309, wps=1041.7, ups=0.53, wpb=1961.3, bsz=128, num_updates=14600, lr=1.46e-05, gnorm=42.169, clip=100, loss_scale=64, train_wall=94, gb_free=14.1, wall=26893
2025-11-01 20:10:44 | INFO | train_inner | epoch 002:   3313 / 11384 loss=0.267629, wps=1146, ups=0.58, wpb=1976.5, bsz=128, num_updates=14650, lr=1.465e-05, gnorm=39.304, clip=100, loss_scale=64, train_wall=86, gb_free=16.1, wall=26979
2025-11-01 20:11:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 20:12:18 | INFO | train_inner | epoch 002:   3364 / 11384 loss=0.264122, wps=1039.2, ups=0.53, wpb=1969.6, bsz=128, num_updates=14700, lr=1.47e-05, gnorm=45.355, clip=100, loss_scale=32, train_wall=95, gb_free=12.1, wall=27074
2025-11-01 20:13:47 | INFO | train_inner | epoch 002:   3414 / 11384 loss=0.252652, wps=1117.2, ups=0.57, wpb=1968.1, bsz=128, num_updates=14750, lr=1.475e-05, gnorm=40.761, clip=100, loss_scale=32, train_wall=86, gb_free=14.5, wall=27162
2025-11-01 20:15:26 | INFO | train_inner | epoch 002:   3464 / 11384 loss=0.253744, wps=986.8, ups=0.5, wpb=1955.8, bsz=128, num_updates=14800, lr=1.48e-05, gnorm=39.648, clip=100, loss_scale=32, train_wall=99, gb_free=15.1, wall=27261
2025-11-01 20:16:54 | INFO | train_inner | epoch 002:   3514 / 11384 loss=0.259068, wps=1112.6, ups=0.57, wpb=1966.8, bsz=128, num_updates=14850, lr=1.485e-05, gnorm=37.127, clip=100, loss_scale=32, train_wall=88, gb_free=15.5, wall=27349
2025-11-01 20:18:07 | INFO | train_inner | epoch 002:   3564 / 11384 loss=0.269561, wps=1309.9, ups=0.68, wpb=1924.4, bsz=128, num_updates=14900, lr=1.49e-05, gnorm=40.637, clip=100, loss_scale=32, train_wall=73, gb_free=17.3, wall=27423
2025-11-01 20:19:42 | INFO | train_inner | epoch 002:   3614 / 11384 loss=0.264848, wps=1033.8, ups=0.53, wpb=1948.7, bsz=128, num_updates=14950, lr=1.495e-05, gnorm=41.341, clip=100, loss_scale=64, train_wall=94, gb_free=14.7, wall=27517
2025-11-01 20:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 20:21:30 | INFO | train_inner | epoch 002:   3665 / 11384 loss=0.267828, wps=897.6, ups=0.46, wpb=1951.6, bsz=128, num_updates=15000, lr=1.5e-05, gnorm=42.667, clip=100, loss_scale=32, train_wall=108, gb_free=15.5, wall=27626
2025-11-01 20:23:10 | INFO | train_inner | epoch 002:   3715 / 11384 loss=0.252437, wps=988, ups=0.5, wpb=1975.6, bsz=128, num_updates=15050, lr=1.505e-05, gnorm=42.781, clip=100, loss_scale=32, train_wall=100, gb_free=16.6, wall=27726
2025-11-01 20:24:59 | INFO | train_inner | epoch 002:   3765 / 11384 loss=0.271662, wps=899, ups=0.46, wpb=1952.8, bsz=128, num_updates=15100, lr=1.51e-05, gnorm=42.99, clip=100, loss_scale=32, train_wall=108, gb_free=16, wall=27834
2025-11-01 20:26:39 | INFO | train_inner | epoch 002:   3815 / 11384 loss=0.253469, wps=994.9, ups=0.5, wpb=1977.4, bsz=128, num_updates=15150, lr=1.515e-05, gnorm=37.109, clip=100, loss_scale=32, train_wall=99, gb_free=13, wall=27934
2025-11-01 20:27:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 20:28:11 | INFO | train_inner | epoch 002:   3866 / 11384 loss=0.263146, wps=1051.7, ups=0.54, wpb=1950.9, bsz=128, num_updates=15200, lr=1.52e-05, gnorm=45.424, clip=100, loss_scale=16, train_wall=92, gb_free=15.5, wall=28027
2025-11-01 20:29:49 | INFO | train_inner | epoch 002:   3916 / 11384 loss=0.257363, wps=1016.4, ups=0.51, wpb=1985.5, bsz=128, num_updates=15250, lr=1.525e-05, gnorm=42.657, clip=100, loss_scale=16, train_wall=97, gb_free=12.4, wall=28124
2025-11-01 20:31:09 | INFO | train_inner | epoch 002:   3966 / 11384 loss=0.244208, wps=1208.1, ups=0.62, wpb=1937.5, bsz=128, num_updates=15300, lr=1.53e-05, gnorm=36.021, clip=100, loss_scale=16, train_wall=80, gb_free=8.7, wall=28205
2025-11-01 20:32:53 | INFO | train_inner | epoch 002:   4016 / 11384 loss=0.252807, wps=958.8, ups=0.48, wpb=1986.7, bsz=128, num_updates=15350, lr=1.535e-05, gnorm=37.7, clip=100, loss_scale=16, train_wall=103, gb_free=16.4, wall=28308
2025-11-01 20:34:10 | INFO | train_inner | epoch 002:   4066 / 11384 loss=0.264132, wps=1251.7, ups=0.65, wpb=1924.5, bsz=128, num_updates=15400, lr=1.54e-05, gnorm=45.092, clip=100, loss_scale=16, train_wall=77, gb_free=14.8, wall=28385
2025-11-01 20:35:56 | INFO | train_inner | epoch 002:   4116 / 11384 loss=0.251112, wps=919.3, ups=0.47, wpb=1946.1, bsz=128, num_updates=15450, lr=1.545e-05, gnorm=37.874, clip=100, loss_scale=32, train_wall=106, gb_free=16.7, wall=28491
2025-11-01 20:38:00 | INFO | train_inner | epoch 002:   4166 / 11384 loss=0.254688, wps=801.5, ups=0.4, wpb=1984.2, bsz=128, num_updates=15500, lr=1.55e-05, gnorm=38.129, clip=100, loss_scale=32, train_wall=124, gb_free=11.5, wall=28615
2025-11-01 20:39:39 | INFO | train_inner | epoch 002:   4216 / 11384 loss=0.238689, wps=969.3, ups=0.5, wpb=1927.7, bsz=128, num_updates=15550, lr=1.555e-05, gnorm=38.777, clip=100, loss_scale=32, train_wall=99, gb_free=6.1, wall=28714
2025-11-01 20:41:00 | INFO | train_inner | epoch 002:   4266 / 11384 loss=0.260131, wps=1212.9, ups=0.62, wpb=1969.2, bsz=128, num_updates=15600, lr=1.56e-05, gnorm=34, clip=100, loss_scale=32, train_wall=81, gb_free=15, wall=28795
2025-11-01 20:42:30 | INFO | train_inner | epoch 002:   4316 / 11384 loss=0.247676, wps=1133.7, ups=0.57, wpb=1995.6, bsz=128, num_updates=15650, lr=1.565e-05, gnorm=38.768, clip=100, loss_scale=32, train_wall=88, gb_free=13.5, wall=28885
2025-11-01 20:44:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 20:44:14 | INFO | train_inner | epoch 002:   4367 / 11384 loss=0.254087, wps=955.4, ups=0.48, wpb=1975.7, bsz=128, num_updates=15700, lr=1.57e-05, gnorm=39.726, clip=100, loss_scale=32, train_wall=103, gb_free=12.6, wall=28989
2025-11-01 20:44:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 20:45:54 | INFO | train_inner | epoch 002:   4418 / 11384 loss=0.253873, wps=972, ups=0.5, wpb=1953.4, bsz=128, num_updates=15750, lr=1.575e-05, gnorm=41.404, clip=100, loss_scale=16, train_wall=100, gb_free=14.8, wall=29089
2025-11-01 20:47:37 | INFO | train_inner | epoch 002:   4468 / 11384 loss=0.251632, wps=959, ups=0.49, wpb=1972, bsz=128, num_updates=15800, lr=1.58e-05, gnorm=40.509, clip=100, loss_scale=16, train_wall=103, gb_free=16.1, wall=29192
2025-11-01 20:49:14 | INFO | train_inner | epoch 002:   4518 / 11384 loss=0.2453, wps=1010.6, ups=0.51, wpb=1968.6, bsz=128, num_updates=15850, lr=1.585e-05, gnorm=42.9, clip=100, loss_scale=16, train_wall=97, gb_free=15.4, wall=29289
2025-11-01 20:50:34 | INFO | train_inner | epoch 002:   4568 / 11384 loss=0.238049, wps=1214.6, ups=0.62, wpb=1947, bsz=128, num_updates=15900, lr=1.59e-05, gnorm=39.5, clip=100, loss_scale=16, train_wall=80, gb_free=16.3, wall=29370
2025-11-01 20:52:03 | INFO | train_inner | epoch 002:   4618 / 11384 loss=0.256206, wps=1100.3, ups=0.56, wpb=1955, bsz=128, num_updates=15950, lr=1.595e-05, gnorm=41.144, clip=100, loss_scale=16, train_wall=89, gb_free=13.7, wall=29458
2025-11-01 20:53:39 | INFO | train_inner | epoch 002:   4668 / 11384 loss=0.237006, wps=1015.1, ups=0.52, wpb=1942.3, bsz=128, num_updates=16000, lr=1.6e-05, gnorm=38.45, clip=100, loss_scale=32, train_wall=95, gb_free=11, wall=29554
2025-11-01 20:55:14 | INFO | train_inner | epoch 002:   4718 / 11384 loss=0.241984, wps=1018.5, ups=0.53, wpb=1938.5, bsz=128, num_updates=16050, lr=1.605e-05, gnorm=38.561, clip=100, loss_scale=32, train_wall=95, gb_free=16, wall=29649
2025-11-01 20:57:03 | INFO | train_inner | epoch 002:   4768 / 11384 loss=0.252754, wps=875.6, ups=0.46, wpb=1910.7, bsz=128, num_updates=16100, lr=1.61e-05, gnorm=39.47, clip=100, loss_scale=32, train_wall=109, gb_free=16, wall=29758
2025-11-01 20:57:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 20:58:10 | INFO | train_inner | epoch 002:   4819 / 11384 loss=0.24182, wps=1440.5, ups=0.75, wpb=1931.6, bsz=128, num_updates=16150, lr=1.615e-05, gnorm=37.502, clip=100, loss_scale=16, train_wall=67, gb_free=15, wall=29826
2025-11-01 20:59:54 | INFO | train_inner | epoch 002:   4869 / 11384 loss=0.244345, wps=937.2, ups=0.48, wpb=1946.3, bsz=128, num_updates=16200, lr=1.62e-05, gnorm=41.099, clip=100, loss_scale=16, train_wall=104, gb_free=15.3, wall=29929
2025-11-01 21:01:25 | INFO | train_inner | epoch 002:   4919 / 11384 loss=0.228526, wps=1084.1, ups=0.55, wpb=1969.2, bsz=128, num_updates=16250, lr=1.625e-05, gnorm=36.299, clip=100, loss_scale=16, train_wall=91, gb_free=17, wall=30020
2025-11-01 21:02:40 | INFO | train_inner | epoch 002:   4969 / 11384 loss=0.225035, wps=1296.6, ups=0.66, wpb=1953.3, bsz=128, num_updates=16300, lr=1.63e-05, gnorm=35.251, clip=100, loss_scale=16, train_wall=75, gb_free=16.6, wall=30096
2025-11-01 21:04:18 | INFO | train_inner | epoch 002:   5019 / 11384 loss=0.254384, wps=999.1, ups=0.51, wpb=1951.7, bsz=128, num_updates=16350, lr=1.635e-05, gnorm=40.376, clip=100, loss_scale=16, train_wall=97, gb_free=16.1, wall=30193
2025-11-01 21:06:16 | INFO | train_inner | epoch 002:   5069 / 11384 loss=0.232679, wps=823.4, ups=0.43, wpb=1936.2, bsz=128, num_updates=16400, lr=1.64e-05, gnorm=37.257, clip=100, loss_scale=32, train_wall=117, gb_free=6.5, wall=30311
2025-11-01 21:07:26 | INFO | train_inner | epoch 002:   5119 / 11384 loss=0.233116, wps=1384.9, ups=0.71, wpb=1954.6, bsz=128, num_updates=16450, lr=1.645e-05, gnorm=34.454, clip=100, loss_scale=32, train_wall=70, gb_free=14.3, wall=30381
2025-11-01 21:08:52 | INFO | train_inner | epoch 002:   5169 / 11384 loss=0.235293, wps=1144, ups=0.59, wpb=1954.1, bsz=128, num_updates=16500, lr=1.65e-05, gnorm=37.068, clip=100, loss_scale=32, train_wall=85, gb_free=15.9, wall=30467
2025-11-01 21:10:27 | INFO | train_inner | epoch 002:   5219 / 11384 loss=0.234272, wps=1034.3, ups=0.52, wpb=1979.3, bsz=128, num_updates=16550, lr=1.655e-05, gnorm=37.262, clip=100, loss_scale=32, train_wall=92, gb_free=14.6, wall=30563
2025-11-01 21:11:52 | INFO | train_inner | epoch 002:   5269 / 11384 loss=0.241806, wps=1166.7, ups=0.59, wpb=1966.3, bsz=128, num_updates=16600, lr=1.66e-05, gnorm=39.74, clip=100, loss_scale=32, train_wall=84, gb_free=15.7, wall=30647
2025-11-01 21:13:06 | INFO | train_inner | epoch 002:   5319 / 11384 loss=0.238874, wps=1314.6, ups=0.67, wpb=1966.4, bsz=128, num_updates=16650, lr=1.665e-05, gnorm=37.259, clip=100, loss_scale=64, train_wall=75, gb_free=10.8, wall=30722
2025-11-01 21:13:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 21:14:50 | INFO | train_inner | epoch 002:   5370 / 11384 loss=0.234567, wps=916.6, ups=0.48, wpb=1902.5, bsz=128, num_updates=16700, lr=1.67e-05, gnorm=39.192, clip=100, loss_scale=32, train_wall=103, gb_free=16.4, wall=30825
2025-11-01 21:16:07 | INFO | train_inner | epoch 002:   5420 / 11384 loss=0.236928, wps=1237.8, ups=0.65, wpb=1905.3, bsz=128, num_updates=16750, lr=1.675e-05, gnorm=38.056, clip=100, loss_scale=32, train_wall=77, gb_free=9.8, wall=30902
2025-11-01 21:17:25 | INFO | train_inner | epoch 002:   5470 / 11384 loss=0.244837, wps=1277.5, ups=0.64, wpb=1989.8, bsz=128, num_updates=16800, lr=1.68e-05, gnorm=38.071, clip=100, loss_scale=32, train_wall=78, gb_free=15.4, wall=30980
2025-11-01 21:19:07 | INFO | train_inner | epoch 002:   5520 / 11384 loss=0.223178, wps=951.2, ups=0.49, wpb=1938.3, bsz=128, num_updates=16850, lr=1.685e-05, gnorm=36.19, clip=100, loss_scale=32, train_wall=102, gb_free=16.4, wall=31082
2025-11-01 21:20:24 | INFO | train_inner | epoch 002:   5570 / 11384 loss=0.221051, wps=1298, ups=0.65, wpb=1997, bsz=128, num_updates=16900, lr=1.69e-05, gnorm=37.518, clip=100, loss_scale=32, train_wall=77, gb_free=13.1, wall=31159
2025-11-01 21:21:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 21:21:44 | INFO | train_inner | epoch 002:   5621 / 11384 loss=0.23264, wps=1251.7, ups=0.62, wpb=2012.8, bsz=128, num_updates=16950, lr=1.695e-05, gnorm=35.086, clip=100, loss_scale=32, train_wall=80, gb_free=16.3, wall=31240
2025-11-01 21:23:11 | INFO | train_inner | epoch 002:   5671 / 11384 loss=0.245727, wps=1113.4, ups=0.57, wpb=1936.9, bsz=128, num_updates=17000, lr=1.7e-05, gnorm=38.462, clip=100, loss_scale=32, train_wall=87, gb_free=14.8, wall=31326
2025-11-01 21:24:42 | INFO | train_inner | epoch 002:   5721 / 11384 loss=0.241978, wps=1072.5, ups=0.55, wpb=1942.2, bsz=128, num_updates=17050, lr=1.705e-05, gnorm=40.629, clip=100, loss_scale=32, train_wall=90, gb_free=14.5, wall=31417
2025-11-01 21:26:16 | INFO | train_inner | epoch 002:   5771 / 11384 loss=0.225572, wps=1038.2, ups=0.53, wpb=1955.5, bsz=128, num_updates=17100, lr=1.71e-05, gnorm=36.521, clip=100, loss_scale=32, train_wall=94, gb_free=16.6, wall=31511
2025-11-01 21:28:11 | INFO | train_inner | epoch 002:   5821 / 11384 loss=0.231629, wps=841.5, ups=0.44, wpb=1927.1, bsz=128, num_updates=17150, lr=1.715e-05, gnorm=39.442, clip=100, loss_scale=32, train_wall=114, gb_free=14.7, wall=31626
2025-11-01 21:29:31 | INFO | train_inner | epoch 002:   5871 / 11384 loss=0.222229, wps=1221.7, ups=0.62, wpb=1976.9, bsz=128, num_updates=17200, lr=1.72e-05, gnorm=37.308, clip=100, loss_scale=32, train_wall=81, gb_free=11.4, wall=31707
2025-11-01 21:31:00 | INFO | train_inner | epoch 002:   5921 / 11384 loss=0.232763, wps=1100.1, ups=0.56, wpb=1958.4, bsz=128, num_updates=17250, lr=1.725e-05, gnorm=40.014, clip=100, loss_scale=64, train_wall=89, gb_free=16.5, wall=31796
2025-11-01 21:32:47 | INFO | train_inner | epoch 002:   5971 / 11384 loss=0.233815, wps=914.4, ups=0.47, wpb=1946.6, bsz=128, num_updates=17300, lr=1.73e-05, gnorm=38.111, clip=100, loss_scale=64, train_wall=106, gb_free=12.3, wall=31902
2025-11-01 21:33:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 21:34:17 | INFO | train_inner | epoch 002:   6022 / 11384 loss=0.230504, wps=1096.8, ups=0.56, wpb=1974.9, bsz=128, num_updates=17350, lr=1.735e-05, gnorm=41.695, clip=100, loss_scale=32, train_wall=90, gb_free=14.3, wall=31992
2025-11-01 21:35:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 21:36:03 | INFO | train_inner | epoch 002:   6073 / 11384 loss=0.225916, wps=934.4, ups=0.47, wpb=1974.2, bsz=128, num_updates=17400, lr=1.74e-05, gnorm=37.982, clip=100, loss_scale=16, train_wall=105, gb_free=7.2, wall=32098
2025-11-01 21:37:22 | INFO | train_inner | epoch 002:   6123 / 11384 loss=0.228024, wps=1251.7, ups=0.63, wpb=1988, bsz=128, num_updates=17450, lr=1.745e-05, gnorm=41.162, clip=100, loss_scale=16, train_wall=79, gb_free=16.4, wall=32177
2025-11-01 21:38:46 | INFO | train_inner | epoch 002:   6173 / 11384 loss=0.221653, wps=1172.2, ups=0.6, wpb=1965.9, bsz=128, num_updates=17500, lr=1.75e-05, gnorm=34.624, clip=100, loss_scale=16, train_wall=84, gb_free=16.6, wall=32261
2025-11-01 21:40:37 | INFO | train_inner | epoch 002:   6223 / 11384 loss=0.21498, wps=865.3, ups=0.45, wpb=1924.5, bsz=128, num_updates=17550, lr=1.755e-05, gnorm=38.46, clip=100, loss_scale=16, train_wall=111, gb_free=15.5, wall=32372
2025-11-01 21:41:54 | INFO | train_inner | epoch 002:   6273 / 11384 loss=0.216853, wps=1263.1, ups=0.65, wpb=1952.2, bsz=128, num_updates=17600, lr=1.76e-05, gnorm=35.488, clip=100, loss_scale=16, train_wall=77, gb_free=13.2, wall=32450
2025-11-01 21:43:33 | INFO | train_inner | epoch 002:   6323 / 11384 loss=0.222542, wps=988.4, ups=0.51, wpb=1944.3, bsz=128, num_updates=17650, lr=1.765e-05, gnorm=38.037, clip=100, loss_scale=32, train_wall=98, gb_free=13.2, wall=32548
2025-11-01 21:45:14 | INFO | train_inner | epoch 002:   6373 / 11384 loss=0.22752, wps=981.9, ups=0.5, wpb=1978.8, bsz=128, num_updates=17700, lr=1.77e-05, gnorm=37.936, clip=100, loss_scale=32, train_wall=101, gb_free=15.8, wall=32649
2025-11-01 21:46:59 | INFO | train_inner | epoch 002:   6423 / 11384 loss=0.218227, wps=944.5, ups=0.48, wpb=1985.7, bsz=128, num_updates=17750, lr=1.775e-05, gnorm=38.726, clip=100, loss_scale=32, train_wall=105, gb_free=11.1, wall=32754
2025-11-01 21:48:37 | INFO | train_inner | epoch 002:   6473 / 11384 loss=0.222112, wps=996.6, ups=0.51, wpb=1966.2, bsz=128, num_updates=17800, lr=1.78e-05, gnorm=38.962, clip=100, loss_scale=32, train_wall=95, gb_free=6.9, wall=32853
2025-11-01 21:50:05 | INFO | train_inner | epoch 002:   6523 / 11384 loss=0.215315, wps=1113.9, ups=0.57, wpb=1947.7, bsz=128, num_updates=17850, lr=1.785e-05, gnorm=40.891, clip=100, loss_scale=32, train_wall=87, gb_free=17.3, wall=32940
2025-11-01 21:51:17 | INFO | train_inner | epoch 002:   6573 / 11384 loss=0.219776, wps=1353, ups=0.69, wpb=1955.2, bsz=128, num_updates=17900, lr=1.79e-05, gnorm=38.742, clip=100, loss_scale=64, train_wall=72, gb_free=14.1, wall=33012
2025-11-01 21:52:44 | INFO | train_inner | epoch 002:   6623 / 11384 loss=0.22839, wps=1138.9, ups=0.58, wpb=1968.1, bsz=128, num_updates=17950, lr=1.795e-05, gnorm=38.322, clip=100, loss_scale=64, train_wall=86, gb_free=12.8, wall=33099
2025-11-01 21:53:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 21:54:13 | INFO | train_inner | epoch 002:   6674 / 11384 loss=0.22389, wps=1073.2, ups=0.56, wpb=1911.9, bsz=128, num_updates=18000, lr=1.8e-05, gnorm=36.811, clip=100, loss_scale=32, train_wall=89, gb_free=16.5, wall=33188
2025-11-01 21:55:26 | INFO | train_inner | epoch 002:   6724 / 11384 loss=0.22245, wps=1351.6, ups=0.68, wpb=1986, bsz=128, num_updates=18050, lr=1.805e-05, gnorm=38.466, clip=100, loss_scale=32, train_wall=73, gb_free=15.5, wall=33261
2025-11-01 21:56:55 | INFO | train_inner | epoch 002:   6774 / 11384 loss=0.217561, wps=1088.5, ups=0.56, wpb=1935.4, bsz=128, num_updates=18100, lr=1.81e-05, gnorm=37.81, clip=100, loss_scale=32, train_wall=89, gb_free=15.9, wall=33350
2025-11-01 21:58:28 | INFO | train_inner | epoch 002:   6824 / 11384 loss=0.2153, wps=1055.7, ups=0.54, wpb=1955.2, bsz=128, num_updates=18150, lr=1.815e-05, gnorm=37.065, clip=100, loss_scale=32, train_wall=92, gb_free=14.4, wall=33443
2025-11-01 21:59:48 | INFO | train_inner | epoch 002:   6874 / 11384 loss=0.208942, wps=1249.2, ups=0.62, wpb=2008, bsz=128, num_updates=18200, lr=1.82e-05, gnorm=34.185, clip=100, loss_scale=32, train_wall=80, gb_free=11.8, wall=33523
2025-11-01 22:01:03 | INFO | train_inner | epoch 002:   6924 / 11384 loss=0.219721, wps=1310.5, ups=0.67, wpb=1958.1, bsz=128, num_updates=18250, lr=1.825e-05, gnorm=39.451, clip=100, loss_scale=64, train_wall=74, gb_free=17, wall=33598
2025-11-01 22:02:46 | INFO | train_inner | epoch 002:   6974 / 11384 loss=0.210442, wps=984.3, ups=0.5, wpb=1963.4, bsz=128, num_updates=18300, lr=1.83e-05, gnorm=36.881, clip=100, loss_scale=64, train_wall=99, gb_free=11.5, wall=33702
2025-11-01 22:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 22:03:51 | INFO | train_inner | epoch 002:   7025 / 11384 loss=0.206908, wps=1532.7, ups=0.78, wpb=1977.7, bsz=128, num_updates=18350, lr=1.835e-05, gnorm=38.309, clip=100, loss_scale=32, train_wall=64, gb_free=10, wall=33766
2025-11-01 22:05:19 | INFO | train_inner | epoch 002:   7075 / 11384 loss=0.226941, wps=1096.6, ups=0.57, wpb=1927.9, bsz=128, num_updates=18400, lr=1.84e-05, gnorm=40.389, clip=100, loss_scale=32, train_wall=88, gb_free=16.4, wall=33854
2025-11-01 22:06:38 | INFO | train_inner | epoch 002:   7125 / 11384 loss=0.21149, wps=1241.9, ups=0.63, wpb=1963.9, bsz=128, num_updates=18450, lr=1.845e-05, gnorm=36.864, clip=100, loss_scale=32, train_wall=79, gb_free=14.3, wall=33933
2025-11-01 22:08:03 | INFO | train_inner | epoch 002:   7175 / 11384 loss=0.217819, wps=1173, ups=0.59, wpb=1983.5, bsz=128, num_updates=18500, lr=1.85e-05, gnorm=39.719, clip=100, loss_scale=32, train_wall=84, gb_free=16, wall=34018
2025-11-01 22:09:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 22:09:50 | INFO | train_inner | epoch 002:   7226 / 11384 loss=0.203956, wps=913.6, ups=0.47, wpb=1959.6, bsz=128, num_updates=18550, lr=1.855e-05, gnorm=35.206, clip=100, loss_scale=16, train_wall=107, gb_free=14.2, wall=34125
2025-11-01 22:11:25 | INFO | train_inner | epoch 002:   7276 / 11384 loss=0.215673, wps=1032.2, ups=0.53, wpb=1957.7, bsz=128, num_updates=18600, lr=1.86e-05, gnorm=42.136, clip=100, loss_scale=16, train_wall=95, gb_free=14.8, wall=34220
2025-11-01 22:12:58 | INFO | train_inner | epoch 002:   7326 / 11384 loss=0.21206, wps=1070.6, ups=0.54, wpb=1994.3, bsz=128, num_updates=18650, lr=1.865e-05, gnorm=38.817, clip=100, loss_scale=16, train_wall=93, gb_free=13, wall=34313
2025-11-01 22:14:27 | INFO | train_inner | epoch 002:   7376 / 11384 loss=0.211005, wps=1102.7, ups=0.56, wpb=1965.9, bsz=128, num_updates=18700, lr=1.87e-05, gnorm=39.43, clip=100, loss_scale=16, train_wall=89, gb_free=15.6, wall=34402
2025-11-01 22:16:07 | INFO | train_inner | epoch 002:   7426 / 11384 loss=0.216287, wps=983.3, ups=0.5, wpb=1964.3, bsz=128, num_updates=18750, lr=1.875e-05, gnorm=40.06, clip=100, loss_scale=16, train_wall=100, gb_free=13.6, wall=34502
2025-11-01 22:17:25 | INFO | train_inner | epoch 002:   7476 / 11384 loss=0.210214, wps=1240, ups=0.64, wpb=1947.3, bsz=128, num_updates=18800, lr=1.88e-05, gnorm=41.402, clip=100, loss_scale=32, train_wall=78, gb_free=15.5, wall=34581
2025-11-01 22:18:50 | INFO | train_inner | epoch 002:   7526 / 11384 loss=0.216847, wps=1184.4, ups=0.59, wpb=1995.7, bsz=128, num_updates=18850, lr=1.885e-05, gnorm=38.351, clip=100, loss_scale=32, train_wall=84, gb_free=15.2, wall=34665
2025-11-01 22:20:14 | INFO | train_inner | epoch 002:   7576 / 11384 loss=0.204889, wps=1177.6, ups=0.6, wpb=1978.3, bsz=128, num_updates=18900, lr=1.89e-05, gnorm=36.274, clip=100, loss_scale=32, train_wall=84, gb_free=12.9, wall=34749
2025-11-01 22:21:27 | INFO | train_inner | epoch 002:   7626 / 11384 loss=0.206599, wps=1350.1, ups=0.68, wpb=1976.9, bsz=128, num_updates=18950, lr=1.895e-05, gnorm=36.717, clip=100, loss_scale=32, train_wall=73, gb_free=12.1, wall=34822
2025-11-01 22:22:52 | INFO | train_inner | epoch 002:   7676 / 11384 loss=0.201862, wps=1138.7, ups=0.58, wpb=1949.1, bsz=128, num_updates=19000, lr=1.9e-05, gnorm=36.856, clip=100, loss_scale=32, train_wall=85, gb_free=16.8, wall=34908
2025-11-01 22:24:25 | INFO | train_inner | epoch 002:   7726 / 11384 loss=0.197004, wps=1067.8, ups=0.54, wpb=1967.2, bsz=128, num_updates=19050, lr=1.905e-05, gnorm=35.039, clip=100, loss_scale=64, train_wall=92, gb_free=15.7, wall=35000
2025-11-01 22:24:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 22:25:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 22:25:38 | INFO | train_inner | epoch 002:   7778 / 11384 loss=0.208203, wps=1343, ups=0.68, wpb=1977.5, bsz=128, num_updates=19100, lr=1.91e-05, gnorm=37.682, clip=100, loss_scale=16, train_wall=73, gb_free=13.9, wall=35073
2025-11-01 22:27:10 | INFO | train_inner | epoch 002:   7828 / 11384 loss=0.206238, wps=1050.8, ups=0.54, wpb=1937.7, bsz=128, num_updates=19150, lr=1.915e-05, gnorm=38.668, clip=100, loss_scale=16, train_wall=91, gb_free=15.8, wall=35166
2025-11-01 22:28:44 | INFO | train_inner | epoch 002:   7878 / 11384 loss=0.197655, wps=1045.4, ups=0.53, wpb=1954.1, bsz=128, num_updates=19200, lr=1.92e-05, gnorm=36.718, clip=100, loss_scale=16, train_wall=93, gb_free=16.4, wall=35259
2025-11-01 22:29:50 | INFO | train_inner | epoch 002:   7928 / 11384 loss=0.205368, wps=1510.4, ups=0.76, wpb=1997.2, bsz=128, num_updates=19250, lr=1.925e-05, gnorm=39.127, clip=100, loss_scale=16, train_wall=66, gb_free=16.7, wall=35325
2025-11-01 22:31:26 | INFO | train_inner | epoch 002:   7978 / 11384 loss=0.19997, wps=1034, ups=0.52, wpb=1981, bsz=128, num_updates=19300, lr=1.93e-05, gnorm=35.095, clip=100, loss_scale=16, train_wall=96, gb_free=11.7, wall=35421
2025-11-01 22:32:50 | INFO | train_inner | epoch 002:   8028 / 11384 loss=0.193598, wps=1173.8, ups=0.59, wpb=1979.1, bsz=128, num_updates=19350, lr=1.935e-05, gnorm=35.671, clip=100, loss_scale=16, train_wall=84, gb_free=16.2, wall=35505
2025-11-01 22:34:12 | INFO | train_inner | epoch 002:   8078 / 11384 loss=0.193374, wps=1158.8, ups=0.61, wpb=1901.5, bsz=128, num_updates=19400, lr=1.94e-05, gnorm=37.93, clip=100, loss_scale=32, train_wall=82, gb_free=16.2, wall=35587
2025-11-01 22:35:49 | INFO | train_inner | epoch 002:   8128 / 11384 loss=0.199221, wps=1017.3, ups=0.52, wpb=1959.9, bsz=128, num_updates=19450, lr=1.945e-05, gnorm=35.386, clip=100, loss_scale=32, train_wall=96, gb_free=12, wall=35684
2025-11-01 22:37:15 | INFO | train_inner | epoch 002:   8178 / 11384 loss=0.202322, wps=1098.8, ups=0.58, wpb=1900.1, bsz=128, num_updates=19500, lr=1.95e-05, gnorm=36.175, clip=100, loss_scale=32, train_wall=86, gb_free=15.3, wall=35770
2025-11-01 22:38:45 | INFO | train_inner | epoch 002:   8228 / 11384 loss=0.205288, wps=1090.4, ups=0.56, wpb=1954.4, bsz=128, num_updates=19550, lr=1.955e-05, gnorm=36.276, clip=100, loss_scale=32, train_wall=89, gb_free=13.3, wall=35860
2025-11-01 22:40:12 | INFO | train_inner | epoch 002:   8278 / 11384 loss=0.200574, wps=1105.5, ups=0.57, wpb=1929.9, bsz=128, num_updates=19600, lr=1.96e-05, gnorm=36.743, clip=100, loss_scale=32, train_wall=87, gb_free=13.9, wall=35947
2025-11-01 22:41:35 | INFO | train_inner | epoch 002:   8328 / 11384 loss=0.197576, wps=1189.8, ups=0.6, wpb=1967, bsz=128, num_updates=19650, lr=1.965e-05, gnorm=35.272, clip=100, loss_scale=64, train_wall=82, gb_free=15.6, wall=36030
2025-11-01 22:42:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 22:43:00 | INFO | train_inner | epoch 002:   8379 / 11384 loss=0.202503, wps=1140.4, ups=0.59, wpb=1947.1, bsz=128, num_updates=19700, lr=1.97e-05, gnorm=40.007, clip=100, loss_scale=32, train_wall=85, gb_free=15.8, wall=36115
2025-11-01 22:44:16 | INFO | train_inner | epoch 002:   8429 / 11384 loss=0.202857, wps=1303, ups=0.66, wpb=1969.9, bsz=128, num_updates=19750, lr=1.975e-05, gnorm=35.689, clip=100, loss_scale=32, train_wall=75, gb_free=9.8, wall=36191
2025-11-01 22:45:39 | INFO | train_inner | epoch 002:   8479 / 11384 loss=0.19547, wps=1158.2, ups=0.6, wpb=1939, bsz=128, num_updates=19800, lr=1.98e-05, gnorm=35.701, clip=100, loss_scale=32, train_wall=83, gb_free=15.9, wall=36275
2025-11-01 22:47:00 | INFO | train_inner | epoch 002:   8529 / 11384 loss=0.202606, wps=1208.7, ups=0.62, wpb=1940.4, bsz=128, num_updates=19850, lr=1.985e-05, gnorm=37.151, clip=100, loss_scale=32, train_wall=80, gb_free=16.9, wall=36355
2025-11-01 22:48:23 | INFO | train_inner | epoch 002:   8579 / 11384 loss=0.206446, wps=1179.1, ups=0.6, wpb=1958.3, bsz=128, num_updates=19900, lr=1.99e-05, gnorm=38.666, clip=100, loss_scale=32, train_wall=83, gb_free=14.8, wall=36438
2025-11-01 22:49:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 22:49:42 | INFO | train_inner | epoch 002:   8630 / 11384 loss=0.189897, wps=1222.7, ups=0.63, wpb=1942.4, bsz=128, num_updates=19950, lr=1.995e-05, gnorm=35.895, clip=100, loss_scale=32, train_wall=79, gb_free=14.9, wall=36517
2025-11-01 22:51:17 | INFO | train_inner | epoch 002:   8680 / 11384 loss=0.190874, wps=1072.7, ups=0.53, wpb=2026.4, bsz=128, num_updates=20000, lr=2e-05, gnorm=35.715, clip=100, loss_scale=32, train_wall=94, gb_free=14.1, wall=36612
2025-11-01 22:52:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 22:52:49 | INFO | train_inner | epoch 002:   8731 / 11384 loss=0.194885, wps=1060.7, ups=0.54, wpb=1969.9, bsz=128, num_updates=20050, lr=2.005e-05, gnorm=34.907, clip=100, loss_scale=16, train_wall=93, gb_free=13.6, wall=36705
2025-11-01 22:54:13 | INFO | train_inner | epoch 002:   8781 / 11384 loss=0.199915, wps=1168.1, ups=0.6, wpb=1943, bsz=128, num_updates=20100, lr=2.01e-05, gnorm=36.003, clip=100, loss_scale=16, train_wall=83, gb_free=15.2, wall=36788
2025-11-01 22:55:55 | INFO | train_inner | epoch 002:   8831 / 11384 loss=0.191783, wps=970, ups=0.49, wpb=1977.1, bsz=128, num_updates=20150, lr=2.015e-05, gnorm=36.433, clip=100, loss_scale=16, train_wall=100, gb_free=16.3, wall=36890
2025-11-01 22:57:03 | INFO | train_inner | epoch 002:   8881 / 11384 loss=0.193323, wps=1427.7, ups=0.73, wpb=1963.3, bsz=128, num_updates=20200, lr=2.02e-05, gnorm=36.99, clip=100, loss_scale=16, train_wall=69, gb_free=16, wall=36959
2025-11-01 22:58:25 | INFO | train_inner | epoch 002:   8931 / 11384 loss=0.185729, wps=1227.8, ups=0.62, wpb=1994.5, bsz=128, num_updates=20250, lr=2.025e-05, gnorm=35.108, clip=100, loss_scale=16, train_wall=81, gb_free=12.5, wall=37040
2025-11-01 23:00:09 | INFO | train_inner | epoch 002:   8981 / 11384 loss=0.204418, wps=922.6, ups=0.48, wpb=1935.4, bsz=128, num_updates=20300, lr=2.03e-05, gnorm=38.906, clip=100, loss_scale=16, train_wall=105, gb_free=14.1, wall=37145
2025-11-01 23:01:28 | INFO | train_inner | epoch 002:   9031 / 11384 loss=0.203287, wps=1282.4, ups=0.64, wpb=2017.7, bsz=128, num_updates=20350, lr=2.035e-05, gnorm=37.988, clip=100, loss_scale=32, train_wall=78, gb_free=14.8, wall=37223
2025-11-01 23:02:55 | INFO | train_inner | epoch 002:   9081 / 11384 loss=0.186629, wps=1142, ups=0.58, wpb=1972.8, bsz=128, num_updates=20400, lr=2.04e-05, gnorm=34.785, clip=100, loss_scale=32, train_wall=86, gb_free=16.6, wall=37310
2025-11-01 23:04:20 | INFO | train_inner | epoch 002:   9131 / 11384 loss=0.186376, wps=1134, ups=0.58, wpb=1940.7, bsz=128, num_updates=20450, lr=2.045e-05, gnorm=33.461, clip=100, loss_scale=32, train_wall=85, gb_free=16.3, wall=37395
2025-11-01 23:05:49 | INFO | train_inner | epoch 002:   9181 / 11384 loss=0.186281, wps=1088.7, ups=0.56, wpb=1942.9, bsz=128, num_updates=20500, lr=2.05e-05, gnorm=33.11, clip=100, loss_scale=32, train_wall=89, gb_free=10.1, wall=37485
2025-11-01 23:06:55 | INFO | train_inner | epoch 002:   9231 / 11384 loss=0.189644, wps=1476.2, ups=0.77, wpb=1924.1, bsz=128, num_updates=20550, lr=2.055e-05, gnorm=35.225, clip=100, loss_scale=32, train_wall=65, gb_free=15.7, wall=37550
2025-11-01 23:08:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-01 23:08:16 | INFO | train_inner | epoch 002:   9282 / 11384 loss=0.182048, wps=1197.2, ups=0.62, wpb=1946.1, bsz=128, num_updates=20600, lr=2.06e-05, gnorm=33.772, clip=100, loss_scale=32, train_wall=81, gb_free=14.1, wall=37631
2025-11-01 23:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 23:09:51 | INFO | train_inner | epoch 002:   9333 / 11384 loss=0.182805, wps=1014.6, ups=0.52, wpb=1933, bsz=128, num_updates=20650, lr=2.065e-05, gnorm=34.732, clip=100, loss_scale=16, train_wall=95, gb_free=15.3, wall=37726
2025-11-01 23:11:27 | INFO | train_inner | epoch 002:   9383 / 11384 loss=0.176881, wps=1034.9, ups=0.52, wpb=1980, bsz=128, num_updates=20700, lr=2.07e-05, gnorm=36.186, clip=100, loss_scale=16, train_wall=95, gb_free=15.2, wall=37822
2025-11-01 23:12:54 | INFO | train_inner | epoch 002:   9433 / 11384 loss=0.177983, wps=1132.8, ups=0.57, wpb=1971.1, bsz=128, num_updates=20750, lr=2.075e-05, gnorm=35.818, clip=100, loss_scale=16, train_wall=87, gb_free=14.4, wall=37909
2025-11-01 23:13:58 | INFO | train_inner | epoch 002:   9483 / 11384 loss=0.186592, wps=1534.1, ups=0.78, wpb=1959.5, bsz=127.9, num_updates=20800, lr=2.08e-05, gnorm=36.901, clip=100, loss_scale=16, train_wall=64, gb_free=11.9, wall=37973
2025-11-01 23:15:27 | INFO | train_inner | epoch 002:   9533 / 11384 loss=0.170636, wps=1084.1, ups=0.56, wpb=1937, bsz=128, num_updates=20850, lr=2.085e-05, gnorm=31.451, clip=100, loss_scale=16, train_wall=89, gb_free=14.5, wall=38062
2025-11-01 23:16:44 | INFO | train_inner | epoch 002:   9583 / 11384 loss=0.191421, wps=1289.7, ups=0.65, wpb=1977.7, bsz=128, num_updates=20900, lr=2.09e-05, gnorm=35.581, clip=100, loss_scale=32, train_wall=76, gb_free=12.3, wall=38139
2025-11-01 23:18:15 | INFO | train_inner | epoch 002:   9633 / 11384 loss=0.175303, wps=1090.8, ups=0.55, wpb=1989.6, bsz=128, num_updates=20950, lr=2.095e-05, gnorm=33.205, clip=100, loss_scale=32, train_wall=91, gb_free=11.1, wall=38230
2025-11-01 23:19:36 | INFO | train_inner | epoch 002:   9683 / 11384 loss=0.183401, wps=1187.4, ups=0.61, wpb=1936.2, bsz=128, num_updates=21000, lr=2.1e-05, gnorm=38.474, clip=100, loss_scale=32, train_wall=81, gb_free=16.3, wall=38312
2025-11-01 23:21:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 23:21:11 | INFO | train_inner | epoch 002:   9734 / 11384 loss=0.1776, wps=1021.1, ups=0.53, wpb=1935.3, bsz=128, num_updates=21050, lr=2.105e-05, gnorm=33.906, clip=100, loss_scale=16, train_wall=95, gb_free=9.9, wall=38406
2025-11-01 23:22:51 | INFO | train_inner | epoch 002:   9784 / 11384 loss=0.174643, wps=978.6, ups=0.5, wpb=1954.9, bsz=128, num_updates=21100, lr=2.11e-05, gnorm=35.471, clip=100, loss_scale=16, train_wall=100, gb_free=15, wall=38506
2025-11-01 23:24:12 | INFO | train_inner | epoch 002:   9834 / 11384 loss=0.180721, wps=1213, ups=0.61, wpb=1974.8, bsz=128, num_updates=21150, lr=2.115e-05, gnorm=35.67, clip=100, loss_scale=16, train_wall=81, gb_free=15.9, wall=38588
2025-11-01 23:25:35 | INFO | train_inner | epoch 002:   9884 / 11384 loss=0.191208, wps=1210.2, ups=0.6, wpb=2005.1, bsz=128, num_updates=21200, lr=2.12e-05, gnorm=41.766, clip=100, loss_scale=16, train_wall=83, gb_free=17.8, wall=38671
2025-11-01 23:27:01 | INFO | train_inner | epoch 002:   9934 / 11384 loss=0.191432, wps=1134, ups=0.59, wpb=1936.8, bsz=128, num_updates=21250, lr=2.125e-05, gnorm=35.616, clip=100, loss_scale=16, train_wall=85, gb_free=13, wall=38756
2025-11-01 23:28:24 | INFO | train_inner | epoch 002:   9984 / 11384 loss=0.17962, wps=1154.4, ups=0.6, wpb=1921.8, bsz=128, num_updates=21300, lr=2.13e-05, gnorm=32.246, clip=100, loss_scale=32, train_wall=83, gb_free=13.6, wall=38839
2025-11-01 23:29:44 | INFO | train_inner | epoch 002:  10034 / 11384 loss=0.180423, wps=1256.1, ups=0.62, wpb=2013.7, bsz=128, num_updates=21350, lr=2.135e-05, gnorm=34.134, clip=100, loss_scale=32, train_wall=80, gb_free=12, wall=38919
2025-11-01 23:29:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 23:31:22 | INFO | train_inner | epoch 002:  10085 / 11384 loss=0.170745, wps=996, ups=0.51, wpb=1946.3, bsz=128, num_updates=21400, lr=2.14e-05, gnorm=37.453, clip=100, loss_scale=16, train_wall=97, gb_free=14.9, wall=39017
2025-11-01 23:32:35 | INFO | train_inner | epoch 002:  10135 / 11384 loss=0.17391, wps=1350.1, ups=0.68, wpb=1978.7, bsz=128, num_updates=21450, lr=2.145e-05, gnorm=35.387, clip=100, loss_scale=16, train_wall=73, gb_free=12.5, wall=39090
2025-11-01 23:34:11 | INFO | train_inner | epoch 002:  10185 / 11384 loss=0.171248, wps=1015.2, ups=0.52, wpb=1946.6, bsz=128, num_updates=21500, lr=2.15e-05, gnorm=31.66, clip=100, loss_scale=16, train_wall=96, gb_free=15.5, wall=39186
2025-11-01 23:35:25 | INFO | train_inner | epoch 002:  10235 / 11384 loss=0.179483, wps=1319.3, ups=0.67, wpb=1960.7, bsz=128, num_updates=21550, lr=2.155e-05, gnorm=34.115, clip=100, loss_scale=16, train_wall=74, gb_free=16.1, wall=39261
2025-11-01 23:36:47 | INFO | train_inner | epoch 002:  10285 / 11384 loss=0.173441, wps=1198.6, ups=0.61, wpb=1953.4, bsz=128, num_updates=21600, lr=2.16e-05, gnorm=32.212, clip=100, loss_scale=16, train_wall=81, gb_free=8.9, wall=39342
2025-11-01 23:38:24 | INFO | train_inner | epoch 002:  10335 / 11384 loss=0.166595, wps=1006.8, ups=0.52, wpb=1953, bsz=128, num_updates=21650, lr=2.165e-05, gnorm=32.223, clip=100, loss_scale=32, train_wall=97, gb_free=14, wall=39439
2025-11-01 23:39:52 | INFO | train_inner | epoch 002:  10385 / 11384 loss=0.179074, wps=1134.5, ups=0.57, wpb=2001.7, bsz=128, num_updates=21700, lr=2.17e-05, gnorm=35.375, clip=100, loss_scale=32, train_wall=87, gb_free=17, wall=39527
2025-11-01 23:41:08 | INFO | train_inner | epoch 002:  10435 / 11384 loss=0.173377, wps=1287, ups=0.66, wpb=1956.2, bsz=128, num_updates=21750, lr=2.175e-05, gnorm=31.605, clip=100, loss_scale=32, train_wall=76, gb_free=16.5, wall=39603
2025-11-01 23:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 23:42:35 | INFO | train_inner | epoch 002:  10486 / 11384 loss=0.175527, wps=1107.5, ups=0.57, wpb=1932, bsz=128, num_updates=21800, lr=2.18e-05, gnorm=34.543, clip=100, loss_scale=16, train_wall=87, gb_free=16.5, wall=39691
2025-11-01 23:44:24 | INFO | train_inner | epoch 002:  10536 / 11384 loss=0.182502, wps=890.9, ups=0.46, wpb=1943.8, bsz=128, num_updates=21850, lr=2.185e-05, gnorm=35.141, clip=100, loss_scale=16, train_wall=109, gb_free=11.4, wall=39800
2025-11-01 23:45:37 | INFO | train_inner | epoch 002:  10586 / 11384 loss=0.1693, wps=1350.5, ups=0.69, wpb=1957.2, bsz=128, num_updates=21900, lr=2.19e-05, gnorm=33.209, clip=100, loss_scale=16, train_wall=72, gb_free=14.6, wall=39872
2025-11-01 23:47:21 | INFO | train_inner | epoch 002:  10636 / 11384 loss=0.165892, wps=940.2, ups=0.48, wpb=1955.8, bsz=128, num_updates=21950, lr=2.195e-05, gnorm=36.279, clip=100, loss_scale=16, train_wall=104, gb_free=17.3, wall=39976
2025-11-01 23:49:08 | INFO | train_inner | epoch 002:  10686 / 11384 loss=0.170341, wps=902, ups=0.47, wpb=1932.1, bsz=128, num_updates=22000, lr=2.2e-05, gnorm=34.174, clip=100, loss_scale=16, train_wall=107, gb_free=15.4, wall=40083
2025-11-01 23:50:10 | INFO | train_inner | epoch 002:  10736 / 11384 loss=0.172117, wps=1582.9, ups=0.8, wpb=1976.6, bsz=128, num_updates=22050, lr=2.205e-05, gnorm=32.838, clip=100, loss_scale=32, train_wall=62, gb_free=14.1, wall=40146
2025-11-01 23:51:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-01 23:51:50 | INFO | train_inner | epoch 002:  10787 / 11384 loss=0.173503, wps=972, ups=0.5, wpb=1925.7, bsz=128, num_updates=22100, lr=2.21e-05, gnorm=32.618, clip=100, loss_scale=16, train_wall=97, gb_free=13.2, wall=40245
2025-11-01 23:53:15 | INFO | train_inner | epoch 002:  10837 / 11384 loss=0.16091, wps=1157.6, ups=0.59, wpb=1971.7, bsz=128, num_updates=22150, lr=2.215e-05, gnorm=31.334, clip=100, loss_scale=16, train_wall=85, gb_free=11.3, wall=40330
2025-11-01 23:54:32 | INFO | train_inner | epoch 002:  10887 / 11384 loss=0.163409, wps=1265.9, ups=0.65, wpb=1956.8, bsz=128, num_updates=22200, lr=2.22e-05, gnorm=32.419, clip=100, loss_scale=16, train_wall=76, gb_free=13.1, wall=40407
2025-11-01 23:56:13 | INFO | train_inner | epoch 002:  10937 / 11384 loss=0.172748, wps=973.4, ups=0.5, wpb=1964.3, bsz=128, num_updates=22250, lr=2.225e-05, gnorm=34.349, clip=100, loss_scale=16, train_wall=101, gb_free=16.2, wall=40508
2025-11-01 23:57:17 | INFO | train_inner | epoch 002:  10987 / 11384 loss=0.16371, wps=1546.2, ups=0.78, wpb=1989.2, bsz=128, num_updates=22300, lr=2.23e-05, gnorm=31.426, clip=100, loss_scale=16, train_wall=64, gb_free=14.1, wall=40572
2025-11-01 23:58:52 | INFO | train_inner | epoch 002:  11037 / 11384 loss=0.16109, wps=1023, ups=0.53, wpb=1929.6, bsz=128, num_updates=22350, lr=2.235e-05, gnorm=31.209, clip=100, loss_scale=32, train_wall=94, gb_free=16.4, wall=40667
2025-11-02 00:00:10 | INFO | train_inner | epoch 002:  11087 / 11384 loss=0.166938, wps=1252.6, ups=0.64, wpb=1952.7, bsz=128, num_updates=22400, lr=2.24e-05, gnorm=32.39, clip=100, loss_scale=32, train_wall=78, gb_free=12, wall=40745
2025-11-02 00:01:50 | INFO | train_inner | epoch 002:  11137 / 11384 loss=0.16669, wps=958, ups=0.5, wpb=1932.9, bsz=128, num_updates=22450, lr=2.245e-05, gnorm=33.396, clip=100, loss_scale=32, train_wall=101, gb_free=9.8, wall=40846
2025-11-02 00:03:10 | INFO | train_inner | epoch 002:  11187 / 11384 loss=0.163283, wps=1208.7, ups=0.63, wpb=1925, bsz=128, num_updates=22500, lr=2.25e-05, gnorm=31.544, clip=100, loss_scale=32, train_wall=79, gb_free=15.2, wall=40925
2025-11-02 00:04:19 | INFO | train_inner | epoch 002:  11237 / 11384 loss=0.172455, wps=1410.4, ups=0.72, wpb=1953.4, bsz=128, num_updates=22550, lr=2.255e-05, gnorm=33.387, clip=100, loss_scale=32, train_wall=69, gb_free=14.5, wall=40995
2025-11-02 00:06:00 | INFO | train_inner | epoch 002:  11287 / 11384 loss=0.171368, wps=957.7, ups=0.5, wpb=1926.2, bsz=128, num_updates=22600, lr=2.26e-05, gnorm=34.519, clip=100, loss_scale=32, train_wall=100, gb_free=14.9, wall=41095
2025-11-02 00:07:30 | INFO | train_inner | epoch 002:  11337 / 11384 loss=0.162789, wps=1082.9, ups=0.56, wpb=1944.9, bsz=128, num_updates=22650, lr=2.265e-05, gnorm=31.982, clip=100, loss_scale=64, train_wall=90, gb_free=15.5, wall=41185
2025-11-02 00:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-11-02 00:23:36 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.161496 | wps 1463.6 | wpb 1948.3 | bsz 127.9 | num_updates 22697 | best_loss 0.161496
2025-11-02 00:23:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 22697 updates
2025-11-02 00:23:36 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint2.pt
2025-11-02 00:23:48 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint2.pt
2025-11-02 00:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /data/run01/scw6f3q/zncao/affincraft-nn/ckpt_pretrian/checkpoint2.pt (epoch 2 @ 22697 updates, score 0.161496) (writing took 270.6253239150392 seconds)
2025-11-02 00:28:07 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2025-11-02 00:28:07 | INFO | train | epoch 002 | loss 0.233711 | wps 945.9 | ups 0.48 | wpb 1958.7 | bsz 128 | num_updates 22697 | lr 2.2697e-05 | gnorm 37.999 | clip 100 | loss_scale 64 | train_wall 21587 | gb_free 15.6 | wall 42422
2025-11-02 00:28:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-11-02 00:28:09 | INFO | fairseq.trainer | begin training epoch 3
2025-11-02 00:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2025-11-02 00:28:26 | INFO | train_inner | epoch 003:      3 / 11384 loss=0.169794, wps=77.3, ups=0.04, wpb=1941.7, bsz=127.7, num_updates=22700, lr=2.27e-05, gnorm=33.288, clip=100, loss_scale=64, train_wall=68, gb_free=14.7, wall=42441
2025-11-02 00:30:07 | INFO | train_inner | epoch 003:     53 / 11384 loss=0.15772, wps=957.9, ups=0.49, wpb=1939.6, bsz=128, num_updates=22750, lr=2.275e-05, gnorm=30.626, clip=100, loss_scale=64, train_wall=101, gb_free=14.8, wall=42543
2025-11-02 00:31:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-11-02 00:31:56 | INFO | train_inner | epoch 003:    104 / 11384 loss=0.161973, wps=893.6, ups=0.46, wpb=1946.9, bsz=128, num_updates=22800, lr=2.28e-05, gnorm=31.911, clip=100, loss_scale=32, train_wall=109, gb_free=10.4, wall=42651
2025-11-02 00:33:26 | INFO | train_inner | epoch 003:    154 / 11384 loss=0.160303, wps=1073.5, ups=0.56, wpb=1933.7, bsz=128, num_updates=22850, lr=2.285e-05, gnorm=31.853, clip=100, loss_scale=32, train_wall=90, gb_free=12.6, wall=42742
2025-11-02 00:35:27 | INFO | train_inner | epoch 003:    204 / 11384 loss=0.163357, wps=812.5, ups=0.41, wpb=1968.8, bsz=128, num_updates=22900, lr=2.29e-05, gnorm=35.258, clip=100, loss_scale=32, train_wall=121, gb_free=14.6, wall=42863
2025-11-02 00:37:28 | INFO | train_inner | epoch 003:    254 / 11384 loss=0.157304, wps=801.1, ups=0.41, wpb=1934, bsz=128, num_updates=22950, lr=2.295e-05, gnorm=30.893, clip=100, loss_scale=32, train_wall=120, gb_free=14.7, wall=42983
2025-11-02 00:38:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-02 00:38:40 | INFO | train_inner | epoch 003:    305 / 11384 loss=0.158252, wps=1336.7, ups=0.7, wpb=1911.6, bsz=128, num_updates=23000, lr=2.3e-05, gnorm=33.828, clip=100, loss_scale=16, train_wall=71, gb_free=11.6, wall=43055
2025-11-02 00:41:42 | INFO | train_inner | epoch 003:    355 / 11384 loss=0.157809, wps=539.9, ups=0.27, wpb=1964.7, bsz=128, num_updates=23050, lr=2.305e-05, gnorm=31.522, clip=100, loss_scale=16, train_wall=182, gb_free=16.6, wall=43237
2025-11-02 00:42:43 | INFO | train_inner | epoch 003:    405 / 11384 loss=0.167204, wps=1603.2, ups=0.82, wpb=1962.4, bsz=128, num_updates=23100, lr=2.31e-05, gnorm=37.695, clip=100, loss_scale=16, train_wall=61, gb_free=15.5, wall=43298
2025-11-02 00:44:15 | INFO | train_inner | epoch 003:    455 / 11384 loss=0.163125, wps=1077.3, ups=0.54, wpb=1982.2, bsz=128, num_updates=23150, lr=2.315e-05, gnorm=31.937, clip=100, loss_scale=16, train_wall=66, gb_free=13.9, wall=43390
2025-11-02 00:46:14 | INFO | train_inner | epoch 003:    505 / 11384 loss=0.15355, wps=824.9, ups=0.42, wpb=1966, bsz=128, num_updates=23200, lr=2.32e-05, gnorm=28.814, clip=100, loss_scale=16, train_wall=66, gb_free=16.7, wall=43509
2025-11-02 00:48:41 | INFO | train_inner | epoch 003:    555 / 11384 loss=0.163158, wps=666.9, ups=0.34, wpb=1965.1, bsz=128, num_updates=23250, lr=2.325e-05, gnorm=34.012, clip=100, loss_scale=32, train_wall=134, gb_free=15.7, wall=43657
2025-11-02 00:49:46 | INFO | train_inner | epoch 003:    605 / 11384 loss=0.159009, wps=1514.2, ups=0.77, wpb=1964.5, bsz=128, num_updates=23300, lr=2.33e-05, gnorm=33.872, clip=100, loss_scale=32, train_wall=65, gb_free=15.7, wall=43722
2025-11-02 00:52:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-02 00:52:32 | INFO | train_inner | epoch 003:    656 / 11384 loss=0.160482, wps=590.6, ups=0.3, wpb=1953.6, bsz=128, num_updates=23350, lr=2.335e-05, gnorm=32.259, clip=100, loss_scale=16, train_wall=165, gb_free=17.2, wall=43887
2025-11-02 00:54:35 | INFO | train_inner | epoch 003:    706 / 11384 loss=0.161799, wps=778.9, ups=0.4, wpb=1926.9, bsz=128, num_updates=23400, lr=2.34e-05, gnorm=34.869, clip=100, loss_scale=16, train_wall=123, gb_free=16.6, wall=44011
2025-11-02 00:56:42 | INFO | train_inner | epoch 003:    756 / 11384 loss=0.148326, wps=789.4, ups=0.39, wpb=2002.9, bsz=128, num_updates=23450, lr=2.345e-05, gnorm=31.672, clip=100, loss_scale=16, train_wall=127, gb_free=12.5, wall=44137
2025-11-02 00:58:47 | INFO | train_inner | epoch 003:    806 / 11384 loss=0.165085, wps=789.1, ups=0.4, wpb=1969.8, bsz=128, num_updates=23500, lr=2.35e-05, gnorm=33.23, clip=100, loss_scale=16, train_wall=116, gb_free=10.9, wall=44262
2025-11-02 01:00:49 | INFO | train_inner | epoch 003:    856 / 11384 loss=0.167012, wps=804.3, ups=0.41, wpb=1960, bsz=128, num_updates=23550, lr=2.355e-05, gnorm=37.175, clip=100, loss_scale=16, train_wall=122, gb_free=16.6, wall=44384
2025-11-02 01:03:56 | INFO | train_inner | epoch 003:    906 / 11384 loss=0.155211, wps=520, ups=0.27, wpb=1941.2, bsz=128, num_updates=23600, lr=2.36e-05, gnorm=33.729, clip=100, loss_scale=32, train_wall=186, gb_free=15.4, wall=44571
2025-11-02 01:03:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-02 01:05:00 | INFO | train_inner | epoch 003:    957 / 11384 loss=0.161126, wps=1518.1, ups=0.77, wpb=1968, bsz=128, num_updates=23650, lr=2.365e-05, gnorm=39.581, clip=100, loss_scale=16, train_wall=65, gb_free=16.7, wall=44636
2025-11-02 01:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-02 01:07:29 | INFO | train_inner | epoch 003:   1008 / 11384 loss=0.157064, wps=664.9, ups=0.34, wpb=1979.1, bsz=128, num_updates=23700, lr=2.37e-05, gnorm=33.636, clip=100, loss_scale=8, train_wall=115, gb_free=14.9, wall=44784
2025-11-02 01:09:35 | INFO | train_inner | epoch 003:   1058 / 11384 loss=0.143987, wps=776.3, ups=0.4, wpb=1952.2, bsz=128, num_updates=23750, lr=2.375e-05, gnorm=30.664, clip=100, loss_scale=8, train_wall=103, gb_free=14.5, wall=44910
2025-11-02 01:11:36 | INFO | train_inner | epoch 003:   1108 / 11384 loss=0.153713, wps=821.1, ups=0.41, wpb=1986.8, bsz=128, num_updates=23800, lr=2.38e-05, gnorm=34.425, clip=100, loss_scale=8, train_wall=121, gb_free=17.2, wall=45031
2025-11-02 01:14:04 | INFO | train_inner | epoch 003:   1158 / 11384 loss=0.146627, wps=654.6, ups=0.34, wpb=1942.7, bsz=128, num_updates=23850, lr=2.385e-05, gnorm=30.437, clip=100, loss_scale=8, train_wall=148, gb_free=11.1, wall=45180
2025-11-02 01:15:07 | INFO | train_inner | epoch 003:   1208 / 11384 loss=0.143579, wps=1589.4, ups=0.8, wpb=1980.1, bsz=128, num_updates=23900, lr=2.39e-05, gnorm=30.285, clip=100, loss_scale=8, train_wall=62, gb_free=9.8, wall=45242
2025-11-02 01:17:31 | INFO | train_inner | epoch 003:   1258 / 11384 loss=0.157202, wps=670.8, ups=0.35, wpb=1937.8, bsz=128, num_updates=23950, lr=2.395e-05, gnorm=34.237, clip=100, loss_scale=16, train_wall=143, gb_free=17.2, wall=45386
2025-11-02 01:19:43 | INFO | train_inner | epoch 003:   1308 / 11384 loss=0.149745, wps=736.8, ups=0.38, wpb=1931.5, bsz=128, num_updates=24000, lr=2.4e-05, gnorm=30.348, clip=100, loss_scale=16, train_wall=101, gb_free=16.7, wall=45518
2025-11-02 01:21:49 | INFO | train_inner | epoch 003:   1358 / 11384 loss=0.150637, wps=775.9, ups=0.4, wpb=1960.1, bsz=128, num_updates=24050, lr=2.405e-05, gnorm=31.476, clip=100, loss_scale=16, train_wall=123, gb_free=11.7, wall=45644
2025-11-02 01:22:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-02 01:24:20 | INFO | train_inner | epoch 003:   1409 / 11384 loss=0.151903, wps=646.6, ups=0.33, wpb=1948.2, bsz=128, num_updates=24100, lr=2.41e-05, gnorm=34.451, clip=100, loss_scale=8, train_wall=150, gb_free=16.6, wall=45795
2025-11-02 01:25:21 | INFO | train_inner | epoch 003:   1459 / 11384 loss=0.144605, wps=1591.5, ups=0.82, wpb=1947.7, bsz=128, num_updates=24150, lr=2.415e-05, gnorm=29.303, clip=100, loss_scale=8, train_wall=61, gb_free=13.1, wall=45856
2025-11-02 01:27:51 | INFO | train_inner | epoch 003:   1509 / 11384 loss=0.151975, wps=643.4, ups=0.33, wpb=1933.9, bsz=128, num_updates=24200, lr=2.42e-05, gnorm=29.374, clip=100, loss_scale=8, train_wall=150, gb_free=16.8, wall=46006
2025-11-02 01:31:00 | INFO | train_inner | epoch 003:   1559 / 11384 loss=0.154808, wps=516.5, ups=0.26, wpb=1954.2, bsz=128, num_updates=24250, lr=2.425e-05, gnorm=33.664, clip=100, loss_scale=8, train_wall=169, gb_free=16.3, wall=46195
2025-11-02 01:33:08 | INFO | train_inner | epoch 003:   1609 / 11384 loss=0.158305, wps=771.3, ups=0.39, wpb=1970.7, bsz=128, num_updates=24300, lr=2.43e-05, gnorm=34.555, clip=100, loss_scale=8, train_wall=63, gb_free=11.4, wall=46323
2025-11-02 01:35:00 | INFO | train_inner | epoch 003:   1659 / 11384 loss=0.143898, wps=877.9, ups=0.45, wpb=1960.9, bsz=128, num_updates=24350, lr=2.435e-05, gnorm=34.166, clip=100, loss_scale=16, train_wall=111, gb_free=6.4, wall=46435
2025-11-02 01:36:32 | INFO | train_inner | epoch 003:   1709 / 11384 loss=0.142292, wps=1050.4, ups=0.54, wpb=1931.4, bsz=128, num_updates=24400, lr=2.44e-05, gnorm=29.031, clip=100, loss_scale=16, train_wall=62, gb_free=16.3, wall=46527
2025-11-02 01:37:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-02 01:38:28 | INFO | train_inner | epoch 003:   1760 / 11384 loss=0.145002, wps=838.8, ups=0.43, wpb=1952.2, bsz=128, num_updates=24450, lr=2.445e-05, gnorm=32.095, clip=100, loss_scale=8, train_wall=116, gb_free=9.1, wall=46643
2025-11-02 01:40:31 | INFO | train_inner | epoch 003:   1810 / 11384 loss=0.14352, wps=783.2, ups=0.41, wpb=1920.5, bsz=128, num_updates=24500, lr=2.45e-05, gnorm=34.391, clip=100, loss_scale=8, train_wall=62, gb_free=16.2, wall=46766
2025-11-02 01:43:06 | INFO | train_inner | epoch 003:   1860 / 11384 loss=0.143564, wps=614.4, ups=0.32, wpb=1913.8, bsz=128, num_updates=24550, lr=2.455e-05, gnorm=29.047, clip=100, loss_scale=8, train_wall=156, gb_free=15.3, wall=46922
2025-11-02 01:45:08 | INFO | train_inner | epoch 003:   1910 / 11384 loss=0.144912, wps=810.3, ups=0.41, wpb=1964.4, bsz=128, num_updates=24600, lr=2.46e-05, gnorm=33.425, clip=100, loss_scale=8, train_wall=76, gb_free=16.3, wall=47043
2025-11-02 01:47:13 | INFO | train_inner | epoch 003:   1960 / 11384 loss=0.148244, wps=789, ups=0.4, wpb=1982.9, bsz=128, num_updates=24650, lr=2.465e-05, gnorm=41.836, clip=100, loss_scale=8, train_wall=125, gb_free=16.2, wall=47168
2025-11-02 01:48:15 | INFO | train_inner | epoch 003:   2010 / 11384 loss=0.14385, wps=1600.4, ups=0.81, wpb=1972.7, bsz=128, num_updates=24700, lr=2.47e-05, gnorm=29.603, clip=100, loss_scale=16, train_wall=61, gb_free=17.7, wall=47230
2025-11-02 01:50:34 | INFO | train_inner | epoch 003:   2060 / 11384 loss=0.146498, wps=701.1, ups=0.36, wpb=1955.1, bsz=128, num_updates=24750, lr=2.475e-05, gnorm=33.368, clip=100, loss_scale=16, train_wall=139, gb_free=15.8, wall=47369
2025-11-02 01:53:07 | INFO | train_inner | epoch 003:   2110 / 11384 loss=0.142984, wps=643.5, ups=0.33, wpb=1964.2, bsz=128, num_updates=24800, lr=2.48e-05, gnorm=29.903, clip=100, loss_scale=16, train_wall=152, gb_free=16.2, wall=47522
2025-11-02 01:55:47 | INFO | train_inner | epoch 003:   2160 / 11384 loss=0.147985, wps=605.8, ups=0.31, wpb=1940.6, bsz=128, num_updates=24850, lr=2.485e-05, gnorm=33.351, clip=100, loss_scale=16, train_wall=160, gb_free=16.4, wall=47682
2025-11-02 01:58:12 | INFO | train_inner | epoch 003:   2210 / 11384 loss=0.148291, wps=681.6, ups=0.34, wpb=1980, bsz=128, num_updates=24900, lr=2.49e-05, gnorm=30.403, clip=100, loss_scale=16, train_wall=145, gb_free=14.1, wall=47827
2025-11-02 01:59:14 | INFO | train_inner | epoch 003:   2260 / 11384 loss=0.14739, wps=1581.7, ups=0.82, wpb=1937, bsz=128, num_updates=24950, lr=2.495e-05, gnorm=33.57, clip=100, loss_scale=32, train_wall=61, gb_free=16.2, wall=47889
2025-11-02 02:01:40 | INFO | train_inner | epoch 003:   2310 / 11384 loss=0.134105, wps=665.9, ups=0.34, wpb=1948.5, bsz=128, num_updates=25000, lr=2.5e-05, gnorm=28.104, clip=100, loss_scale=32, train_wall=146, gb_free=16.3, wall=48035
2025-11-02 02:03:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-02 02:03:35 | INFO | train_inner | epoch 003:   2361 / 11384 loss=0.139023, wps=854, ups=0.43, wpb=1968.1, bsz=128, num_updates=25050, lr=2.505e-05, gnorm=28.584, clip=100, loss_scale=16, train_wall=111, gb_free=13.3, wall=48150
2025-11-02 02:03:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-11-02 02:06:01 | INFO | train_inner | epoch 003:   2412 / 11384 loss=0.143506, wps=670.9, ups=0.34, wpb=1953.1, bsz=128, num_updates=25100, lr=2.51e-05, gnorm=33.472, clip=100, loss_scale=8, train_wall=145, gb_free=12.3, wall=48296
2025-11-02 02:08:16 | INFO | train_inner | epoch 003:   2462 / 11384 loss=0.140953, wps=723.4, ups=0.37, wpb=1965.5, bsz=128, num_updates=25150, lr=2.515e-05, gnorm=33.179, clip=100, loss_scale=8, train_wall=136, gb_free=15.4, wall=48432
2025-11-02 02:10:29 | INFO | train_inner | epoch 003:   2512 / 11384 loss=0.1404, wps=750.1, ups=0.38, wpb=1981.3, bsz=128, num_updates=25200, lr=2.52e-05, gnorm=30.015, clip=100, loss_scale=8, train_wall=72, gb_free=13.1, wall=48564
2025-11-02 02:11:44 | INFO | train_inner | epoch 003:   2562 / 11384 loss=0.144813, wps=1312.1, ups=0.66, wpb=1974.7, bsz=128, num_updates=25250, lr=2.525e-05, gnorm=32.72, clip=100, loss_scale=8, train_wall=75, gb_free=16.7, wall=48639
2025-11-02 02:14:08 | INFO | train_inner | epoch 003:   2612 / 11384 loss=0.144393, wps=680.8, ups=0.35, wpb=1957.6, bsz=128, num_updates=25300, lr=2.53e-05, gnorm=28.486, clip=100, loss_scale=8, train_wall=62, gb_free=16.1, wall=48783
2025-11-02 02:16:10 | INFO | train_inner | epoch 003:   2662 / 11384 loss=0.132493, wps=810, ups=0.41, wpb=1977.2, bsz=128, num_updates=25350, lr=2.535e-05, gnorm=29.733, clip=100, loss_scale=16, train_wall=65, gb_free=16.6, wall=48905
2025-11-02 02:19:17 | INFO | train_inner | epoch 003:   2712 / 11384 loss=0.141157, wps=525.4, ups=0.27, wpb=1959.8, bsz=128, num_updates=25400, lr=2.54e-05, gnorm=30.789, clip=100, loss_scale=16, train_wall=186, gb_free=16.4, wall=49092
2025-11-02 02:20:29 | INFO | train_inner | epoch 003:   2762 / 11384 loss=0.146521, wps=1374, ups=0.69, wpb=1977.3, bsz=128, num_updates=25450, lr=2.545e-05, gnorm=34.282, clip=100, loss_scale=16, train_wall=72, gb_free=15.9, wall=49164
2025-11-02 02:22:14 | INFO | train_inner | epoch 003:   2812 / 11384 loss=0.152174, wps=949.4, ups=0.48, wpb=1997.3, bsz=128, num_updates=25500, lr=2.55e-05, gnorm=33.633, clip=100, loss_scale=16, train_wall=105, gb_free=16.9, wall=49269
2025-11-02 02:23:29 | INFO | train_inner | epoch 003:   2862 / 11384 loss=0.134237, wps=1285.4, ups=0.66, wpb=1944, bsz=128, num_updates=25550, lr=2.555e-05, gnorm=29.782, clip=100, loss_scale=16, train_wall=75, gb_free=15.4, wall=49345
2025-11-02 02:24:45 | INFO | train_inner | epoch 003:   2912 / 11384 loss=0.140552, wps=1297.3, ups=0.66, wpb=1955.4, bsz=128, num_updates=25600, lr=2.56e-05, gnorm=27.982, clip=100, loss_scale=32, train_wall=75, gb_free=8.5, wall=49420
2025-11-02 02:26:00 | INFO | train_inner | epoch 003:   2962 / 11384 loss=0.142715, wps=1299.3, ups=0.67, wpb=1945, bsz=128, num_updates=25650, lr=2.565e-05, gnorm=33.406, clip=100, loss_scale=32, train_wall=74, gb_free=16.2, wall=49495
2025-11-02 02:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-11-02 02:27:38 | INFO | train_inner | epoch 003:   3013 / 11384 loss=0.138073, wps=993.8, ups=0.51, wpb=1961.9, bsz=128, num_updates=25700, lr=2.57e-05, gnorm=29.07, clip=100, loss_scale=16, train_wall=98, gb_free=16.3, wall=49594
2025-11-02 02:29:23 | INFO | train_inner | epoch 003:   3063 / 11384 loss=0.134215, wps=949.3, ups=0.48, wpb=1989.3, bsz=128, num_updates=25750, lr=2.575e-05, gnorm=31.774, clip=100, loss_scale=16, train_wall=105, gb_free=16.8, wall=49698
2025-11-02 02:30:37 | INFO | train_inner | epoch 003:   3113 / 11384 loss=0.131179, wps=1337.8, ups=0.68, wpb=1972.2, bsz=128, num_updates=25800, lr=2.58e-05, gnorm=27.75, clip=100, loss_scale=16, train_wall=74, gb_free=13.4, wall=49772
