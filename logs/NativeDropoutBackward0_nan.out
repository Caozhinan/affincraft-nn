[INFO] Job starting at Thu Oct 30 18:47:44 CST 2025
==========================================
 üéØ AffinCraft GPU ‰ªªÂä°ÂêØÂä® (LMDBÊ†ºÂºè)
 ËäÇÁÇπ:        g0499
 ‰Ωú‰∏öID:      4500676
 GPUs:        0,1,2,3,4,5,6,7
 ÂêØÂä®Êó∂Èó¥:    Thu Oct 30 18:47:44 CST 2025
==========================================
[INFO] Python path: /data/run01/scw6f3q/zncao/affincraft/bin/python
[INFO] Torch version: 2.6.0+cu126
[INFO] CUDA available: True
===================================================================
          AffinCraft - Â§öGPUÂàÜÂ∏ÉÂºèÈ¢ÑËÆ≠ÁªÉ (LMDBÊ†ºÂºè)          
===================================================================
Á°¨‰ª∂ÈÖçÁΩÆ:           8 GPUs √ó 1 node(s)
DataLoader workers: 6 per GPU
ËÆ≠ÁªÉÊï∞ÊçÆ:           /ssd/home/scw6f3q/train_lmdb
È™åËØÅÊï∞ÊçÆ:           /ssd/home/scw6f3q/valid_lmdb
Ê£ÄÊü•ÁÇπ‰øùÂ≠òÁõÆÂΩï:     ./affincraft_pretrain_ckpts_lmdb_multi_gpu
Ê¢ØÂ∫¶Á¥ØÁßØÊ≠•Êï∞:       1
ÂÖ®Â±ÄÊúâÊïàÊâπÊ¨°Â§ßÂ∞è:   128
===================================================================
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:51:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 0
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 4
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 7
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 2
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 3
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 1
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 5
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2025-10-30 18:52:46 | INFO | fairseq.distributed.utils | initialized host g0499 as rank 6
2025-10-30 18:52:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 50, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 1, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 100, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 150, 'max_update': 1875000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './affincraft_pretrain_ckpts_lmdb_multi_gpu', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 20, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=1, fp16_scale_window=128, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=150, max_update=1875000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts_lmdb_multi_gpu', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=474, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=75000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1875000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.1, act_dropout=0.1, dropout=0.1, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large'), 'task': {'_name': 'graph_prediction', 'dataset_name': 'pcqm4m', 'num_classes': 1, 'max_nodes': 474, 'dataset_source': 'affincraft', 'num_atoms': 4608, 'num_edges': 1536, 'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, 'multi_hop_max_dist': 5, 'spatial_pos_max': 1024, 'edge_type': 'multi_hop', 'seed': 42, 'pretrained_model_name': 'none', 'load_pretrained_model_output_layer': False, 'train_epoch_shuffle': True, 'user_data_dir': '', 'data_path': '', 'train_pkl_pattern': '/ssd/home/scw6f3q/train_lmdb', 'valid_pkl_pattern': '/ssd/home/scw6f3q/valid_lmdb', 'test_pkl_pattern': '', 'merged_pkl_file': '', 'train_pkl_objects': 10000, 'valid_pkl_objects': 1000, 'test_pkl_objects': 0, 'train_pkl_index': '', 'valid_pkl_index': '', 'test_pkl_index': ''}, 'criterion': {'_name': 'l2_loss_rmsd'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 75000, 'force_anneal': None, 'end_learning_rate': 1e-09, 'power': 1.0, 'total_num_update': 1875000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
Ê†∑Êú¨ÊÄªÊï∞: 1,457,129LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb



Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129Ê†∑Êú¨ÊÄªÊï∞: 1,457,129




Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdb2025-10-30 18:52:47 | INFO | graphormer.tasks.graph_prediction | ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå1457129 ‰∏™Ê†∑Êú¨

LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/train_lmdbÊ†∑Êú¨ÊÄªÊï∞: 1,457,129

Ê†∑Êú¨ÊÄªÊï∞: 1,457,129
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb
LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbLMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdb

LMDBÊï∞ÊçÆÈõÜÂä†ËΩΩÂÆåÊàê: /ssd/home/scw6f3q/valid_lmdbÊ†∑Êú¨ÊÄªÊï∞: 80,568



Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568

Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568Ê†∑Êú¨ÊÄªÊï∞: 80,568

Ê†∑Êú¨ÊÄªÊï∞: 80,568




2025-10-30 18:52:47 | INFO | graphormer.tasks.graph_prediction | È™åËØÅÊï∞ÊçÆÈõÜ(LMDB)Âä†ËΩΩÂÆåÊàêÔºå80568 ‰∏™Ê†∑Êú¨
2025-10-30 18:52:47 | INFO | graphormer.models.graphormer | Namespace(no_progress_bar=False, log_interval=50, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=42, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=1, fp16_scale_window=128, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/data/run01/scw6f3q/zncao/affincraft-nn/graphormer', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='l2_loss_rmsd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', scoring='bleu', task='graph_prediction', num_workers=6, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=100, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=8, distributed_num_procs=8, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=8, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='graphormer_large', max_epoch=150, max_update=1875000, stop_time_hours=0, clip_norm=5.0, sentence_avg=False, update_freq=[1], lr=[0.0001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./affincraft_pretrain_ckpts_lmdb_multi_gpu', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=20, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, layerdrop=0.0, embed_scale=-1.0, sandwich_ln=False, dist_head='none', num_dist_head_kernel=128, num_edge_types=8192, sample_weight_estimator=False, sample_weight_estimator_pat='pdbbind', fingerprint=False, dataset_name='pcqm4m', num_classes=1, max_nodes=474, dataset_source='affincraft', num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, spatial_pos_max=1024, edge_type='multi_hop', pretrained_model_name='none', load_pretrained_model_output_layer=False, train_epoch_shuffle=True, user_data_dir='', data_path='', train_pkl_pattern='/ssd/home/scw6f3q/train_lmdb', valid_pkl_pattern='/ssd/home/scw6f3q/valid_lmdb', test_pkl_pattern='', merged_pkl_file='', train_pkl_objects=10000, valid_pkl_objects=1000, test_pkl_objects=0, train_pkl_index='', valid_pkl_index='', test_pkl_index='', adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=75000, force_anneal=None, end_learning_rate=1e-09, power=1.0, total_num_update='1875000', pad=1, eos=2, unk=3, encoder_layers=18, encoder_embed_dim=896, encoder_ffn_embed_dim=896, encoder_attention_heads=32, attention_dropout=0.1, act_dropout=0.1, dropout=0.1, no_seed_provided=False, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=False, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, _name='graphormer_large')
2025-10-30 18:52:48 | INFO | fairseq_cli.train | GraphormerModel(
  (encoder): GraphormerEncoder(
    (graph_encoder): AffinCraftGraphEncoder(
      (dropout_module): FairseqDropout()
      (graph_node_feature): AffinCraftNodeFeature(
        (node_encoder): Linear(in_features=9, out_features=896, bias=True)
        (graph_token): Embedding(1, 896)
        (local_masif_encoder): Sequential(
          (0): Linear(in_features=80, out_features=448, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=448, out_features=448, bias=True)
        )
        (global_masif_encoder): Sequential(
          (0): Linear(in_features=448, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (attention_weights): Linear(in_features=448, out_features=1, bias=True)
        (gbscore_encoder): Sequential(
          (0): Linear(in_features=400, out_features=896, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=896, out_features=896, bias=True)
        )
        (feature_fusion): Linear(in_features=2688, out_features=896, bias=True)
      )
      (graph_attn_bias): AffinCraftAttnBias(
        (structural_edge_encoder): Embedding(20, 32, padding_idx=0)
        (plip_intra_protein_encoder): Embedding(15, 32, padding_idx=0)
        (plip_intra_ligand_encoder): Embedding(15, 32, padding_idx=0)
        (plip_inter_molecular_encoder): Embedding(15, 32, padding_idx=0)
        (distance_encoder): Sequential(
          (0): Linear(in_features=1, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (edge_location_encoder): Embedding(4, 32)
        (graph_token_virtual_distance): Embedding(1, 32)
        (angle_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
        (multi_dist_encoder): Sequential(
          (0): Linear(in_features=28, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (emb_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-17): 18 x GraphormerGraphEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=896, out_features=896, bias=True)
            (v_proj): Linear(in_features=896, out_features=896, bias=True)
            (q_proj): Linear(in_features=896, out_features=896, bias=True)
            (out_proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=896, out_features=896, bias=True)
          (fc2): Linear(in_features=896, out_features=896, bias=True)
          (final_layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (masked_lm_pooler): Linear(in_features=896, out_features=896, bias=True)
    (lm_head_transform_weight): Linear(in_features=896, out_features=896, bias=True)
    (layer_norm): LayerNorm((896,), eps=1e-05, elementwise_affine=True)
    (embed_out): Linear(in_features=896, out_features=1, bias=False)
  )
)
2025-10-30 18:52:48 | INFO | fairseq_cli.train | task: GraphPredictionTask
2025-10-30 18:52:48 | INFO | fairseq_cli.train | model: GraphormerModel
2025-10-30 18:52:48 | INFO | fairseq_cli.train | criterion: GraphPredictionL2LossWithRMSD
2025-10-30 18:52:48 | INFO | fairseq_cli.train | num. shared model params: 93,510,754 (num. trained: 93,510,754)
2025-10-30 18:52:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-10-30 18:52:48 | INFO | graphormer.tasks.graph_prediction | Loaded valid with #samples: 80568
2025-10-30 18:52:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   4: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   5: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   6: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | rank   7: capabilities =  8.9  ; total memory = 22.152 GB ; name = NVIDIA GeForce RTX 4090                 
2025-10-30 18:52:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2025-10-30 18:52:49 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2025-10-30 18:52:49 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 16
2025-10-30 18:52:49 | INFO | fairseq.trainer | Preparing to load checkpoint ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint_last.pt
2025-10-30 18:52:49 | INFO | fairseq.trainer | No existing checkpoint found ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint_last.pt
2025-10-30 18:52:49 | INFO | fairseq.trainer | loading train data for epoch 1
2025-10-30 18:52:49 | INFO | graphormer.tasks.graph_prediction | Loaded train with #samples: 1457129
2025-10-30 18:52:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-10-30 18:52:54 | INFO | fairseq.trainer | begin training epoch 1
2025-10-30 18:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2025-10-30 18:54:00 | INFO | train_inner | epoch 001:     50 / 11384 loss=0.875373, wps=1732.9, ups=0.89, wpb=1948.1, bsz=128, num_updates=50, lr=6.66667e-08, gnorm=156.097, clip=100, loss_scale=1, train_wall=61, gb_free=11.7, wall=71
2025-10-30 18:54:48 | INFO | train_inner | epoch 001:    100 / 11384 loss=0.80136, wps=2045.4, ups=1.05, wpb=1957.1, bsz=128, num_updates=100, lr=1.33333e-07, gnorm=166.322, clip=100, loss_scale=1, train_wall=48, gb_free=11.9, wall=119
2025-10-30 18:55:37 | INFO | train_inner | epoch 001:    150 / 11384 loss=0.698405, wps=2035.5, ups=1.03, wpb=1978, bsz=128, num_updates=150, lr=2e-07, gnorm=95.342, clip=100, loss_scale=2, train_wall=48, gb_free=13.5, wall=168
2025-10-30 18:56:23 | INFO | train_inner | epoch 001:    200 / 11384 loss=0.688354, wps=2077.1, ups=1.08, wpb=1924.8, bsz=128, num_updates=200, lr=2.66667e-07, gnorm=82.644, clip=100, loss_scale=2, train_wall=46, gb_free=14.6, wall=214
2025-10-30 18:57:10 | INFO | train_inner | epoch 001:    250 / 11384 loss=0.660611, wps=2067.7, ups=1.06, wpb=1954.2, bsz=128, num_updates=250, lr=3.33333e-07, gnorm=73.103, clip=100, loss_scale=2, train_wall=47, gb_free=16.2, wall=261
2025-10-30 18:57:59 | INFO | train_inner | epoch 001:    300 / 11384 loss=0.622469, wps=2027.1, ups=1.02, wpb=1987.6, bsz=128, num_updates=300, lr=4e-07, gnorm=90.821, clip=100, loss_scale=4, train_wall=49, gb_free=13.1, wall=310
2025-10-30 18:58:48 | INFO | train_inner | epoch 001:    350 / 11384 loss=0.628725, wps=2020.5, ups=1.01, wpb=1990.8, bsz=128, num_updates=350, lr=4.66667e-07, gnorm=81.946, clip=100, loss_scale=4, train_wall=49, gb_free=12.5, wall=360
2025-10-30 18:59:38 | INFO | train_inner | epoch 001:    400 / 11384 loss=0.689503, wps=1977, ups=1, wpb=1968.3, bsz=128, num_updates=400, lr=5.33333e-07, gnorm=116.9, clip=100, loss_scale=8, train_wall=50, gb_free=16.4, wall=410
2025-10-30 19:00:25 | INFO | train_inner | epoch 001:    450 / 11384 loss=0.597476, wps=2073.3, ups=1.07, wpb=1935.8, bsz=128, num_updates=450, lr=6e-07, gnorm=86.633, clip=100, loss_scale=8, train_wall=46, gb_free=12.2, wall=456
2025-10-30 19:01:51 | INFO | train_inner | epoch 001:    500 / 11384 loss=0.601446, wps=1130.9, ups=0.58, wpb=1937.9, bsz=128, num_updates=500, lr=6.66667e-07, gnorm=89.378, clip=100, loss_scale=8, train_wall=85, gb_free=17.4, wall=542
2025-10-30 19:02:46 | INFO | train_inner | epoch 001:    550 / 11384 loss=0.60515, wps=1754.8, ups=0.9, wpb=1947.1, bsz=128, num_updates=550, lr=7.33333e-07, gnorm=113.711, clip=100, loss_scale=16, train_wall=55, gb_free=14.8, wall=597
2025-10-30 19:03:40 | INFO | train_inner | epoch 001:    600 / 11384 loss=0.56499, wps=1796.9, ups=0.92, wpb=1949.8, bsz=128, num_updates=600, lr=8e-07, gnorm=88.502, clip=100, loss_scale=16, train_wall=54, gb_free=12.4, wall=652
2025-10-30 19:04:37 | INFO | train_inner | epoch 001:    650 / 11384 loss=0.570334, wps=1725.5, ups=0.89, wpb=1943.3, bsz=128, num_updates=650, lr=8.66667e-07, gnorm=94.158, clip=100, loss_scale=32, train_wall=56, gb_free=15.2, wall=708
2025-10-30 19:05:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-30 19:05:29 | INFO | train_inner | epoch 001:    701 / 11384 loss=0.565751, wps=1861.7, ups=0.95, wpb=1957, bsz=128, num_updates=700, lr=9.33333e-07, gnorm=82.687, clip=100, loss_scale=16, train_wall=52, gb_free=16.2, wall=761
2025-10-30 19:06:24 | INFO | train_inner | epoch 001:    751 / 11384 loss=0.542417, wps=1765.2, ups=0.91, wpb=1934.8, bsz=128, num_updates=750, lr=1e-06, gnorm=91.129, clip=100, loss_scale=16, train_wall=55, gb_free=10.9, wall=815
2025-10-30 19:07:23 | INFO | train_inner | epoch 001:    801 / 11384 loss=0.570636, wps=1665, ups=0.84, wpb=1971.3, bsz=128, num_updates=800, lr=1.06667e-06, gnorm=105.417, clip=100, loss_scale=16, train_wall=59, gb_free=16.3, wall=875
2025-10-30 19:10:30 | INFO | train_inner | epoch 001:    851 / 11384 loss=0.520952, wps=531.1, ups=0.27, wpb=1982.4, bsz=128, num_updates=850, lr=1.13333e-06, gnorm=85.127, clip=100, loss_scale=32, train_wall=185, gb_free=16.1, wall=1061
2025-10-30 19:11:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-30 19:12:06 | INFO | train_inner | epoch 001:    902 / 11384 loss=0.546275, wps=1025.2, ups=0.52, wpb=1963.1, bsz=128, num_updates=900, lr=1.2e-06, gnorm=103.713, clip=100, loss_scale=16, train_wall=95, gb_free=16.7, wall=1157
2025-10-30 19:13:38 | INFO | train_inner | epoch 001:    952 / 11384 loss=0.525737, wps=1061.5, ups=0.54, wpb=1963.6, bsz=128, num_updates=950, lr=1.26667e-06, gnorm=106.121, clip=100, loss_scale=16, train_wall=92, gb_free=15.1, wall=1250
2025-10-30 19:15:16 | INFO | train_inner | epoch 001:   1002 / 11384 loss=0.52779, wps=1001.7, ups=0.51, wpb=1961.9, bsz=128, num_updates=1000, lr=1.33333e-06, gnorm=82.577, clip=100, loss_scale=32, train_wall=98, gb_free=14, wall=1348
2025-10-30 19:15:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-30 19:16:31 | INFO | train_inner | epoch 001:   1053 / 11384 loss=0.500281, wps=1303, ups=0.67, wpb=1939.9, bsz=128, num_updates=1050, lr=1.4e-06, gnorm=79.128, clip=100, loss_scale=16, train_wall=74, gb_free=11.9, wall=1422
2025-10-30 19:17:25 | INFO | train_inner | epoch 001:   1103 / 11384 loss=0.504899, wps=1766, ups=0.92, wpb=1912.5, bsz=128, num_updates=1100, lr=1.46667e-06, gnorm=84.649, clip=100, loss_scale=16, train_wall=54, gb_free=15.3, wall=1476
2025-10-30 19:18:56 | INFO | train_inner | epoch 001:   1153 / 11384 loss=0.504118, wps=1071, ups=0.55, wpb=1949.3, bsz=128, num_updates=1150, lr=1.53333e-06, gnorm=93.387, clip=100, loss_scale=32, train_wall=62, gb_free=14.7, wall=1567
2025-10-30 19:20:57 | INFO | train_inner | epoch 001:   1203 / 11384 loss=0.488008, wps=806.9, ups=0.41, wpb=1953.7, bsz=128, num_updates=1200, lr=1.6e-06, gnorm=76.681, clip=100, loss_scale=32, train_wall=121, gb_free=16.1, wall=1689
2025-10-30 19:21:57 | INFO | train_inner | epoch 001:   1253 / 11384 loss=0.490809, wps=1620.3, ups=0.83, wpb=1948.8, bsz=128, num_updates=1250, lr=1.66667e-06, gnorm=81.045, clip=100, loss_scale=32, train_wall=60, gb_free=16, wall=1749
2025-10-30 19:23:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 19:23:31 | INFO | train_inner | epoch 001:   1304 / 11384 loss=0.483578, wps=1040.1, ups=0.53, wpb=1953.1, bsz=128, num_updates=1300, lr=1.73333e-06, gnorm=69.438, clip=100, loss_scale=32, train_wall=94, gb_free=15.8, wall=1843
2025-10-30 19:24:47 | INFO | train_inner | epoch 001:   1354 / 11384 loss=0.483573, wps=1294.1, ups=0.66, wpb=1952.3, bsz=128, num_updates=1350, lr=1.8e-06, gnorm=80.008, clip=100, loss_scale=32, train_wall=75, gb_free=15.4, wall=1918
2025-10-30 19:26:43 | INFO | train_inner | epoch 001:   1404 / 11384 loss=0.486978, wps=822.1, ups=0.43, wpb=1906.6, bsz=128, num_updates=1400, lr=1.86667e-06, gnorm=68.746, clip=100, loss_scale=32, train_wall=116, gb_free=15.9, wall=2034
2025-10-30 19:27:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 19:28:03 | INFO | train_inner | epoch 001:   1455 / 11384 loss=0.471567, wps=1226.5, ups=0.63, wpb=1959.6, bsz=128, num_updates=1450, lr=1.93333e-06, gnorm=65.549, clip=100, loss_scale=32, train_wall=80, gb_free=15.1, wall=2114
2025-10-30 19:29:23 | INFO | train_inner | epoch 001:   1505 / 11384 loss=0.485437, wps=1175.8, ups=0.62, wpb=1899.4, bsz=128, num_updates=1500, lr=2e-06, gnorm=68.73, clip=100, loss_scale=32, train_wall=81, gb_free=16.5, wall=2195
2025-10-30 19:30:35 | INFO | train_inner | epoch 001:   1555 / 11384 loss=0.459211, wps=1330.3, ups=0.69, wpb=1917.4, bsz=128, num_updates=1550, lr=2.06667e-06, gnorm=59.254, clip=100, loss_scale=32, train_wall=72, gb_free=11.8, wall=2267
2025-10-30 19:30:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 19:33:23 | INFO | train_inner | epoch 001:   1606 / 11384 loss=0.491784, wps=583, ups=0.3, wpb=1952.2, bsz=128, num_updates=1600, lr=2.13333e-06, gnorm=69.238, clip=100, loss_scale=32, train_wall=167, gb_free=14.7, wall=2434
2025-10-30 19:34:14 | INFO | train_inner | epoch 001:   1656 / 11384 loss=0.452195, wps=1935.5, ups=0.97, wpb=1992.4, bsz=128, num_updates=1650, lr=2.2e-06, gnorm=60.195, clip=100, loss_scale=32, train_wall=51, gb_free=12.4, wall=2486
2025-10-30 19:35:39 | INFO | train_inner | epoch 001:   1706 / 11384 loss=0.470901, wps=1158.1, ups=0.59, wpb=1960.5, bsz=128, num_updates=1700, lr=2.26667e-06, gnorm=51.551, clip=100, loss_scale=64, train_wall=58, gb_free=12.6, wall=2570
2025-10-30 19:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 19:37:58 | INFO | train_inner | epoch 001:   1757 / 11384 loss=0.460705, wps=710.2, ups=0.36, wpb=1979, bsz=128, num_updates=1750, lr=2.33333e-06, gnorm=54.572, clip=100, loss_scale=32, train_wall=139, gb_free=16.8, wall=2710
2025-10-30 19:39:41 | INFO | train_inner | epoch 001:   1807 / 11384 loss=0.459858, wps=935.8, ups=0.49, wpb=1918.1, bsz=128, num_updates=1800, lr=2.4e-06, gnorm=51.85, clip=100, loss_scale=32, train_wall=72, gb_free=9.8, wall=2812
2025-10-30 19:41:47 | INFO | train_inner | epoch 001:   1857 / 11384 loss=0.476307, wps=779.1, ups=0.4, wpb=1970, bsz=128, num_updates=1850, lr=2.46667e-06, gnorm=49.776, clip=100, loss_scale=32, train_wall=107, gb_free=14.9, wall=2939
2025-10-30 19:42:38 | INFO | train_inner | epoch 001:   1907 / 11384 loss=0.442821, wps=1925.2, ups=0.98, wpb=1966.9, bsz=128, num_updates=1900, lr=2.53333e-06, gnorm=49.36, clip=100, loss_scale=64, train_wall=51, gb_free=14.7, wall=2990
2025-10-30 19:44:15 | INFO | train_inner | epoch 001:   1957 / 11384 loss=0.456497, wps=1022.4, ups=0.52, wpb=1979.5, bsz=128, num_updates=1950, lr=2.6e-06, gnorm=51.06, clip=100, loss_scale=64, train_wall=96, gb_free=11.6, wall=3086
2025-10-30 19:47:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 19:47:08 | INFO | train_inner | epoch 001:   2008 / 11384 loss=0.457177, wps=560.8, ups=0.29, wpb=1933.7, bsz=128, num_updates=2000, lr=2.66667e-06, gnorm=51.967, clip=100, loss_scale=64, train_wall=172, gb_free=16.4, wall=3259
2025-10-30 19:48:17 | INFO | train_inner | epoch 001:   2058 / 11384 loss=0.435237, wps=1397.8, ups=0.72, wpb=1940.3, bsz=128, num_updates=2050, lr=2.73333e-06, gnorm=48.899, clip=100, loss_scale=64, train_wall=69, gb_free=17.5, wall=3328
2025-10-30 19:49:43 | INFO | train_inner | epoch 001:   2108 / 11384 loss=0.468316, wps=1154.7, ups=0.58, wpb=1991.1, bsz=128, num_updates=2100, lr=2.8e-06, gnorm=47.101, clip=100, loss_scale=64, train_wall=86, gb_free=14.5, wall=3414
2025-10-30 19:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 19:51:06 | INFO | train_inner | epoch 001:   2159 / 11384 loss=0.452135, wps=1163, ups=0.61, wpb=1919.1, bsz=128, num_updates=2150, lr=2.86667e-06, gnorm=48.948, clip=100, loss_scale=64, train_wall=82, gb_free=16.1, wall=3497
2025-10-30 19:51:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 19:52:55 | INFO | train_inner | epoch 001:   2210 / 11384 loss=0.464193, wps=893.7, ups=0.46, wpb=1946.1, bsz=128, num_updates=2200, lr=2.93333e-06, gnorm=46.959, clip=100, loss_scale=32, train_wall=92, gb_free=14.7, wall=3606
2025-10-30 19:54:24 | INFO | train_inner | epoch 001:   2260 / 11384 loss=0.451206, wps=1083.1, ups=0.56, wpb=1941.8, bsz=128, num_updates=2250, lr=3e-06, gnorm=37.709, clip=100, loss_scale=32, train_wall=76, gb_free=16.7, wall=3696
2025-10-30 19:55:16 | INFO | train_inner | epoch 001:   2310 / 11384 loss=0.444572, wps=1867.2, ups=0.97, wpb=1922, bsz=128, num_updates=2300, lr=3.06667e-06, gnorm=40.305, clip=100, loss_scale=64, train_wall=51, gb_free=15.8, wall=3747
2025-10-30 19:55:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 19:57:16 | INFO | train_inner | epoch 001:   2361 / 11384 loss=0.466121, wps=820.7, ups=0.41, wpb=1983, bsz=128, num_updates=2350, lr=3.13333e-06, gnorm=45.08, clip=100, loss_scale=32, train_wall=101, gb_free=14.8, wall=3868
2025-10-30 19:58:39 | INFO | train_inner | epoch 001:   2411 / 11384 loss=0.426949, wps=1177.5, ups=0.61, wpb=1933.9, bsz=128, num_updates=2400, lr=3.2e-06, gnorm=36.985, clip=100, loss_scale=32, train_wall=82, gb_free=17.2, wall=3950
2025-10-30 19:59:57 | INFO | train_inner | epoch 001:   2461 / 11384 loss=0.459359, wps=1244.3, ups=0.64, wpb=1951.1, bsz=128, num_updates=2450, lr=3.26667e-06, gnorm=43.385, clip=100, loss_scale=64, train_wall=73, gb_free=17.3, wall=4028
2025-10-30 20:01:57 | INFO | train_inner | epoch 001:   2511 / 11384 loss=0.432892, wps=829.2, ups=0.42, wpb=1996.8, bsz=128, num_updates=2500, lr=3.33333e-06, gnorm=37.118, clip=100, loss_scale=64, train_wall=112, gb_free=15.8, wall=4149
2025-10-30 20:04:17 | INFO | train_inner | epoch 001:   2561 / 11384 loss=0.44154, wps=703.5, ups=0.36, wpb=1965, bsz=128, num_updates=2550, lr=3.4e-06, gnorm=39.649, clip=100, loss_scale=64, train_wall=139, gb_free=6.5, wall=4288
2025-10-30 20:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 20:05:10 | INFO | train_inner | epoch 001:   2612 / 11384 loss=0.439464, wps=1868.8, ups=0.95, wpb=1964.8, bsz=128, num_updates=2600, lr=3.46667e-06, gnorm=34.642, clip=100, loss_scale=64, train_wall=52, gb_free=10.9, wall=4341
2025-10-30 20:07:53 | INFO | train_inner | epoch 001:   2662 / 11384 loss=0.443921, wps=598.2, ups=0.31, wpb=1957.5, bsz=128, num_updates=2650, lr=3.53333e-06, gnorm=39.33, clip=100, loss_scale=64, train_wall=163, gb_free=17.1, wall=4505
2025-10-30 20:09:29 | INFO | train_inner | epoch 001:   2712 / 11384 loss=0.444408, wps=1027.7, ups=0.52, wpb=1962.3, bsz=128, num_updates=2700, lr=3.6e-06, gnorm=37.546, clip=100, loss_scale=64, train_wall=95, gb_free=11.6, wall=4600
2025-10-30 20:10:42 | INFO | train_inner | epoch 001:   2762 / 11384 loss=0.441346, wps=1311.7, ups=0.68, wpb=1933.5, bsz=128, num_updates=2750, lr=3.66667e-06, gnorm=38.881, clip=100, loss_scale=128, train_wall=63, gb_free=14.6, wall=4674
2025-10-30 20:11:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 20:12:11 | INFO | train_inner | epoch 001:   2813 / 11384 loss=0.440861, wps=1120, ups=0.57, wpb=1976.1, bsz=128, num_updates=2800, lr=3.73333e-06, gnorm=41.317, clip=100, loss_scale=64, train_wall=54, gb_free=12, wall=4762
2025-10-30 20:13:35 | INFO | train_inner | epoch 001:   2863 / 11384 loss=0.431161, wps=1164.8, ups=0.59, wpb=1962.6, bsz=128, num_updates=2850, lr=3.8e-06, gnorm=37.053, clip=100, loss_scale=64, train_wall=68, gb_free=14.1, wall=4846
2025-10-30 20:15:10 | INFO | train_inner | epoch 001:   2913 / 11384 loss=0.448726, wps=1015.3, ups=0.53, wpb=1926.4, bsz=128, num_updates=2900, lr=3.86667e-06, gnorm=37.492, clip=100, loss_scale=128, train_wall=65, gb_free=13.6, wall=4941
2025-10-30 20:15:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 20:16:42 | INFO | train_inner | epoch 001:   2964 / 11384 loss=0.42405, wps=1075.4, ups=0.54, wpb=1979.5, bsz=128, num_updates=2950, lr=3.93333e-06, gnorm=43.298, clip=100, loss_scale=64, train_wall=84, gb_free=14.9, wall=5033
2025-10-30 20:17:34 | INFO | train_inner | epoch 001:   3014 / 11384 loss=0.418896, wps=1884.8, ups=0.96, wpb=1968.3, bsz=128, num_updates=3000, lr=4e-06, gnorm=34.517, clip=100, loss_scale=64, train_wall=52, gb_free=16.4, wall=5085
2025-10-30 20:20:42 | INFO | train_inner | epoch 001:   3064 / 11384 loss=0.418349, wps=531.3, ups=0.27, wpb=1995.9, bsz=128, num_updates=3050, lr=4.06667e-06, gnorm=39.157, clip=100, loss_scale=64, train_wall=94, gb_free=12, wall=5273
2025-10-30 20:22:19 | INFO | train_inner | epoch 001:   3114 / 11384 loss=0.44132, wps=1010.5, ups=0.52, wpb=1955.3, bsz=128, num_updates=3100, lr=4.13333e-06, gnorm=37.656, clip=100, loss_scale=128, train_wall=70, gb_free=16.4, wall=5370
2025-10-30 20:23:46 | INFO | train_inner | epoch 001:   3164 / 11384 loss=0.411333, wps=1106.6, ups=0.57, wpb=1936.7, bsz=128, num_updates=3150, lr=4.2e-06, gnorm=36.956, clip=100, loss_scale=128, train_wall=54, gb_free=15.5, wall=5457
2025-10-30 20:25:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 20:25:59 | INFO | train_inner | epoch 001:   3215 / 11384 loss=0.430792, wps=739.8, ups=0.38, wpb=1961.3, bsz=128, num_updates=3200, lr=4.26667e-06, gnorm=41.495, clip=100, loss_scale=128, train_wall=132, gb_free=13.5, wall=5590
2025-10-30 20:26:52 | INFO | train_inner | epoch 001:   3265 / 11384 loss=0.421557, wps=1834.9, ups=0.93, wpb=1974.1, bsz=127.9, num_updates=3250, lr=4.33333e-06, gnorm=39.401, clip=100, loss_scale=128, train_wall=54, gb_free=13, wall=5644
2025-10-30 20:28:24 | INFO | train_inner | epoch 001:   3315 / 11384 loss=0.419576, wps=1050.2, ups=0.54, wpb=1931.5, bsz=128, num_updates=3300, lr=4.4e-06, gnorm=33.019, clip=100, loss_scale=128, train_wall=61, gb_free=13.5, wall=5736
2025-10-30 20:30:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 20:30:39 | INFO | train_inner | epoch 001:   3366 / 11384 loss=0.416668, wps=729.3, ups=0.37, wpb=1964.2, bsz=128, num_updates=3350, lr=4.46667e-06, gnorm=30.771, clip=100, loss_scale=128, train_wall=130, gb_free=7.4, wall=5870
2025-10-30 20:32:37 | INFO | train_inner | epoch 001:   3416 / 11384 loss=0.424126, wps=832.3, ups=0.43, wpb=1955.6, bsz=128, num_updates=3400, lr=4.53333e-06, gnorm=37.67, clip=100, loss_scale=128, train_wall=69, gb_free=16.2, wall=5988
2025-10-30 20:33:29 | INFO | train_inner | epoch 001:   3466 / 11384 loss=0.402433, wps=1826.7, ups=0.95, wpb=1926.5, bsz=128, num_updates=3450, lr=4.6e-06, gnorm=29.727, clip=100, loss_scale=128, train_wall=53, gb_free=15.7, wall=6041
2025-10-30 20:35:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 20:36:07 | INFO | train_inner | epoch 001:   3517 / 11384 loss=0.431895, wps=622.8, ups=0.32, wpb=1969.7, bsz=128, num_updates=3500, lr=4.66667e-06, gnorm=38.562, clip=100, loss_scale=128, train_wall=90, gb_free=13.2, wall=6199
2025-10-30 20:37:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 20:37:32 | INFO | train_inner | epoch 001:   3568 / 11384 loss=0.431756, wps=1148.9, ups=0.59, wpb=1950, bsz=128, num_updates=3550, lr=4.73333e-06, gnorm=33.051, clip=100, loss_scale=64, train_wall=70, gb_free=11.2, wall=6284
2025-10-30 20:38:55 | INFO | train_inner | epoch 001:   3618 / 11384 loss=0.426114, wps=1198.6, ups=0.6, wpb=1993.9, bsz=128, num_updates=3600, lr=4.8e-06, gnorm=41.167, clip=100, loss_scale=64, train_wall=83, gb_free=14.8, wall=6367
2025-10-30 20:40:55 | INFO | train_inner | epoch 001:   3668 / 11384 loss=0.405469, wps=817.3, ups=0.42, wpb=1946, bsz=128, num_updates=3650, lr=4.86667e-06, gnorm=29.033, clip=100, loss_scale=64, train_wall=119, gb_free=9.2, wall=6486
2025-10-30 20:41:50 | INFO | train_inner | epoch 001:   3718 / 11384 loss=0.405014, wps=1781.4, ups=0.9, wpb=1983.6, bsz=128, num_updates=3700, lr=4.93333e-06, gnorm=33.875, clip=100, loss_scale=128, train_wall=55, gb_free=15.4, wall=6542
2025-10-30 20:43:33 | INFO | train_inner | epoch 001:   3768 / 11384 loss=0.418593, wps=959.1, ups=0.49, wpb=1975.7, bsz=128, num_updates=3750, lr=5e-06, gnorm=32.873, clip=100, loss_scale=128, train_wall=103, gb_free=15.6, wall=6645
2025-10-30 20:45:20 | INFO | train_inner | epoch 001:   3818 / 11384 loss=0.383806, wps=918.5, ups=0.47, wpb=1968.6, bsz=128, num_updates=3800, lr=5.06667e-06, gnorm=28.691, clip=100, loss_scale=128, train_wall=75, gb_free=17, wall=6752
2025-10-30 20:45:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 20:46:13 | INFO | train_inner | epoch 001:   3869 / 11384 loss=0.411366, wps=1855.3, ups=0.96, wpb=1933.1, bsz=128, num_updates=3850, lr=5.13333e-06, gnorm=33.281, clip=100, loss_scale=128, train_wall=52, gb_free=12.6, wall=6804
2025-10-30 20:48:23 | INFO | train_inner | epoch 001:   3919 / 11384 loss=0.421983, wps=751.4, ups=0.38, wpb=1965.2, bsz=128, num_updates=3900, lr=5.2e-06, gnorm=33.546, clip=100, loss_scale=128, train_wall=106, gb_free=11.6, wall=6935
2025-10-30 20:49:57 | INFO | train_inner | epoch 001:   3969 / 11384 loss=0.402344, wps=1058.7, ups=0.53, wpb=1989.3, bsz=128, num_updates=3950, lr=5.26667e-06, gnorm=33.828, clip=100, loss_scale=256, train_wall=86, gb_free=12.4, wall=7029
2025-10-30 20:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 20:51:30 | INFO | train_inner | epoch 001:   4020 / 11384 loss=0.407258, wps=1039.3, ups=0.54, wpb=1932.8, bsz=128, num_updates=4000, lr=5.33333e-06, gnorm=35.709, clip=100, loss_scale=128, train_wall=93, gb_free=16.3, wall=7122
2025-10-30 20:53:54 | INFO | train_inner | epoch 001:   4070 / 11384 loss=0.393607, wps=675.2, ups=0.35, wpb=1945.2, bsz=128, num_updates=4050, lr=5.4e-06, gnorm=31.666, clip=100, loss_scale=128, train_wall=144, gb_free=15, wall=7266
2025-10-30 20:54:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 20:55:28 | INFO | train_inner | epoch 001:   4121 / 11384 loss=0.396123, wps=1039.6, ups=0.53, wpb=1947.8, bsz=128, num_updates=4100, lr=5.46667e-06, gnorm=32.52, clip=100, loss_scale=128, train_wall=93, gb_free=16.5, wall=7359
2025-10-30 20:56:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 20:56:42 | INFO | train_inner | epoch 001:   4172 / 11384 loss=0.400762, wps=1318.9, ups=0.68, wpb=1940.1, bsz=128, num_updates=4150, lr=5.53333e-06, gnorm=36.482, clip=100, loss_scale=64, train_wall=73, gb_free=13.3, wall=7433
2025-10-30 20:59:06 | INFO | train_inner | epoch 001:   4222 / 11384 loss=0.395692, wps=674, ups=0.35, wpb=1947.7, bsz=128, num_updates=4200, lr=5.6e-06, gnorm=37.347, clip=100, loss_scale=64, train_wall=60, gb_free=15.1, wall=7577
2025-10-30 21:00:01 | INFO | train_inner | epoch 001:   4272 / 11384 loss=0.413886, wps=1816.4, ups=0.91, wpb=1992.4, bsz=128, num_updates=4250, lr=5.66667e-06, gnorm=37.328, clip=100, loss_scale=64, train_wall=55, gb_free=10.2, wall=7632
2025-10-30 21:01:48 | INFO | train_inner | epoch 001:   4322 / 11384 loss=0.393439, wps=911.3, ups=0.47, wpb=1935.8, bsz=128, num_updates=4300, lr=5.73333e-06, gnorm=35.39, clip=100, loss_scale=128, train_wall=106, gb_free=16.5, wall=7739
2025-10-30 21:04:28 | INFO | train_inner | epoch 001:   4372 / 11384 loss=0.416126, wps=624.9, ups=0.31, wpb=1998.3, bsz=128, num_updates=4350, lr=5.8e-06, gnorm=34.325, clip=100, loss_scale=128, train_wall=160, gb_free=16.3, wall=7899
2025-10-30 21:05:58 | INFO | train_inner | epoch 001:   4422 / 11384 loss=0.419464, wps=1081.2, ups=0.55, wpb=1952.4, bsz=128, num_updates=4400, lr=5.86667e-06, gnorm=34.311, clip=100, loss_scale=256, train_wall=71, gb_free=11.6, wall=7989
2025-10-30 21:06:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:06:52 | INFO | train_inner | epoch 001:   4473 / 11384 loss=0.411935, wps=1831.8, ups=0.93, wpb=1968.7, bsz=128, num_updates=4450, lr=5.93333e-06, gnorm=37.768, clip=100, loss_scale=128, train_wall=54, gb_free=17.4, wall=8043
2025-10-30 21:08:58 | INFO | train_inner | epoch 001:   4523 / 11384 loss=0.4239, wps=783.3, ups=0.4, wpb=1974.5, bsz=128, num_updates=4500, lr=6e-06, gnorm=36.567, clip=100, loss_scale=128, train_wall=126, gb_free=15.4, wall=8169
2025-10-30 21:10:33 | INFO | train_inner | epoch 001:   4573 / 11384 loss=0.409148, wps=1032, ups=0.53, wpb=1956.4, bsz=128, num_updates=4550, lr=6.06667e-06, gnorm=37.307, clip=100, loss_scale=128, train_wall=94, gb_free=10.9, wall=8264
2025-10-30 21:10:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:11:26 | INFO | train_inner | epoch 001:   4624 / 11384 loss=0.397014, wps=1828.2, ups=0.93, wpb=1964.2, bsz=128, num_updates=4600, lr=6.13333e-06, gnorm=35.882, clip=100, loss_scale=128, train_wall=54, gb_free=13.4, wall=8318
2025-10-30 21:13:00 | INFO | train_inner | epoch 001:   4674 / 11384 loss=0.388304, wps=1035.3, ups=0.53, wpb=1943.2, bsz=128, num_updates=4650, lr=6.2e-06, gnorm=29.855, clip=100, loss_scale=128, train_wall=80, gb_free=16.5, wall=8412
2025-10-30 21:14:58 | INFO | train_inner | epoch 001:   4724 / 11384 loss=0.404642, wps=832.9, ups=0.43, wpb=1953.9, bsz=128, num_updates=4700, lr=6.26667e-06, gnorm=35.442, clip=100, loss_scale=256, train_wall=117, gb_free=16.2, wall=8529
2025-10-30 21:15:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:16:34 | INFO | train_inner | epoch 001:   4775 / 11384 loss=0.396101, wps=1031, ups=0.52, wpb=1997.5, bsz=128, num_updates=4750, lr=6.33333e-06, gnorm=34.393, clip=100, loss_scale=128, train_wall=97, gb_free=12.7, wall=8626
2025-10-30 21:17:53 | INFO | train_inner | epoch 001:   4825 / 11384 loss=0.386563, wps=1223.8, ups=0.64, wpb=1917.2, bsz=128, num_updates=4800, lr=6.4e-06, gnorm=31.933, clip=100, loss_scale=128, train_wall=78, gb_free=8.5, wall=8704
2025-10-30 21:18:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:19:17 | INFO | train_inner | epoch 001:   4876 / 11384 loss=0.411474, wps=1131, ups=0.59, wpb=1905.1, bsz=128, num_updates=4850, lr=6.46667e-06, gnorm=37.818, clip=100, loss_scale=128, train_wall=84, gb_free=16.3, wall=8788
2025-10-30 21:20:22 | INFO | train_inner | epoch 001:   4926 / 11384 loss=0.392988, wps=1528.3, ups=0.77, wpb=1982.8, bsz=128, num_updates=4900, lr=6.53333e-06, gnorm=30.38, clip=100, loss_scale=128, train_wall=65, gb_free=17.3, wall=8853
2025-10-30 21:21:38 | INFO | train_inner | epoch 001:   4976 / 11384 loss=0.393289, wps=1274, ups=0.66, wpb=1938.5, bsz=128, num_updates=4950, lr=6.6e-06, gnorm=32.361, clip=100, loss_scale=128, train_wall=65, gb_free=16.7, wall=8930
2025-10-30 21:22:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:22:33 | INFO | train_inner | epoch 001:   5027 / 11384 loss=0.375245, wps=1758.6, ups=0.91, wpb=1929.2, bsz=128, num_updates=5000, lr=6.66667e-06, gnorm=32.642, clip=100, loss_scale=128, train_wall=55, gb_free=16.5, wall=8985
2025-10-30 21:23:53 | INFO | train_inner | epoch 001:   5077 / 11384 loss=0.39171, wps=1211.9, ups=0.63, wpb=1924, bsz=128, num_updates=5050, lr=6.73333e-06, gnorm=34.834, clip=100, loss_scale=128, train_wall=79, gb_free=10.9, wall=9064
2025-10-30 21:26:23 | INFO | train_inner | epoch 001:   5127 / 11384 loss=0.382204, wps=655.9, ups=0.33, wpb=1975.1, bsz=128, num_updates=5100, lr=6.8e-06, gnorm=31.778, clip=100, loss_scale=256, train_wall=150, gb_free=13.7, wall=9214
2025-10-30 21:26:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:27:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 21:27:45 | INFO | train_inner | epoch 001:   5179 / 11384 loss=0.391838, wps=1213.4, ups=0.62, wpb=1972.7, bsz=128, num_updates=5150, lr=6.86667e-06, gnorm=33.943, clip=100, loss_scale=64, train_wall=81, gb_free=13.6, wall=9296
2025-10-30 21:29:02 | INFO | train_inner | epoch 001:   5229 / 11384 loss=0.407284, wps=1266.9, ups=0.65, wpb=1962.6, bsz=128, num_updates=5200, lr=6.93333e-06, gnorm=42.977, clip=100, loss_scale=64, train_wall=77, gb_free=7.7, wall=9373
2025-10-30 21:30:05 | INFO | train_inner | epoch 001:   5279 / 11384 loss=0.391732, wps=1556.6, ups=0.8, wpb=1954.4, bsz=128, num_updates=5250, lr=7e-06, gnorm=33.727, clip=100, loss_scale=128, train_wall=63, gb_free=14.3, wall=9436
2025-10-30 21:31:01 | INFO | train_inner | epoch 001:   5329 / 11384 loss=0.378045, wps=1728.8, ups=0.89, wpb=1943.2, bsz=128, num_updates=5300, lr=7.06667e-06, gnorm=33.197, clip=100, loss_scale=128, train_wall=56, gb_free=16.4, wall=9492
2025-10-30 21:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 21:32:08 | INFO | train_inner | epoch 001:   5380 / 11384 loss=0.397691, wps=1475, ups=0.75, wpb=1976.8, bsz=128, num_updates=5350, lr=7.13333e-06, gnorm=42.222, clip=100, loss_scale=64, train_wall=67, gb_free=11.9, wall=9559
2025-10-30 21:33:04 | INFO | train_inner | epoch 001:   5430 / 11384 loss=0.382423, wps=1762.2, ups=0.9, wpb=1957.8, bsz=128, num_updates=5400, lr=7.2e-06, gnorm=40.47, clip=100, loss_scale=64, train_wall=55, gb_free=12.5, wall=9615
2025-10-30 21:34:04 | INFO | train_inner | epoch 001:   5480 / 11384 loss=0.388218, wps=1641.6, ups=0.83, wpb=1970.5, bsz=128, num_updates=5450, lr=7.26667e-06, gnorm=38.996, clip=100, loss_scale=64, train_wall=60, gb_free=8.1, wall=9675
2025-10-30 21:35:12 | INFO | train_inner | epoch 001:   5530 / 11384 loss=0.385207, wps=1438.1, ups=0.74, wpb=1952.3, bsz=128, num_updates=5500, lr=7.33333e-06, gnorm=34.968, clip=100, loss_scale=128, train_wall=68, gb_free=10.9, wall=9743
2025-10-30 21:36:03 | INFO | train_inner | epoch 001:   5580 / 11384 loss=0.371907, wps=1915.7, ups=0.98, wpb=1963.2, bsz=128, num_updates=5550, lr=7.4e-06, gnorm=31.631, clip=100, loss_scale=128, train_wall=51, gb_free=9.2, wall=9794
2025-10-30 21:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:37:01 | INFO | train_inner | epoch 001:   5631 / 11384 loss=0.393103, wps=1697.4, ups=0.87, wpb=1956.9, bsz=128, num_updates=5600, lr=7.46667e-06, gnorm=38.105, clip=100, loss_scale=128, train_wall=57, gb_free=14.9, wall=9852
2025-10-30 21:37:58 | INFO | train_inner | epoch 001:   5681 / 11384 loss=0.378471, wps=1687.3, ups=0.87, wpb=1940.6, bsz=128, num_updates=5650, lr=7.53333e-06, gnorm=31.058, clip=100, loss_scale=128, train_wall=57, gb_free=11.1, wall=9909
2025-10-30 21:38:53 | INFO | train_inner | epoch 001:   5731 / 11384 loss=0.376711, wps=1778.1, ups=0.91, wpb=1960.8, bsz=128, num_updates=5700, lr=7.6e-06, gnorm=38.454, clip=100, loss_scale=128, train_wall=55, gb_free=16.4, wall=9965
2025-10-30 21:39:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:39:49 | INFO | train_inner | epoch 001:   5782 / 11384 loss=0.378861, wps=1729.9, ups=0.9, wpb=1929.5, bsz=128, num_updates=5750, lr=7.66667e-06, gnorm=36.758, clip=100, loss_scale=128, train_wall=56, gb_free=13.2, wall=10021
2025-10-30 21:40:53 | INFO | train_inner | epoch 001:   5832 / 11384 loss=0.370776, wps=1496.4, ups=0.78, wpb=1922.7, bsz=128, num_updates=5800, lr=7.73333e-06, gnorm=33.087, clip=100, loss_scale=128, train_wall=64, gb_free=17.2, wall=10085
2025-10-30 21:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2025-10-30 21:42:20 | INFO | train_inner | epoch 001:   5883 / 11384 loss=0.394565, wps=1135.7, ups=0.58, wpb=1967.3, bsz=128, num_updates=5850, lr=7.8e-06, gnorm=34.454, clip=100, loss_scale=128, train_wall=86, gb_free=13.6, wall=10171
2025-10-30 21:43:54 | INFO | train_inner | epoch 001:   5933 / 11384 loss=0.366458, wps=1024.1, ups=0.53, wpb=1932.1, bsz=128, num_updates=5900, lr=7.86667e-06, gnorm=34.912, clip=100, loss_scale=128, train_wall=94, gb_free=15.4, wall=10266
2025-10-30 21:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 21:45:00 | INFO | train_inner | epoch 001:   5984 / 11384 loss=0.354068, wps=1466.7, ups=0.76, wpb=1925, bsz=128, num_updates=5950, lr=7.93333e-06, gnorm=35.46, clip=100, loss_scale=64, train_wall=65, gb_free=15.9, wall=10331
2025-10-30 21:46:09 | INFO | train_inner | epoch 001:   6034 / 11384 loss=0.369594, wps=1404.7, ups=0.72, wpb=1948.1, bsz=128, num_updates=6000, lr=8e-06, gnorm=40.527, clip=100, loss_scale=64, train_wall=69, gb_free=15, wall=10401
2025-10-30 21:47:11 | INFO | train_inner | epoch 001:   6084 / 11384 loss=0.357428, wps=1618, ups=0.82, wpb=1982.3, bsz=128, num_updates=6050, lr=8.06667e-06, gnorm=37.616, clip=100, loss_scale=128, train_wall=61, gb_free=16.1, wall=10462
2025-10-30 21:47:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 21:47:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 21:48:08 | INFO | train_inner | epoch 001:   6136 / 11384 loss=0.362299, wps=1662.3, ups=0.87, wpb=1907.9, bsz=128, num_updates=6100, lr=8.13333e-06, gnorm=41.378, clip=100, loss_scale=32, train_wall=57, gb_free=16.8, wall=10520
2025-10-30 21:49:04 | INFO | train_inner | epoch 001:   6186 / 11384 loss=0.372125, wps=1763.3, ups=0.89, wpb=1972, bsz=128, num_updates=6150, lr=8.2e-06, gnorm=35.622, clip=100, loss_scale=32, train_wall=56, gb_free=12.3, wall=10576
2025-10-30 21:50:09 | INFO | train_inner | epoch 001:   6236 / 11384 loss=0.385025, wps=1533.4, ups=0.78, wpb=1961.4, bsz=128, num_updates=6200, lr=8.26667e-06, gnorm=34.977, clip=100, loss_scale=64, train_wall=64, gb_free=16.8, wall=10640
2025-10-30 21:51:06 | INFO | train_inner | epoch 001:   6286 / 11384 loss=0.396457, wps=1678.2, ups=0.87, wpb=1922.3, bsz=128, num_updates=6250, lr=8.33333e-06, gnorm=39.962, clip=100, loss_scale=64, train_wall=57, gb_free=13.3, wall=10697
2025-10-30 21:52:11 | INFO | train_inner | epoch 001:   6336 / 11384 loss=0.368964, wps=1520.9, ups=0.77, wpb=1967.3, bsz=128, num_updates=6300, lr=8.4e-06, gnorm=32.801, clip=100, loss_scale=64, train_wall=64, gb_free=15.7, wall=10762
2025-10-30 21:53:14 | INFO | train_inner | epoch 001:   6386 / 11384 loss=0.369384, wps=1534.8, ups=0.79, wpb=1948.8, bsz=128, num_updates=6350, lr=8.46667e-06, gnorm=35.992, clip=100, loss_scale=128, train_wall=63, gb_free=15.7, wall=10825
2025-10-30 21:53:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 21:54:14 | INFO | train_inner | epoch 001:   6437 / 11384 loss=0.340715, wps=1655.9, ups=0.84, wpb=1969.9, bsz=128, num_updates=6400, lr=8.53333e-06, gnorm=32.6, clip=100, loss_scale=64, train_wall=59, gb_free=15, wall=10885
2025-10-30 21:55:38 | INFO | train_inner | epoch 001:   6487 / 11384 loss=0.360352, wps=1176.2, ups=0.6, wpb=1975.8, bsz=128, num_updates=6450, lr=8.6e-06, gnorm=35.693, clip=100, loss_scale=64, train_wall=84, gb_free=12, wall=10969
2025-10-30 21:56:38 | INFO | train_inner | epoch 001:   6537 / 11384 loss=0.351918, wps=1610.8, ups=0.82, wpb=1962.7, bsz=128, num_updates=6500, lr=8.66667e-06, gnorm=32.12, clip=100, loss_scale=64, train_wall=61, gb_free=13.3, wall=11030
2025-10-30 21:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 21:57:38 | INFO | train_inner | epoch 001:   6588 / 11384 loss=0.34981, wps=1642.8, ups=0.84, wpb=1954.3, bsz=128, num_updates=6550, lr=8.73333e-06, gnorm=34.852, clip=100, loss_scale=64, train_wall=59, gb_free=14, wall=11089
2025-10-30 21:58:39 | INFO | train_inner | epoch 001:   6638 / 11384 loss=0.37333, wps=1591.3, ups=0.82, wpb=1946.3, bsz=128, num_updates=6600, lr=8.8e-06, gnorm=37.125, clip=100, loss_scale=64, train_wall=61, gb_free=15.8, wall=11150
2025-10-30 21:59:53 | INFO | train_inner | epoch 001:   6688 / 11384 loss=0.35729, wps=1352.9, ups=0.68, wpb=1998.9, bsz=128, num_updates=6650, lr=8.86667e-06, gnorm=35.718, clip=100, loss_scale=64, train_wall=74, gb_free=15.8, wall=11224
2025-10-30 22:01:03 | INFO | train_inner | epoch 001:   6738 / 11384 loss=0.355409, wps=1409.3, ups=0.71, wpb=1980.7, bsz=128, num_updates=6700, lr=8.93333e-06, gnorm=35.295, clip=100, loss_scale=128, train_wall=70, gb_free=13.6, wall=11295
2025-10-30 22:01:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:02:16 | INFO | train_inner | epoch 001:   6789 / 11384 loss=0.356252, wps=1350, ups=0.69, wpb=1953.3, bsz=128, num_updates=6750, lr=9e-06, gnorm=37.775, clip=100, loss_scale=64, train_wall=72, gb_free=15.5, wall=11367
2025-10-30 22:03:18 | INFO | train_inner | epoch 001:   6839 / 11384 loss=0.371448, wps=1583.7, ups=0.81, wpb=1957.2, bsz=128, num_updates=6800, lr=9.06667e-06, gnorm=38.412, clip=100, loss_scale=64, train_wall=62, gb_free=15.1, wall=11429
2025-10-30 22:04:27 | INFO | train_inner | epoch 001:   6889 / 11384 loss=0.374012, wps=1399.2, ups=0.72, wpb=1953.3, bsz=128, num_updates=6850, lr=9.13333e-06, gnorm=35.421, clip=100, loss_scale=64, train_wall=65, gb_free=15.9, wall=11499
2025-10-30 22:05:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:05:32 | INFO | train_inner | epoch 001:   6940 / 11384 loss=0.363977, wps=1482.1, ups=0.77, wpb=1912.4, bsz=128, num_updates=6900, lr=9.2e-06, gnorm=34.852, clip=100, loss_scale=64, train_wall=64, gb_free=15, wall=11563
2025-10-30 22:06:32 | INFO | train_inner | epoch 001:   6990 / 11384 loss=0.392397, wps=1619.9, ups=0.83, wpb=1947.5, bsz=128, num_updates=6950, lr=9.26667e-06, gnorm=43.132, clip=100, loss_scale=64, train_wall=60, gb_free=16.2, wall=11623
2025-10-30 22:07:34 | INFO | train_inner | epoch 001:   7040 / 11384 loss=0.377913, wps=1584.1, ups=0.81, wpb=1966.4, bsz=128, num_updates=7000, lr=9.33333e-06, gnorm=35.878, clip=100, loss_scale=64, train_wall=62, gb_free=12.4, wall=11685
2025-10-30 22:08:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:08:45 | INFO | train_inner | epoch 001:   7091 / 11384 loss=0.351805, wps=1377.5, ups=0.71, wpb=1940.9, bsz=128, num_updates=7050, lr=9.4e-06, gnorm=30.712, clip=100, loss_scale=64, train_wall=70, gb_free=14.8, wall=11756
2025-10-30 22:09:48 | INFO | train_inner | epoch 001:   7141 / 11384 loss=0.362855, wps=1542.2, ups=0.79, wpb=1946.9, bsz=128, num_updates=7100, lr=9.46667e-06, gnorm=36.126, clip=100, loss_scale=64, train_wall=63, gb_free=16.2, wall=11819
2025-10-30 22:11:00 | INFO | train_inner | epoch 001:   7191 / 11384 loss=0.356082, wps=1349, ups=0.69, wpb=1954.6, bsz=128, num_updates=7150, lr=9.53333e-06, gnorm=36.085, clip=100, loss_scale=64, train_wall=72, gb_free=11.7, wall=11891
2025-10-30 22:11:57 | INFO | train_inner | epoch 001:   7241 / 11384 loss=0.35387, wps=1714, ups=0.88, wpb=1956.7, bsz=128, num_updates=7200, lr=9.6e-06, gnorm=33.634, clip=100, loss_scale=128, train_wall=57, gb_free=17, wall=11949
2025-10-30 22:12:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:12:58 | INFO | train_inner | epoch 001:   7292 / 11384 loss=0.359981, wps=1607.4, ups=0.82, wpb=1954.3, bsz=128, num_updates=7250, lr=9.66667e-06, gnorm=35.146, clip=100, loss_scale=64, train_wall=60, gb_free=15.4, wall=12010
2025-10-30 22:14:07 | INFO | train_inner | epoch 001:   7342 / 11384 loss=0.359211, wps=1469.1, ups=0.73, wpb=2012.1, bsz=128, num_updates=7300, lr=9.73333e-06, gnorm=41.552, clip=100, loss_scale=64, train_wall=68, gb_free=10.7, wall=12078
2025-10-30 22:15:07 | INFO | train_inner | epoch 001:   7392 / 11384 loss=0.355184, wps=1596.9, ups=0.82, wpb=1936.7, bsz=128, num_updates=7350, lr=9.8e-06, gnorm=34.446, clip=100, loss_scale=128, train_wall=60, gb_free=17, wall=12139
2025-10-30 22:15:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:16:19 | INFO | train_inner | epoch 001:   7443 / 11384 loss=0.35353, wps=1422.8, ups=0.7, wpb=2026.1, bsz=128, num_updates=7400, lr=9.86667e-06, gnorm=37.441, clip=100, loss_scale=64, train_wall=71, gb_free=14.1, wall=12210
2025-10-30 22:17:17 | INFO | train_inner | epoch 001:   7493 / 11384 loss=0.362348, wps=1656.1, ups=0.85, wpb=1947.1, bsz=128, num_updates=7450, lr=9.93333e-06, gnorm=33.15, clip=100, loss_scale=64, train_wall=59, gb_free=15.7, wall=12269
2025-10-30 22:18:23 | INFO | train_inner | epoch 001:   7543 / 11384 loss=0.36161, wps=1525.8, ups=0.76, wpb=1996.5, bsz=128, num_updates=7500, lr=1e-05, gnorm=40.39, clip=100, loss_scale=128, train_wall=65, gb_free=7.8, wall=12334
2025-10-30 22:18:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:19:34 | INFO | train_inner | epoch 001:   7594 / 11384 loss=0.386989, wps=1384.5, ups=0.71, wpb=1957, bsz=128, num_updates=7550, lr=1.00667e-05, gnorm=35.328, clip=100, loss_scale=64, train_wall=70, gb_free=13.7, wall=12405
2025-10-30 22:20:41 | INFO | train_inner | epoch 001:   7644 / 11384 loss=0.347566, wps=1474.4, ups=0.74, wpb=1985, bsz=128, num_updates=7600, lr=1.01333e-05, gnorm=35.124, clip=100, loss_scale=64, train_wall=67, gb_free=14.4, wall=12472
2025-10-30 22:22:02 | INFO | train_inner | epoch 001:   7694 / 11384 loss=0.352271, wps=1212.9, ups=0.62, wpb=1968.5, bsz=128, num_updates=7650, lr=1.02e-05, gnorm=39.178, clip=100, loss_scale=128, train_wall=81, gb_free=16.5, wall=12554
2025-10-30 22:22:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:23:09 | INFO | train_inner | epoch 001:   7745 / 11384 loss=0.353811, wps=1470.5, ups=0.75, wpb=1971.9, bsz=128, num_updates=7700, lr=1.02667e-05, gnorm=38.049, clip=100, loss_scale=64, train_wall=67, gb_free=13.4, wall=12621
2025-10-30 22:24:11 | INFO | train_inner | epoch 001:   7795 / 11384 loss=0.350103, wps=1557, ups=0.81, wpb=1922.2, bsz=128, num_updates=7750, lr=1.03333e-05, gnorm=36.599, clip=100, loss_scale=64, train_wall=62, gb_free=15.9, wall=12682
2025-10-30 22:25:23 | INFO | train_inner | epoch 001:   7845 / 11384 loss=0.339023, wps=1377.9, ups=0.69, wpb=1983.9, bsz=128, num_updates=7800, lr=1.04e-05, gnorm=32.931, clip=100, loss_scale=128, train_wall=72, gb_free=14.3, wall=12754
2025-10-30 22:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:26:28 | INFO | train_inner | epoch 001:   7896 / 11384 loss=0.344988, wps=1542.6, ups=0.78, wpb=1988.8, bsz=128, num_updates=7850, lr=1.04667e-05, gnorm=33.992, clip=100, loss_scale=64, train_wall=64, gb_free=12.8, wall=12819
2025-10-30 22:27:32 | INFO | train_inner | epoch 001:   7946 / 11384 loss=0.356523, wps=1534.8, ups=0.77, wpb=1991.7, bsz=128, num_updates=7900, lr=1.05333e-05, gnorm=39.789, clip=100, loss_scale=64, train_wall=65, gb_free=16.5, wall=12884
2025-10-30 22:28:37 | INFO | train_inner | epoch 001:   7996 / 11384 loss=0.347105, wps=1531.9, ups=0.77, wpb=1985.4, bsz=128, num_updates=7950, lr=1.06e-05, gnorm=35.868, clip=100, loss_scale=128, train_wall=65, gb_free=15.5, wall=12949
2025-10-30 22:28:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:29:46 | INFO | train_inner | epoch 001:   8047 / 11384 loss=0.348893, wps=1424.2, ups=0.73, wpb=1951.8, bsz=128, num_updates=8000, lr=1.06667e-05, gnorm=40.54, clip=100, loss_scale=64, train_wall=68, gb_free=15.6, wall=13017
2025-10-30 22:30:45 | INFO | train_inner | epoch 001:   8097 / 11384 loss=0.357006, wps=1656.1, ups=0.85, wpb=1945.4, bsz=128, num_updates=8050, lr=1.07333e-05, gnorm=38.247, clip=100, loss_scale=64, train_wall=58, gb_free=16.2, wall=13076
2025-10-30 22:31:47 | INFO | train_inner | epoch 001:   8147 / 11384 loss=0.345227, wps=1555.8, ups=0.8, wpb=1933.6, bsz=128, num_updates=8100, lr=1.08e-05, gnorm=36.809, clip=100, loss_scale=128, train_wall=62, gb_free=15.5, wall=13138
2025-10-30 22:32:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:32:44 | INFO | train_inner | epoch 001:   8198 / 11384 loss=0.361827, wps=1755.1, ups=0.88, wpb=1989.7, bsz=128, num_updates=8150, lr=1.08667e-05, gnorm=39.458, clip=100, loss_scale=64, train_wall=56, gb_free=16.8, wall=13195
2025-10-30 22:33:54 | INFO | train_inner | epoch 001:   8248 / 11384 loss=0.340794, wps=1407.5, ups=0.71, wpb=1991.1, bsz=128, num_updates=8200, lr=1.09333e-05, gnorm=37.883, clip=100, loss_scale=64, train_wall=70, gb_free=13.3, wall=13266
2025-10-30 22:34:54 | INFO | train_inner | epoch 001:   8298 / 11384 loss=0.327522, wps=1643, ups=0.84, wpb=1957.3, bsz=128, num_updates=8250, lr=1.1e-05, gnorm=37.116, clip=100, loss_scale=64, train_wall=59, gb_free=15.1, wall=13325
2025-10-30 22:35:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:36:05 | INFO | train_inner | epoch 001:   8349 / 11384 loss=0.338621, wps=1372.4, ups=0.71, wpb=1945.3, bsz=128, num_updates=8300, lr=1.10667e-05, gnorm=37.701, clip=100, loss_scale=64, train_wall=71, gb_free=13.4, wall=13396
2025-10-30 22:37:34 | INFO | train_inner | epoch 001:   8399 / 11384 loss=0.328807, wps=1110.6, ups=0.56, wpb=1968.8, bsz=128, num_updates=8350, lr=1.11333e-05, gnorm=38.51, clip=100, loss_scale=64, train_wall=88, gb_free=15, wall=13485
2025-10-30 22:38:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:38:32 | INFO | train_inner | epoch 001:   8450 / 11384 loss=0.356217, wps=1718.2, ups=0.87, wpb=1975.1, bsz=128, num_updates=8400, lr=1.12e-05, gnorm=42.464, clip=100, loss_scale=64, train_wall=57, gb_free=14.5, wall=13544
2025-10-30 22:39:34 | INFO | train_inner | epoch 001:   8500 / 11384 loss=0.348511, wps=1573, ups=0.81, wpb=1951.9, bsz=128, num_updates=8450, lr=1.12667e-05, gnorm=38.195, clip=100, loss_scale=64, train_wall=62, gb_free=17.1, wall=13606
2025-10-30 22:40:42 | INFO | train_inner | epoch 001:   8550 / 11384 loss=0.336282, wps=1427.3, ups=0.74, wpb=1939.7, bsz=128, num_updates=8500, lr=1.13333e-05, gnorm=31.849, clip=100, loss_scale=64, train_wall=68, gb_free=15.1, wall=13674
2025-10-30 22:41:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:41:58 | INFO | train_inner | epoch 001:   8601 / 11384 loss=0.339599, wps=1251.6, ups=0.66, wpb=1898.3, bsz=128, num_updates=8550, lr=1.14e-05, gnorm=34.496, clip=100, loss_scale=64, train_wall=76, gb_free=15.7, wall=13749
2025-10-30 22:42:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 22:43:04 | INFO | train_inner | epoch 001:   8652 / 11384 loss=0.338146, wps=1533.3, ups=0.76, wpb=2010.7, bsz=128, num_updates=8600, lr=1.14667e-05, gnorm=35.344, clip=100, loss_scale=32, train_wall=61, gb_free=14.6, wall=13815
2025-10-30 22:44:04 | INFO | train_inner | epoch 001:   8702 / 11384 loss=0.338799, wps=1627.7, ups=0.84, wpb=1948.9, bsz=128, num_updates=8650, lr=1.15333e-05, gnorm=38.158, clip=100, loss_scale=32, train_wall=60, gb_free=17.1, wall=13875
2025-10-30 22:45:03 | INFO | train_inner | epoch 001:   8752 / 11384 loss=0.336054, wps=1673.7, ups=0.85, wpb=1976.2, bsz=128, num_updates=8700, lr=1.16e-05, gnorm=36.096, clip=100, loss_scale=32, train_wall=59, gb_free=14.7, wall=13934
2025-10-30 22:46:05 | INFO | train_inner | epoch 001:   8802 / 11384 loss=0.339551, wps=1575.3, ups=0.81, wpb=1949.7, bsz=128, num_updates=8750, lr=1.16667e-05, gnorm=43.002, clip=100, loss_scale=64, train_wall=54, gb_free=14.5, wall=13996
2025-10-30 22:46:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 22:47:20 | INFO | train_inner | epoch 001:   8853 / 11384 loss=0.344385, wps=1301.8, ups=0.67, wpb=1957, bsz=128, num_updates=8800, lr=1.17333e-05, gnorm=38.608, clip=100, loss_scale=32, train_wall=64, gb_free=14.3, wall=14071
2025-10-30 22:48:13 | INFO | train_inner | epoch 001:   8903 / 11384 loss=0.342528, wps=1832.8, ups=0.94, wpb=1957.8, bsz=128, num_updates=8850, lr=1.18e-05, gnorm=32.18, clip=100, loss_scale=32, train_wall=53, gb_free=12, wall=14124
2025-10-30 22:49:16 | INFO | train_inner | epoch 001:   8953 / 11384 loss=0.334198, wps=1606.2, ups=0.8, wpb=2008.9, bsz=128, num_updates=8900, lr=1.18667e-05, gnorm=39.108, clip=100, loss_scale=64, train_wall=62, gb_free=12.4, wall=14187
2025-10-30 22:50:21 | INFO | train_inner | epoch 001:   9003 / 11384 loss=0.333925, wps=1504.2, ups=0.76, wpb=1967, bsz=128, num_updates=8950, lr=1.19333e-05, gnorm=33.964, clip=100, loss_scale=64, train_wall=65, gb_free=17.1, wall=14252
2025-10-30 22:51:18 | INFO | train_inner | epoch 001:   9053 / 11384 loss=0.347216, wps=1697.2, ups=0.88, wpb=1937.5, bsz=128, num_updates=9000, lr=1.2e-05, gnorm=38.131, clip=100, loss_scale=64, train_wall=57, gb_free=14.5, wall=14309
2025-10-30 22:51:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 22:52:34 | INFO | train_inner | epoch 001:   9104 / 11384 loss=0.341861, wps=1290.3, ups=0.66, wpb=1952.4, bsz=128, num_updates=9050, lr=1.20667e-05, gnorm=39.176, clip=100, loss_scale=64, train_wall=59, gb_free=16.5, wall=14385
2025-10-30 22:53:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 22:53:42 | INFO | train_inner | epoch 001:   9155 / 11384 loss=0.330781, wps=1450.7, ups=0.73, wpb=1978.8, bsz=128, num_updates=9100, lr=1.21333e-05, gnorm=36.1, clip=100, loss_scale=32, train_wall=58, gb_free=14.3, wall=14453
2025-10-30 22:54:46 | INFO | train_inner | epoch 001:   9205 / 11384 loss=0.336696, wps=1555.4, ups=0.78, wpb=1982.4, bsz=128, num_updates=9150, lr=1.22e-05, gnorm=37.243, clip=100, loss_scale=32, train_wall=59, gb_free=14.6, wall=14517
2025-10-30 22:55:50 | INFO | train_inner | epoch 001:   9255 / 11384 loss=0.325839, wps=1497.3, ups=0.77, wpb=1937.8, bsz=128, num_updates=9200, lr=1.22667e-05, gnorm=35.668, clip=100, loss_scale=32, train_wall=52, gb_free=12, wall=14582
2025-10-30 22:57:15 | INFO | train_inner | epoch 001:   9305 / 11384 loss=0.322557, wps=1180.7, ups=0.59, wpb=2002.9, bsz=128, num_updates=9250, lr=1.23333e-05, gnorm=39.345, clip=100, loss_scale=64, train_wall=64, gb_free=16.1, wall=14667
2025-10-30 22:58:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 22:58:29 | INFO | train_inner | epoch 001:   9356 / 11384 loss=0.32311, wps=1334.6, ups=0.68, wpb=1965.1, bsz=128, num_updates=9300, lr=1.24e-05, gnorm=39.152, clip=100, loss_scale=32, train_wall=73, gb_free=11.5, wall=14740
2025-10-30 22:59:42 | INFO | train_inner | epoch 001:   9406 / 11384 loss=0.347581, wps=1379.1, ups=0.69, wpb=2007.6, bsz=128, num_updates=9350, lr=1.24667e-05, gnorm=37.087, clip=100, loss_scale=32, train_wall=73, gb_free=16.8, wall=14813
2025-10-30 23:00:41 | INFO | train_inner | epoch 001:   9456 / 11384 loss=0.345535, wps=1617.6, ups=0.84, wpb=1918.8, bsz=128, num_updates=9400, lr=1.25333e-05, gnorm=43.154, clip=100, loss_scale=32, train_wall=59, gb_free=13, wall=14873
2025-10-30 23:01:44 | INFO | train_inner | epoch 001:   9506 / 11384 loss=0.336593, wps=1547.5, ups=0.79, wpb=1955.5, bsz=128, num_updates=9450, lr=1.26e-05, gnorm=40.346, clip=100, loss_scale=64, train_wall=63, gb_free=17.2, wall=14936
2025-10-30 23:02:56 | INFO | train_inner | epoch 001:   9556 / 11384 loss=0.333914, wps=1375.6, ups=0.7, wpb=1956.9, bsz=128, num_updates=9500, lr=1.26667e-05, gnorm=38.285, clip=100, loss_scale=64, train_wall=71, gb_free=12.8, wall=15007
2025-10-30 23:04:04 | INFO | train_inner | epoch 001:   9606 / 11384 loss=0.325981, wps=1431.3, ups=0.74, wpb=1942.8, bsz=128, num_updates=9550, lr=1.27333e-05, gnorm=38.472, clip=100, loss_scale=128, train_wall=68, gb_free=16, wall=15075
2025-10-30 23:05:06 | INFO | train_inner | epoch 001:   9656 / 11384 loss=0.326587, wps=1606.6, ups=0.81, wpb=1992.1, bsz=128, num_updates=9600, lr=1.28e-05, gnorm=37.815, clip=100, loss_scale=128, train_wall=62, gb_free=11.7, wall=15137
2025-10-30 23:05:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 23:06:20 | INFO | train_inner | epoch 001:   9707 / 11384 loss=0.310251, wps=1328.9, ups=0.68, wpb=1968.2, bsz=128, num_updates=9650, lr=1.28667e-05, gnorm=33.591, clip=100, loss_scale=64, train_wall=74, gb_free=5.1, wall=15211
2025-10-30 23:06:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 23:07:18 | INFO | train_inner | epoch 001:   9758 / 11384 loss=0.319081, wps=1713.5, ups=0.86, wpb=1987.5, bsz=128, num_updates=9700, lr=1.29333e-05, gnorm=41.472, clip=100, loss_scale=32, train_wall=56, gb_free=15.9, wall=15269
2025-10-30 23:08:24 | INFO | train_inner | epoch 001:   9808 / 11384 loss=0.331517, wps=1449.1, ups=0.75, wpb=1928.5, bsz=128, num_updates=9750, lr=1.3e-05, gnorm=38.791, clip=100, loss_scale=32, train_wall=54, gb_free=12.8, wall=15336
2025-10-30 23:09:24 | INFO | train_inner | epoch 001:   9858 / 11384 loss=0.318006, wps=1624, ups=0.84, wpb=1943.9, bsz=128, num_updates=9800, lr=1.30667e-05, gnorm=38.649, clip=100, loss_scale=64, train_wall=60, gb_free=17.7, wall=15396
2025-10-30 23:10:44 | INFO | train_inner | epoch 001:   9908 / 11384 loss=0.34213, wps=1226.8, ups=0.63, wpb=1947.6, bsz=128, num_updates=9850, lr=1.31333e-05, gnorm=40.98, clip=100, loss_scale=64, train_wall=79, gb_free=11.3, wall=15475
2025-10-30 23:12:05 | INFO | train_inner | epoch 001:   9958 / 11384 loss=0.330333, wps=1201.9, ups=0.62, wpb=1947.2, bsz=128, num_updates=9900, lr=1.32e-05, gnorm=36.863, clip=100, loss_scale=64, train_wall=81, gb_free=14, wall=15556
2025-10-30 23:13:09 | INFO | train_inner | epoch 001:  10008 / 11384 loss=0.321018, wps=1533.1, ups=0.78, wpb=1970.9, bsz=128, num_updates=9950, lr=1.32667e-05, gnorm=37.245, clip=100, loss_scale=128, train_wall=64, gb_free=12.6, wall=15620
2025-10-30 23:13:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 23:13:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 23:14:46 | INFO | train_inner | epoch 001:  10060 / 11384 loss=0.332402, wps=1007.2, ups=0.52, wpb=1944.5, bsz=128, num_updates=10000, lr=1.33333e-05, gnorm=46.235, clip=100, loss_scale=32, train_wall=96, gb_free=15.8, wall=15717
2025-10-30 23:15:50 | INFO | train_inner | epoch 001:  10110 / 11384 loss=0.319996, wps=1497.4, ups=0.77, wpb=1933.3, bsz=128, num_updates=10050, lr=1.34e-05, gnorm=34.525, clip=100, loss_scale=32, train_wall=59, gb_free=16, wall=15781
2025-10-30 23:16:45 | INFO | train_inner | epoch 001:  10160 / 11384 loss=0.316025, wps=1805.1, ups=0.92, wpb=1963.3, bsz=128, num_updates=10100, lr=1.34667e-05, gnorm=36.47, clip=100, loss_scale=64, train_wall=54, gb_free=12.3, wall=15836
2025-10-30 23:17:48 | INFO | train_inner | epoch 001:  10210 / 11384 loss=0.331326, wps=1530.9, ups=0.78, wpb=1953.2, bsz=128, num_updates=10150, lr=1.35333e-05, gnorm=32.924, clip=100, loss_scale=64, train_wall=58, gb_free=14.4, wall=15900
2025-10-30 23:18:50 | INFO | train_inner | epoch 001:  10260 / 11384 loss=0.323304, wps=1584.8, ups=0.81, wpb=1961.8, bsz=128, num_updates=10200, lr=1.36e-05, gnorm=36.857, clip=100, loss_scale=64, train_wall=62, gb_free=13.3, wall=15962
2025-10-30 23:20:01 | INFO | train_inner | epoch 001:  10310 / 11384 loss=0.319354, wps=1390.8, ups=0.71, wpb=1956, bsz=128, num_updates=10250, lr=1.36667e-05, gnorm=35.754, clip=100, loss_scale=128, train_wall=70, gb_free=13, wall=16032
2025-10-30 23:20:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 23:21:09 | INFO | train_inner | epoch 001:  10361 / 11384 loss=0.322202, wps=1438.1, ups=0.74, wpb=1956.2, bsz=128, num_updates=10300, lr=1.37333e-05, gnorm=37.142, clip=100, loss_scale=64, train_wall=68, gb_free=15.5, wall=16100
2025-10-30 23:22:13 | INFO | train_inner | epoch 001:  10411 / 11384 loss=0.31478, wps=1530.2, ups=0.78, wpb=1962.4, bsz=128, num_updates=10350, lr=1.38e-05, gnorm=37.897, clip=100, loss_scale=64, train_wall=64, gb_free=15.9, wall=16164
2025-10-30 23:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 23:23:17 | INFO | train_inner | epoch 001:  10462 / 11384 loss=0.324488, wps=1542.2, ups=0.78, wpb=1979.2, bsz=128, num_updates=10400, lr=1.38667e-05, gnorm=38.614, clip=100, loss_scale=32, train_wall=64, gb_free=11.8, wall=16228
2025-10-30 23:24:28 | INFO | train_inner | epoch 001:  10512 / 11384 loss=0.32082, wps=1368.8, ups=0.7, wpb=1944.3, bsz=128, num_updates=10450, lr=1.39333e-05, gnorm=38.154, clip=100, loss_scale=32, train_wall=71, gb_free=17, wall=16300
2025-10-30 23:25:26 | INFO | train_inner | epoch 001:  10562 / 11384 loss=0.317845, wps=1708.2, ups=0.88, wpb=1951.6, bsz=128, num_updates=10500, lr=1.4e-05, gnorm=37.841, clip=100, loss_scale=64, train_wall=57, gb_free=9.9, wall=16357
2025-10-30 23:26:43 | INFO | train_inner | epoch 001:  10612 / 11384 loss=0.313864, wps=1274.2, ups=0.65, wpb=1971.2, bsz=128, num_updates=10550, lr=1.40667e-05, gnorm=37.495, clip=100, loss_scale=64, train_wall=77, gb_free=15.6, wall=16434
2025-10-30 23:28:11 | INFO | train_inner | epoch 001:  10662 / 11384 loss=0.327246, wps=1114.4, ups=0.57, wpb=1957.8, bsz=128, num_updates=10600, lr=1.41333e-05, gnorm=35.863, clip=100, loss_scale=64, train_wall=88, gb_free=13.5, wall=16522
2025-10-30 23:28:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 23:29:38 | INFO | train_inner | epoch 001:  10713 / 11384 loss=0.314552, wps=1141.4, ups=0.58, wpb=1980.6, bsz=128, num_updates=10650, lr=1.42e-05, gnorm=37.503, clip=100, loss_scale=64, train_wall=87, gb_free=15.9, wall=16609
2025-10-30 23:29:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 23:30:53 | INFO | train_inner | epoch 001:  10764 / 11384 loss=0.30893, wps=1311, ups=0.66, wpb=1977.4, bsz=128, num_updates=10700, lr=1.42667e-05, gnorm=38.908, clip=100, loss_scale=32, train_wall=75, gb_free=16.7, wall=16684
2025-10-30 23:32:10 | INFO | train_inner | epoch 001:  10814 / 11384 loss=0.331693, wps=1281.9, ups=0.65, wpb=1977.1, bsz=128, num_updates=10750, lr=1.43333e-05, gnorm=44.789, clip=100, loss_scale=32, train_wall=77, gb_free=15.3, wall=16762
2025-10-30 23:33:08 | INFO | train_inner | epoch 001:  10864 / 11384 loss=0.314623, wps=1701.8, ups=0.87, wpb=1965.9, bsz=128, num_updates=10800, lr=1.44e-05, gnorm=36.849, clip=100, loss_scale=64, train_wall=57, gb_free=5.7, wall=16819
2025-10-30 23:34:04 | INFO | train_inner | epoch 001:  10914 / 11384 loss=0.320804, wps=1790.9, ups=0.9, wpb=1985.9, bsz=128, num_updates=10850, lr=1.44667e-05, gnorm=41.02, clip=100, loss_scale=64, train_wall=55, gb_free=12.8, wall=16875
2025-10-30 23:35:18 | INFO | train_inner | epoch 001:  10964 / 11384 loss=0.315308, wps=1331.6, ups=0.68, wpb=1972.3, bsz=128, num_updates=10900, lr=1.45333e-05, gnorm=32.54, clip=100, loss_scale=64, train_wall=74, gb_free=16.7, wall=16949
2025-10-30 23:35:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 23:36:19 | INFO | train_inner | epoch 001:  11015 / 11384 loss=0.309199, wps=1567.5, ups=0.81, wpb=1931.9, bsz=128, num_updates=10950, lr=1.46e-05, gnorm=34.231, clip=100, loss_scale=64, train_wall=61, gb_free=14.3, wall=17011
2025-10-30 23:37:21 | INFO | train_inner | epoch 001:  11065 / 11384 loss=0.289308, wps=1597.5, ups=0.81, wpb=1964.9, bsz=128, num_updates=11000, lr=1.46667e-05, gnorm=36.923, clip=100, loss_scale=64, train_wall=61, gb_free=15.2, wall=17072
2025-10-30 23:38:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-30 23:38:21 | INFO | train_inner | epoch 001:  11116 / 11384 loss=0.323391, wps=1638.9, ups=0.83, wpb=1972.7, bsz=128, num_updates=11050, lr=1.47333e-05, gnorm=38.065, clip=100, loss_scale=32, train_wall=60, gb_free=16.4, wall=17132
2025-10-30 23:39:34 | INFO | train_inner | epoch 001:  11166 / 11384 loss=0.306021, wps=1313.6, ups=0.68, wpb=1931.6, bsz=128, num_updates=11100, lr=1.48e-05, gnorm=36.895, clip=100, loss_scale=32, train_wall=73, gb_free=16.5, wall=17206
2025-10-30 23:40:32 | INFO | train_inner | epoch 001:  11216 / 11384 loss=0.310343, wps=1682.8, ups=0.87, wpb=1939.9, bsz=128, num_updates=11150, lr=1.48667e-05, gnorm=37.327, clip=100, loss_scale=32, train_wall=57, gb_free=12.3, wall=17263
2025-10-30 23:41:40 | INFO | train_inner | epoch 001:  11266 / 11384 loss=0.318595, wps=1471, ups=0.74, wpb=1984.1, bsz=128, num_updates=11200, lr=1.49333e-05, gnorm=39.288, clip=100, loss_scale=64, train_wall=67, gb_free=11.6, wall=17331
2025-10-30 23:43:34 | INFO | train_inner | epoch 001:  11316 / 11384 loss=0.312058, wps=850.7, ups=0.44, wpb=1948.5, bsz=128, num_updates=11250, lr=1.5e-05, gnorm=36.272, clip=100, loss_scale=64, train_wall=114, gb_free=9.8, wall=17445
2025-10-30 23:44:35 | INFO | train_inner | epoch 001:  11366 / 11384 loss=0.312377, wps=1628, ups=0.83, wpb=1972.5, bsz=128, num_updates=11300, lr=1.50667e-05, gnorm=38.978, clip=100, loss_scale=128, train_wall=60, gb_free=15.4, wall=17506
2025-10-30 23:44:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-30 23:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-10-31 00:00:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.291922 | wps 1519.9 | wpb 1948.3 | bsz 127.9 | num_updates 11317
2025-10-31 00:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 11317 updates
2025-10-31 00:00:45 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint1.pt
2025-10-31 00:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint1.pt
2025-10-31 00:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint1.pt (epoch 1 @ 11317 updates, score 0.291922) (writing took 137.01733241602778 seconds)
2025-10-31 00:03:02 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2025-10-31 00:03:02 | INFO | train | epoch 001 | loss 0.402197 | wps 1191.4 | ups 0.61 | wpb 1958 | bsz 128 | num_updates 11317 | lr 1.50893e-05 | gnorm 45.042 | clip 100 | loss_scale 64 | train_wall 16558 | gb_free 16.7 | wall 18613
2025-10-31 00:03:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-10-31 00:03:11 | INFO | fairseq.trainer | begin training epoch 2
2025-10-31 00:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2025-10-31 00:05:41 | INFO | train_inner | epoch 002:     33 / 11384 loss=0.30112, wps=77.5, ups=0.04, wpb=1962.7, bsz=127.7, num_updates=11350, lr=1.51333e-05, gnorm=34.279, clip=100, loss_scale=64, train_wall=161, gb_free=16.2, wall=18772
2025-10-31 00:05:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 00:07:34 | INFO | train_inner | epoch 002:     84 / 11384 loss=0.311763, wps=872.4, ups=0.44, wpb=1965.7, bsz=128, num_updates=11400, lr=1.52e-05, gnorm=40.826, clip=100, loss_scale=32, train_wall=112, gb_free=13.2, wall=18885
2025-10-31 00:08:23 | INFO | train_inner | epoch 002:    134 / 11384 loss=0.30674, wps=2008.6, ups=1.01, wpb=1990.4, bsz=128, num_updates=11450, lr=1.52667e-05, gnorm=35.654, clip=100, loss_scale=32, train_wall=49, gb_free=15.4, wall=18935
2025-10-31 00:09:51 | INFO | train_inner | epoch 002:    184 / 11384 loss=0.290019, wps=1124.4, ups=0.57, wpb=1975, bsz=128, num_updates=11500, lr=1.53333e-05, gnorm=36.757, clip=100, loss_scale=64, train_wall=88, gb_free=15.1, wall=19023
2025-10-31 00:10:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 00:10:50 | INFO | train_inner | epoch 002:    235 / 11384 loss=0.308499, wps=1688.4, ups=0.86, wpb=1973.6, bsz=128, num_updates=11550, lr=1.54e-05, gnorm=39.986, clip=100, loss_scale=32, train_wall=58, gb_free=15.2, wall=19081
2025-10-31 00:12:51 | INFO | train_inner | epoch 002:    285 / 11384 loss=0.317406, wps=803, ups=0.41, wpb=1947.9, bsz=128, num_updates=11600, lr=1.54667e-05, gnorm=40.174, clip=100, loss_scale=32, train_wall=121, gb_free=16.6, wall=19203
2025-10-31 00:14:28 | INFO | train_inner | epoch 002:    335 / 11384 loss=0.320695, wps=1011.2, ups=0.52, wpb=1959.8, bsz=128, num_updates=11650, lr=1.55333e-05, gnorm=41.667, clip=100, loss_scale=64, train_wall=97, gb_free=5.2, wall=19299
2025-10-31 00:15:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 00:15:58 | INFO | train_inner | epoch 002:    386 / 11384 loss=0.305088, wps=1083.1, ups=0.56, wpb=1950.5, bsz=128, num_updates=11700, lr=1.56e-05, gnorm=39.651, clip=100, loss_scale=32, train_wall=90, gb_free=15.1, wall=19389
2025-10-31 00:17:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 00:17:44 | INFO | train_inner | epoch 002:    437 / 11384 loss=0.307454, wps=920.7, ups=0.47, wpb=1946.5, bsz=128, num_updates=11750, lr=1.56667e-05, gnorm=38.297, clip=100, loss_scale=16, train_wall=105, gb_free=15.2, wall=19495
2025-10-31 00:19:13 | INFO | train_inner | epoch 002:    487 / 11384 loss=0.291068, wps=1057.9, ups=0.56, wpb=1880.5, bsz=128, num_updates=11800, lr=1.57333e-05, gnorm=36.708, clip=100, loss_scale=16, train_wall=89, gb_free=8.7, wall=19584
2025-10-31 00:21:22 | INFO | train_inner | epoch 002:    537 / 11384 loss=0.293392, wps=750.8, ups=0.39, wpb=1948.4, bsz=128, num_updates=11850, lr=1.58e-05, gnorm=38.784, clip=100, loss_scale=16, train_wall=130, gb_free=15.9, wall=19714
2025-10-31 00:23:33 | INFO | train_inner | epoch 002:    587 / 11384 loss=0.29511, wps=754.8, ups=0.38, wpb=1964.5, bsz=128, num_updates=11900, lr=1.58667e-05, gnorm=35.487, clip=100, loss_scale=32, train_wall=130, gb_free=14.4, wall=19844
2025-10-31 00:24:31 | INFO | train_inner | epoch 002:    637 / 11384 loss=0.299457, wps=1655.6, ups=0.85, wpb=1946.4, bsz=128, num_updates=11950, lr=1.59333e-05, gnorm=39.204, clip=100, loss_scale=32, train_wall=59, gb_free=12.7, wall=19903
2025-10-31 00:26:23 | INFO | train_inner | epoch 002:    687 / 11384 loss=0.29426, wps=863.3, ups=0.45, wpb=1930.5, bsz=128, num_updates=12000, lr=1.6e-05, gnorm=38.63, clip=100, loss_scale=32, train_wall=79, gb_free=16.2, wall=20015
2025-10-31 00:28:30 | INFO | train_inner | epoch 002:    737 / 11384 loss=0.29386, wps=761.4, ups=0.39, wpb=1929.8, bsz=128, num_updates=12050, lr=1.60667e-05, gnorm=38.37, clip=100, loss_scale=64, train_wall=117, gb_free=14.7, wall=20141
2025-10-31 00:30:53 | INFO | train_inner | epoch 002:    787 / 11384 loss=0.290635, wps=681.5, ups=0.35, wpb=1947.1, bsz=128, num_updates=12100, lr=1.61333e-05, gnorm=38.392, clip=100, loss_scale=64, train_wall=94, gb_free=11.2, wall=20284
2025-10-31 00:32:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-31 00:32:45 | INFO | train_inner | epoch 002:    838 / 11384 loss=0.298612, wps=890.9, ups=0.45, wpb=1993.2, bsz=128, num_updates=12150, lr=1.62e-05, gnorm=37.382, clip=100, loss_scale=64, train_wall=112, gb_free=15.5, wall=20396
2025-10-31 00:35:16 | INFO | train_inner | epoch 002:    888 / 11384 loss=0.297876, wps=647.6, ups=0.33, wpb=1963.3, bsz=128, num_updates=12200, lr=1.62667e-05, gnorm=35.806, clip=100, loss_scale=64, train_wall=85, gb_free=15.2, wall=20548
2025-10-31 00:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 00:37:06 | INFO | train_inner | epoch 002:    939 / 11384 loss=0.294631, wps=897.4, ups=0.46, wpb=1969.1, bsz=128, num_updates=12250, lr=1.63333e-05, gnorm=38.44, clip=100, loss_scale=32, train_wall=109, gb_free=16.3, wall=20657
2025-10-31 00:38:24 | INFO | train_inner | epoch 002:    989 / 11384 loss=0.286233, wps=1228.2, ups=0.64, wpb=1921, bsz=128, num_updates=12300, lr=1.64e-05, gnorm=39.668, clip=100, loss_scale=32, train_wall=78, gb_free=15.3, wall=20735
2025-10-31 00:40:49 | INFO | train_inner | epoch 002:   1039 / 11384 loss=0.28974, wps=670.1, ups=0.35, wpb=1939.3, bsz=128, num_updates=12350, lr=1.64667e-05, gnorm=42.564, clip=100, loss_scale=64, train_wall=144, gb_free=15.3, wall=20880
2025-10-31 00:43:08 | INFO | train_inner | epoch 002:   1089 / 11384 loss=0.293025, wps=696.2, ups=0.36, wpb=1930.5, bsz=128, num_updates=12400, lr=1.65333e-05, gnorm=40.262, clip=100, loss_scale=64, train_wall=138, gb_free=15.4, wall=21019
2025-10-31 00:44:41 | INFO | train_inner | epoch 002:   1139 / 11384 loss=0.282548, wps=1059.5, ups=0.53, wpb=1984.9, bsz=128, num_updates=12450, lr=1.66e-05, gnorm=36.971, clip=100, loss_scale=64, train_wall=93, gb_free=15.5, wall=21113
2025-10-31 00:44:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 00:46:53 | INFO | train_inner | epoch 002:   1190 / 11384 loss=0.279965, wps=738.1, ups=0.38, wpb=1940.1, bsz=128, num_updates=12500, lr=1.66667e-05, gnorm=35.736, clip=100, loss_scale=32, train_wall=114, gb_free=16.2, wall=21244
2025-10-31 00:49:29 | INFO | train_inner | epoch 002:   1240 / 11384 loss=0.298217, wps=632.2, ups=0.32, wpb=1973.1, bsz=128, num_updates=12550, lr=1.67333e-05, gnorm=41.14, clip=100, loss_scale=32, train_wall=87, gb_free=16.5, wall=21400
2025-10-31 00:51:43 | INFO | train_inner | epoch 002:   1290 / 11384 loss=0.290791, wps=728, ups=0.37, wpb=1955.3, bsz=128, num_updates=12600, lr=1.68e-05, gnorm=37.886, clip=100, loss_scale=64, train_wall=70, gb_free=15.7, wall=21534
2025-10-31 00:52:46 | INFO | train_inner | epoch 002:   1340 / 11384 loss=0.289102, wps=1533.7, ups=0.79, wpb=1932.6, bsz=128, num_updates=12650, lr=1.68667e-05, gnorm=37.418, clip=100, loss_scale=64, train_wall=63, gb_free=17.1, wall=21597
2025-10-31 00:55:22 | INFO | train_inner | epoch 002:   1390 / 11384 loss=0.289759, wps=619, ups=0.32, wpb=1932.7, bsz=128, num_updates=12700, lr=1.69333e-05, gnorm=39.379, clip=100, loss_scale=64, train_wall=156, gb_free=16.6, wall=21753
2025-10-31 00:55:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-31 00:55:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 00:57:31 | INFO | train_inner | epoch 002:   1442 / 11384 loss=0.28789, wps=760.6, ups=0.39, wpb=1964.5, bsz=128, num_updates=12750, lr=1.7e-05, gnorm=40.357, clip=100, loss_scale=32, train_wall=129, gb_free=15.6, wall=21883
2025-10-31 00:58:44 | INFO | train_inner | epoch 002:   1492 / 11384 loss=0.287217, wps=1381.3, ups=0.69, wpb=2004.1, bsz=128, num_updates=12800, lr=1.70667e-05, gnorm=41.822, clip=100, loss_scale=32, train_wall=72, gb_free=16.4, wall=21955
2025-10-31 01:01:12 | INFO | train_inner | epoch 002:   1542 / 11384 loss=0.288482, wps=670.4, ups=0.34, wpb=1987.4, bsz=128, num_updates=12850, lr=1.71333e-05, gnorm=39.52, clip=100, loss_scale=32, train_wall=65, gb_free=15.2, wall=22103
2025-10-31 01:03:53 | INFO | train_inner | epoch 002:   1592 / 11384 loss=0.28874, wps=606.9, ups=0.31, wpb=1959.5, bsz=128, num_updates=12900, lr=1.72e-05, gnorm=40.605, clip=100, loss_scale=64, train_wall=161, gb_free=14.6, wall=22265
2025-10-31 01:06:34 | INFO | train_inner | epoch 002:   1642 / 11384 loss=0.283261, wps=601.9, ups=0.31, wpb=1927.7, bsz=128, num_updates=12950, lr=1.72667e-05, gnorm=37.556, clip=100, loss_scale=64, train_wall=160, gb_free=12.7, wall=22425
2025-10-31 01:06:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:07:57 | INFO | train_inner | epoch 002:   1693 / 11384 loss=0.277954, wps=1178.3, ups=0.6, wpb=1969.7, bsz=128, num_updates=13000, lr=1.73333e-05, gnorm=38.945, clip=100, loss_scale=32, train_wall=83, gb_free=15.9, wall=22509
2025-10-31 01:10:21 | INFO | train_inner | epoch 002:   1743 / 11384 loss=0.2807, wps=694, ups=0.35, wpb=1998.2, bsz=128, num_updates=13050, lr=1.74e-05, gnorm=38.285, clip=100, loss_scale=32, train_wall=64, gb_free=15.5, wall=22652
2025-10-31 01:12:12 | INFO | train_inner | epoch 002:   1793 / 11384 loss=0.284086, wps=885, ups=0.45, wpb=1963.2, bsz=128, num_updates=13100, lr=1.74667e-05, gnorm=38.568, clip=100, loss_scale=32, train_wall=78, gb_free=16, wall=22763
2025-10-31 01:13:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:14:08 | INFO | train_inner | epoch 002:   1844 / 11384 loss=0.286485, wps=848, ups=0.43, wpb=1964, bsz=128, num_updates=13150, lr=1.75333e-05, gnorm=43.582, clip=100, loss_scale=32, train_wall=116, gb_free=15.9, wall=22879
2025-10-31 01:16:42 | INFO | train_inner | epoch 002:   1894 / 11384 loss=0.270485, wps=627.6, ups=0.33, wpb=1930.8, bsz=128, num_updates=13200, lr=1.76e-05, gnorm=37.873, clip=100, loss_scale=32, train_wall=117, gb_free=11.3, wall=23033
2025-10-31 01:17:51 | INFO | train_inner | epoch 002:   1944 / 11384 loss=0.279111, wps=1452.7, ups=0.72, wpb=2009.7, bsz=128, num_updates=13250, lr=1.76667e-05, gnorm=38.179, clip=100, loss_scale=32, train_wall=69, gb_free=8, wall=23102
2025-10-31 01:19:39 | INFO | train_inner | epoch 002:   1994 / 11384 loss=0.285542, wps=919, ups=0.46, wpb=1977.4, bsz=128, num_updates=13300, lr=1.77333e-05, gnorm=36.582, clip=100, loss_scale=64, train_wall=107, gb_free=6.4, wall=23210
2025-10-31 01:19:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:21:50 | INFO | train_inner | epoch 002:   2045 / 11384 loss=0.281724, wps=751.4, ups=0.38, wpb=1974.9, bsz=128, num_updates=13350, lr=1.78e-05, gnorm=39.644, clip=100, loss_scale=32, train_wall=131, gb_free=5.1, wall=23341
2025-10-31 01:24:25 | INFO | train_inner | epoch 002:   2095 / 11384 loss=0.275667, wps=634.6, ups=0.32, wpb=1968, bsz=128, num_updates=13400, lr=1.78667e-05, gnorm=37.628, clip=100, loss_scale=32, train_wall=154, gb_free=16.6, wall=23496
2025-10-31 01:26:20 | INFO | train_inner | epoch 002:   2145 / 11384 loss=0.272071, wps=854.2, ups=0.43, wpb=1971.4, bsz=128, num_updates=13450, lr=1.79333e-05, gnorm=38.469, clip=100, loss_scale=64, train_wall=69, gb_free=12.9, wall=23612
2025-10-31 01:26:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:28:47 | INFO | train_inner | epoch 002:   2196 / 11384 loss=0.285297, wps=668.9, ups=0.34, wpb=1957.2, bsz=128, num_updates=13500, lr=1.8e-05, gnorm=42.247, clip=100, loss_scale=32, train_wall=145, gb_free=14.4, wall=23758
2025-10-31 01:29:47 | INFO | train_inner | epoch 002:   2246 / 11384 loss=0.273455, wps=1628.5, ups=0.83, wpb=1959.2, bsz=128, num_updates=13550, lr=1.80667e-05, gnorm=41.28, clip=100, loss_scale=32, train_wall=60, gb_free=15.7, wall=23818
2025-10-31 01:32:13 | INFO | train_inner | epoch 002:   2296 / 11384 loss=0.277426, wps=663.2, ups=0.34, wpb=1934.4, bsz=128, num_updates=13600, lr=1.81333e-05, gnorm=37.913, clip=100, loss_scale=64, train_wall=76, gb_free=16.4, wall=23964
2025-10-31 01:34:24 | INFO | train_inner | epoch 002:   2346 / 11384 loss=0.261868, wps=748.8, ups=0.38, wpb=1962.7, bsz=128, num_updates=13650, lr=1.82e-05, gnorm=33.356, clip=100, loss_scale=64, train_wall=131, gb_free=16, wall=24095
2025-10-31 01:34:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:37:27 | INFO | train_inner | epoch 002:   2397 / 11384 loss=0.279314, wps=539.6, ups=0.27, wpb=1977.4, bsz=128, num_updates=13700, lr=1.82667e-05, gnorm=35.48, clip=100, loss_scale=32, train_wall=183, gb_free=13.9, wall=24278
2025-10-31 01:40:21 | INFO | train_inner | epoch 002:   2447 / 11384 loss=0.27851, wps=577.8, ups=0.29, wpb=2007.7, bsz=128, num_updates=13750, lr=1.83333e-05, gnorm=38.53, clip=100, loss_scale=32, train_wall=174, gb_free=14.5, wall=24452
2025-10-31 01:41:35 | INFO | train_inner | epoch 002:   2497 / 11384 loss=0.271616, wps=1335, ups=0.68, wpb=1973.2, bsz=128, num_updates=13800, lr=1.84e-05, gnorm=37.164, clip=100, loss_scale=64, train_wall=74, gb_free=12, wall=24526
2025-10-31 01:42:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:43:20 | INFO | train_inner | epoch 002:   2548 / 11384 loss=0.273464, wps=934.3, ups=0.48, wpb=1964.9, bsz=128, num_updates=13850, lr=1.84667e-05, gnorm=36.668, clip=100, loss_scale=32, train_wall=105, gb_free=16.3, wall=24632
2025-10-31 01:45:05 | INFO | train_inner | epoch 002:   2598 / 11384 loss=0.266798, wps=928.9, ups=0.48, wpb=1948.7, bsz=128, num_updates=13900, lr=1.85333e-05, gnorm=37.462, clip=100, loss_scale=32, train_wall=105, gb_free=12.9, wall=24737
2025-10-31 01:46:33 | INFO | train_inner | epoch 002:   2648 / 11384 loss=0.274644, wps=1112.5, ups=0.57, wpb=1957.4, bsz=128, num_updates=13950, lr=1.86e-05, gnorm=37.829, clip=100, loss_scale=32, train_wall=88, gb_free=16.9, wall=24825
2025-10-31 01:49:04 | INFO | train_inner | epoch 002:   2698 / 11384 loss=0.260085, wps=652.2, ups=0.33, wpb=1967.7, bsz=128, num_updates=14000, lr=1.86667e-05, gnorm=34.875, clip=100, loss_scale=64, train_wall=151, gb_free=15.6, wall=24975
2025-10-31 01:50:50 | INFO | train_inner | epoch 002:   2748 / 11384 loss=0.265065, wps=933.1, ups=0.47, wpb=1975.4, bsz=128, num_updates=14050, lr=1.87333e-05, gnorm=39.577, clip=100, loss_scale=64, train_wall=89, gb_free=15.5, wall=25081
2025-10-31 01:53:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-31 01:53:41 | INFO | train_inner | epoch 002:   2799 / 11384 loss=0.270005, wps=570.9, ups=0.29, wpb=1951.6, bsz=128, num_updates=14100, lr=1.88e-05, gnorm=39.83, clip=100, loss_scale=64, train_wall=135, gb_free=16.2, wall=25252
2025-10-31 01:55:57 | INFO | train_inner | epoch 002:   2849 / 11384 loss=0.268248, wps=731.2, ups=0.37, wpb=1988.9, bsz=128, num_updates=14150, lr=1.88667e-05, gnorm=39.943, clip=100, loss_scale=64, train_wall=136, gb_free=16.8, wall=25388
2025-10-31 01:56:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 01:57:08 | INFO | train_inner | epoch 002:   2900 / 11384 loss=0.263298, wps=1388.2, ups=0.71, wpb=1967.6, bsz=128, num_updates=14200, lr=1.89333e-05, gnorm=40.097, clip=100, loss_scale=32, train_wall=71, gb_free=14.9, wall=25459
2025-10-31 01:59:11 | INFO | train_inner | epoch 002:   2950 / 11384 loss=0.268133, wps=794.4, ups=0.41, wpb=1957.7, bsz=128, num_updates=14250, lr=1.9e-05, gnorm=40.582, clip=100, loss_scale=32, train_wall=123, gb_free=10.4, wall=25582
2025-10-31 02:00:56 | INFO | train_inner | epoch 002:   3000 / 11384 loss=0.26403, wps=922.5, ups=0.48, wpb=1940.5, bsz=128, num_updates=14300, lr=1.90667e-05, gnorm=38.04, clip=100, loss_scale=64, train_wall=105, gb_free=16.1, wall=25688
2025-10-31 02:01:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 02:03:06 | INFO | train_inner | epoch 002:   3051 / 11384 loss=0.263102, wps=744.5, ups=0.39, wpb=1919.7, bsz=128, num_updates=14350, lr=1.91333e-05, gnorm=36.796, clip=100, loss_scale=32, train_wall=129, gb_free=16.7, wall=25817
2025-10-31 02:04:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 02:04:58 | INFO | train_inner | epoch 002:   3102 / 11384 loss=0.273595, wps=884.8, ups=0.45, wpb=1961, bsz=128, num_updates=14400, lr=1.92e-05, gnorm=37.685, clip=100, loss_scale=16, train_wall=111, gb_free=16.7, wall=25929
2025-10-31 02:07:18 | INFO | train_inner | epoch 002:   3152 / 11384 loss=0.27949, wps=704.8, ups=0.36, wpb=1970.1, bsz=128, num_updates=14450, lr=1.92667e-05, gnorm=43.42, clip=100, loss_scale=16, train_wall=140, gb_free=16.7, wall=26069
2025-10-31 02:09:32 | INFO | train_inner | epoch 002:   3202 / 11384 loss=0.264558, wps=745.7, ups=0.37, wpb=1992.3, bsz=128, num_updates=14500, lr=1.93333e-05, gnorm=40.061, clip=100, loss_scale=16, train_wall=133, gb_free=12.8, wall=26203
2025-10-31 02:10:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 02:10:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 02:10:56 | INFO | train_inner | epoch 002:   3254 / 11384 loss=0.265559, wps=1171.3, ups=0.6, wpb=1960.5, bsz=128, num_updates=14550, lr=1.94e-05, gnorm=35.636, clip=100, loss_scale=8, train_wall=83, gb_free=16.7, wall=26287
2025-10-31 02:12:26 | INFO | train_inner | epoch 002:   3304 / 11384 loss=0.253471, wps=1095.1, ups=0.55, wpb=1979.9, bsz=128, num_updates=14600, lr=1.94667e-05, gnorm=37.651, clip=100, loss_scale=8, train_wall=90, gb_free=13, wall=26377
2025-10-31 02:14:32 | INFO | train_inner | epoch 002:   3354 / 11384 loss=0.266896, wps=781.6, ups=0.4, wpb=1974.2, bsz=128, num_updates=14650, lr=1.95333e-05, gnorm=43.058, clip=100, loss_scale=8, train_wall=121, gb_free=16.6, wall=26504
2025-10-31 02:16:08 | INFO | train_inner | epoch 002:   3404 / 11384 loss=0.262613, wps=1021, ups=0.53, wpb=1944, bsz=128, num_updates=14700, lr=1.96e-05, gnorm=39.406, clip=100, loss_scale=16, train_wall=95, gb_free=16.2, wall=26599
2025-10-31 02:17:36 | INFO | train_inner | epoch 002:   3454 / 11384 loss=0.249974, wps=1121.7, ups=0.57, wpb=1973.2, bsz=128, num_updates=14750, lr=1.96667e-05, gnorm=39.706, clip=100, loss_scale=16, train_wall=88, gb_free=15.4, wall=26687
2025-10-31 02:19:05 | INFO | train_inner | epoch 002:   3504 / 11384 loss=0.255767, wps=1106.1, ups=0.56, wpb=1984.8, bsz=128, num_updates=14800, lr=1.97333e-05, gnorm=36.172, clip=100, loss_scale=32, train_wall=89, gb_free=16.3, wall=26777
2025-10-31 02:20:51 | INFO | train_inner | epoch 002:   3554 / 11384 loss=0.271472, wps=910.5, ups=0.47, wpb=1918.9, bsz=128, num_updates=14850, lr=1.98e-05, gnorm=39.111, clip=100, loss_scale=32, train_wall=105, gb_free=16, wall=26882
2025-10-31 02:22:15 | INFO | train_inner | epoch 002:   3604 / 11384 loss=0.266381, wps=1144.9, ups=0.59, wpb=1932.7, bsz=128, num_updates=14900, lr=1.98667e-05, gnorm=39.735, clip=100, loss_scale=32, train_wall=84, gb_free=16.2, wall=26967
2025-10-31 02:23:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 02:23:42 | INFO | train_inner | epoch 002:   3655 / 11384 loss=0.258414, wps=1138.4, ups=0.58, wpb=1963.8, bsz=128, num_updates=14950, lr=1.99333e-05, gnorm=38.195, clip=100, loss_scale=32, train_wall=86, gb_free=16.8, wall=27053
2025-10-31 02:25:24 | INFO | train_inner | epoch 002:   3705 / 11384 loss=0.248566, wps=957.5, ups=0.49, wpb=1965.7, bsz=128, num_updates=15000, lr=2e-05, gnorm=39.851, clip=100, loss_scale=32, train_wall=102, gb_free=15.9, wall=27156
2025-10-31 02:26:31 | INFO | train_inner | epoch 002:   3755 / 11384 loss=0.262371, wps=1471.2, ups=0.76, wpb=1947.5, bsz=128, num_updates=15050, lr=2.00667e-05, gnorm=36.969, clip=100, loss_scale=32, train_wall=66, gb_free=12.5, wall=27222
2025-10-31 02:27:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 02:28:26 | INFO | train_inner | epoch 002:   3806 / 11384 loss=0.262728, wps=858, ups=0.43, wpb=1988.7, bsz=128, num_updates=15100, lr=2.01333e-05, gnorm=39.229, clip=100, loss_scale=32, train_wall=116, gb_free=16.8, wall=27338
2025-10-31 02:29:46 | INFO | train_inner | epoch 002:   3856 / 11384 loss=0.262611, wps=1230.5, ups=0.63, wpb=1960.5, bsz=128, num_updates=15150, lr=2.02e-05, gnorm=44.123, clip=100, loss_scale=32, train_wall=79, gb_free=13.3, wall=27417
2025-10-31 02:31:33 | INFO | train_inner | epoch 002:   3906 / 11384 loss=0.261226, wps=932.3, ups=0.47, wpb=1983, bsz=128, num_updates=15200, lr=2.02667e-05, gnorm=36.028, clip=100, loss_scale=64, train_wall=106, gb_free=14.3, wall=27524
2025-10-31 02:33:22 | INFO | train_inner | epoch 002:   3956 / 11384 loss=0.244236, wps=880.6, ups=0.45, wpb=1935.3, bsz=128, num_updates=15250, lr=2.03333e-05, gnorm=37.854, clip=100, loss_scale=64, train_wall=110, gb_free=16, wall=27634
2025-10-31 02:33:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 02:34:53 | INFO | train_inner | epoch 002:   4007 / 11384 loss=0.246132, wps=1088.8, ups=0.55, wpb=1971.8, bsz=128, num_updates=15300, lr=2.04e-05, gnorm=36.763, clip=100, loss_scale=32, train_wall=90, gb_free=12.4, wall=27724
2025-10-31 02:36:32 | INFO | train_inner | epoch 002:   4057 / 11384 loss=0.250909, wps=981, ups=0.51, wpb=1938.2, bsz=128, num_updates=15350, lr=2.04667e-05, gnorm=40.985, clip=100, loss_scale=32, train_wall=99, gb_free=14.3, wall=27823
2025-10-31 02:37:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 02:38:19 | INFO | train_inner | epoch 002:   4108 / 11384 loss=0.244544, wps=900.5, ups=0.47, wpb=1934.7, bsz=128, num_updates=15400, lr=2.05333e-05, gnorm=36.152, clip=100, loss_scale=16, train_wall=107, gb_free=13.5, wall=27931
2025-10-31 02:39:40 | INFO | train_inner | epoch 002:   4158 / 11384 loss=0.258121, wps=1230.1, ups=0.62, wpb=1987.7, bsz=128, num_updates=15450, lr=2.06e-05, gnorm=38.262, clip=100, loss_scale=16, train_wall=80, gb_free=12.5, wall=28011
2025-10-31 02:41:21 | INFO | train_inner | epoch 002:   4208 / 11384 loss=0.249438, wps=957.4, ups=0.5, wpb=1930.5, bsz=128, num_updates=15500, lr=2.06667e-05, gnorm=39.794, clip=100, loss_scale=16, train_wall=100, gb_free=12.5, wall=28112
2025-10-31 02:42:57 | INFO | train_inner | epoch 002:   4258 / 11384 loss=0.250312, wps=1029.8, ups=0.52, wpb=1973.1, bsz=128, num_updates=15550, lr=2.07333e-05, gnorm=34.101, clip=100, loss_scale=32, train_wall=96, gb_free=9.9, wall=28208
2025-10-31 02:44:09 | INFO | train_inner | epoch 002:   4308 / 11384 loss=0.25864, wps=1354.9, ups=0.69, wpb=1968.8, bsz=128, num_updates=15600, lr=2.08e-05, gnorm=41.118, clip=100, loss_scale=32, train_wall=72, gb_free=16.9, wall=28281
2025-10-31 02:45:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 02:45:32 | INFO | train_inner | epoch 002:   4359 / 11384 loss=0.237345, wps=1206.1, ups=0.6, wpb=1995.4, bsz=128, num_updates=15650, lr=2.08667e-05, gnorm=36.642, clip=100, loss_scale=32, train_wall=82, gb_free=16.5, wall=28363
2025-10-31 02:45:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 02:47:02 | INFO | train_inner | epoch 002:   4410 / 11384 loss=0.246783, wps=1090.3, ups=0.56, wpb=1955.8, bsz=128, num_updates=15700, lr=2.09333e-05, gnorm=37.749, clip=100, loss_scale=16, train_wall=89, gb_free=15.4, wall=28453
2025-10-31 02:48:31 | INFO | train_inner | epoch 002:   4460 / 11384 loss=0.247275, wps=1107.1, ups=0.56, wpb=1970, bsz=128, num_updates=15750, lr=2.1e-05, gnorm=40.331, clip=100, loss_scale=16, train_wall=89, gb_free=12.3, wall=28542
2025-10-31 02:49:59 | INFO | train_inner | epoch 002:   4510 / 11384 loss=0.251913, wps=1112.6, ups=0.57, wpb=1954.1, bsz=128, num_updates=15800, lr=2.10667e-05, gnorm=37.802, clip=100, loss_scale=32, train_wall=88, gb_free=8, wall=28630
2025-10-31 02:51:33 | INFO | train_inner | epoch 002:   4560 / 11384 loss=0.239121, wps=1043.6, ups=0.53, wpb=1960.9, bsz=128, num_updates=15850, lr=2.11333e-05, gnorm=37.464, clip=100, loss_scale=32, train_wall=94, gb_free=16.2, wall=28724
2025-10-31 02:52:58 | INFO | train_inner | epoch 002:   4610 / 11384 loss=0.25047, wps=1152.3, ups=0.59, wpb=1965.2, bsz=128, num_updates=15900, lr=2.12e-05, gnorm=41.674, clip=100, loss_scale=32, train_wall=85, gb_free=15, wall=28809
2025-10-31 02:54:54 | INFO | train_inner | epoch 002:   4660 / 11384 loss=0.242631, wps=852.9, ups=0.44, wpb=1932.3, bsz=128, num_updates=15950, lr=2.12667e-05, gnorm=37.708, clip=100, loss_scale=64, train_wall=113, gb_free=12.2, wall=28923
2025-10-31 02:56:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 02:56:48 | INFO | train_inner | epoch 002:   4711 / 11384 loss=0.231467, wps=852.1, ups=0.44, wpb=1930.7, bsz=128, num_updates=16000, lr=2.13333e-05, gnorm=35.477, clip=100, loss_scale=32, train_wall=113, gb_free=14.7, wall=29039
2025-10-31 02:58:19 | INFO | train_inner | epoch 002:   4761 / 11384 loss=0.252189, wps=1047.8, ups=0.55, wpb=1918.7, bsz=128, num_updates=16050, lr=2.14e-05, gnorm=36.388, clip=100, loss_scale=32, train_wall=91, gb_free=16.6, wall=29131
2025-10-31 02:59:48 | INFO | train_inner | epoch 002:   4811 / 11384 loss=0.246645, wps=1092.7, ups=0.57, wpb=1927, bsz=128, num_updates=16100, lr=2.14667e-05, gnorm=36.66, clip=100, loss_scale=32, train_wall=88, gb_free=14.7, wall=29219
2025-10-31 03:01:22 | INFO | train_inner | epoch 002:   4861 / 11384 loss=0.243497, wps=1038.2, ups=0.53, wpb=1950, bsz=128, num_updates=16150, lr=2.15333e-05, gnorm=37.308, clip=100, loss_scale=64, train_wall=94, gb_free=15.6, wall=29313
2025-10-31 03:01:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:02:58 | INFO | train_inner | epoch 002:   4912 / 11384 loss=0.236653, wps=1027.6, ups=0.52, wpb=1974.9, bsz=128, num_updates=16200, lr=2.16e-05, gnorm=35.517, clip=100, loss_scale=32, train_wall=95, gb_free=14.8, wall=29409
2025-10-31 03:03:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 03:04:18 | INFO | train_inner | epoch 002:   4963 / 11384 loss=0.236567, wps=1229.9, ups=0.63, wpb=1963.8, bsz=128, num_updates=16250, lr=2.16667e-05, gnorm=35.309, clip=100, loss_scale=16, train_wall=78, gb_free=16, wall=29489
2025-10-31 03:05:41 | INFO | train_inner | epoch 002:   5013 / 11384 loss=0.263582, wps=1162.9, ups=0.6, wpb=1948.6, bsz=128, num_updates=16300, lr=2.17333e-05, gnorm=36.228, clip=100, loss_scale=16, train_wall=84, gb_free=16.6, wall=29573
2025-10-31 03:07:12 | INFO | train_inner | epoch 002:   5063 / 11384 loss=0.240345, wps=1055.1, ups=0.55, wpb=1917.6, bsz=128, num_updates=16350, lr=2.18e-05, gnorm=39.088, clip=100, loss_scale=16, train_wall=91, gb_free=13.6, wall=29664
2025-10-31 03:08:45 | INFO | train_inner | epoch 002:   5113 / 11384 loss=0.232373, wps=1053.2, ups=0.54, wpb=1960.6, bsz=128, num_updates=16400, lr=2.18667e-05, gnorm=36.084, clip=100, loss_scale=32, train_wall=93, gb_free=14, wall=29757
2025-10-31 03:10:08 | INFO | train_inner | epoch 002:   5163 / 11384 loss=0.241196, wps=1177.4, ups=0.6, wpb=1953, bsz=128, num_updates=16450, lr=2.19333e-05, gnorm=36.603, clip=100, loss_scale=32, train_wall=83, gb_free=13.6, wall=29840
2025-10-31 03:11:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 03:12:13 | INFO | train_inner | epoch 002:   5214 / 11384 loss=0.237819, wps=789.8, ups=0.4, wpb=1969.3, bsz=128, num_updates=16500, lr=2.2e-05, gnorm=35.672, clip=100, loss_scale=16, train_wall=124, gb_free=13.8, wall=29964
2025-10-31 03:14:10 | INFO | train_inner | epoch 002:   5264 / 11384 loss=0.248223, wps=836.5, ups=0.43, wpb=1954, bsz=128, num_updates=16550, lr=2.20667e-05, gnorm=42.353, clip=100, loss_scale=16, train_wall=117, gb_free=16.4, wall=30081
2025-10-31 03:15:36 | INFO | train_inner | epoch 002:   5314 / 11384 loss=0.251313, wps=1157.7, ups=0.58, wpb=1984.9, bsz=128, num_updates=16600, lr=2.21333e-05, gnorm=38.851, clip=100, loss_scale=16, train_wall=85, gb_free=14.2, wall=30167
2025-10-31 03:17:02 | INFO | train_inner | epoch 002:   5364 / 11384 loss=0.237525, wps=1106.8, ups=0.58, wpb=1902.3, bsz=128, num_updates=16650, lr=2.22e-05, gnorm=36.914, clip=100, loss_scale=32, train_wall=86, gb_free=16.4, wall=30253
2025-10-31 03:18:30 | INFO | train_inner | epoch 002:   5414 / 11384 loss=0.227068, wps=1078.8, ups=0.57, wpb=1904.7, bsz=128, num_updates=16700, lr=2.22667e-05, gnorm=35.183, clip=100, loss_scale=32, train_wall=88, gb_free=12.3, wall=30341
2025-10-31 03:19:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:19:55 | INFO | train_inner | epoch 002:   5465 / 11384 loss=0.249743, wps=1169, ups=0.59, wpb=1989, bsz=128, num_updates=16750, lr=2.23333e-05, gnorm=39.892, clip=100, loss_scale=32, train_wall=85, gb_free=15.5, wall=30427
2025-10-31 03:21:20 | INFO | train_inner | epoch 002:   5515 / 11384 loss=0.227512, wps=1150.8, ups=0.59, wpb=1942, bsz=128, num_updates=16800, lr=2.24e-05, gnorm=36.155, clip=100, loss_scale=32, train_wall=84, gb_free=14.7, wall=30511
2025-10-31 03:22:40 | INFO | train_inner | epoch 002:   5565 / 11384 loss=0.225305, wps=1233.2, ups=0.62, wpb=1990.5, bsz=128, num_updates=16850, lr=2.24667e-05, gnorm=34.075, clip=100, loss_scale=32, train_wall=80, gb_free=17.3, wall=30592
2025-10-31 03:23:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:24:13 | INFO | train_inner | epoch 002:   5616 / 11384 loss=0.232405, wps=1079.9, ups=0.54, wpb=1999.2, bsz=128, num_updates=16900, lr=2.25333e-05, gnorm=36.202, clip=100, loss_scale=32, train_wall=92, gb_free=12.5, wall=30684
2025-10-31 03:25:28 | INFO | train_inner | epoch 002:   5666 / 11384 loss=0.24167, wps=1301.5, ups=0.67, wpb=1953.6, bsz=128, num_updates=16950, lr=2.26e-05, gnorm=38.955, clip=100, loss_scale=32, train_wall=75, gb_free=9.4, wall=30759
2025-10-31 03:27:01 | INFO | train_inner | epoch 002:   5716 / 11384 loss=0.232031, wps=1047, ups=0.54, wpb=1939.6, bsz=128, num_updates=17000, lr=2.26667e-05, gnorm=36.099, clip=100, loss_scale=32, train_wall=92, gb_free=15.1, wall=30852
2025-10-31 03:27:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:29:09 | INFO | train_inner | epoch 002:   5767 / 11384 loss=0.229706, wps=755.5, ups=0.39, wpb=1947.3, bsz=128, num_updates=17050, lr=2.27333e-05, gnorm=36.23, clip=100, loss_scale=32, train_wall=129, gb_free=17.6, wall=30981
2025-10-31 03:30:46 | INFO | train_inner | epoch 002:   5817 / 11384 loss=0.226768, wps=1001.5, ups=0.52, wpb=1941.9, bsz=128, num_updates=17100, lr=2.28e-05, gnorm=38.114, clip=100, loss_scale=32, train_wall=97, gb_free=13, wall=31078
2025-10-31 03:32:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:32:28 | INFO | train_inner | epoch 002:   5868 / 11384 loss=0.227787, wps=969, ups=0.49, wpb=1966.5, bsz=128, num_updates=17150, lr=2.28667e-05, gnorm=34.875, clip=100, loss_scale=32, train_wall=101, gb_free=14.7, wall=31179
2025-10-31 03:33:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 03:34:00 | INFO | train_inner | epoch 002:   5919 / 11384 loss=0.21934, wps=1063.6, ups=0.54, wpb=1959.4, bsz=128, num_updates=17200, lr=2.29333e-05, gnorm=36.178, clip=100, loss_scale=16, train_wall=92, gb_free=14.7, wall=31271
2025-10-31 03:35:33 | INFO | train_inner | epoch 002:   5969 / 11384 loss=0.236427, wps=1044.1, ups=0.54, wpb=1946.5, bsz=128, num_updates=17250, lr=2.3e-05, gnorm=38.975, clip=100, loss_scale=16, train_wall=93, gb_free=7.4, wall=31365
2025-10-31 03:36:58 | INFO | train_inner | epoch 002:   6019 / 11384 loss=0.232597, wps=1167, ups=0.59, wpb=1977.6, bsz=128, num_updates=17300, lr=2.30667e-05, gnorm=38.032, clip=100, loss_scale=16, train_wall=84, gb_free=16.3, wall=31449
2025-10-31 03:38:20 | INFO | train_inner | epoch 002:   6069 / 11384 loss=0.228803, wps=1192.8, ups=0.61, wpb=1967.5, bsz=128, num_updates=17350, lr=2.31333e-05, gnorm=38.089, clip=100, loss_scale=32, train_wall=82, gb_free=14.4, wall=31532
2025-10-31 03:39:56 | INFO | train_inner | epoch 002:   6119 / 11384 loss=0.23186, wps=1043, ups=0.52, wpb=1996.1, bsz=128, num_updates=17400, lr=2.32e-05, gnorm=38.147, clip=100, loss_scale=32, train_wall=95, gb_free=13.3, wall=31627
2025-10-31 03:41:21 | INFO | train_inner | epoch 002:   6169 / 11384 loss=0.227778, wps=1158.4, ups=0.59, wpb=1969.4, bsz=128, num_updates=17450, lr=2.32667e-05, gnorm=33.668, clip=100, loss_scale=64, train_wall=85, gb_free=17.4, wall=31712
2025-10-31 03:42:50 | INFO | train_inner | epoch 002:   6219 / 11384 loss=0.211828, wps=1087.1, ups=0.56, wpb=1927.1, bsz=128, num_updates=17500, lr=2.33333e-05, gnorm=36.43, clip=100, loss_scale=64, train_wall=88, gb_free=15.5, wall=31801
2025-10-31 03:43:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:43:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 03:44:20 | INFO | train_inner | epoch 002:   6271 / 11384 loss=0.218183, wps=1080.1, ups=0.55, wpb=1949, bsz=128, num_updates=17550, lr=2.34e-05, gnorm=34.678, clip=100, loss_scale=16, train_wall=87, gb_free=15.1, wall=31891
2025-10-31 03:46:07 | INFO | train_inner | epoch 002:   6321 / 11384 loss=0.22366, wps=903.7, ups=0.47, wpb=1933.6, bsz=128, num_updates=17600, lr=2.34667e-05, gnorm=35.208, clip=100, loss_scale=16, train_wall=107, gb_free=13.3, wall=31998
2025-10-31 03:47:37 | INFO | train_inner | epoch 002:   6371 / 11384 loss=0.230542, wps=1097.3, ups=0.55, wpb=1978.8, bsz=128, num_updates=17650, lr=2.35333e-05, gnorm=37.606, clip=100, loss_scale=32, train_wall=90, gb_free=13.7, wall=32089
2025-10-31 03:49:12 | INFO | train_inner | epoch 002:   6421 / 11384 loss=0.222188, wps=1049, ups=0.53, wpb=1987.3, bsz=128, num_updates=17700, lr=2.36e-05, gnorm=37.208, clip=100, loss_scale=32, train_wall=94, gb_free=15.9, wall=32183
2025-10-31 03:50:56 | INFO | train_inner | epoch 002:   6471 / 11384 loss=0.228241, wps=938.7, ups=0.48, wpb=1959.9, bsz=128, num_updates=17750, lr=2.36667e-05, gnorm=36.131, clip=100, loss_scale=32, train_wall=104, gb_free=15.1, wall=32288
2025-10-31 03:51:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:52:22 | INFO | train_inner | epoch 002:   6522 / 11384 loss=0.219282, wps=1140.4, ups=0.58, wpb=1952.3, bsz=128, num_updates=17800, lr=2.37333e-05, gnorm=36.231, clip=100, loss_scale=32, train_wall=85, gb_free=15.7, wall=32373
2025-10-31 03:53:37 | INFO | train_inner | epoch 002:   6572 / 11384 loss=0.220983, wps=1296.8, ups=0.66, wpb=1953.3, bsz=128, num_updates=17850, lr=2.38e-05, gnorm=34.694, clip=100, loss_scale=32, train_wall=75, gb_free=6.9, wall=32449
2025-10-31 03:54:56 | INFO | train_inner | epoch 002:   6622 / 11384 loss=0.229353, wps=1260.2, ups=0.64, wpb=1968.5, bsz=128, num_updates=17900, lr=2.38667e-05, gnorm=34.767, clip=100, loss_scale=32, train_wall=78, gb_free=15.2, wall=32527
2025-10-31 03:55:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 03:56:23 | INFO | train_inner | epoch 002:   6673 / 11384 loss=0.220314, wps=1100.4, ups=0.57, wpb=1919.4, bsz=128, num_updates=17950, lr=2.39333e-05, gnorm=34.234, clip=100, loss_scale=32, train_wall=87, gb_free=16.7, wall=32614
2025-10-31 03:57:29 | INFO | train_inner | epoch 002:   6723 / 11384 loss=0.230129, wps=1493.7, ups=0.75, wpb=1986.3, bsz=128, num_updates=18000, lr=2.4e-05, gnorm=36.526, clip=100, loss_scale=32, train_wall=66, gb_free=13, wall=32681
2025-10-31 03:58:46 | INFO | train_inner | epoch 002:   6773 / 11384 loss=0.215799, wps=1259.6, ups=0.65, wpb=1938.8, bsz=128, num_updates=18050, lr=2.40667e-05, gnorm=35.155, clip=100, loss_scale=32, train_wall=77, gb_free=15.3, wall=32758
2025-10-31 03:59:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:00:15 | INFO | train_inner | epoch 002:   6824 / 11384 loss=0.218305, wps=1095.9, ups=0.56, wpb=1945.7, bsz=128, num_updates=18100, lr=2.41333e-05, gnorm=35.263, clip=100, loss_scale=32, train_wall=88, gb_free=14.4, wall=32846
2025-10-31 04:01:28 | INFO | train_inner | epoch 002:   6874 / 11384 loss=0.2148, wps=1386.1, ups=0.69, wpb=2008, bsz=128, num_updates=18150, lr=2.42e-05, gnorm=38.604, clip=100, loss_scale=32, train_wall=72, gb_free=11.8, wall=32919
2025-10-31 04:02:45 | INFO | train_inner | epoch 002:   6924 / 11384 loss=0.229384, wps=1267.4, ups=0.65, wpb=1958.1, bsz=128, num_updates=18200, lr=2.42667e-05, gnorm=39.43, clip=100, loss_scale=64, train_wall=77, gb_free=17, wall=32996
2025-10-31 04:03:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:04:09 | INFO | train_inner | epoch 002:   6975 / 11384 loss=0.214583, wps=1163.9, ups=0.59, wpb=1958.7, bsz=128, num_updates=18250, lr=2.43333e-05, gnorm=36.4, clip=100, loss_scale=32, train_wall=84, gb_free=16.9, wall=33080
2025-10-31 04:05:22 | INFO | train_inner | epoch 002:   7025 / 11384 loss=0.212291, wps=1362.8, ups=0.69, wpb=1979.5, bsz=128, num_updates=18300, lr=2.44e-05, gnorm=35.663, clip=100, loss_scale=32, train_wall=72, gb_free=10, wall=33153
2025-10-31 04:06:53 | INFO | train_inner | epoch 002:   7075 / 11384 loss=0.217152, wps=1050.6, ups=0.54, wpb=1927.9, bsz=128, num_updates=18350, lr=2.44667e-05, gnorm=34.255, clip=100, loss_scale=32, train_wall=92, gb_free=16.4, wall=33245
2025-10-31 04:07:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:07:50 | INFO | train_inner | epoch 002:   7126 / 11384 loss=0.218781, wps=1742.7, ups=0.89, wpb=1961.3, bsz=128, num_updates=18400, lr=2.45333e-05, gnorm=33.305, clip=100, loss_scale=32, train_wall=56, gb_free=15.1, wall=33301
2025-10-31 04:09:35 | INFO | train_inner | epoch 002:   7176 / 11384 loss=0.22005, wps=941.4, ups=0.47, wpb=1988.7, bsz=128, num_updates=18450, lr=2.46e-05, gnorm=36.551, clip=100, loss_scale=32, train_wall=105, gb_free=7.5, wall=33407
2025-10-31 04:10:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 04:10:48 | INFO | train_inner | epoch 002:   7227 / 11384 loss=0.209335, wps=1340.3, ups=0.69, wpb=1956.6, bsz=128, num_updates=18500, lr=2.46667e-05, gnorm=35.169, clip=100, loss_scale=16, train_wall=73, gb_free=14.9, wall=33480
2025-10-31 04:12:00 | INFO | train_inner | epoch 002:   7277 / 11384 loss=0.207931, wps=1368.1, ups=0.7, wpb=1959.4, bsz=128, num_updates=18550, lr=2.47333e-05, gnorm=36.783, clip=100, loss_scale=16, train_wall=71, gb_free=14.7, wall=33551
2025-10-31 04:13:47 | INFO | train_inner | epoch 002:   7327 / 11384 loss=0.221917, wps=931, ups=0.47, wpb=2000.7, bsz=128, num_updates=18600, lr=2.48e-05, gnorm=40.371, clip=100, loss_scale=16, train_wall=107, gb_free=14.7, wall=33659
2025-10-31 04:14:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 04:15:39 | INFO | train_inner | epoch 002:   7378 / 11384 loss=0.20625, wps=875.2, ups=0.45, wpb=1954, bsz=128, num_updates=18650, lr=2.48667e-05, gnorm=37.915, clip=100, loss_scale=16, train_wall=111, gb_free=15.2, wall=33770
2025-10-31 04:17:09 | INFO | train_inner | epoch 002:   7428 / 11384 loss=0.218265, wps=1094.9, ups=0.55, wpb=1972.9, bsz=128, num_updates=18700, lr=2.49333e-05, gnorm=36.852, clip=100, loss_scale=16, train_wall=90, gb_free=15.7, wall=33860
2025-10-31 04:18:24 | INFO | train_inner | epoch 002:   7478 / 11384 loss=0.211285, wps=1287.9, ups=0.66, wpb=1942.4, bsz=128, num_updates=18750, lr=2.5e-05, gnorm=35.658, clip=100, loss_scale=16, train_wall=75, gb_free=17.9, wall=33936
2025-10-31 04:19:33 | INFO | train_inner | epoch 002:   7528 / 11384 loss=0.216452, wps=1464.1, ups=0.73, wpb=1994.4, bsz=128, num_updates=18800, lr=2.50667e-05, gnorm=34.684, clip=100, loss_scale=32, train_wall=68, gb_free=14, wall=34004
2025-10-31 04:21:02 | INFO | train_inner | epoch 002:   7578 / 11384 loss=0.211724, wps=1105.7, ups=0.56, wpb=1987.1, bsz=128, num_updates=18850, lr=2.51333e-05, gnorm=35.704, clip=100, loss_scale=32, train_wall=90, gb_free=13.5, wall=34094
2025-10-31 04:22:23 | INFO | train_inner | epoch 002:   7628 / 11384 loss=0.213029, wps=1222.2, ups=0.62, wpb=1968.8, bsz=128, num_updates=18900, lr=2.52e-05, gnorm=35.282, clip=100, loss_scale=64, train_wall=80, gb_free=15.5, wall=34174
2025-10-31 04:23:37 | INFO | train_inner | epoch 002:   7678 / 11384 loss=0.199844, wps=1315.1, ups=0.68, wpb=1947.2, bsz=128, num_updates=18950, lr=2.52667e-05, gnorm=31.926, clip=100, loss_scale=64, train_wall=74, gb_free=15.8, wall=34248
2025-10-31 04:25:06 | INFO | train_inner | epoch 002:   7728 / 11384 loss=0.204325, wps=1109.4, ups=0.56, wpb=1976.2, bsz=128, num_updates=19000, lr=2.53333e-05, gnorm=33.434, clip=100, loss_scale=64, train_wall=89, gb_free=15.1, wall=34338
2025-10-31 04:25:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-31 04:26:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:26:20 | INFO | train_inner | epoch 002:   7780 / 11384 loss=0.2127, wps=1339.9, ups=0.68, wpb=1977.2, bsz=128, num_updates=19050, lr=2.54e-05, gnorm=36.086, clip=100, loss_scale=32, train_wall=74, gb_free=14.7, wall=34411
2025-10-31 04:27:32 | INFO | train_inner | epoch 002:   7830 / 11384 loss=0.207924, wps=1356.5, ups=0.7, wpb=1944.9, bsz=128, num_updates=19100, lr=2.54667e-05, gnorm=35.221, clip=100, loss_scale=32, train_wall=71, gb_free=9.6, wall=34483
2025-10-31 04:28:52 | INFO | train_inner | epoch 002:   7880 / 11384 loss=0.203416, wps=1210.1, ups=0.62, wpb=1948, bsz=128, num_updates=19150, lr=2.55333e-05, gnorm=33.902, clip=100, loss_scale=32, train_wall=80, gb_free=15.9, wall=34563
2025-10-31 04:30:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:30:12 | INFO | train_inner | epoch 002:   7931 / 11384 loss=0.195737, wps=1248.1, ups=0.63, wpb=1990, bsz=128, num_updates=19200, lr=2.56e-05, gnorm=33.872, clip=100, loss_scale=32, train_wall=79, gb_free=14.1, wall=34643
2025-10-31 04:31:40 | INFO | train_inner | epoch 002:   7981 / 11384 loss=0.20417, wps=1131.6, ups=0.57, wpb=1986.8, bsz=128, num_updates=19250, lr=2.56667e-05, gnorm=35.493, clip=100, loss_scale=32, train_wall=87, gb_free=7.1, wall=34731
2025-10-31 04:32:55 | INFO | train_inner | epoch 002:   8031 / 11384 loss=0.200395, wps=1312.4, ups=0.67, wpb=1971.7, bsz=128, num_updates=19300, lr=2.57333e-05, gnorm=34.997, clip=100, loss_scale=32, train_wall=75, gb_free=16, wall=34806
2025-10-31 04:34:30 | INFO | train_inner | epoch 002:   8081 / 11384 loss=0.197853, wps=989, ups=0.52, wpb=1890.5, bsz=128, num_updates=19350, lr=2.58e-05, gnorm=35.501, clip=100, loss_scale=64, train_wall=95, gb_free=16.7, wall=34902
2025-10-31 04:35:45 | INFO | train_inner | epoch 002:   8131 / 11384 loss=0.204188, wps=1331.3, ups=0.67, wpb=1974.9, bsz=128, num_updates=19400, lr=2.58667e-05, gnorm=33.905, clip=100, loss_scale=64, train_wall=74, gb_free=15.7, wall=34976
2025-10-31 04:36:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:37:12 | INFO | train_inner | epoch 002:   8182 / 11384 loss=0.206814, wps=1091.7, ups=0.57, wpb=1903.9, bsz=128, num_updates=19450, lr=2.59333e-05, gnorm=34.035, clip=100, loss_scale=32, train_wall=87, gb_free=16.3, wall=35063
2025-10-31 04:38:36 | INFO | train_inner | epoch 002:   8232 / 11384 loss=0.208218, wps=1154.7, ups=0.59, wpb=1950.2, bsz=128, num_updates=19500, lr=2.6e-05, gnorm=33.805, clip=100, loss_scale=32, train_wall=84, gb_free=16.9, wall=35148
2025-10-31 04:39:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 04:40:12 | INFO | train_inner | epoch 002:   8283 / 11384 loss=0.198025, wps=1012.5, ups=0.52, wpb=1939.3, bsz=128, num_updates=19550, lr=2.60667e-05, gnorm=32.985, clip=100, loss_scale=16, train_wall=94, gb_free=17.2, wall=35243
2025-10-31 04:41:54 | INFO | train_inner | epoch 002:   8333 / 11384 loss=0.200452, wps=953.4, ups=0.49, wpb=1952.3, bsz=128, num_updates=19600, lr=2.61333e-05, gnorm=36.318, clip=100, loss_scale=16, train_wall=102, gb_free=15.3, wall=35346
2025-10-31 04:42:52 | INFO | train_inner | epoch 002:   8383 / 11384 loss=0.199991, wps=1728.3, ups=0.88, wpb=1971.9, bsz=128, num_updates=19650, lr=2.62e-05, gnorm=33.708, clip=100, loss_scale=16, train_wall=57, gb_free=13.9, wall=35403
2025-10-31 04:44:11 | INFO | train_inner | epoch 002:   8433 / 11384 loss=0.205342, wps=1225.2, ups=0.63, wpb=1953.7, bsz=128, num_updates=19700, lr=2.62667e-05, gnorm=36.792, clip=100, loss_scale=32, train_wall=79, gb_free=15.8, wall=35483
2025-10-31 04:45:28 | INFO | train_inner | epoch 002:   8483 / 11384 loss=0.207384, wps=1269.2, ups=0.65, wpb=1945.6, bsz=128, num_updates=19750, lr=2.63333e-05, gnorm=33.77, clip=100, loss_scale=32, train_wall=76, gb_free=14.8, wall=35559
2025-10-31 04:46:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:46:59 | INFO | train_inner | epoch 002:   8534 / 11384 loss=0.199767, wps=1066.7, ups=0.55, wpb=1936.3, bsz=128, num_updates=19800, lr=2.64e-05, gnorm=34.298, clip=100, loss_scale=32, train_wall=90, gb_free=15.6, wall=35650
2025-10-31 04:47:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 04:48:04 | INFO | train_inner | epoch 002:   8585 / 11384 loss=0.199604, wps=1504.2, ups=0.77, wpb=1952.8, bsz=128, num_updates=19850, lr=2.64667e-05, gnorm=33.576, clip=100, loss_scale=16, train_wall=65, gb_free=13.8, wall=35715
2025-10-31 04:49:30 | INFO | train_inner | epoch 002:   8635 / 11384 loss=0.202334, wps=1122.5, ups=0.58, wpb=1949.1, bsz=128, num_updates=19900, lr=2.65333e-05, gnorm=33.883, clip=100, loss_scale=16, train_wall=84, gb_free=15.9, wall=35802
2025-10-31 04:50:42 | INFO | train_inner | epoch 002:   8685 / 11384 loss=0.199993, wps=1425.7, ups=0.7, wpb=2037, bsz=128, num_updates=19950, lr=2.66e-05, gnorm=34.275, clip=100, loss_scale=32, train_wall=71, gb_free=15.5, wall=35873
2025-10-31 04:51:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 04:52:13 | INFO | train_inner | epoch 002:   8736 / 11384 loss=0.201372, wps=1071.6, ups=0.55, wpb=1944.5, bsz=128, num_updates=20000, lr=2.66667e-05, gnorm=34.737, clip=100, loss_scale=16, train_wall=90, gb_free=15.8, wall=35964
2025-10-31 04:53:59 | INFO | train_inner | epoch 002:   8786 / 11384 loss=0.200747, wps=919.9, ups=0.47, wpb=1949.8, bsz=128, num_updates=20050, lr=2.67333e-05, gnorm=35.632, clip=100, loss_scale=16, train_wall=106, gb_free=16.6, wall=36070
2025-10-31 04:55:03 | INFO | train_inner | epoch 002:   8836 / 11384 loss=0.201922, wps=1529.6, ups=0.77, wpb=1984, bsz=128, num_updates=20100, lr=2.68e-05, gnorm=35.935, clip=100, loss_scale=32, train_wall=65, gb_free=9.5, wall=36135
2025-10-31 04:56:41 | INFO | train_inner | epoch 002:   8886 / 11384 loss=0.206653, wps=1012.5, ups=0.51, wpb=1970.8, bsz=128, num_updates=20150, lr=2.68667e-05, gnorm=34.265, clip=100, loss_scale=32, train_wall=97, gb_free=14.1, wall=36232
2025-10-31 04:58:06 | INFO | train_inner | epoch 002:   8936 / 11384 loss=0.199856, wps=1156.7, ups=0.59, wpb=1967.1, bsz=128, num_updates=20200, lr=2.69333e-05, gnorm=34.801, clip=100, loss_scale=32, train_wall=85, gb_free=15.8, wall=36317
2025-10-31 04:59:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 04:59:53 | INFO | train_inner | epoch 002:   8987 / 11384 loss=0.209113, wps=911.4, ups=0.46, wpb=1960.8, bsz=128, num_updates=20250, lr=2.7e-05, gnorm=39.7, clip=100, loss_scale=32, train_wall=107, gb_free=10.6, wall=36425
2025-10-31 05:00:56 | INFO | train_inner | epoch 002:   9037 / 11384 loss=0.201044, wps=1604, ups=0.8, wpb=2009.4, bsz=128, num_updates=20300, lr=2.70667e-05, gnorm=36.545, clip=100, loss_scale=32, train_wall=62, gb_free=11.9, wall=36487
2025-10-31 05:00:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 05:02:18 | INFO | train_inner | epoch 002:   9088 / 11384 loss=0.1953, wps=1196.2, ups=0.61, wpb=1969.9, bsz=128, num_updates=20350, lr=2.71333e-05, gnorm=36.31, clip=100, loss_scale=16, train_wall=82, gb_free=15, wall=36570
2025-10-31 05:03:27 | INFO | train_inner | epoch 002:   9138 / 11384 loss=0.186373, wps=1416.5, ups=0.73, wpb=1937.5, bsz=128, num_updates=20400, lr=2.72e-05, gnorm=33.079, clip=100, loss_scale=16, train_wall=68, gb_free=15.4, wall=36638
2025-10-31 05:04:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 05:04:52 | INFO | train_inner | epoch 002:   9189 / 11384 loss=0.200254, wps=1144.1, ups=0.59, wpb=1952.8, bsz=128, num_updates=20450, lr=2.72667e-05, gnorm=33.187, clip=100, loss_scale=16, train_wall=85, gb_free=14.1, wall=36724
2025-10-31 05:06:01 | INFO | train_inner | epoch 002:   9239 / 11384 loss=0.201038, wps=1395.1, ups=0.73, wpb=1924, bsz=128, num_updates=20500, lr=2.73333e-05, gnorm=34.276, clip=100, loss_scale=16, train_wall=69, gb_free=15.6, wall=36792
2025-10-31 05:07:35 | INFO | train_inner | epoch 002:   9289 / 11384 loss=0.195138, wps=1033.8, ups=0.53, wpb=1933.2, bsz=128, num_updates=20550, lr=2.74e-05, gnorm=39.081, clip=100, loss_scale=16, train_wall=93, gb_free=16.7, wall=36886
2025-10-31 05:08:52 | INFO | train_inner | epoch 002:   9339 / 11384 loss=0.189406, wps=1265.2, ups=0.65, wpb=1956, bsz=128, num_updates=20600, lr=2.74667e-05, gnorm=30.751, clip=100, loss_scale=32, train_wall=77, gb_free=15.5, wall=36963
2025-10-31 05:10:14 | INFO | train_inner | epoch 002:   9389 / 11384 loss=0.191304, wps=1205.4, ups=0.61, wpb=1981.3, bsz=128, num_updates=20650, lr=2.75333e-05, gnorm=34.897, clip=100, loss_scale=32, train_wall=82, gb_free=15.3, wall=37045
2025-10-31 05:11:14 | INFO | train_inner | epoch 002:   9439 / 11384 loss=0.188868, wps=1649.1, ups=0.84, wpb=1959.8, bsz=128, num_updates=20700, lr=2.76e-05, gnorm=33.653, clip=100, loss_scale=32, train_wall=59, gb_free=10.3, wall=37105
2025-10-31 05:12:45 | INFO | train_inner | epoch 002:   9489 / 11384 loss=0.200044, wps=1070.5, ups=0.55, wpb=1959.3, bsz=127.9, num_updates=20750, lr=2.76667e-05, gnorm=35.465, clip=100, loss_scale=64, train_wall=91, gb_free=8.8, wall=37196
2025-10-31 05:12:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:14:32 | INFO | train_inner | epoch 002:   9540 / 11384 loss=0.184673, wps=914.7, ups=0.47, wpb=1950.8, bsz=128, num_updates=20800, lr=2.77333e-05, gnorm=31.808, clip=100, loss_scale=32, train_wall=106, gb_free=16.3, wall=37303
2025-10-31 05:15:30 | INFO | train_inner | epoch 002:   9590 / 11384 loss=0.200253, wps=1692.2, ups=0.85, wpb=1981.7, bsz=128, num_updates=20850, lr=2.78e-05, gnorm=33.264, clip=100, loss_scale=32, train_wall=58, gb_free=14.9, wall=37362
2025-10-31 05:17:10 | INFO | train_inner | epoch 002:   9640 / 11384 loss=0.191918, wps=996.7, ups=0.5, wpb=1976, bsz=128, num_updates=20900, lr=2.78667e-05, gnorm=34.651, clip=100, loss_scale=64, train_wall=99, gb_free=13.2, wall=37461
2025-10-31 05:17:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:18:27 | INFO | train_inner | epoch 002:   9691 / 11384 loss=0.188345, wps=1255.5, ups=0.65, wpb=1934.5, bsz=128, num_updates=20950, lr=2.79333e-05, gnorm=32.178, clip=100, loss_scale=32, train_wall=77, gb_free=15.7, wall=37538
2025-10-31 05:20:11 | INFO | train_inner | epoch 002:   9741 / 11384 loss=0.175354, wps=925.3, ups=0.48, wpb=1929.4, bsz=128, num_updates=21000, lr=2.8e-05, gnorm=32.18, clip=100, loss_scale=32, train_wall=104, gb_free=16, wall=37642
2025-10-31 05:21:31 | INFO | train_inner | epoch 002:   9791 / 11384 loss=0.178089, wps=1229, ups=0.63, wpb=1960.7, bsz=128, num_updates=21050, lr=2.80667e-05, gnorm=31.714, clip=100, loss_scale=64, train_wall=80, gb_free=15.1, wall=37722
2025-10-31 05:22:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:23:01 | INFO | train_inner | epoch 002:   9842 / 11384 loss=0.187815, wps=1102.2, ups=0.56, wpb=1976, bsz=128, num_updates=21100, lr=2.81333e-05, gnorm=34.09, clip=100, loss_scale=32, train_wall=89, gb_free=10.8, wall=37812
2025-10-31 05:24:09 | INFO | train_inner | epoch 002:   9892 / 11384 loss=0.198324, wps=1453.3, ups=0.73, wpb=2003.9, bsz=128, num_updates=21150, lr=2.82e-05, gnorm=34.241, clip=100, loss_scale=32, train_wall=69, gb_free=14.5, wall=37881
2025-10-31 05:25:33 | INFO | train_inner | epoch 002:   9942 / 11384 loss=0.186145, wps=1164.3, ups=0.6, wpb=1937.9, bsz=128, num_updates=21200, lr=2.82667e-05, gnorm=32.772, clip=100, loss_scale=32, train_wall=83, gb_free=16.9, wall=37964
2025-10-31 05:26:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:27:04 | INFO | train_inner | epoch 002:   9993 / 11384 loss=0.186308, wps=1057.4, ups=0.55, wpb=1931.7, bsz=128, num_updates=21250, lr=2.83333e-05, gnorm=32.63, clip=100, loss_scale=32, train_wall=91, gb_free=12.3, wall=38055
2025-10-31 05:27:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 05:28:04 | INFO | train_inner | epoch 002:  10044 / 11384 loss=0.189951, wps=1663.3, ups=0.83, wpb=2004.8, bsz=128, num_updates=21300, lr=2.84e-05, gnorm=35.094, clip=100, loss_scale=16, train_wall=60, gb_free=16.4, wall=38116
2025-10-31 05:29:41 | INFO | train_inner | epoch 002:  10094 / 11384 loss=0.181395, wps=1001.8, ups=0.52, wpb=1926.9, bsz=128, num_updates=21350, lr=2.84667e-05, gnorm=35.851, clip=100, loss_scale=16, train_wall=96, gb_free=16, wall=38212
2025-10-31 05:30:36 | INFO | train_inner | epoch 002:  10144 / 11384 loss=0.180967, wps=1791.2, ups=0.9, wpb=1994.2, bsz=128, num_updates=21400, lr=2.85333e-05, gnorm=32.199, clip=100, loss_scale=32, train_wall=55, gb_free=12.8, wall=38268
2025-10-31 05:31:59 | INFO | train_inner | epoch 002:  10194 / 11384 loss=0.182655, wps=1176.6, ups=0.6, wpb=1954.2, bsz=128, num_updates=21450, lr=2.86e-05, gnorm=30.821, clip=100, loss_scale=32, train_wall=83, gb_free=16.9, wall=38351
2025-10-31 05:33:43 | INFO | train_inner | epoch 002:  10244 / 11384 loss=0.188578, wps=942.2, ups=0.48, wpb=1954.8, bsz=128, num_updates=21500, lr=2.86667e-05, gnorm=34.932, clip=100, loss_scale=32, train_wall=103, gb_free=13, wall=38454
2025-10-31 05:35:25 | INFO | train_inner | epoch 002:  10294 / 11384 loss=0.181553, wps=960.4, ups=0.49, wpb=1954.9, bsz=128, num_updates=21550, lr=2.87333e-05, gnorm=32.569, clip=100, loss_scale=64, train_wall=102, gb_free=15.5, wall=38556
2025-10-31 05:36:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:36:41 | INFO | train_inner | epoch 002:  10345 / 11384 loss=0.185624, wps=1277.4, ups=0.65, wpb=1954.3, bsz=128, num_updates=21600, lr=2.88e-05, gnorm=35.525, clip=100, loss_scale=32, train_wall=76, gb_free=14.8, wall=38633
2025-10-31 05:38:04 | INFO | train_inner | epoch 002:  10395 / 11384 loss=0.178901, wps=1203.1, ups=0.61, wpb=1987.2, bsz=128, num_updates=21650, lr=2.88667e-05, gnorm=35.274, clip=100, loss_scale=32, train_wall=82, gb_free=13.4, wall=38715
2025-10-31 05:39:42 | INFO | train_inner | epoch 002:  10445 / 11384 loss=0.181173, wps=1001.1, ups=0.51, wpb=1960.5, bsz=128, num_updates=21700, lr=2.89333e-05, gnorm=30.991, clip=100, loss_scale=32, train_wall=98, gb_free=16.6, wall=38813
2025-10-31 05:39:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:41:05 | INFO | train_inner | epoch 002:  10496 / 11384 loss=0.185223, wps=1166, ups=0.6, wpb=1945.8, bsz=128, num_updates=21750, lr=2.9e-05, gnorm=32.351, clip=100, loss_scale=32, train_wall=83, gb_free=13.4, wall=38897
2025-10-31 05:42:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 05:42:14 | INFO | train_inner | epoch 002:  10547 / 11384 loss=0.193108, wps=1407.2, ups=0.73, wpb=1928.2, bsz=128, num_updates=21800, lr=2.90667e-05, gnorm=35.048, clip=100, loss_scale=16, train_wall=68, gb_free=8.4, wall=38965
2025-10-31 05:43:36 | INFO | train_inner | epoch 002:  10597 / 11384 loss=0.172725, wps=1185.2, ups=0.61, wpb=1955.8, bsz=128, num_updates=21850, lr=2.91333e-05, gnorm=30.944, clip=100, loss_scale=16, train_wall=82, gb_free=14.1, wall=39048
2025-10-31 05:45:13 | INFO | train_inner | epoch 002:  10647 / 11384 loss=0.180136, wps=1018.2, ups=0.52, wpb=1974.9, bsz=128, num_updates=21900, lr=2.92e-05, gnorm=33.144, clip=100, loss_scale=16, train_wall=97, gb_free=13.6, wall=39145
2025-10-31 05:46:37 | INFO | train_inner | epoch 002:  10697 / 11384 loss=0.197717, wps=1150.8, ups=0.6, wpb=1914.6, bsz=128, num_updates=21950, lr=2.92667e-05, gnorm=43.541, clip=100, loss_scale=32, train_wall=83, gb_free=15, wall=39228
2025-10-31 05:47:47 | INFO | train_inner | epoch 002:  10747 / 11384 loss=0.184681, wps=1386.6, ups=0.71, wpb=1963.2, bsz=128, num_updates=22000, lr=2.93333e-05, gnorm=29.781, clip=100, loss_scale=32, train_wall=71, gb_free=14.4, wall=39299
2025-10-31 05:49:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 05:49:09 | INFO | train_inner | epoch 002:  10798 / 11384 loss=0.188001, wps=1198.7, ups=0.61, wpb=1965.6, bsz=128, num_updates=22050, lr=2.94e-05, gnorm=32.822, clip=100, loss_scale=16, train_wall=82, gb_free=15.8, wall=39381
2025-10-31 05:50:33 | INFO | train_inner | epoch 002:  10848 / 11384 loss=0.183905, wps=1175.4, ups=0.6, wpb=1965.1, bsz=128, num_updates=22100, lr=2.94667e-05, gnorm=32.64, clip=100, loss_scale=16, train_wall=83, gb_free=15.6, wall=39464
2025-10-31 05:51:44 | INFO | train_inner | epoch 002:  10898 / 11384 loss=0.17949, wps=1385.1, ups=0.71, wpb=1954.4, bsz=128, num_updates=22150, lr=2.95333e-05, gnorm=32.764, clip=100, loss_scale=16, train_wall=70, gb_free=11.8, wall=39535
2025-10-31 05:53:16 | INFO | train_inner | epoch 002:  10948 / 11384 loss=0.18046, wps=1055.7, ups=0.54, wpb=1959.1, bsz=128, num_updates=22200, lr=2.96e-05, gnorm=30.03, clip=100, loss_scale=32, train_wall=93, gb_free=15.7, wall=39628
2025-10-31 05:54:39 | INFO | train_inner | epoch 002:  10998 / 11384 loss=0.180002, wps=1205.2, ups=0.61, wpb=1984.8, bsz=128, num_updates=22250, lr=2.96667e-05, gnorm=34.342, clip=100, loss_scale=32, train_wall=82, gb_free=16.7, wall=39710
2025-10-31 05:55:59 | INFO | train_inner | epoch 002:  11048 / 11384 loss=0.18087, wps=1209.7, ups=0.63, wpb=1929.2, bsz=128, num_updates=22300, lr=2.97333e-05, gnorm=31.206, clip=100, loss_scale=32, train_wall=79, gb_free=5.3, wall=39790
2025-10-31 05:57:29 | INFO | train_inner | epoch 002:  11098 / 11384 loss=0.177902, wps=1080.7, ups=0.55, wpb=1947.7, bsz=128, num_updates=22350, lr=2.98e-05, gnorm=32.283, clip=100, loss_scale=64, train_wall=90, gb_free=16.5, wall=39880
2025-10-31 05:58:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 05:59:18 | INFO | train_inner | epoch 002:  11149 / 11384 loss=0.179321, wps=889.8, ups=0.46, wpb=1941, bsz=128, num_updates=22400, lr=2.98667e-05, gnorm=32.043, clip=100, loss_scale=32, train_wall=109, gb_free=13.6, wall=39989
2025-10-31 06:00:30 | INFO | train_inner | epoch 002:  11199 / 11384 loss=0.178348, wps=1334.5, ups=0.69, wpb=1925.6, bsz=128, num_updates=22450, lr=2.99333e-05, gnorm=30.605, clip=100, loss_scale=32, train_wall=72, gb_free=7.7, wall=40061
2025-10-31 06:02:05 | INFO | train_inner | epoch 002:  11249 / 11384 loss=0.187374, wps=1012.5, ups=0.52, wpb=1928.6, bsz=128, num_updates=22500, lr=3e-05, gnorm=33.14, clip=100, loss_scale=32, train_wall=95, gb_free=16.7, wall=40157
2025-10-31 06:03:05 | INFO | train_inner | epoch 002:  11299 / 11384 loss=0.182064, wps=1617.2, ups=0.83, wpb=1941.2, bsz=128, num_updates=22550, lr=3.00667e-05, gnorm=30.456, clip=100, loss_scale=64, train_wall=60, gb_free=15.4, wall=40217
2025-10-31 06:04:38 | INFO | train_inner | epoch 002:  11349 / 11384 loss=0.18144, wps=1055.4, ups=0.54, wpb=1947.4, bsz=128, num_updates=22600, lr=3.01333e-05, gnorm=30.826, clip=100, loss_scale=64, train_wall=92, gb_free=11.2, wall=40309
2025-10-31 06:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2025-10-31 06:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-10-31 06:19:25 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.165963 | wps 1438.8 | wpb 1948.3 | bsz 127.9 | num_updates 22634 | best_loss 0.165963
2025-10-31 06:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 22634 updates
2025-10-31 06:19:25 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint2.pt
2025-10-31 06:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint2.pt
2025-10-31 06:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint2.pt (epoch 2 @ 22634 updates, score 0.165963) (writing took 14.694648729986511 seconds)
2025-10-31 06:19:40 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2025-10-31 06:19:40 | INFO | train | epoch 002 | loss 0.23545 | wps 980.9 | ups 0.5 | wpb 1958.7 | bsz 128 | num_updates 22634 | lr 3.01787e-05 | gnorm 36.502 | clip 100 | loss_scale 64 | train_wall 20919 | gb_free 15.6 | wall 41212
2025-10-31 06:19:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-10-31 06:19:44 | INFO | fairseq.trainer | begin training epoch 3
2025-10-31 06:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2025-10-31 06:25:11 | INFO | train_inner | epoch 003:     16 / 11384 loss=0.185548, wps=78.7, ups=0.04, wpb=1940.7, bsz=127.7, num_updates=22650, lr=3.02e-05, gnorm=33.602, clip=100, loss_scale=64, train_wall=126, gb_free=14, wall=41542
2025-10-31 06:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 06:26:23 | INFO | train_inner | epoch 003:     67 / 11384 loss=0.178561, wps=1340.6, ups=0.69, wpb=1948.8, bsz=128, num_updates=22700, lr=3.02667e-05, gnorm=29.336, clip=100, loss_scale=32, train_wall=72, gb_free=15.5, wall=41615
2025-10-31 06:27:29 | INFO | train_inner | epoch 003:    117 / 11384 loss=0.177742, wps=1484.1, ups=0.76, wpb=1941.3, bsz=128, num_updates=22750, lr=3.03333e-05, gnorm=32.756, clip=100, loss_scale=32, train_wall=65, gb_free=16.3, wall=41680
2025-10-31 06:29:53 | INFO | train_inner | epoch 003:    167 / 11384 loss=0.172422, wps=678.6, ups=0.35, wpb=1957.7, bsz=128, num_updates=22800, lr=3.04e-05, gnorm=29.397, clip=100, loss_scale=64, train_wall=144, gb_free=11.6, wall=41824
2025-10-31 06:30:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 06:31:44 | INFO | train_inner | epoch 003:    218 / 11384 loss=0.171855, wps=874.8, ups=0.45, wpb=1942.5, bsz=128, num_updates=22850, lr=3.04667e-05, gnorm=33.891, clip=100, loss_scale=32, train_wall=111, gb_free=13.8, wall=41936
2025-10-31 06:31:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 06:33:35 | INFO | train_inner | epoch 003:    269 / 11384 loss=0.170473, wps=868.5, ups=0.45, wpb=1917.7, bsz=128, num_updates=22900, lr=3.05333e-05, gnorm=33.184, clip=100, loss_scale=16, train_wall=110, gb_free=15.1, wall=42046
2025-10-31 06:35:03 | INFO | train_inner | epoch 003:    319 / 11384 loss=0.168187, wps=1097.5, ups=0.56, wpb=1943.7, bsz=128, num_updates=22950, lr=3.06e-05, gnorm=31.134, clip=100, loss_scale=16, train_wall=88, gb_free=15.2, wall=42135
2025-10-31 06:35:56 | INFO | train_inner | epoch 003:    369 / 11384 loss=0.175334, wps=1858.4, ups=0.94, wpb=1968.7, bsz=128, num_updates=23000, lr=3.06667e-05, gnorm=30.399, clip=100, loss_scale=32, train_wall=53, gb_free=15.5, wall=42188
2025-10-31 06:37:59 | INFO | train_inner | epoch 003:    419 / 11384 loss=0.182095, wps=795.7, ups=0.41, wpb=1957.7, bsz=128, num_updates=23050, lr=3.07333e-05, gnorm=33.709, clip=100, loss_scale=32, train_wall=122, gb_free=6.8, wall=42311
2025-10-31 06:39:45 | INFO | train_inner | epoch 003:    469 / 11384 loss=0.17576, wps=940.3, ups=0.48, wpb=1976.2, bsz=128, num_updates=23100, lr=3.08e-05, gnorm=30.563, clip=100, loss_scale=32, train_wall=104, gb_free=15.8, wall=42416
2025-10-31 06:40:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 06:41:58 | INFO | train_inner | epoch 003:    520 / 11384 loss=0.178617, wps=734.3, ups=0.37, wpb=1967.6, bsz=128, num_updates=23150, lr=3.08667e-05, gnorm=30.667, clip=100, loss_scale=32, train_wall=134, gb_free=15.6, wall=42550
2025-10-31 06:44:11 | INFO | train_inner | epoch 003:    570 / 11384 loss=0.170103, wps=740.5, ups=0.38, wpb=1961.3, bsz=128, num_updates=23200, lr=3.09333e-05, gnorm=31.616, clip=100, loss_scale=32, train_wall=132, gb_free=15.7, wall=42682
2025-10-31 06:45:03 | INFO | train_inner | epoch 003:    620 / 11384 loss=0.176759, wps=1906.9, ups=0.97, wpb=1972.6, bsz=128, num_updates=23250, lr=3.1e-05, gnorm=29.763, clip=100, loss_scale=32, train_wall=52, gb_free=7.5, wall=42734
2025-10-31 06:46:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 06:47:02 | INFO | train_inner | epoch 003:    671 / 11384 loss=0.168011, wps=812.1, ups=0.42, wpb=1946.3, bsz=128, num_updates=23300, lr=3.10667e-05, gnorm=27.658, clip=100, loss_scale=32, train_wall=53, gb_free=16.5, wall=42854
2025-10-31 06:48:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 06:48:58 | INFO | train_inner | epoch 003:    722 / 11384 loss=0.17588, wps=832.9, ups=0.43, wpb=1930, bsz=128, num_updates=23350, lr=3.11333e-05, gnorm=31.084, clip=100, loss_scale=16, train_wall=64, gb_free=16.9, wall=42970
2025-10-31 06:50:49 | INFO | train_inner | epoch 003:    772 / 11384 loss=0.169099, wps=911.9, ups=0.45, wpb=2016.7, bsz=128, num_updates=23400, lr=3.12e-05, gnorm=29.194, clip=100, loss_scale=16, train_wall=75, gb_free=15.8, wall=43080
2025-10-31 06:53:42 | INFO | train_inner | epoch 003:    822 / 11384 loss=0.17008, wps=564.5, ups=0.29, wpb=1953.4, bsz=128, num_updates=23450, lr=3.12667e-05, gnorm=32.778, clip=100, loss_scale=16, train_wall=173, gb_free=14.2, wall=43253
2025-10-31 06:55:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 06:55:35 | INFO | train_inner | epoch 003:    873 / 11384 loss=0.174208, wps=858.8, ups=0.44, wpb=1950.5, bsz=128, num_updates=23500, lr=3.13333e-05, gnorm=32.819, clip=100, loss_scale=16, train_wall=113, gb_free=7, wall=43367
2025-10-31 06:57:37 | INFO | train_inner | epoch 003:    923 / 11384 loss=0.170597, wps=801.9, ups=0.41, wpb=1951.4, bsz=128, num_updates=23550, lr=3.14e-05, gnorm=29.775, clip=100, loss_scale=16, train_wall=121, gb_free=15, wall=43488
2025-10-31 06:59:31 | INFO | train_inner | epoch 003:    973 / 11384 loss=0.173325, wps=858.8, ups=0.44, wpb=1962, bsz=128, num_updates=23600, lr=3.14667e-05, gnorm=32.323, clip=100, loss_scale=16, train_wall=66, gb_free=13.9, wall=43603
2025-10-31 07:02:12 | INFO | train_inner | epoch 003:   1023 / 11384 loss=0.170537, wps=613.6, ups=0.31, wpb=1976.8, bsz=128, num_updates=23650, lr=3.15333e-05, gnorm=35.42, clip=100, loss_scale=32, train_wall=53, gb_free=16.8, wall=43764
2025-10-31 07:02:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 07:03:08 | INFO | train_inner | epoch 003:   1074 / 11384 loss=0.164444, wps=1765.9, ups=0.91, wpb=1951.2, bsz=128, num_updates=23700, lr=3.16e-05, gnorm=33.266, clip=100, loss_scale=16, train_wall=55, gb_free=16.1, wall=43819
2025-10-31 07:05:33 | INFO | train_inner | epoch 003:   1124 / 11384 loss=0.176993, wps=680, ups=0.35, wpb=1966.4, bsz=128, num_updates=23750, lr=3.16667e-05, gnorm=35.201, clip=100, loss_scale=16, train_wall=69, gb_free=14.4, wall=43964
2025-10-31 07:07:43 | INFO | train_inner | epoch 003:   1174 / 11384 loss=0.15443, wps=764.4, ups=0.38, wpb=1994.6, bsz=128, num_updates=23800, lr=3.17333e-05, gnorm=30.119, clip=100, loss_scale=32, train_wall=82, gb_free=16.4, wall=44095
2025-10-31 07:10:14 | INFO | train_inner | epoch 003:   1224 / 11384 loss=0.160536, wps=646.5, ups=0.33, wpb=1947.1, bsz=128, num_updates=23850, lr=3.18e-05, gnorm=29.654, clip=100, loss_scale=32, train_wall=50, gb_free=13.9, wall=44245
2025-10-31 07:10:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 07:12:00 | INFO | train_inner | epoch 003:   1275 / 11384 loss=0.159943, wps=909.3, ups=0.47, wpb=1935.6, bsz=128, num_updates=23900, lr=3.18667e-05, gnorm=32.281, clip=100, loss_scale=16, train_wall=74, gb_free=15.9, wall=44352
2025-10-31 07:14:20 | INFO | train_inner | epoch 003:   1325 / 11384 loss=0.165283, wps=699.3, ups=0.36, wpb=1950.3, bsz=128, num_updates=23950, lr=3.19333e-05, gnorm=32.5, clip=100, loss_scale=16, train_wall=139, gb_free=13, wall=44491
2025-10-31 07:15:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 07:15:12 | INFO | train_inner | epoch 003:   1376 / 11384 loss=0.16623, wps=1881.9, ups=0.96, wpb=1953.2, bsz=128, num_updates=24000, lr=3.2e-05, gnorm=30.54, clip=100, loss_scale=16, train_wall=52, gb_free=14.3, wall=44543
2025-10-31 07:17:00 | INFO | train_inner | epoch 003:   1426 / 11384 loss=0.161935, wps=895.4, ups=0.46, wpb=1946, bsz=128, num_updates=24050, lr=3.20667e-05, gnorm=30.881, clip=100, loss_scale=16, train_wall=108, gb_free=15.5, wall=44652
2025-10-31 07:19:29 | INFO | train_inner | epoch 003:   1476 / 11384 loss=0.16305, wps=649.6, ups=0.34, wpb=1929, bsz=128, num_updates=24100, lr=3.21333e-05, gnorm=30.14, clip=100, loss_scale=16, train_wall=131, gb_free=14.1, wall=44800
2025-10-31 07:21:51 | INFO | train_inner | epoch 003:   1526 / 11384 loss=0.162123, wps=685.6, ups=0.35, wpb=1945.6, bsz=128, num_updates=24150, lr=3.22e-05, gnorm=31.411, clip=100, loss_scale=32, train_wall=130, gb_free=15.7, wall=44942
2025-10-31 07:25:14 | INFO | train_inner | epoch 003:   1576 / 11384 loss=0.165994, wps=484.8, ups=0.25, wpb=1967.6, bsz=128, num_updates=24200, lr=3.22667e-05, gnorm=31.602, clip=100, loss_scale=32, train_wall=203, gb_free=11.6, wall=45145
2025-10-31 07:26:05 | INFO | train_inner | epoch 003:   1626 / 11384 loss=0.161582, wps=1918, ups=0.98, wpb=1966.8, bsz=128, num_updates=24250, lr=3.23333e-05, gnorm=29.283, clip=100, loss_scale=32, train_wall=51, gb_free=15.3, wall=45196
2025-10-31 07:28:43 | INFO | train_inner | epoch 003:   1676 / 11384 loss=0.159284, wps=615.3, ups=0.32, wpb=1948.5, bsz=128, num_updates=24300, lr=3.24e-05, gnorm=29.38, clip=100, loss_scale=64, train_wall=59, gb_free=15.6, wall=45354
2025-10-31 07:28:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 07:31:09 | INFO | train_inner | epoch 003:   1727 / 11384 loss=0.160519, wps=671.5, ups=0.34, wpb=1961.1, bsz=128, num_updates=24350, lr=3.24667e-05, gnorm=28.416, clip=100, loss_scale=32, train_wall=146, gb_free=13.9, wall=45501
2025-10-31 07:32:55 | INFO | train_inner | epoch 003:   1777 / 11384 loss=0.164133, wps=913.9, ups=0.47, wpb=1934.7, bsz=128, num_updates=24400, lr=3.25333e-05, gnorm=28.293, clip=100, loss_scale=32, train_wall=106, gb_free=16.9, wall=45606
2025-10-31 07:33:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 07:34:51 | INFO | train_inner | epoch 003:   1828 / 11384 loss=0.170773, wps=827.6, ups=0.43, wpb=1923.3, bsz=128, num_updates=24450, lr=3.26e-05, gnorm=30.208, clip=100, loss_scale=16, train_wall=116, gb_free=16.1, wall=45723
2025-10-31 07:36:57 | INFO | train_inner | epoch 003:   1878 / 11384 loss=0.168232, wps=768.7, ups=0.4, wpb=1935.6, bsz=128, num_updates=24500, lr=3.26667e-05, gnorm=33.287, clip=100, loss_scale=16, train_wall=126, gb_free=15.3, wall=45848
2025-10-31 07:37:52 | INFO | train_inner | epoch 003:   1928 / 11384 loss=0.166924, wps=1793, ups=0.92, wpb=1958.6, bsz=128, num_updates=24550, lr=3.27333e-05, gnorm=31.8, clip=100, loss_scale=32, train_wall=54, gb_free=16.3, wall=45903
2025-10-31 07:40:02 | INFO | train_inner | epoch 003:   1978 / 11384 loss=0.157313, wps=764.5, ups=0.38, wpb=1987.3, bsz=128, num_updates=24600, lr=3.28e-05, gnorm=28.983, clip=100, loss_scale=32, train_wall=130, gb_free=15.1, wall=46033
2025-10-31 07:42:44 | INFO | train_inner | epoch 003:   2028 / 11384 loss=0.164322, wps=609.3, ups=0.31, wpb=1970.6, bsz=128, num_updates=24650, lr=3.28667e-05, gnorm=30.281, clip=100, loss_scale=32, train_wall=162, gb_free=15.2, wall=46195
2025-10-31 07:43:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 07:44:50 | INFO | train_inner | epoch 003:   2079 / 11384 loss=0.164702, wps=773.9, ups=0.4, wpb=1957.6, bsz=128, num_updates=24700, lr=3.29333e-05, gnorm=32.283, clip=100, loss_scale=32, train_wall=54, gb_free=12, wall=46322
2025-10-31 07:45:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 07:45:43 | INFO | train_inner | epoch 003:   2130 / 11384 loss=0.165611, wps=1836.2, ups=0.95, wpb=1933.2, bsz=128, num_updates=24750, lr=3.3e-05, gnorm=30.254, clip=100, loss_scale=16, train_wall=52, gb_free=17.3, wall=46374
2025-10-31 07:48:29 | INFO | train_inner | epoch 003:   2180 / 11384 loss=0.162822, wps=595.8, ups=0.3, wpb=1972.6, bsz=128, num_updates=24800, lr=3.30667e-05, gnorm=28.107, clip=100, loss_scale=16, train_wall=65, gb_free=17.3, wall=46540
2025-10-31 07:51:10 | INFO | train_inner | epoch 003:   2230 / 11384 loss=0.159812, wps=613.7, ups=0.31, wpb=1957.2, bsz=128, num_updates=24850, lr=3.31333e-05, gnorm=27.365, clip=100, loss_scale=16, train_wall=159, gb_free=15.4, wall=46701
2025-10-31 07:53:52 | INFO | train_inner | epoch 003:   2280 / 11384 loss=0.162806, wps=596.8, ups=0.31, wpb=1933.9, bsz=128, num_updates=24900, lr=3.32e-05, gnorm=31.061, clip=100, loss_scale=32, train_wall=162, gb_free=10.9, wall=46863
2025-10-31 07:54:45 | INFO | train_inner | epoch 003:   2330 / 11384 loss=0.157959, wps=1852.9, ups=0.93, wpb=1986, bsz=128, num_updates=24950, lr=3.32667e-05, gnorm=30.274, clip=100, loss_scale=32, train_wall=53, gb_free=14.4, wall=46917
2025-10-31 07:56:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 07:57:10 | INFO | train_inner | epoch 003:   2381 / 11384 loss=0.141162, wps=678.8, ups=0.35, wpb=1956.4, bsz=128, num_updates=25000, lr=3.33333e-05, gnorm=26.926, clip=100, loss_scale=16, train_wall=144, gb_free=16, wall=47061
2025-10-31 07:59:41 | INFO | train_inner | epoch 003:   2431 / 11384 loss=0.16137, wps=641.2, ups=0.33, wpb=1937, bsz=128, num_updates=25050, lr=3.34e-05, gnorm=31.982, clip=100, loss_scale=16, train_wall=151, gb_free=14.6, wall=47212
2025-10-31 08:01:24 | INFO | train_inner | epoch 003:   2481 / 11384 loss=0.151653, wps=950.1, ups=0.48, wpb=1962.5, bsz=128, num_updates=25100, lr=3.34667e-05, gnorm=31.017, clip=100, loss_scale=16, train_wall=103, gb_free=15.7, wall=47315
2025-10-31 08:03:46 | INFO | train_inner | epoch 003:   2531 / 11384 loss=0.162418, wps=700.8, ups=0.35, wpb=1987.1, bsz=128, num_updates=25150, lr=3.35333e-05, gnorm=29.553, clip=100, loss_scale=32, train_wall=142, gb_free=12.9, wall=47457
2025-10-31 08:04:41 | INFO | train_inner | epoch 003:   2581 / 11384 loss=0.160212, wps=1801, ups=0.9, wpb=1991.9, bsz=128, num_updates=25200, lr=3.36e-05, gnorm=28.841, clip=100, loss_scale=32, train_wall=55, gb_free=17.4, wall=47512
2025-10-31 08:06:30 | INFO | train_inner | epoch 003:   2631 / 11384 loss=0.158047, wps=902.7, ups=0.46, wpb=1972.4, bsz=128, num_updates=25250, lr=3.36667e-05, gnorm=27.41, clip=100, loss_scale=64, train_wall=109, gb_free=14.4, wall=47622
2025-10-31 08:06:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 08:08:32 | INFO | train_inner | epoch 003:   2682 / 11384 loss=0.159577, wps=812.3, ups=0.41, wpb=1971.4, bsz=128, num_updates=25300, lr=3.37333e-05, gnorm=30.273, clip=100, loss_scale=32, train_wall=69, gb_free=11.5, wall=47743
2025-10-31 08:11:14 | INFO | train_inner | epoch 003:   2732 / 11384 loss=0.159242, wps=603.4, ups=0.31, wpb=1957.5, bsz=128, num_updates=25350, lr=3.38e-05, gnorm=29.335, clip=100, loss_scale=32, train_wall=162, gb_free=16.2, wall=47905
2025-10-31 08:14:25 | INFO | train_inner | epoch 003:   2782 / 11384 loss=0.158586, wps=517, ups=0.26, wpb=1973.3, bsz=128, num_updates=25400, lr=3.38667e-05, gnorm=29.863, clip=100, loss_scale=64, train_wall=53, gb_free=15.3, wall=48096
2025-10-31 08:14:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 08:15:18 | INFO | train_inner | epoch 003:   2833 / 11384 loss=0.156549, wps=1871, ups=0.94, wpb=1982.2, bsz=128, num_updates=25450, lr=3.39333e-05, gnorm=28.441, clip=100, loss_scale=32, train_wall=53, gb_free=11.1, wall=48149
2025-10-31 08:17:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 08:17:30 | INFO | train_inner | epoch 003:   2884 / 11384 loss=0.148924, wps=730.7, ups=0.38, wpb=1933.2, bsz=128, num_updates=25500, lr=3.4e-05, gnorm=26.974, clip=100, loss_scale=16, train_wall=131, gb_free=14.1, wall=48281
2025-10-31 08:19:51 | INFO | train_inner | epoch 003:   2934 / 11384 loss=0.152547, wps=700.2, ups=0.35, wpb=1974.5, bsz=128, num_updates=25550, lr=3.40667e-05, gnorm=29.346, clip=100, loss_scale=16, train_wall=141, gb_free=12.8, wall=48423
2025-10-31 08:20:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 08:21:53 | INFO | train_inner | epoch 003:   2985 / 11384 loss=0.15887, wps=797.9, ups=0.41, wpb=1949, bsz=128, num_updates=25600, lr=3.41333e-05, gnorm=32.736, clip=100, loss_scale=8, train_wall=122, gb_free=8.5, wall=48545
2025-10-31 08:22:46 | INFO | train_inner | epoch 003:   3035 / 11384 loss=0.163511, wps=1874.2, ups=0.96, wpb=1956, bsz=128, num_updates=25650, lr=3.42e-05, gnorm=29.861, clip=100, loss_scale=8, train_wall=52, gb_free=15.7, wall=48597
2025-10-31 08:24:45 | INFO | train_inner | epoch 003:   3085 / 11384 loss=0.147184, wps=843.3, ups=0.42, wpb=2006.7, bsz=128, num_updates=25700, lr=3.42667e-05, gnorm=29.536, clip=100, loss_scale=16, train_wall=119, gb_free=16.1, wall=48716
2025-10-31 08:26:07 | INFO | train_inner | epoch 003:   3135 / 11384 loss=0.159609, wps=1172.4, ups=0.61, wpb=1927.6, bsz=128, num_updates=25750, lr=3.43333e-05, gnorm=27.763, clip=100, loss_scale=16, train_wall=82, gb_free=11.7, wall=48798
2025-10-31 08:28:07 | INFO | train_inner | epoch 003:   3185 / 11384 loss=0.145268, wps=826.5, ups=0.42, wpb=1980.2, bsz=128, num_updates=25800, lr=3.44e-05, gnorm=29.423, clip=100, loss_scale=16, train_wall=120, gb_free=10.6, wall=48918
2025-10-31 08:30:26 | INFO | train_inner | epoch 003:   3235 / 11384 loss=0.158541, wps=690.8, ups=0.36, wpb=1927.4, bsz=128, num_updates=25850, lr=3.44667e-05, gnorm=31.426, clip=100, loss_scale=32, train_wall=139, gb_free=16, wall=49058
2025-10-31 08:31:48 | INFO | train_inner | epoch 003:   3285 / 11384 loss=0.153549, wps=1213.1, ups=0.61, wpb=1992.9, bsz=128, num_updates=25900, lr=3.45333e-05, gnorm=28.714, clip=100, loss_scale=32, train_wall=82, gb_free=14.5, wall=49140
2025-10-31 08:33:01 | INFO | train_inner | epoch 003:   3335 / 11384 loss=0.159778, wps=1375.7, ups=0.69, wpb=2005.4, bsz=128, num_updates=25950, lr=3.46e-05, gnorm=31.05, clip=100, loss_scale=64, train_wall=73, gb_free=15.7, wall=49213
2025-10-31 08:33:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 08:34:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 08:34:12 | INFO | train_inner | epoch 003:   3387 / 11384 loss=0.15579, wps=1407.8, ups=0.7, wpb=2000.2, bsz=128, num_updates=26000, lr=3.46667e-05, gnorm=31.362, clip=100, loss_scale=16, train_wall=71, gb_free=11.7, wall=49284
2025-10-31 08:35:14 | INFO | train_inner | epoch 003:   3437 / 11384 loss=0.150666, wps=1581.7, ups=0.81, wpb=1947.5, bsz=128, num_updates=26050, lr=3.47333e-05, gnorm=34.994, clip=100, loss_scale=16, train_wall=60, gb_free=17.1, wall=49345
2025-10-31 08:36:41 | INFO | train_inner | epoch 003:   3487 / 11384 loss=0.146844, wps=1116.6, ups=0.57, wpb=1951.7, bsz=128, num_updates=26100, lr=3.48e-05, gnorm=28.435, clip=100, loss_scale=16, train_wall=87, gb_free=15.9, wall=49433
2025-10-31 08:37:59 | INFO | train_inner | epoch 003:   3537 / 11384 loss=0.145924, wps=1288.2, ups=0.64, wpb=2001.5, bsz=128, num_updates=26150, lr=3.48667e-05, gnorm=26.612, clip=100, loss_scale=32, train_wall=77, gb_free=15.8, wall=49510
2025-10-31 08:39:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 08:39:13 | INFO | train_inner | epoch 003:   3588 / 11384 loss=0.147245, wps=1411.3, ups=0.71, wpb=1974.6, bsz=128, num_updates=26200, lr=3.49333e-05, gnorm=25.776, clip=100, loss_scale=16, train_wall=70, gb_free=14.4, wall=49584
2025-10-31 08:40:43 | INFO | train_inner | epoch 003:   3638 / 11384 loss=0.149145, wps=1091.1, ups=0.55, wpb=1966.3, bsz=128, num_updates=26250, lr=3.5e-05, gnorm=26.96, clip=100, loss_scale=16, train_wall=86, gb_free=14.5, wall=49674
2025-10-31 08:41:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 08:42:10 | INFO | train_inner | epoch 003:   3689 / 11384 loss=0.14131, wps=1110.9, ups=0.58, wpb=1931, bsz=128, num_updates=26300, lr=3.50667e-05, gnorm=25.916, clip=100, loss_scale=8, train_wall=87, gb_free=13, wall=49761
2025-10-31 08:44:22 | INFO | train_inner | epoch 003:   3739 / 11384 loss=0.144719, wps=742.4, ups=0.38, wpb=1957.4, bsz=128, num_updates=26350, lr=3.51333e-05, gnorm=26.729, clip=100, loss_scale=8, train_wall=125, gb_free=14.6, wall=49893
2025-10-31 08:45:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 08:45:30 | INFO | train_inner | epoch 003:   3790 / 11384 loss=0.147359, wps=1430, ups=0.73, wpb=1953.1, bsz=128, num_updates=26400, lr=3.52e-05, gnorm=26.479, clip=100, loss_scale=8, train_wall=68, gb_free=16, wall=49961
2025-10-31 08:46:59 | INFO | train_inner | epoch 003:   3840 / 11384 loss=0.145523, wps=1100, ups=0.56, wpb=1960.5, bsz=128, num_updates=26450, lr=3.52667e-05, gnorm=27.979, clip=100, loss_scale=8, train_wall=89, gb_free=13.8, wall=50051
2025-10-31 08:48:08 | INFO | train_inner | epoch 003:   3890 / 11384 loss=0.162279, wps=1416.9, ups=0.73, wpb=1937.5, bsz=128, num_updates=26500, lr=3.53333e-05, gnorm=30.345, clip=100, loss_scale=8, train_wall=68, gb_free=10.8, wall=50119
2025-10-31 08:49:21 | INFO | train_inner | epoch 003:   3940 / 11384 loss=0.1538, wps=1336.9, ups=0.68, wpb=1964.1, bsz=128, num_updates=26550, lr=3.54e-05, gnorm=30.912, clip=100, loss_scale=16, train_wall=73, gb_free=15.6, wall=50192
2025-10-31 08:50:59 | INFO | train_inner | epoch 003:   3990 / 11384 loss=0.14249, wps=986.5, ups=0.51, wpb=1926.8, bsz=128, num_updates=26600, lr=3.54667e-05, gnorm=27.094, clip=100, loss_scale=16, train_wall=97, gb_free=13.2, wall=50290
2025-10-31 08:52:10 | INFO | train_inner | epoch 003:   4040 / 11384 loss=0.157327, wps=1395.6, ups=0.7, wpb=1980.5, bsz=128, num_updates=26650, lr=3.55333e-05, gnorm=30.448, clip=100, loss_scale=16, train_wall=71, gb_free=13.5, wall=50361
2025-10-31 08:53:17 | INFO | train_inner | epoch 003:   4090 / 11384 loss=0.153556, wps=1452.2, ups=0.74, wpb=1955.8, bsz=128, num_updates=26700, lr=3.56e-05, gnorm=33.922, clip=100, loss_scale=32, train_wall=67, gb_free=13.4, wall=50429
2025-10-31 08:54:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 08:55:38 | INFO | train_inner | epoch 003:   4141 / 11384 loss=0.155329, wps=689.9, ups=0.36, wpb=1938.1, bsz=128, num_updates=26750, lr=3.56667e-05, gnorm=29.54, clip=100, loss_scale=16, train_wall=140, gb_free=12.6, wall=50569
2025-10-31 08:57:09 | INFO | train_inner | epoch 003:   4191 / 11384 loss=0.157318, wps=1071.5, ups=0.55, wpb=1955.1, bsz=128, num_updates=26800, lr=3.57333e-05, gnorm=27.777, clip=100, loss_scale=16, train_wall=91, gb_free=16, wall=50660
2025-10-31 08:58:26 | INFO | train_inner | epoch 003:   4241 / 11384 loss=0.159632, wps=1247.6, ups=0.65, wpb=1911.7, bsz=128, num_updates=26850, lr=3.58e-05, gnorm=34.57, clip=100, loss_scale=32, train_wall=76, gb_free=14.9, wall=50737
2025-10-31 08:58:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 08:59:49 | INFO | train_inner | epoch 003:   4292 / 11384 loss=0.144782, wps=1190.8, ups=0.6, wpb=1978.3, bsz=128, num_updates=26900, lr=3.58667e-05, gnorm=29.005, clip=100, loss_scale=16, train_wall=83, gb_free=15.1, wall=50820
2025-10-31 09:01:03 | INFO | train_inner | epoch 003:   4342 / 11384 loss=0.143229, wps=1332.3, ups=0.67, wpb=1977.4, bsz=128, num_updates=26950, lr=3.59333e-05, gnorm=25.875, clip=100, loss_scale=16, train_wall=74, gb_free=15.8, wall=50894
2025-10-31 09:02:02 | INFO | train_inner | epoch 003:   4392 / 11384 loss=0.145035, wps=1689.9, ups=0.86, wpb=1975, bsz=128, num_updates=27000, lr=3.6e-05, gnorm=26.862, clip=100, loss_scale=32, train_wall=58, gb_free=13.5, wall=50953
2025-10-31 09:03:19 | INFO | train_inner | epoch 003:   4442 / 11384 loss=0.152702, wps=1318.7, ups=0.68, wpb=1949.3, bsz=128, num_updates=27050, lr=3.60667e-05, gnorm=27.254, clip=100, loss_scale=32, train_wall=74, gb_free=16.1, wall=51031
2025-10-31 09:04:36 | INFO | train_inner | epoch 003:   4492 / 11384 loss=0.144491, wps=1305, ups=0.65, wpb=2003.7, bsz=128, num_updates=27100, lr=3.61333e-05, gnorm=30.402, clip=100, loss_scale=32, train_wall=72, gb_free=10.3, wall=51107
2025-10-31 09:05:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 09:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:05:56 | INFO | train_inner | epoch 003:   4544 / 11384 loss=0.134759, wps=1232.5, ups=0.63, wpb=1966.6, bsz=128, num_updates=27150, lr=3.62e-05, gnorm=25.766, clip=100, loss_scale=16, train_wall=80, gb_free=14.2, wall=51187
2025-10-31 09:07:32 | INFO | train_inner | epoch 003:   4594 / 11384 loss=0.142275, wps=1022.1, ups=0.52, wpb=1972.5, bsz=128, num_updates=27200, lr=3.62667e-05, gnorm=28.863, clip=100, loss_scale=16, train_wall=96, gb_free=11.7, wall=51284
2025-10-31 09:09:41 | INFO | train_inner | epoch 003:   4644 / 11384 loss=0.140958, wps=774.6, ups=0.39, wpb=1985.8, bsz=128, num_updates=27250, lr=3.63333e-05, gnorm=26.169, clip=100, loss_scale=16, train_wall=126, gb_free=16.2, wall=51412
2025-10-31 09:11:12 | INFO | train_inner | epoch 003:   4694 / 11384 loss=0.143978, wps=1087.7, ups=0.55, wpb=1983.5, bsz=128, num_updates=27300, lr=3.64e-05, gnorm=29.227, clip=100, loss_scale=32, train_wall=87, gb_free=10.6, wall=51503
2025-10-31 09:11:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:12:21 | INFO | train_inner | epoch 003:   4745 / 11384 loss=0.143421, wps=1430.2, ups=0.73, wpb=1959.5, bsz=128, num_updates=27350, lr=3.64667e-05, gnorm=27.97, clip=100, loss_scale=16, train_wall=68, gb_free=2.4, wall=51572
2025-10-31 09:13:19 | INFO | train_inner | epoch 003:   4795 / 11384 loss=0.142426, wps=1688, ups=0.85, wpb=1975.4, bsz=128, num_updates=27400, lr=3.65333e-05, gnorm=27.531, clip=100, loss_scale=16, train_wall=58, gb_free=16.8, wall=51630
2025-10-31 09:14:48 | INFO | train_inner | epoch 003:   4845 / 11384 loss=0.14562, wps=1092, ups=0.56, wpb=1945.4, bsz=128, num_updates=27450, lr=3.66e-05, gnorm=26.445, clip=100, loss_scale=32, train_wall=89, gb_free=14.3, wall=51719
2025-10-31 09:15:48 | INFO | train_inner | epoch 003:   4895 / 11384 loss=0.145665, wps=1612.4, ups=0.83, wpb=1940.6, bsz=128, num_updates=27500, lr=3.66667e-05, gnorm=26.988, clip=100, loss_scale=32, train_wall=60, gb_free=15.6, wall=51780
2025-10-31 09:16:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:17:11 | INFO | train_inner | epoch 003:   4946 / 11384 loss=0.141971, wps=1203.1, ups=0.61, wpb=1985.8, bsz=128, num_updates=27550, lr=3.67333e-05, gnorm=23.757, clip=100, loss_scale=16, train_wall=82, gb_free=14.6, wall=51862
2025-10-31 09:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 09:18:45 | INFO | train_inner | epoch 003:   4997 / 11384 loss=0.152345, wps=1028.9, ups=0.53, wpb=1946.3, bsz=128, num_updates=27600, lr=3.68e-05, gnorm=28.926, clip=100, loss_scale=8, train_wall=94, gb_free=12.9, wall=51957
2025-10-31 09:20:19 | INFO | train_inner | epoch 003:   5047 / 11384 loss=0.142683, wps=1067, ups=0.54, wpb=1989.9, bsz=128, num_updates=27650, lr=3.68667e-05, gnorm=26.329, clip=100, loss_scale=8, train_wall=93, gb_free=16, wall=52050
2025-10-31 09:21:39 | INFO | train_inner | epoch 003:   5097 / 11384 loss=0.14408, wps=1206.5, ups=0.62, wpb=1938.9, bsz=128, num_updates=27700, lr=3.69333e-05, gnorm=28.893, clip=100, loss_scale=8, train_wall=80, gb_free=16.1, wall=52130
2025-10-31 09:22:46 | INFO | train_inner | epoch 003:   5147 / 11384 loss=0.141759, wps=1478.1, ups=0.75, wpb=1965.8, bsz=128, num_updates=27750, lr=3.7e-05, gnorm=28.094, clip=100, loss_scale=16, train_wall=66, gb_free=15.6, wall=52197
2025-10-31 09:24:16 | INFO | train_inner | epoch 003:   5197 / 11384 loss=0.139494, wps=1097.4, ups=0.56, wpb=1971.9, bsz=128, num_updates=27800, lr=3.70667e-05, gnorm=25.688, clip=100, loss_scale=16, train_wall=90, gb_free=15.6, wall=52287
2025-10-31 09:25:43 | INFO | train_inner | epoch 003:   5247 / 11384 loss=0.142274, wps=1102.7, ups=0.57, wpb=1931, bsz=128, num_updates=27850, lr=3.71333e-05, gnorm=24.612, clip=100, loss_scale=32, train_wall=87, gb_free=15.6, wall=52374
2025-10-31 09:26:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:27:00 | INFO | train_inner | epoch 003:   5298 / 11384 loss=0.145295, wps=1297.5, ups=0.65, wpb=1993.5, bsz=128, num_updates=27900, lr=3.72e-05, gnorm=27.774, clip=100, loss_scale=16, train_wall=77, gb_free=14.3, wall=52451
2025-10-31 09:28:16 | INFO | train_inner | epoch 003:   5348 / 11384 loss=0.142351, wps=1262.5, ups=0.66, wpb=1927, bsz=128, num_updates=27950, lr=3.72667e-05, gnorm=25.455, clip=100, loss_scale=16, train_wall=76, gb_free=16.9, wall=52528
2025-10-31 09:29:42 | INFO | train_inner | epoch 003:   5398 / 11384 loss=0.152893, wps=1149.8, ups=0.58, wpb=1970.6, bsz=128, num_updates=28000, lr=3.73333e-05, gnorm=27.859, clip=100, loss_scale=16, train_wall=85, gb_free=13.6, wall=52613
2025-10-31 09:31:27 | INFO | train_inner | epoch 003:   5448 / 11384 loss=0.145717, wps=924.2, ups=0.47, wpb=1948.9, bsz=128, num_updates=28050, lr=3.74e-05, gnorm=26.936, clip=100, loss_scale=32, train_wall=105, gb_free=15.9, wall=52719
2025-10-31 09:32:25 | INFO | train_inner | epoch 003:   5498 / 11384 loss=0.132553, wps=1711.2, ups=0.87, wpb=1967, bsz=128, num_updates=28100, lr=3.74667e-05, gnorm=26.793, clip=100, loss_scale=32, train_wall=53, gb_free=15.5, wall=52776
2025-10-31 09:33:46 | INFO | train_inner | epoch 003:   5548 / 11384 loss=0.141519, wps=1230.3, ups=0.62, wpb=1995.2, bsz=128, num_updates=28150, lr=3.75333e-05, gnorm=25.834, clip=100, loss_scale=64, train_wall=77, gb_free=17, wall=52857
2025-10-31 09:33:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 09:35:04 | INFO | train_inner | epoch 003:   5599 / 11384 loss=0.134012, wps=1239, ups=0.64, wpb=1922, bsz=128, num_updates=28200, lr=3.76e-05, gnorm=24.76, clip=100, loss_scale=32, train_wall=77, gb_free=15.7, wall=52935
2025-10-31 09:36:11 | INFO | train_inner | epoch 003:   5649 / 11384 loss=0.142079, wps=1456.2, ups=0.75, wpb=1947.5, bsz=128, num_updates=28250, lr=3.76667e-05, gnorm=28.159, clip=100, loss_scale=32, train_wall=67, gb_free=13.2, wall=53002
2025-10-31 09:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:37:46 | INFO | train_inner | epoch 003:   5700 / 11384 loss=0.140561, wps=1020.1, ups=0.53, wpb=1941.3, bsz=128, num_updates=28300, lr=3.77333e-05, gnorm=28.782, clip=100, loss_scale=16, train_wall=95, gb_free=10.3, wall=53097
2025-10-31 09:39:04 | INFO | train_inner | epoch 003:   5750 / 11384 loss=0.143928, wps=1243.5, ups=0.64, wpb=1939, bsz=128, num_updates=28350, lr=3.78e-05, gnorm=30.878, clip=100, loss_scale=16, train_wall=78, gb_free=16, wall=53175
2025-10-31 09:40:34 | INFO | train_inner | epoch 003:   5800 / 11384 loss=0.128819, wps=1076.2, ups=0.56, wpb=1932.1, bsz=128, num_updates=28400, lr=3.78667e-05, gnorm=24.894, clip=100, loss_scale=32, train_wall=89, gb_free=16, wall=53265
2025-10-31 09:42:13 | INFO | train_inner | epoch 003:   5850 / 11384 loss=0.13806, wps=985.7, ups=0.5, wpb=1964.9, bsz=128, num_updates=28450, lr=3.79333e-05, gnorm=25.421, clip=100, loss_scale=32, train_wall=99, gb_free=16.3, wall=53365
2025-10-31 09:43:23 | INFO | train_inner | epoch 003:   5900 / 11384 loss=0.148444, wps=1408.7, ups=0.71, wpb=1972.5, bsz=128, num_updates=28500, lr=3.8e-05, gnorm=26.869, clip=100, loss_scale=32, train_wall=70, gb_free=17.1, wall=53435
2025-10-31 09:44:39 | INFO | train_inner | epoch 003:   5950 / 11384 loss=0.128465, wps=1295.2, ups=0.66, wpb=1952.1, bsz=128, num_updates=28550, lr=3.80667e-05, gnorm=23.821, clip=100, loss_scale=64, train_wall=75, gb_free=13.9, wall=53510
2025-10-31 09:44:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 09:46:09 | INFO | train_inner | epoch 003:   6001 / 11384 loss=0.134985, wps=1098.9, ups=0.55, wpb=1988.8, bsz=128, num_updates=28600, lr=3.81333e-05, gnorm=24.779, clip=100, loss_scale=32, train_wall=90, gb_free=16.3, wall=53600
2025-10-31 09:47:17 | INFO | train_inner | epoch 003:   6051 / 11384 loss=0.132585, wps=1445.7, ups=0.74, wpb=1951.1, bsz=128, num_updates=28650, lr=3.82e-05, gnorm=25.703, clip=100, loss_scale=32, train_wall=67, gb_free=16.3, wall=53668
2025-10-31 09:48:35 | INFO | train_inner | epoch 003:   6101 / 11384 loss=0.140839, wps=1285.4, ups=0.64, wpb=2005.5, bsz=128, num_updates=28700, lr=3.82667e-05, gnorm=25.017, clip=100, loss_scale=64, train_wall=78, gb_free=17.1, wall=53746
2025-10-31 09:49:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 09:49:55 | INFO | train_inner | epoch 003:   6152 / 11384 loss=0.14167, wps=1232.4, ups=0.62, wpb=1972.7, bsz=128, num_updates=28750, lr=3.83333e-05, gnorm=27.999, clip=100, loss_scale=32, train_wall=80, gb_free=15.1, wall=53826
2025-10-31 09:51:27 | INFO | train_inner | epoch 003:   6202 / 11384 loss=0.146678, wps=1055.2, ups=0.54, wpb=1956.3, bsz=128, num_updates=28800, lr=3.84e-05, gnorm=27.469, clip=100, loss_scale=32, train_wall=92, gb_free=16.1, wall=53919
2025-10-31 09:52:47 | INFO | train_inner | epoch 003:   6252 / 11384 loss=0.156204, wps=1233.5, ups=0.63, wpb=1963.4, bsz=128, num_updates=28850, lr=3.84667e-05, gnorm=28.342, clip=100, loss_scale=64, train_wall=79, gb_free=11.3, wall=53998
2025-10-31 09:52:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 09:54:30 | INFO | train_inner | epoch 003:   6303 / 11384 loss=0.145929, wps=935, ups=0.49, wpb=1918.1, bsz=128, num_updates=28900, lr=3.85333e-05, gnorm=27.275, clip=100, loss_scale=32, train_wall=102, gb_free=16.3, wall=54101
2025-10-31 09:54:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:55:42 | INFO | train_inner | epoch 003:   6354 / 11384 loss=0.147131, wps=1317.5, ups=0.69, wpb=1915.9, bsz=128, num_updates=28950, lr=3.86e-05, gnorm=29.265, clip=100, loss_scale=16, train_wall=72, gb_free=15.1, wall=54174
2025-10-31 09:57:10 | INFO | train_inner | epoch 003:   6404 / 11384 loss=0.134337, wps=1118.5, ups=0.57, wpb=1947.4, bsz=128, num_updates=29000, lr=3.86667e-05, gnorm=23.518, clip=100, loss_scale=16, train_wall=87, gb_free=14.5, wall=54261
2025-10-31 09:58:37 | INFO | train_inner | epoch 003:   6454 / 11384 loss=0.135264, wps=1133.7, ups=0.57, wpb=1987.1, bsz=128, num_updates=29050, lr=3.87333e-05, gnorm=28.531, clip=100, loss_scale=32, train_wall=80, gb_free=15.1, wall=54348
2025-10-31 09:58:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 09:59:48 | INFO | train_inner | epoch 003:   6505 / 11384 loss=0.129792, wps=1394, ups=0.71, wpb=1962.7, bsz=128, num_updates=29100, lr=3.88e-05, gnorm=24.924, clip=100, loss_scale=16, train_wall=70, gb_free=7.8, wall=54419
2025-10-31 10:01:12 | INFO | train_inner | epoch 003:   6555 / 11384 loss=0.13445, wps=1149, ups=0.59, wpb=1942.7, bsz=128, num_updates=29150, lr=3.88667e-05, gnorm=25.199, clip=100, loss_scale=16, train_wall=84, gb_free=16.2, wall=54504
2025-10-31 10:02:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:02:39 | INFO | train_inner | epoch 003:   6606 / 11384 loss=0.136425, wps=1122, ups=0.58, wpb=1950, bsz=128, num_updates=29200, lr=3.89333e-05, gnorm=27.236, clip=100, loss_scale=16, train_wall=85, gb_free=15.7, wall=54590
2025-10-31 10:04:04 | INFO | train_inner | epoch 003:   6656 / 11384 loss=0.146024, wps=1158, ups=0.59, wpb=1968.6, bsz=128, num_updates=29250, lr=3.9e-05, gnorm=26.399, clip=100, loss_scale=16, train_wall=85, gb_free=16.6, wall=54675
2025-10-31 10:05:37 | INFO | train_inner | epoch 003:   6706 / 11384 loss=0.135912, wps=1059.4, ups=0.54, wpb=1972.8, bsz=128, num_updates=29300, lr=3.90667e-05, gnorm=23.945, clip=100, loss_scale=16, train_wall=93, gb_free=15.3, wall=54769
2025-10-31 10:06:50 | INFO | train_inner | epoch 003:   6756 / 11384 loss=0.144781, wps=1385.6, ups=0.69, wpb=2004.7, bsz=128, num_updates=29350, lr=3.91333e-05, gnorm=26.296, clip=100, loss_scale=32, train_wall=72, gb_free=16.5, wall=54841
2025-10-31 10:07:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:08:33 | INFO | train_inner | epoch 003:   6807 / 11384 loss=0.134554, wps=949.6, ups=0.48, wpb=1971.3, bsz=128, num_updates=29400, lr=3.92e-05, gnorm=24.715, clip=100, loss_scale=16, train_wall=65, gb_free=10.7, wall=54945
2025-10-31 10:09:34 | INFO | train_inner | epoch 003:   6857 / 11384 loss=0.129794, wps=1594.5, ups=0.82, wpb=1938.2, bsz=128, num_updates=29450, lr=3.92667e-05, gnorm=26.616, clip=100, loss_scale=16, train_wall=61, gb_free=16.9, wall=55005
2025-10-31 10:10:50 | INFO | train_inner | epoch 003:   6907 / 11384 loss=0.13682, wps=1290.8, ups=0.66, wpb=1958, bsz=128, num_updates=29500, lr=3.93333e-05, gnorm=25.593, clip=100, loss_scale=32, train_wall=76, gb_free=17, wall=55081
2025-10-31 10:12:11 | INFO | train_inner | epoch 003:   6957 / 11384 loss=0.124546, wps=1194.5, ups=0.62, wpb=1933.6, bsz=128, num_updates=29550, lr=3.94e-05, gnorm=25.376, clip=100, loss_scale=32, train_wall=81, gb_free=15.8, wall=55162
2025-10-31 10:13:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:13:37 | INFO | train_inner | epoch 003:   7008 / 11384 loss=0.122283, wps=1174, ups=0.58, wpb=2018.4, bsz=128, num_updates=29600, lr=3.94667e-05, gnorm=23.346, clip=100, loss_scale=16, train_wall=86, gb_free=14.8, wall=55248
2025-10-31 10:14:37 | INFO | train_inner | epoch 003:   7058 / 11384 loss=0.127659, wps=1661.5, ups=0.84, wpb=1979.5, bsz=128, num_updates=29650, lr=3.95333e-05, gnorm=25.446, clip=100, loss_scale=16, train_wall=59, gb_free=16, wall=55308
2025-10-31 10:16:16 | INFO | train_inner | epoch 003:   7108 / 11384 loss=0.128892, wps=991.7, ups=0.51, wpb=1961.8, bsz=128, num_updates=29700, lr=3.96e-05, gnorm=29.202, clip=100, loss_scale=16, train_wall=99, gb_free=16.8, wall=55407
2025-10-31 10:17:20 | INFO | train_inner | epoch 003:   7158 / 11384 loss=0.126892, wps=1553.1, ups=0.78, wpb=1992.2, bsz=128, num_updates=29750, lr=3.96667e-05, gnorm=22.507, clip=100, loss_scale=32, train_wall=64, gb_free=14.7, wall=55471
2025-10-31 10:18:42 | INFO | train_inner | epoch 003:   7208 / 11384 loss=0.138851, wps=1202.5, ups=0.61, wpb=1961.4, bsz=128, num_updates=29800, lr=3.97333e-05, gnorm=26.166, clip=100, loss_scale=32, train_wall=81, gb_free=16.8, wall=55553
2025-10-31 10:19:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:20:09 | INFO | train_inner | epoch 003:   7259 / 11384 loss=0.132078, wps=1127.8, ups=0.57, wpb=1970.3, bsz=128, num_updates=29850, lr=3.98e-05, gnorm=27.029, clip=100, loss_scale=16, train_wall=87, gb_free=8.7, wall=55640
2025-10-31 10:21:46 | INFO | train_inner | epoch 003:   7309 / 11384 loss=0.135888, wps=1024.1, ups=0.52, wpb=1979.4, bsz=128, num_updates=29900, lr=3.98667e-05, gnorm=25.582, clip=100, loss_scale=16, train_wall=86, gb_free=14.3, wall=55737
2025-10-31 10:22:49 | INFO | train_inner | epoch 003:   7359 / 11384 loss=0.134375, wps=1542.3, ups=0.78, wpb=1969.1, bsz=128, num_updates=29950, lr=3.99333e-05, gnorm=24.642, clip=100, loss_scale=32, train_wall=64, gb_free=16.6, wall=55801
2025-10-31 10:24:06 | INFO | train_inner | epoch 003:   7409 / 11384 loss=0.13801, wps=1298.4, ups=0.65, wpb=1991.5, bsz=128, num_updates=30000, lr=4e-05, gnorm=26.056, clip=100, loss_scale=32, train_wall=76, gb_free=12.9, wall=55877
2025-10-31 10:24:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:25:05 | INFO | train_inner | epoch 003:   7460 / 11384 loss=0.130918, wps=1633.8, ups=0.84, wpb=1935.6, bsz=128, num_updates=30050, lr=4.00667e-05, gnorm=27.718, clip=100, loss_scale=16, train_wall=59, gb_free=16.8, wall=55937
2025-10-31 10:26:19 | INFO | train_inner | epoch 003:   7510 / 11384 loss=0.13009, wps=1312, ups=0.68, wpb=1935.4, bsz=128, num_updates=30100, lr=4.01333e-05, gnorm=24.844, clip=100, loss_scale=16, train_wall=74, gb_free=16.7, wall=56010
2025-10-31 10:28:10 | INFO | train_inner | epoch 003:   7560 / 11384 loss=0.127921, wps=897.8, ups=0.45, wpb=1989.8, bsz=128, num_updates=30150, lr=4.02e-05, gnorm=25.75, clip=100, loss_scale=32, train_wall=90, gb_free=11, wall=56121
2025-10-31 10:29:24 | INFO | train_inner | epoch 003:   7610 / 11384 loss=0.120538, wps=1316, ups=0.68, wpb=1942, bsz=128, num_updates=30200, lr=4.02667e-05, gnorm=22.208, clip=100, loss_scale=32, train_wall=74, gb_free=15.7, wall=56195
2025-10-31 10:29:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:30:51 | INFO | train_inner | epoch 003:   7661 / 11384 loss=0.136416, wps=1128.2, ups=0.57, wpb=1962.1, bsz=128, num_updates=30250, lr=4.03333e-05, gnorm=27.616, clip=100, loss_scale=16, train_wall=87, gb_free=12.4, wall=56282
2025-10-31 10:32:08 | INFO | train_inner | epoch 003:   7711 / 11384 loss=0.121457, wps=1282.9, ups=0.64, wpb=1990.5, bsz=128, num_updates=30300, lr=4.04e-05, gnorm=25.899, clip=100, loss_scale=16, train_wall=77, gb_free=17.4, wall=56360
2025-10-31 10:33:16 | INFO | train_inner | epoch 003:   7761 / 11384 loss=0.131423, wps=1425, ups=0.74, wpb=1928.3, bsz=128, num_updates=30350, lr=4.04667e-05, gnorm=25.877, clip=100, loss_scale=32, train_wall=67, gb_free=13.6, wall=56427
2025-10-31 10:34:59 | INFO | train_inner | epoch 003:   7811 / 11384 loss=0.131348, wps=941.9, ups=0.49, wpb=1939.8, bsz=128, num_updates=30400, lr=4.05333e-05, gnorm=25.381, clip=100, loss_scale=32, train_wall=103, gb_free=15.1, wall=56530
2025-10-31 10:36:08 | INFO | train_inner | epoch 003:   7861 / 11384 loss=0.128464, wps=1424, ups=0.72, wpb=1966.4, bsz=128, num_updates=30450, lr=4.06e-05, gnorm=23.122, clip=100, loss_scale=32, train_wall=69, gb_free=17.6, wall=56599
2025-10-31 10:37:14 | INFO | train_inner | epoch 003:   7911 / 11384 loss=0.121151, wps=1475.6, ups=0.76, wpb=1943.6, bsz=128, num_updates=30500, lr=4.06667e-05, gnorm=22.663, clip=100, loss_scale=64, train_wall=66, gb_free=15.8, wall=56665
2025-10-31 10:38:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 10:38:49 | INFO | train_inner | epoch 003:   7962 / 11384 loss=0.126937, wps=1035.3, ups=0.52, wpb=1977, bsz=128, num_updates=30550, lr=4.07333e-05, gnorm=22.446, clip=100, loss_scale=32, train_wall=95, gb_free=16.1, wall=56761
2025-10-31 10:40:10 | INFO | train_inner | epoch 003:   8012 / 11384 loss=0.129151, wps=1234.1, ups=0.62, wpb=1988.7, bsz=128, num_updates=30600, lr=4.08e-05, gnorm=23.379, clip=100, loss_scale=32, train_wall=80, gb_free=8.8, wall=56841
2025-10-31 10:41:32 | INFO | train_inner | epoch 003:   8062 / 11384 loss=0.126939, wps=1199.6, ups=0.61, wpb=1968.2, bsz=128, num_updates=30650, lr=4.08667e-05, gnorm=23.457, clip=100, loss_scale=32, train_wall=82, gb_free=12.9, wall=56924
2025-10-31 10:42:47 | INFO | train_inner | epoch 003:   8112 / 11384 loss=0.127124, wps=1323.2, ups=0.67, wpb=1974.6, bsz=128, num_updates=30700, lr=4.09333e-05, gnorm=25.388, clip=100, loss_scale=64, train_wall=74, gb_free=14.1, wall=56998
2025-10-31 10:43:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 10:44:07 | INFO | train_inner | epoch 003:   8163 / 11384 loss=0.131524, wps=1248.2, ups=0.63, wpb=1993.8, bsz=128, num_updates=30750, lr=4.1e-05, gnorm=26.574, clip=100, loss_scale=32, train_wall=80, gb_free=16, wall=57078
2025-10-31 10:45:30 | INFO | train_inner | epoch 003:   8213 / 11384 loss=0.124718, wps=1173.4, ups=0.6, wpb=1961.2, bsz=128, num_updates=30800, lr=4.10667e-05, gnorm=24.583, clip=100, loss_scale=32, train_wall=83, gb_free=10, wall=57162
2025-10-31 10:46:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:46:44 | INFO | train_inner | epoch 003:   8264 / 11384 loss=0.136216, wps=1324.3, ups=0.68, wpb=1950, bsz=128, num_updates=30850, lr=4.11333e-05, gnorm=26.483, clip=100, loss_scale=16, train_wall=73, gb_free=13.8, wall=57235
2025-10-31 10:48:03 | INFO | train_inner | epoch 003:   8314 / 11384 loss=0.136377, wps=1211.4, ups=0.63, wpb=1920.7, bsz=127.9, num_updates=30900, lr=4.12e-05, gnorm=24.854, clip=100, loss_scale=16, train_wall=79, gb_free=16.3, wall=57315
2025-10-31 10:49:34 | INFO | train_inner | epoch 003:   8364 / 11384 loss=0.120888, wps=1059.1, ups=0.55, wpb=1923.3, bsz=128, num_updates=30950, lr=4.12667e-05, gnorm=23.166, clip=100, loss_scale=16, train_wall=91, gb_free=13.3, wall=57405
2025-10-31 10:50:52 | INFO | train_inner | epoch 003:   8414 / 11384 loss=0.115289, wps=1262.1, ups=0.64, wpb=1971.8, bsz=128, num_updates=31000, lr=4.13333e-05, gnorm=21.651, clip=100, loss_scale=32, train_wall=78, gb_free=13.7, wall=57484
2025-10-31 10:52:18 | INFO | train_inner | epoch 003:   8464 / 11384 loss=0.123913, wps=1165.7, ups=0.6, wpb=1932.8, bsz=128, num_updates=31050, lr=4.14e-05, gnorm=24.317, clip=100, loss_scale=32, train_wall=83, gb_free=16.8, wall=57569
2025-10-31 10:53:35 | INFO | train_inner | epoch 003:   8514 / 11384 loss=0.117637, wps=1256.4, ups=0.65, wpb=1947, bsz=128, num_updates=31100, lr=4.14667e-05, gnorm=21.844, clip=100, loss_scale=64, train_wall=76, gb_free=15.5, wall=57647
2025-10-31 10:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 10:54:46 | INFO | train_inner | epoch 003:   8565 / 11384 loss=0.132275, wps=1382.5, ups=0.7, wpb=1967.1, bsz=128, num_updates=31150, lr=4.15333e-05, gnorm=22.771, clip=100, loss_scale=32, train_wall=71, gb_free=15.4, wall=57718
2025-10-31 10:55:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 10:56:28 | INFO | train_inner | epoch 003:   8616 / 11384 loss=0.119313, wps=964.3, ups=0.49, wpb=1957.5, bsz=128, num_updates=31200, lr=4.16e-05, gnorm=21.751, clip=100, loss_scale=16, train_wall=98, gb_free=12, wall=57819
2025-10-31 10:57:23 | INFO | train_inner | epoch 003:   8666 / 11384 loss=0.133447, wps=1783.6, ups=0.92, wpb=1947.4, bsz=128, num_updates=31250, lr=4.16667e-05, gnorm=24.97, clip=100, loss_scale=16, train_wall=54, gb_free=15.1, wall=57874
2025-10-31 10:58:52 | INFO | train_inner | epoch 003:   8716 / 11384 loss=0.127933, wps=1103, ups=0.56, wpb=1966.9, bsz=128, num_updates=31300, lr=4.17333e-05, gnorm=22.737, clip=100, loss_scale=32, train_wall=74, gb_free=15, wall=57963
2025-10-31 11:00:13 | INFO | train_inner | epoch 003:   8766 / 11384 loss=0.136138, wps=1217.4, ups=0.61, wpb=1980.2, bsz=128, num_updates=31350, lr=4.18e-05, gnorm=27.109, clip=100, loss_scale=32, train_wall=81, gb_free=16.5, wall=58044
2025-10-31 11:01:43 | INFO | train_inner | epoch 003:   8816 / 11384 loss=0.126761, wps=1101.6, ups=0.56, wpb=1970, bsz=128, num_updates=31400, lr=4.18667e-05, gnorm=24.346, clip=100, loss_scale=32, train_wall=89, gb_free=14.7, wall=58134
2025-10-31 11:02:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:03:07 | INFO | train_inner | epoch 003:   8867 / 11384 loss=0.132291, wps=1153.9, ups=0.6, wpb=1938.9, bsz=128, num_updates=31450, lr=4.19333e-05, gnorm=24.507, clip=100, loss_scale=32, train_wall=84, gb_free=15.4, wall=58218
2025-10-31 11:03:58 | INFO | train_inner | epoch 003:   8917 / 11384 loss=0.124589, wps=1879.1, ups=0.97, wpb=1931, bsz=128, num_updates=31500, lr=4.2e-05, gnorm=22.302, clip=100, loss_scale=32, train_wall=51, gb_free=15.4, wall=58269
2025-10-31 11:05:35 | INFO | train_inner | epoch 003:   8967 / 11384 loss=0.125158, wps=1079.7, ups=0.54, wpb=2007.9, bsz=128, num_updates=31550, lr=4.20667e-05, gnorm=22.681, clip=100, loss_scale=32, train_wall=93, gb_free=13.8, wall=58366
2025-10-31 11:07:14 | INFO | train_inner | epoch 003:   9017 / 11384 loss=0.118429, wps=992.1, ups=0.5, wpb=1971.9, bsz=128, num_updates=31600, lr=4.21333e-05, gnorm=22.179, clip=100, loss_scale=64, train_wall=98, gb_free=11.9, wall=58466
2025-10-31 11:07:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:08:10 | INFO | train_inner | epoch 003:   9068 / 11384 loss=0.114148, wps=1795.5, ups=0.9, wpb=1990.4, bsz=128, num_updates=31650, lr=4.22e-05, gnorm=22.754, clip=100, loss_scale=32, train_wall=55, gb_free=16.4, wall=58521
2025-10-31 11:09:36 | INFO | train_inner | epoch 003:   9118 / 11384 loss=0.127964, wps=1135.9, ups=0.58, wpb=1967.7, bsz=128, num_updates=31700, lr=4.22667e-05, gnorm=24.115, clip=100, loss_scale=32, train_wall=86, gb_free=15.6, wall=58608
2025-10-31 11:11:07 | INFO | train_inner | epoch 003:   9168 / 11384 loss=0.121651, wps=1081.3, ups=0.55, wpb=1950.2, bsz=128, num_updates=31750, lr=4.23333e-05, gnorm=23.026, clip=100, loss_scale=64, train_wall=90, gb_free=13.8, wall=58698
2025-10-31 11:12:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:12:07 | INFO | train_inner | epoch 003:   9219 / 11384 loss=0.132161, wps=1617.4, ups=0.82, wpb=1963.5, bsz=128, num_updates=31800, lr=4.24e-05, gnorm=25.011, clip=100, loss_scale=32, train_wall=60, gb_free=13.9, wall=58759
2025-10-31 11:13:30 | INFO | train_inner | epoch 003:   9269 / 11384 loss=0.128096, wps=1180.5, ups=0.6, wpb=1956, bsz=128, num_updates=31850, lr=4.24667e-05, gnorm=24.579, clip=100, loss_scale=32, train_wall=83, gb_free=13.4, wall=58842
2025-10-31 11:13:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 11:14:57 | INFO | train_inner | epoch 003:   9320 / 11384 loss=0.137082, wps=1121.1, ups=0.58, wpb=1944.9, bsz=128, num_updates=31900, lr=4.25333e-05, gnorm=25.383, clip=100, loss_scale=16, train_wall=86, gb_free=15.7, wall=58928
2025-10-31 11:16:33 | INFO | train_inner | epoch 003:   9370 / 11384 loss=0.121009, wps=1011.9, ups=0.52, wpb=1943, bsz=128, num_updates=31950, lr=4.26e-05, gnorm=22.163, clip=100, loss_scale=16, train_wall=93, gb_free=13.5, wall=59024
2025-10-31 11:17:44 | INFO | train_inner | epoch 003:   9420 / 11384 loss=0.127946, wps=1384.1, ups=0.71, wpb=1955.7, bsz=128, num_updates=32000, lr=4.26667e-05, gnorm=23.219, clip=100, loss_scale=32, train_wall=70, gb_free=13.9, wall=59095
2025-10-31 11:18:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 11:18:59 | INFO | train_inner | epoch 003:   9471 / 11384 loss=0.126502, wps=1306.8, ups=0.66, wpb=1979.1, bsz=128, num_updates=32050, lr=4.27333e-05, gnorm=24.109, clip=100, loss_scale=16, train_wall=75, gb_free=16.3, wall=59171
2025-10-31 11:20:28 | INFO | train_inner | epoch 003:   9521 / 11384 loss=0.118734, wps=1099, ups=0.57, wpb=1942.2, bsz=128, num_updates=32100, lr=4.28e-05, gnorm=22.589, clip=100, loss_scale=16, train_wall=88, gb_free=9.6, wall=59259
2025-10-31 11:21:39 | INFO | train_inner | epoch 003:   9571 / 11384 loss=0.124124, wps=1372.2, ups=0.7, wpb=1947.6, bsz=128, num_updates=32150, lr=4.28667e-05, gnorm=22.709, clip=100, loss_scale=16, train_wall=71, gb_free=14.9, wall=59330
2025-10-31 11:21:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 11:23:01 | INFO | train_inner | epoch 003:   9622 / 11384 loss=0.125807, wps=1192.6, ups=0.61, wpb=1968.6, bsz=128, num_updates=32200, lr=4.29333e-05, gnorm=23.924, clip=100, loss_scale=16, train_wall=82, gb_free=14.6, wall=59413
2025-10-31 11:24:27 | INFO | train_inner | epoch 003:   9672 / 11384 loss=0.119821, wps=1149.3, ups=0.59, wpb=1962.5, bsz=128, num_updates=32250, lr=4.3e-05, gnorm=23.54, clip=100, loss_scale=16, train_wall=85, gb_free=5.7, wall=59498
2025-10-31 11:25:32 | INFO | train_inner | epoch 003:   9722 / 11384 loss=0.116592, wps=1475.1, ups=0.76, wpb=1940.7, bsz=128, num_updates=32300, lr=4.30667e-05, gnorm=20.955, clip=100, loss_scale=32, train_wall=66, gb_free=15.6, wall=59564
2025-10-31 11:26:57 | INFO | train_inner | epoch 003:   9772 / 11384 loss=0.120529, wps=1180.5, ups=0.59, wpb=1996.6, bsz=128, num_updates=32350, lr=4.31333e-05, gnorm=19.835, clip=100, loss_scale=32, train_wall=84, gb_free=16.6, wall=59648
2025-10-31 11:28:27 | INFO | train_inner | epoch 003:   9822 / 11384 loss=0.126163, wps=1103.8, ups=0.56, wpb=1977.5, bsz=128, num_updates=32400, lr=4.32e-05, gnorm=22.137, clip=100, loss_scale=32, train_wall=89, gb_free=15.6, wall=59738
2025-10-31 11:29:50 | INFO | train_inner | epoch 003:   9872 / 11384 loss=0.12314, wps=1188.2, ups=0.6, wpb=1984.2, bsz=128, num_updates=32450, lr=4.32667e-05, gnorm=20.914, clip=100, loss_scale=64, train_wall=83, gb_free=16.9, wall=59821
2025-10-31 11:30:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:30:58 | INFO | train_inner | epoch 003:   9923 / 11384 loss=0.117485, wps=1448.8, ups=0.73, wpb=1981, bsz=128, num_updates=32500, lr=4.33333e-05, gnorm=22.881, clip=100, loss_scale=32, train_wall=68, gb_free=17.5, wall=59890
2025-10-31 11:32:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 11:32:26 | INFO | train_inner | epoch 003:   9974 / 11384 loss=0.124639, wps=1099.3, ups=0.57, wpb=1929.8, bsz=128, num_updates=32550, lr=4.34e-05, gnorm=21.516, clip=100, loss_scale=16, train_wall=84, gb_free=9.9, wall=59978
2025-10-31 11:33:51 | INFO | train_inner | epoch 003:  10024 / 11384 loss=0.116934, wps=1157.1, ups=0.59, wpb=1963.4, bsz=128, num_updates=32600, lr=4.34667e-05, gnorm=21.535, clip=100, loss_scale=16, train_wall=85, gb_free=12.6, wall=60062
2025-10-31 11:35:22 | INFO | train_inner | epoch 003:  10074 / 11384 loss=0.110358, wps=1060.1, ups=0.55, wpb=1937.4, bsz=128, num_updates=32650, lr=4.35333e-05, gnorm=20.236, clip=100, loss_scale=16, train_wall=91, gb_free=12.1, wall=60154
2025-10-31 11:36:16 | INFO | train_inner | epoch 003:  10124 / 11384 loss=0.118557, wps=1771.7, ups=0.93, wpb=1910.7, bsz=128, num_updates=32700, lr=4.36e-05, gnorm=21.074, clip=100, loss_scale=32, train_wall=54, gb_free=15.9, wall=60208
2025-10-31 11:36:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 11:38:01 | INFO | train_inner | epoch 003:  10175 / 11384 loss=0.114768, wps=924.4, ups=0.48, wpb=1935.7, bsz=128, num_updates=32750, lr=4.36667e-05, gnorm=24.309, clip=100, loss_scale=16, train_wall=103, gb_free=16.1, wall=60312
2025-10-31 11:39:20 | INFO | train_inner | epoch 003:  10225 / 11384 loss=0.118233, wps=1243, ups=0.64, wpb=1951.5, bsz=128, num_updates=32800, lr=4.37333e-05, gnorm=20.611, clip=100, loss_scale=16, train_wall=78, gb_free=16.2, wall=60391
2025-10-31 11:40:41 | INFO | train_inner | epoch 003:  10275 / 11384 loss=0.124693, wps=1211.6, ups=0.61, wpb=1983.1, bsz=128, num_updates=32850, lr=4.38e-05, gnorm=23.225, clip=100, loss_scale=32, train_wall=82, gb_free=14, wall=60473
2025-10-31 11:42:09 | INFO | train_inner | epoch 003:  10325 / 11384 loss=0.125474, wps=1128.5, ups=0.57, wpb=1974.6, bsz=128, num_updates=32900, lr=4.38667e-05, gnorm=25.028, clip=100, loss_scale=32, train_wall=87, gb_free=11.4, wall=60560
2025-10-31 11:43:08 | INFO | train_inner | epoch 003:  10375 / 11384 loss=0.118574, wps=1661.5, ups=0.84, wpb=1969.3, bsz=128, num_updates=32950, lr=4.39333e-05, gnorm=23.395, clip=100, loss_scale=32, train_wall=59, gb_free=14.6, wall=60620
2025-10-31 11:44:47 | INFO | train_inner | epoch 003:  10425 / 11384 loss=0.114962, wps=1000.1, ups=0.51, wpb=1978.6, bsz=128, num_updates=33000, lr=4.4e-05, gnorm=22.565, clip=100, loss_scale=64, train_wall=87, gb_free=15.7, wall=60718
2025-10-31 11:45:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:45:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 11:46:09 | INFO | train_inner | epoch 003:  10477 / 11384 loss=0.124412, wps=1206.3, ups=0.61, wpb=1976, bsz=128, num_updates=33050, lr=4.40667e-05, gnorm=25.312, clip=100, loss_scale=16, train_wall=82, gb_free=14.7, wall=60800
2025-10-31 11:47:34 | INFO | train_inner | epoch 003:  10527 / 11384 loss=0.124129, wps=1119.1, ups=0.59, wpb=1900.7, bsz=128, num_updates=33100, lr=4.41333e-05, gnorm=22.619, clip=100, loss_scale=16, train_wall=82, gb_free=15.1, wall=60885
2025-10-31 11:49:08 | INFO | train_inner | epoch 003:  10577 / 11384 loss=0.112377, wps=1049, ups=0.53, wpb=1965.4, bsz=128, num_updates=33150, lr=4.42e-05, gnorm=20.708, clip=100, loss_scale=16, train_wall=93, gb_free=16.7, wall=60979
2025-10-31 11:50:01 | INFO | train_inner | epoch 003:  10627 / 11384 loss=0.121725, wps=1846.9, ups=0.94, wpb=1962.8, bsz=128, num_updates=33200, lr=4.42667e-05, gnorm=23.212, clip=100, loss_scale=32, train_wall=53, gb_free=10.9, wall=61032
2025-10-31 11:51:26 | INFO | train_inner | epoch 003:  10677 / 11384 loss=0.12012, wps=1130.4, ups=0.59, wpb=1913.7, bsz=128, num_updates=33250, lr=4.43333e-05, gnorm=20.911, clip=100, loss_scale=32, train_wall=84, gb_free=17.4, wall=61117
2025-10-31 11:52:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:52:40 | INFO | train_inner | epoch 003:  10728 / 11384 loss=0.12466, wps=1306.6, ups=0.67, wpb=1945.4, bsz=128, num_updates=33300, lr=4.44e-05, gnorm=26.57, clip=100, loss_scale=32, train_wall=74, gb_free=13.9, wall=61191
2025-10-31 11:54:01 | INFO | train_inner | epoch 003:  10778 / 11384 loss=0.118771, wps=1213.5, ups=0.62, wpb=1964.5, bsz=128, num_updates=33350, lr=4.44667e-05, gnorm=23.383, clip=100, loss_scale=32, train_wall=81, gb_free=13.6, wall=61272
2025-10-31 11:55:33 | INFO | train_inner | epoch 003:  10828 / 11384 loss=0.116076, wps=1070.3, ups=0.54, wpb=1969.3, bsz=128, num_updates=33400, lr=4.45333e-05, gnorm=23.064, clip=100, loss_scale=32, train_wall=92, gb_free=12.4, wall=61364
2025-10-31 11:56:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 11:56:44 | INFO | train_inner | epoch 003:  10879 / 11384 loss=0.115688, wps=1377.5, ups=0.71, wpb=1945.1, bsz=128, num_updates=33450, lr=4.46e-05, gnorm=21.46, clip=100, loss_scale=32, train_wall=70, gb_free=14.9, wall=61435
2025-10-31 11:58:18 | INFO | train_inner | epoch 003:  10929 / 11384 loss=0.120909, wps=1040.3, ups=0.53, wpb=1958.9, bsz=128, num_updates=33500, lr=4.46667e-05, gnorm=20.618, clip=100, loss_scale=32, train_wall=94, gb_free=7.4, wall=61529
2025-10-31 11:59:26 | INFO | train_inner | epoch 003:  10979 / 11384 loss=0.11697, wps=1442.7, ups=0.73, wpb=1976.1, bsz=128, num_updates=33550, lr=4.47333e-05, gnorm=23.819, clip=100, loss_scale=64, train_wall=68, gb_free=16.2, wall=61598
2025-10-31 11:59:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 12:00:48 | INFO | train_inner | epoch 003:  11030 / 11384 loss=0.107958, wps=1197.7, ups=0.61, wpb=1947.5, bsz=128, num_updates=33600, lr=4.48e-05, gnorm=19.364, clip=100, loss_scale=32, train_wall=81, gb_free=16.8, wall=61679
2025-10-31 12:02:22 | INFO | train_inner | epoch 003:  11080 / 11384 loss=0.108994, wps=1031.8, ups=0.53, wpb=1937.5, bsz=128, num_updates=33650, lr=4.48667e-05, gnorm=20.934, clip=100, loss_scale=32, train_wall=94, gb_free=13.3, wall=61773
2025-10-31 12:03:39 | INFO | train_inner | epoch 003:  11130 / 11384 loss=0.117652, wps=1255.5, ups=0.64, wpb=1948.3, bsz=128, num_updates=33700, lr=4.49333e-05, gnorm=22.222, clip=100, loss_scale=64, train_wall=77, gb_free=14.8, wall=61850
2025-10-31 12:04:52 | INFO | train_inner | epoch 003:  11180 / 11384 loss=0.114631, wps=1302.2, ups=0.68, wpb=1906, bsz=128, num_updates=33750, lr=4.5e-05, gnorm=20.247, clip=100, loss_scale=64, train_wall=73, gb_free=16.3, wall=61924
2025-10-31 12:05:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 12:06:04 | INFO | train_inner | epoch 003:  11231 / 11384 loss=0.118903, wps=1339.9, ups=0.7, wpb=1919.7, bsz=128, num_updates=33800, lr=4.50667e-05, gnorm=22.995, clip=100, loss_scale=32, train_wall=71, gb_free=13.1, wall=61995
2025-10-31 12:06:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 12:07:40 | INFO | train_inner | epoch 003:  11282 / 11384 loss=0.117724, wps=1009.4, ups=0.52, wpb=1948.8, bsz=128, num_updates=33850, lr=4.51333e-05, gnorm=26.654, clip=100, loss_scale=16, train_wall=96, gb_free=9.8, wall=62092
2025-10-31 12:08:45 | INFO | train_inner | epoch 003:  11332 / 11384 loss=0.118207, wps=1557.6, ups=0.78, wpb=1996.2, bsz=128, num_updates=33900, lr=4.52e-05, gnorm=21.41, clip=100, loss_scale=16, train_wall=64, gb_free=16.2, wall=62156
2025-10-31 12:10:04 | INFO | train_inner | epoch 003:  11382 / 11384 loss=0.13573, wps=1218.3, ups=0.63, wpb=1945.1, bsz=128, num_updates=33950, lr=4.52667e-05, gnorm=23.244, clip=100, loss_scale=32, train_wall=80, gb_free=14.5, wall=62236
2025-10-31 12:10:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-10-31 12:25:14 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.136293 | wps 1353 | wpb 1948.3 | bsz 127.9 | num_updates 33952 | best_loss 0.136293
2025-10-31 12:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 33952 updates
2025-10-31 12:25:15 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint3.pt
2025-10-31 12:25:19 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint3.pt
2025-10-31 12:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint3.pt (epoch 3 @ 33952 updates, score 0.136293) (writing took 257.24631117796525 seconds)
2025-10-31 12:29:32 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2025-10-31 12:29:33 | INFO | train | epoch 003 | loss 0.142013 | wps 999.3 | ups 0.51 | wpb 1959.5 | bsz 128 | num_updates 33952 | lr 4.52693e-05 | gnorm 26.794 | clip 100 | loss_scale 32 | train_wall 19503 | gb_free 15.3 | wall 63405
2025-10-31 12:29:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-10-31 12:29:36 | INFO | fairseq.trainer | begin training epoch 4
2025-10-31 12:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2025-10-31 12:31:08 | INFO | train_inner | epoch 004:     48 / 11384 loss=0.122739, wps=78, ups=0.04, wpb=1970.4, bsz=127.7, num_updates=34000, lr=4.53333e-05, gnorm=22.165, clip=100, loss_scale=32, train_wall=90, gb_free=16.2, wall=63499
2025-10-31 12:32:35 | INFO | train_inner | epoch 004:     98 / 11384 loss=0.111213, wps=1099.9, ups=0.57, wpb=1925, bsz=128, num_updates=34050, lr=4.54e-05, gnorm=19.728, clip=100, loss_scale=32, train_wall=87, gb_free=14.6, wall=63586
2025-10-31 12:34:27 | INFO | train_inner | epoch 004:    148 / 11384 loss=0.106635, wps=877.9, ups=0.45, wpb=1968.7, bsz=128, num_updates=34100, lr=4.54667e-05, gnorm=20.223, clip=100, loss_scale=64, train_wall=112, gb_free=15.9, wall=63699
2025-10-31 12:34:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 12:34:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 12:35:30 | INFO | train_inner | epoch 004:    200 / 11384 loss=0.112194, wps=1589.1, ups=0.8, wpb=1983.8, bsz=128, num_updates=34150, lr=4.55333e-05, gnorm=23.813, clip=100, loss_scale=16, train_wall=62, gb_free=12.8, wall=63761
2025-10-31 12:36:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 12:36:40 | INFO | train_inner | epoch 004:    251 / 11384 loss=0.108919, wps=1392.2, ups=0.71, wpb=1958.8, bsz=128, num_updates=34200, lr=4.56e-05, gnorm=23.528, clip=100, loss_scale=8, train_wall=70, gb_free=16.2, wall=63831
2025-10-31 12:38:41 | INFO | train_inner | epoch 004:    301 / 11384 loss=0.111779, wps=815.5, ups=0.41, wpb=1977.4, bsz=128, num_updates=34250, lr=4.56667e-05, gnorm=22.275, clip=100, loss_scale=8, train_wall=121, gb_free=17.1, wall=63953
2025-10-31 12:39:36 | INFO | train_inner | epoch 004:    351 / 11384 loss=0.108804, wps=1755.2, ups=0.91, wpb=1926.3, bsz=128, num_updates=34300, lr=4.57333e-05, gnorm=20.824, clip=100, loss_scale=8, train_wall=55, gb_free=14.1, wall=64008
2025-10-31 12:41:37 | INFO | train_inner | epoch 004:    401 / 11384 loss=0.113964, wps=797.8, ups=0.42, wpb=1919.7, bsz=128, num_updates=34350, lr=4.58e-05, gnorm=21.852, clip=100, loss_scale=16, train_wall=104, gb_free=10.8, wall=64128
2025-10-31 12:42:36 | INFO | train_inner | epoch 004:    451 / 11384 loss=0.124214, wps=1653.2, ups=0.85, wpb=1946, bsz=128, num_updates=34400, lr=4.58667e-05, gnorm=25.529, clip=100, loss_scale=16, train_wall=59, gb_free=16.1, wall=64187
2025-10-31 12:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 12:44:35 | INFO | train_inner | epoch 004:    502 / 11384 loss=0.115298, wps=829.5, ups=0.42, wpb=1984.3, bsz=128, num_updates=34450, lr=4.59333e-05, gnorm=23.394, clip=100, loss_scale=16, train_wall=67, gb_free=8, wall=64306
2025-10-31 12:46:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 12:46:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-10-31 12:46:20 | INFO | train_inner | epoch 004:    554 / 11384 loss=0.11601, wps=918, ups=0.48, wpb=1921.6, bsz=128, num_updates=34500, lr=4.6e-05, gnorm=21.908, clip=100, loss_scale=4, train_wall=104, gb_free=16.2, wall=64411
2025-10-31 12:48:15 | INFO | train_inner | epoch 004:    604 / 11384 loss=0.109414, wps=862.7, ups=0.43, wpb=1983.4, bsz=128, num_updates=34550, lr=4.60667e-05, gnorm=24.427, clip=100, loss_scale=4, train_wall=89, gb_free=15.3, wall=64526
2025-10-31 12:50:41 | INFO | train_inner | epoch 004:    654 / 11384 loss=0.114766, wps=668.7, ups=0.34, wpb=1957.9, bsz=128, num_updates=34600, lr=4.61333e-05, gnorm=22.575, clip=100, loss_scale=4, train_wall=146, gb_free=16.7, wall=64672
2025-10-31 12:52:46 | INFO | train_inner | epoch 004:    704 / 11384 loss=0.121927, wps=803.6, ups=0.4, wpb=1998.4, bsz=128, num_updates=34650, lr=4.62e-05, gnorm=24.491, clip=100, loss_scale=8, train_wall=114, gb_free=16.3, wall=64797
2025-10-31 12:54:30 | INFO | train_inner | epoch 004:    754 / 11384 loss=0.131462, wps=938.7, ups=0.48, wpb=1965, bsz=128, num_updates=34700, lr=4.62667e-05, gnorm=27.016, clip=100, loss_scale=8, train_wall=104, gb_free=16.3, wall=64902
2025-10-31 12:56:31 | INFO | train_inner | epoch 004:    804 / 11384 loss=0.126668, wps=812.2, ups=0.41, wpb=1960.8, bsz=128, num_updates=34750, lr=4.63333e-05, gnorm=22.126, clip=100, loss_scale=16, train_wall=120, gb_free=9.1, wall=65022
2025-10-31 12:58:37 | INFO | train_inner | epoch 004:    854 / 11384 loss=0.108932, wps=784.1, ups=0.4, wpb=1974.1, bsz=128, num_updates=34800, lr=4.64e-05, gnorm=18.04, clip=100, loss_scale=16, train_wall=69, gb_free=10.1, wall=65148
2025-10-31 12:59:38 | INFO | train_inner | epoch 004:    904 / 11384 loss=0.113698, wps=1574.7, ups=0.82, wpb=1913.1, bsz=128, num_updates=34850, lr=4.64667e-05, gnorm=21.986, clip=100, loss_scale=16, train_wall=61, gb_free=14.3, wall=65209
2025-10-31 13:01:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 13:01:50 | INFO | train_inner | epoch 004:    955 / 11384 loss=0.11278, wps=745.5, ups=0.38, wpb=1981.6, bsz=128, num_updates=34900, lr=4.65333e-05, gnorm=19.987, clip=100, loss_scale=8, train_wall=133, gb_free=14.7, wall=65342
2025-10-31 13:04:33 | INFO | train_inner | epoch 004:   1005 / 11384 loss=0.11142, wps=602.2, ups=0.31, wpb=1955.8, bsz=128, num_updates=34950, lr=4.66e-05, gnorm=20.484, clip=100, loss_scale=8, train_wall=162, gb_free=13.3, wall=65504
2025-10-31 13:07:08 | INFO | train_inner | epoch 004:   1055 / 11384 loss=0.110475, wps=630.7, ups=0.32, wpb=1954, bsz=128, num_updates=35000, lr=4.66667e-05, gnorm=21.346, clip=100, loss_scale=16, train_wall=61, gb_free=15.8, wall=65659
2025-10-31 13:08:28 | INFO | train_inner | epoch 004:   1105 / 11384 loss=0.109496, wps=1205.1, ups=0.62, wpb=1942.4, bsz=128, num_updates=35050, lr=4.67333e-05, gnorm=18.377, clip=100, loss_scale=16, train_wall=80, gb_free=16, wall=65740
2025-10-31 13:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 13:11:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-10-31 13:11:31 | INFO | train_inner | epoch 004:   1157 / 11384 loss=0.116004, wps=532.7, ups=0.27, wpb=1945.6, bsz=128, num_updates=35100, lr=4.68e-05, gnorm=21.938, clip=100, loss_scale=4, train_wall=182, gb_free=17.3, wall=65922
2025-10-31 13:12:39 | INFO | train_inner | epoch 004:   1207 / 11384 loss=0.101894, wps=1445.9, ups=0.74, wpb=1963, bsz=128, num_updates=35150, lr=4.68667e-05, gnorm=19.005, clip=100, loss_scale=4, train_wall=68, gb_free=16.7, wall=65990
2025-10-31 13:14:35 | INFO | train_inner | epoch 004:   1257 / 11384 loss=0.109873, wps=868.1, ups=0.43, wpb=2006.5, bsz=128, num_updates=35200, lr=4.69333e-05, gnorm=20.636, clip=100, loss_scale=4, train_wall=115, gb_free=16.4, wall=66106
2025-10-31 13:16:40 | INFO | train_inner | epoch 004:   1307 / 11384 loss=0.110596, wps=781.5, ups=0.4, wpb=1955.7, bsz=128, num_updates=35250, lr=4.7e-05, gnorm=24.035, clip=100, loss_scale=8, train_wall=86, gb_free=15, wall=66231
2025-10-31 13:18:52 | INFO | train_inner | epoch 004:   1357 / 11384 loss=0.110762, wps=731.9, ups=0.38, wpb=1942.6, bsz=128, num_updates=35300, lr=4.70667e-05, gnorm=20.006, clip=100, loss_scale=8, train_wall=132, gb_free=15.5, wall=66364
2025-10-31 13:21:18 | INFO | train_inner | epoch 004:   1407 / 11384 loss=0.107039, wps=672.6, ups=0.34, wpb=1957.6, bsz=128, num_updates=35350, lr=4.71333e-05, gnorm=18.991, clip=100, loss_scale=16, train_wall=145, gb_free=9.8, wall=66509
2025-10-31 13:22:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 13:23:02 | INFO | train_inner | epoch 004:   1458 / 11384 loss=0.114372, wps=956.7, ups=0.48, wpb=1983.5, bsz=128, num_updates=35400, lr=4.72e-05, gnorm=22.185, clip=100, loss_scale=8, train_wall=88, gb_free=12.4, wall=66613
2025-10-31 13:25:26 | INFO | train_inner | epoch 004:   1508 / 11384 loss=0.109365, wps=679.3, ups=0.35, wpb=1961.4, bsz=128, num_updates=35450, lr=4.72667e-05, gnorm=21.515, clip=100, loss_scale=8, train_wall=144, gb_free=9.2, wall=66757
2025-10-31 13:26:27 | INFO | train_inner | epoch 004:   1558 / 11384 loss=0.111084, wps=1614.7, ups=0.82, wpb=1973, bsz=128, num_updates=35500, lr=4.73333e-05, gnorm=19.884, clip=100, loss_scale=8, train_wall=61, gb_free=15.9, wall=66818
2025-10-31 13:28:11 | INFO | train_inner | epoch 004:   1608 / 11384 loss=0.120784, wps=948.9, ups=0.48, wpb=1970.5, bsz=128, num_updates=35550, lr=4.74e-05, gnorm=24.769, clip=100, loss_scale=16, train_wall=73, gb_free=16, wall=66922
2025-10-31 13:31:02 | INFO | train_inner | epoch 004:   1658 / 11384 loss=0.120812, wps=579.5, ups=0.29, wpb=1981.2, bsz=128, num_updates=35600, lr=4.74667e-05, gnorm=23.157, clip=100, loss_scale=16, train_wall=171, gb_free=15.4, wall=67093
2025-10-31 13:33:34 | INFO | train_inner | epoch 004:   1708 / 11384 loss=0.119046, wps=642.9, ups=0.33, wpb=1950.9, bsz=128, num_updates=35650, lr=4.75333e-05, gnorm=23.353, clip=100, loss_scale=16, train_wall=152, gb_free=15.6, wall=67245
2025-10-31 13:35:57 | INFO | train_inner | epoch 004:   1758 / 11384 loss=0.108261, wps=690.2, ups=0.35, wpb=1986.3, bsz=128, num_updates=35700, lr=4.76e-05, gnorm=19.008, clip=100, loss_scale=32, train_wall=144, gb_free=10.6, wall=67389
2025-10-31 13:38:02 | INFO | train_inner | epoch 004:   1808 / 11384 loss=0.112668, wps=786.4, ups=0.4, wpb=1964.2, bsz=128, num_updates=35750, lr=4.76667e-05, gnorm=20.541, clip=100, loss_scale=32, train_wall=78, gb_free=16.3, wall=67514
2025-10-31 13:40:00 | INFO | train_inner | epoch 004:   1858 / 11384 loss=0.105717, wps=830.6, ups=0.43, wpb=1949.2, bsz=128, num_updates=35800, lr=4.77333e-05, gnorm=17.531, clip=100, loss_scale=64, train_wall=117, gb_free=14.4, wall=67631
2025-10-31 13:41:39 | INFO | train_inner | epoch 004:   1908 / 11384 loss=0.10659, wps=974.1, ups=0.51, wpb=1928, bsz=128, num_updates=35850, lr=4.78e-05, gnorm=20.738, clip=100, loss_scale=64, train_wall=60, gb_free=13.8, wall=67730
2025-10-31 13:42:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 13:42:42 | INFO | train_inner | epoch 004:   1959 / 11384 loss=0.106024, wps=1489.8, ups=0.79, wpb=1895.6, bsz=128, num_updates=35900, lr=4.78667e-05, gnorm=18.774, clip=100, loss_scale=32, train_wall=63, gb_free=11.4, wall=67794
2025-10-31 13:45:35 | INFO | train_inner | epoch 004:   2009 / 11384 loss=0.106621, wps=565.6, ups=0.29, wpb=1956.6, bsz=128, num_updates=35950, lr=4.79333e-05, gnorm=20.781, clip=100, loss_scale=32, train_wall=173, gb_free=15.7, wall=67967
2025-10-31 13:45:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 13:47:53 | INFO | train_inner | epoch 004:   2060 / 11384 loss=0.109442, wps=699.8, ups=0.36, wpb=1923.4, bsz=128, num_updates=36000, lr=4.8e-05, gnorm=20.817, clip=100, loss_scale=16, train_wall=135, gb_free=15.4, wall=68104
2025-10-31 13:49:18 | INFO | train_inner | epoch 004:   2110 / 11384 loss=0.103629, wps=1138.7, ups=0.59, wpb=1934.6, bsz=128, num_updates=36050, lr=4.80667e-05, gnorm=17.672, clip=100, loss_scale=16, train_wall=85, gb_free=15.1, wall=68189
2025-10-31 13:51:15 | INFO | train_inner | epoch 004:   2160 / 11384 loss=0.103425, wps=843.1, ups=0.42, wpb=1984.4, bsz=128, num_updates=36100, lr=4.81333e-05, gnorm=17.735, clip=100, loss_scale=32, train_wall=117, gb_free=9.9, wall=68307
2025-10-31 13:51:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 13:53:57 | INFO | train_inner | epoch 004:   2211 / 11384 loss=0.108502, wps=614.7, ups=0.31, wpb=1992.5, bsz=128, num_updates=36150, lr=4.82e-05, gnorm=21.669, clip=100, loss_scale=16, train_wall=162, gb_free=13.6, wall=68469
2025-10-31 13:55:59 | INFO | train_inner | epoch 004:   2261 / 11384 loss=0.106187, wps=808.4, ups=0.41, wpb=1971.8, bsz=128, num_updates=36200, lr=4.82667e-05, gnorm=19.396, clip=100, loss_scale=16, train_wall=66, gb_free=16.6, wall=68591
2025-10-31 13:56:59 | INFO | train_inner | epoch 004:   2311 / 11384 loss=0.101024, wps=1600, ups=0.83, wpb=1916.4, bsz=128, num_updates=36250, lr=4.83333e-05, gnorm=20.001, clip=100, loss_scale=32, train_wall=60, gb_free=7.6, wall=68651
2025-10-31 13:59:47 | INFO | train_inner | epoch 004:   2361 / 11384 loss=0.099288, wps=579.2, ups=0.3, wpb=1944.9, bsz=128, num_updates=36300, lr=4.84e-05, gnorm=19.728, clip=100, loss_scale=32, train_wall=168, gb_free=15.4, wall=68818
2025-10-31 14:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 14:02:32 | INFO | train_inner | epoch 004:   2412 / 11384 loss=0.101045, wps=601.2, ups=0.3, wpb=1981.8, bsz=128, num_updates=36350, lr=4.84667e-05, gnorm=18.319, clip=100, loss_scale=16, train_wall=164, gb_free=15.7, wall=68983
2025-10-31 14:04:12 | INFO | train_inner | epoch 004:   2462 / 11384 loss=0.105914, wps=981.1, ups=0.5, wpb=1970.3, bsz=128, num_updates=36400, lr=4.85333e-05, gnorm=19.748, clip=100, loss_scale=16, train_wall=100, gb_free=10.4, wall=69084
2025-10-31 14:06:33 | INFO | train_inner | epoch 004:   2512 / 11384 loss=0.10326, wps=690.9, ups=0.35, wpb=1947.1, bsz=128, num_updates=36450, lr=4.86e-05, gnorm=21.257, clip=100, loss_scale=16, train_wall=63, gb_free=16.3, wall=69225
2025-10-31 14:07:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 14:08:57 | INFO | train_inner | epoch 004:   2563 / 11384 loss=0.103861, wps=678.2, ups=0.35, wpb=1953.5, bsz=128, num_updates=36500, lr=4.86667e-05, gnorm=20.108, clip=100, loss_scale=16, train_wall=142, gb_free=16.4, wall=69369
2025-10-31 14:09:58 | INFO | train_inner | epoch 004:   2613 / 11384 loss=0.107221, wps=1625.9, ups=0.83, wpb=1968, bsz=128, num_updates=36550, lr=4.87333e-05, gnorm=18.905, clip=100, loss_scale=16, train_wall=60, gb_free=15.8, wall=69429
2025-10-31 14:12:01 | INFO | train_inner | epoch 004:   2663 / 11384 loss=0.111344, wps=798.9, ups=0.41, wpb=1964.8, bsz=128, num_updates=36600, lr=4.88e-05, gnorm=22.626, clip=100, loss_scale=16, train_wall=123, gb_free=15.1, wall=69552
2025-10-31 14:13:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 14:13:59 | INFO | train_inner | epoch 004:   2714 / 11384 loss=0.103871, wps=819.2, ups=0.42, wpb=1937.6, bsz=128, num_updates=36650, lr=4.88667e-05, gnorm=21.035, clip=100, loss_scale=16, train_wall=118, gb_free=15.4, wall=69671
2025-10-31 14:16:16 | INFO | train_inner | epoch 004:   2764 / 11384 loss=0.106093, wps=721.6, ups=0.37, wpb=1971.5, bsz=128, num_updates=36700, lr=4.89333e-05, gnorm=20.993, clip=100, loss_scale=16, train_wall=136, gb_free=14.2, wall=69807
2025-10-31 14:18:33 | INFO | train_inner | epoch 004:   2814 / 11384 loss=0.100066, wps=721.3, ups=0.37, wpb=1973.3, bsz=128, num_updates=36750, lr=4.9e-05, gnorm=18.275, clip=100, loss_scale=16, train_wall=86, gb_free=14.4, wall=69944
2025-10-31 14:20:26 | INFO | train_inner | epoch 004:   2864 / 11384 loss=0.105248, wps=874.4, ups=0.44, wpb=1971.7, bsz=128, num_updates=36800, lr=4.90667e-05, gnorm=19.137, clip=100, loss_scale=32, train_wall=67, gb_free=16, wall=70057
2025-10-31 14:23:04 | INFO | train_inner | epoch 004:   2914 / 11384 loss=0.101268, wps=608.5, ups=0.32, wpb=1927.4, bsz=128, num_updates=36850, lr=4.91333e-05, gnorm=20.018, clip=100, loss_scale=32, train_wall=149, gb_free=14.6, wall=70215
2025-10-31 14:23:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 14:24:19 | INFO | train_inner | epoch 004:   2965 / 11384 loss=0.102973, wps=1289.1, ups=0.67, wpb=1920.9, bsz=128, num_updates=36900, lr=4.92e-05, gnorm=17.772, clip=100, loss_scale=16, train_wall=74, gb_free=13.4, wall=70290
2025-10-31 14:25:56 | INFO | train_inner | epoch 004:   3015 / 11384 loss=0.113141, wps=1005.7, ups=0.51, wpb=1955.9, bsz=128, num_updates=36950, lr=4.92667e-05, gnorm=28.121, clip=100, loss_scale=16, train_wall=97, gb_free=16, wall=70387
2025-10-31 14:27:12 | INFO | train_inner | epoch 004:   3065 / 11384 loss=0.11088, wps=1284.3, ups=0.66, wpb=1958.6, bsz=128, num_updates=37000, lr=4.93333e-05, gnorm=19.26, clip=100, loss_scale=32, train_wall=76, gb_free=16.2, wall=70464
2025-10-31 14:28:32 | INFO | train_inner | epoch 004:   3115 / 11384 loss=0.111615, wps=1236.5, ups=0.63, wpb=1959.3, bsz=128, num_updates=37050, lr=4.94e-05, gnorm=19.929, clip=100, loss_scale=32, train_wall=79, gb_free=14.3, wall=70543
2025-10-31 14:30:10 | INFO | train_inner | epoch 004:   3165 / 11384 loss=0.116241, wps=993.7, ups=0.51, wpb=1953.4, bsz=128, num_updates=37100, lr=4.94667e-05, gnorm=21.238, clip=100, loss_scale=32, train_wall=98, gb_free=15.9, wall=70641
2025-10-31 14:30:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 14:31:53 | INFO | train_inner | epoch 004:   3216 / 11384 loss=0.103675, wps=969.4, ups=0.48, wpb=2001.4, bsz=128, num_updates=37150, lr=4.95333e-05, gnorm=18.559, clip=100, loss_scale=32, train_wall=103, gb_free=13.7, wall=70745
2025-10-31 14:32:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 14:33:38 | INFO | train_inner | epoch 004:   3267 / 11384 loss=0.103637, wps=939.7, ups=0.48, wpb=1961, bsz=128, num_updates=37200, lr=4.96e-05, gnorm=24.044, clip=100, loss_scale=16, train_wall=104, gb_free=16.8, wall=70849
2025-10-31 14:35:16 | INFO | train_inner | epoch 004:   3317 / 11384 loss=0.118548, wps=1010.6, ups=0.51, wpb=1980.3, bsz=128, num_updates=37250, lr=4.96667e-05, gnorm=22.679, clip=100, loss_scale=16, train_wall=98, gb_free=15, wall=70947
2025-10-31 14:36:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 14:36:44 | INFO | train_inner | epoch 004:   3368 / 11384 loss=0.105645, wps=1110, ups=0.57, wpb=1952.3, bsz=128, num_updates=37300, lr=4.97333e-05, gnorm=21.143, clip=100, loss_scale=8, train_wall=88, gb_free=11.2, wall=71035
2025-10-31 14:38:13 | INFO | train_inner | epoch 004:   3418 / 11384 loss=0.108512, wps=1116, ups=0.56, wpb=1982.3, bsz=128, num_updates=37350, lr=4.98e-05, gnorm=19.02, clip=100, loss_scale=8, train_wall=89, gb_free=16.7, wall=71124
2025-10-31 14:38:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-10-31 14:39:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2025-10-31 14:40:03 | INFO | train_inner | epoch 004:   3470 / 11384 loss=0.100948, wps=893.4, ups=0.45, wpb=1971.4, bsz=128, num_updates=37400, lr=4.98667e-05, gnorm=19.33, clip=100, loss_scale=2, train_wall=107, gb_free=13.3, wall=71234
2025-10-31 14:41:10 | INFO | train_inner | epoch 004:   3520 / 11384 loss=0.112292, wps=1461.7, ups=0.75, wpb=1943.8, bsz=128, num_updates=37450, lr=4.99333e-05, gnorm=28.291, clip=100, loss_scale=2, train_wall=66, gb_free=14.1, wall=71301
2025-10-31 14:42:37 | INFO | train_inner | epoch 004:   3570 / 11384 loss=0.106913, wps=1113.1, ups=0.57, wpb=1944.5, bsz=128, num_updates=37500, lr=5e-05, gnorm=22.438, clip=100, loss_scale=2, train_wall=87, gb_free=17.2, wall=71388
2025-10-31 14:43:58 | INFO | train_inner | epoch 004:   3620 / 11384 loss=0.103095, wps=1189.2, ups=0.62, wpb=1921.6, bsz=128, num_updates=37550, lr=5.00667e-05, gnorm=17.315, clip=100, loss_scale=4, train_wall=81, gb_free=15.4, wall=71469
2025-10-31 14:45:07 | INFO | train_inner | epoch 004:   3670 / 11384 loss=0.113553, wps=1399.4, ups=0.72, wpb=1942.2, bsz=128, num_updates=37600, lr=5.01333e-05, gnorm=28.842, clip=100, loss_scale=4, train_wall=67, gb_free=14.4, wall=71539
2025-10-31 14:47:15 | INFO | train_inner | epoch 004:   3720 / 11384 loss=0.103678, wps=756.5, ups=0.39, wpb=1932.7, bsz=128, num_updates=37650, lr=5.02e-05, gnorm=21.05, clip=100, loss_scale=8, train_wall=127, gb_free=8.9, wall=71666
2025-10-31 14:48:49 | INFO | train_inner | epoch 004:   3770 / 11384 loss=0.101891, wps=1031.9, ups=0.53, wpb=1945.2, bsz=128, num_updates=37700, lr=5.02667e-05, gnorm=17, clip=100, loss_scale=8, train_wall=94, gb_free=14.8, wall=71761
2025-10-31 14:50:06 | INFO | train_inner | epoch 004:   3820 / 11384 loss=0.094958, wps=1294.6, ups=0.65, wpb=1992.8, bsz=128, num_updates=37750, lr=5.03333e-05, gnorm=17.41, clip=100, loss_scale=8, train_wall=77, gb_free=17.9, wall=71838
2025-10-31 14:52:12 | INFO | train_inner | epoch 004:   3870 / 11384 loss=0.103999, wps=776.2, ups=0.4, wpb=1948.6, bsz=128, num_updates=37800, lr=5.04e-05, gnorm=17.414, clip=100, loss_scale=16, train_wall=125, gb_free=15.2, wall=71963
2025-10-31 14:53:42 | INFO | train_inner | epoch 004:   3920 / 11384 loss=0.105533, wps=1101, ups=0.55, wpb=1992.4, bsz=128, num_updates=37850, lr=5.04667e-05, gnorm=17.525, clip=100, loss_scale=16, train_wall=90, gb_free=16.6, wall=72054
2025-10-31 14:54:52 | INFO | train_inner | epoch 004:   3970 / 11384 loss=0.112109, wps=1394.3, ups=0.71, wpb=1950.8, bsz=128, num_updates=37900, lr=5.05333e-05, gnorm=23.15, clip=100, loss_scale=32, train_wall=70, gb_free=9.1, wall=72124
2025-10-31 14:56:04 | INFO | train_inner | epoch 004:   4020 / 11384 loss=0.114784, wps=1376, ups=0.7, wpb=1974.1, bsz=128, num_updates=37950, lr=5.06e-05, gnorm=21.403, clip=100, loss_scale=32, train_wall=71, gb_free=16.6, wall=72196
2025-10-31 14:57:26 | INFO | train_inner | epoch 004:   4070 / 11384 loss=0.10491, wps=1201.8, ups=0.61, wpb=1965.2, bsz=128, num_updates=38000, lr=5.06667e-05, gnorm=20.369, clip=100, loss_scale=32, train_wall=82, gb_free=16.7, wall=72277
2025-10-31 14:58:49 | INFO | train_inner | epoch 004:   4120 / 11384 loss=0.100717, wps=1188.5, ups=0.6, wpb=1971.5, bsz=128, num_updates=38050, lr=5.07333e-05, gnorm=17.81, clip=100, loss_scale=64, train_wall=83, gb_free=16.1, wall=72360
2025-10-31 14:58:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 14:59:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 15:00:04 | INFO | train_inner | epoch 004:   4172 / 11384 loss=0.099249, wps=1280.8, ups=0.66, wpb=1931.2, bsz=128, num_updates=38100, lr=5.08e-05, gnorm=17.307, clip=100, loss_scale=16, train_wall=75, gb_free=15.1, wall=72436
2025-10-31 15:00:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 15:01:34 | INFO | train_inner | epoch 004:   4223 / 11384 loss=0.099489, wps=1107.3, ups=0.56, wpb=1987.4, bsz=128, num_updates=38150, lr=5.08667e-05, gnorm=18.837, clip=100, loss_scale=8, train_wall=89, gb_free=17.5, wall=72525
2025-10-31 15:03:19 | INFO | train_inner | epoch 004:   4273 / 11384 loss=0.105654, wps=923.6, ups=0.48, wpb=1932.6, bsz=128, num_updates=38200, lr=5.09333e-05, gnorm=23.681, clip=100, loss_scale=8, train_wall=104, gb_free=7.9, wall=72630
2025-10-31 15:05:10 | INFO | train_inner | epoch 004:   4323 / 11384 loss=0.12172, wps=882.1, ups=0.45, wpb=1967.7, bsz=128, num_updates=38250, lr=5.1e-05, gnorm=22.45, clip=100, loss_scale=16, train_wall=111, gb_free=15.9, wall=72742
2025-10-31 15:06:18 | INFO | train_inner | epoch 004:   4373 / 11384 loss=0.116414, wps=1455, ups=0.74, wpb=1959.2, bsz=128, num_updates=38300, lr=5.10667e-05, gnorm=21.231, clip=100, loss_scale=16, train_wall=67, gb_free=16.2, wall=72809
2025-10-31 15:07:58 | INFO | train_inner | epoch 004:   4423 / 11384 loss=0.100732, wps=987.3, ups=0.5, wpb=1982.4, bsz=128, num_updates=38350, lr=5.11333e-05, gnorm=19.706, clip=100, loss_scale=16, train_wall=100, gb_free=16.7, wall=72909
2025-10-31 15:09:29 | INFO | train_inner | epoch 004:   4473 / 11384 loss=0.099051, wps=1062.3, ups=0.55, wpb=1934.6, bsz=128, num_updates=38400, lr=5.12e-05, gnorm=18.4, clip=100, loss_scale=32, train_wall=91, gb_free=14.1, wall=73001
2025-10-31 15:10:48 | INFO | train_inner | epoch 004:   4523 / 11384 loss=0.106907, wps=1239.3, ups=0.63, wpb=1955.1, bsz=128, num_updates=38450, lr=5.12667e-05, gnorm=21.703, clip=100, loss_scale=32, train_wall=79, gb_free=15.3, wall=73079
2025-10-31 15:12:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 15:12:30 | INFO | train_inner | epoch 004:   4574 / 11384 loss=0.098093, wps=970.5, ups=0.49, wpb=1968.6, bsz=128, num_updates=38500, lr=5.13333e-05, gnorm=19.178, clip=100, loss_scale=32, train_wall=101, gb_free=16.1, wall=73181
2025-10-31 15:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 15:13:49 | INFO | train_inner | epoch 004:   4625 / 11384 loss=0.103575, wps=1213.4, ups=0.63, wpb=1920.4, bsz=128, num_updates=38550, lr=5.14e-05, gnorm=21.462, clip=100, loss_scale=16, train_wall=79, gb_free=15.6, wall=73260
2025-10-31 15:15:31 | INFO | train_inner | epoch 004:   4675 / 11384 loss=0.105349, wps=944.4, ups=0.49, wpb=1933.3, bsz=128, num_updates=38600, lr=5.14667e-05, gnorm=19.274, clip=100, loss_scale=16, train_wall=102, gb_free=16.4, wall=73362
2025-10-31 15:16:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 15:16:52 | INFO | train_inner | epoch 004:   4726 / 11384 loss=0.105047, wps=1222, ups=0.62, wpb=1967.3, bsz=128, num_updates=38650, lr=5.15333e-05, gnorm=17.499, clip=100, loss_scale=8, train_wall=80, gb_free=15.5, wall=73443
2025-10-31 15:18:20 | INFO | train_inner | epoch 004:   4776 / 11384 loss=0.102432, wps=1103.4, ups=0.56, wpb=1960.8, bsz=128, num_updates=38700, lr=5.16e-05, gnorm=20.272, clip=100, loss_scale=8, train_wall=89, gb_free=13.2, wall=73532
2025-10-31 15:19:25 | INFO | train_inner | epoch 004:   4826 / 11384 loss=0.112124, wps=1503.8, ups=0.78, wpb=1930.2, bsz=128, num_updates=38750, lr=5.16667e-05, gnorm=23.435, clip=100, loss_scale=8, train_wall=64, gb_free=16.4, wall=73596
2025-10-31 15:21:05 | INFO | train_inner | epoch 004:   4876 / 11384 loss=0.110307, wps=992.3, ups=0.5, wpb=1987.9, bsz=128, num_updates=38800, lr=5.17333e-05, gnorm=18.672, clip=100, loss_scale=16, train_wall=100, gb_free=10.1, wall=73696
2025-10-31 15:22:36 | INFO | train_inner | epoch 004:   4926 / 11384 loss=0.105011, wps=1067.3, ups=0.55, wpb=1946, bsz=128, num_updates=38850, lr=5.18e-05, gnorm=21.441, clip=100, loss_scale=16, train_wall=91, gb_free=17.3, wall=73787
2025-10-31 15:23:56 | INFO | train_inner | epoch 004:   4976 / 11384 loss=0.102151, wps=1225, ups=0.63, wpb=1952.6, bsz=128, num_updates=38900, lr=5.18667e-05, gnorm=19.436, clip=100, loss_scale=32, train_wall=79, gb_free=17.1, wall=73867
2025-10-31 15:25:36 | INFO | train_inner | epoch 004:   5026 / 11384 loss=0.099349, wps=973.1, ups=0.5, wpb=1953.1, bsz=128, num_updates=38950, lr=5.19333e-05, gnorm=17.802, clip=100, loss_scale=32, train_wall=100, gb_free=15.8, wall=73967
2025-10-31 15:27:02 | INFO | train_inner | epoch 004:   5076 / 11384 loss=0.093867, wps=1144.2, ups=0.58, wpb=1972.5, bsz=128, num_updates=39000, lr=5.2e-05, gnorm=17.317, clip=100, loss_scale=32, train_wall=86, gb_free=16.8, wall=74054
2025-10-31 15:28:23 | INFO | train_inner | epoch 004:   5126 / 11384 loss=0.099194, wps=1233.2, ups=0.62, wpb=1987.8, bsz=128, num_updates=39050, lr=5.20667e-05, gnorm=19.978, clip=100, loss_scale=64, train_wall=80, gb_free=16.2, wall=74134
2025-10-31 15:29:53 | INFO | train_inner | epoch 004:   5176 / 11384 loss=0.109098, wps=1081.5, ups=0.55, wpb=1954.8, bsz=128, num_updates=39100, lr=5.21333e-05, gnorm=19.54, clip=100, loss_scale=64, train_wall=90, gb_free=14.8, wall=74225
2025-10-31 15:30:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 15:31:14 | INFO | train_inner | epoch 004:   5227 / 11384 loss=0.095347, wps=1214.2, ups=0.62, wpb=1958.8, bsz=128, num_updates=39150, lr=5.22e-05, gnorm=16.562, clip=100, loss_scale=32, train_wall=80, gb_free=16.6, wall=74305
2025-10-31 15:32:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 15:32:40 | INFO | train_inner | epoch 004:   5278 / 11384 loss=0.102514, wps=1149.2, ups=0.58, wpb=1980.7, bsz=128, num_updates=39200, lr=5.22667e-05, gnorm=21.295, clip=100, loss_scale=16, train_wall=86, gb_free=16.8, wall=74391
2025-10-31 15:34:05 | INFO | train_inner | epoch 004:   5328 / 11384 loss=0.097591, wps=1156.3, ups=0.59, wpb=1968.9, bsz=128, num_updates=39250, lr=5.23333e-05, gnorm=15.936, clip=100, loss_scale=16, train_wall=80, gb_free=14.8, wall=74477
2025-10-31 15:35:27 | INFO | train_inner | epoch 004:   5378 / 11384 loss=0.105051, wps=1204, ups=0.61, wpb=1967.6, bsz=128, num_updates=39300, lr=5.24e-05, gnorm=17.719, clip=100, loss_scale=16, train_wall=81, gb_free=16.5, wall=74558
2025-10-31 15:37:00 | INFO | train_inner | epoch 004:   5428 / 11384 loss=0.098359, wps=1035.6, ups=0.54, wpb=1932.7, bsz=128, num_updates=39350, lr=5.24667e-05, gnorm=19.361, clip=100, loss_scale=32, train_wall=93, gb_free=13, wall=74652
2025-10-31 15:38:09 | INFO | train_inner | epoch 004:   5478 / 11384 loss=0.10609, wps=1428.2, ups=0.73, wpb=1951.3, bsz=128, num_updates=39400, lr=5.25333e-05, gnorm=18.233, clip=100, loss_scale=32, train_wall=68, gb_free=17.2, wall=74720
2025-10-31 15:39:23 | INFO | train_inner | epoch 004:   5528 / 11384 loss=0.09843, wps=1329.4, ups=0.67, wpb=1977, bsz=128, num_updates=39450, lr=5.26e-05, gnorm=18.696, clip=100, loss_scale=64, train_wall=74, gb_free=13.7, wall=74795
2025-10-31 15:40:57 | INFO | train_inner | epoch 004:   5578 / 11384 loss=0.103587, wps=1031.7, ups=0.53, wpb=1930.8, bsz=128, num_updates=39500, lr=5.26667e-05, gnorm=17.997, clip=100, loss_scale=64, train_wall=93, gb_free=14.5, wall=74888
2025-10-31 15:41:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 15:42:21 | INFO | train_inner | epoch 004:   5629 / 11384 loss=0.091833, wps=1155.9, ups=0.59, wpb=1954.9, bsz=128, num_updates=39550, lr=5.27333e-05, gnorm=16.838, clip=100, loss_scale=32, train_wall=84, gb_free=14, wall=74973
2025-10-31 15:43:49 | INFO | train_inner | epoch 004:   5679 / 11384 loss=0.105706, wps=1132.4, ups=0.57, wpb=1981.2, bsz=128, num_updates=39600, lr=5.28e-05, gnorm=17.806, clip=100, loss_scale=32, train_wall=87, gb_free=14, wall=75060
2025-10-31 15:45:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 15:45:30 | INFO | train_inner | epoch 004:   5730 / 11384 loss=0.097577, wps=999.3, ups=0.5, wpb=2010, bsz=128, num_updates=39650, lr=5.28667e-05, gnorm=17.231, clip=100, loss_scale=32, train_wall=100, gb_free=15.9, wall=75161
2025-10-31 15:45:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 15:47:01 | INFO | train_inner | epoch 004:   5781 / 11384 loss=0.10204, wps=1068.7, ups=0.54, wpb=1962.8, bsz=128, num_updates=39700, lr=5.29333e-05, gnorm=17.766, clip=100, loss_scale=16, train_wall=92, gb_free=14.8, wall=75253
2025-10-31 15:48:19 | INFO | train_inner | epoch 004:   5831 / 11384 loss=0.111359, wps=1255.8, ups=0.64, wpb=1954.8, bsz=128, num_updates=39750, lr=5.3e-05, gnorm=19.051, clip=100, loss_scale=16, train_wall=78, gb_free=15.4, wall=75331
2025-10-31 15:49:42 | INFO | train_inner | epoch 004:   5881 / 11384 loss=0.098853, wps=1202.7, ups=0.61, wpb=1976.5, bsz=128, num_updates=39800, lr=5.30667e-05, gnorm=17.014, clip=100, loss_scale=32, train_wall=82, gb_free=15.5, wall=75413
2025-10-31 15:50:59 | INFO | train_inner | epoch 004:   5931 / 11384 loss=0.10452, wps=1271.4, ups=0.65, wpb=1963.8, bsz=128, num_updates=39850, lr=5.31333e-05, gnorm=20.038, clip=100, loss_scale=32, train_wall=77, gb_free=4.5, wall=75490
2025-10-31 15:52:05 | INFO | train_inner | epoch 004:   5981 / 11384 loss=0.099926, wps=1486.2, ups=0.76, wpb=1967.3, bsz=128, num_updates=39900, lr=5.32e-05, gnorm=18.56, clip=100, loss_scale=32, train_wall=66, gb_free=15.6, wall=75556
2025-10-31 15:53:43 | INFO | train_inner | epoch 004:   6031 / 11384 loss=0.094981, wps=998.3, ups=0.51, wpb=1960.1, bsz=128, num_updates=39950, lr=5.32667e-05, gnorm=17.384, clip=100, loss_scale=64, train_wall=98, gb_free=14.3, wall=75655
2025-10-31 15:54:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 15:55:11 | INFO | train_inner | epoch 004:   6082 / 11384 loss=0.098466, wps=1144.4, ups=0.57, wpb=1995.6, bsz=128, num_updates=40000, lr=5.33333e-05, gnorm=18.789, clip=100, loss_scale=32, train_wall=87, gb_free=10.4, wall=75742
2025-10-31 15:56:21 | INFO | train_inner | epoch 004:   6132 / 11384 loss=0.097187, wps=1383.4, ups=0.71, wpb=1960.4, bsz=128, num_updates=40050, lr=5.34e-05, gnorm=18.871, clip=100, loss_scale=32, train_wall=71, gb_free=14.7, wall=75813
2025-10-31 15:56:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 15:57:45 | INFO | train_inner | epoch 004:   6183 / 11384 loss=0.093891, wps=1158.4, ups=0.6, wpb=1928.9, bsz=128, num_updates=40100, lr=5.34667e-05, gnorm=17.779, clip=100, loss_scale=16, train_wall=83, gb_free=15.4, wall=75896
2025-10-31 15:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 15:59:13 | INFO | train_inner | epoch 004:   6234 / 11384 loss=0.09558, wps=1120.7, ups=0.57, wpb=1972.3, bsz=128, num_updates=40150, lr=5.35333e-05, gnorm=19.852, clip=100, loss_scale=8, train_wall=88, gb_free=16.6, wall=75984
2025-10-31 16:01:00 | INFO | train_inner | epoch 004:   6284 / 11384 loss=0.097864, wps=907.7, ups=0.47, wpb=1946.9, bsz=128, num_updates=40200, lr=5.36e-05, gnorm=17.257, clip=100, loss_scale=8, train_wall=107, gb_free=15.3, wall=76091
2025-10-31 16:01:59 | INFO | train_inner | epoch 004:   6334 / 11384 loss=0.091585, wps=1664.4, ups=0.84, wpb=1974.3, bsz=128, num_updates=40250, lr=5.36667e-05, gnorm=15.793, clip=100, loss_scale=16, train_wall=59, gb_free=14, wall=76151
2025-10-31 16:03:59 | INFO | train_inner | epoch 004:   6384 / 11384 loss=0.100356, wps=822.9, ups=0.42, wpb=1965.4, bsz=128, num_updates=40300, lr=5.37333e-05, gnorm=15.987, clip=100, loss_scale=16, train_wall=119, gb_free=15.9, wall=76270
2025-10-31 16:05:08 | INFO | train_inner | epoch 004:   6434 / 11384 loss=0.098736, wps=1441.4, ups=0.72, wpb=2003.3, bsz=128, num_updates=40350, lr=5.38e-05, gnorm=19.393, clip=100, loss_scale=16, train_wall=69, gb_free=16.4, wall=76340
2025-10-31 16:06:31 | INFO | train_inner | epoch 004:   6484 / 11384 loss=0.10267, wps=1170.9, ups=0.6, wpb=1939.9, bsz=128, num_updates=40400, lr=5.38667e-05, gnorm=23.005, clip=100, loss_scale=32, train_wall=83, gb_free=16.6, wall=76422
2025-10-31 16:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 16:07:51 | INFO | train_inner | epoch 004:   6535 / 11384 loss=0.100001, wps=1208.2, ups=0.63, wpb=1931.9, bsz=128, num_updates=40450, lr=5.39333e-05, gnorm=17.913, clip=100, loss_scale=16, train_wall=80, gb_free=11.7, wall=76502
2025-10-31 16:09:04 | INFO | train_inner | epoch 004:   6585 / 11384 loss=0.097645, wps=1378.6, ups=0.69, wpb=2000.6, bsz=128, num_updates=40500, lr=5.4e-05, gnorm=18.944, clip=100, loss_scale=16, train_wall=72, gb_free=12.8, wall=76575
2025-10-31 16:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 16:10:27 | INFO | train_inner | epoch 004:   6636 / 11384 loss=0.098377, wps=1169.2, ups=0.6, wpb=1943.3, bsz=128, num_updates=40550, lr=5.40667e-05, gnorm=20.87, clip=100, loss_scale=8, train_wall=83, gb_free=15.3, wall=76658
2025-10-31 16:12:00 | INFO | train_inner | epoch 004:   6686 / 11384 loss=0.100627, wps=1059.5, ups=0.54, wpb=1965, bsz=128, num_updates=40600, lr=5.41333e-05, gnorm=19.936, clip=100, loss_scale=8, train_wall=92, gb_free=15.5, wall=76751
2025-10-31 16:13:03 | INFO | train_inner | epoch 004:   6736 / 11384 loss=0.106067, wps=1532.1, ups=0.79, wpb=1930.7, bsz=128, num_updates=40650, lr=5.42e-05, gnorm=18.307, clip=100, loss_scale=16, train_wall=63, gb_free=13.5, wall=76814
2025-10-31 16:14:31 | INFO | train_inner | epoch 004:   6786 / 11384 loss=0.097395, wps=1114.3, ups=0.57, wpb=1968.1, bsz=128, num_updates=40700, lr=5.42667e-05, gnorm=17.991, clip=100, loss_scale=16, train_wall=88, gb_free=15.9, wall=76902
2025-10-31 16:14:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 16:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-10-31 16:15:50 | INFO | train_inner | epoch 004:   6838 / 11384 loss=0.105079, wps=1264.1, ups=0.63, wpb=1991.6, bsz=128, num_updates=40750, lr=5.43333e-05, gnorm=17.437, clip=100, loss_scale=4, train_wall=78, gb_free=15.4, wall=76981
2025-10-31 16:17:17 | INFO | train_inner | epoch 004:   6888 / 11384 loss=0.094674, wps=1136.8, ups=0.57, wpb=1980.1, bsz=128, num_updates=40800, lr=5.44e-05, gnorm=16.335, clip=100, loss_scale=4, train_wall=87, gb_free=16.3, wall=77068
2025-10-31 16:18:33 | INFO | train_inner | epoch 004:   6938 / 11384 loss=0.088903, wps=1265, ups=0.66, wpb=1925.9, bsz=128, num_updates=40850, lr=5.44667e-05, gnorm=15.406, clip=100, loss_scale=4, train_wall=76, gb_free=14.6, wall=77144
2025-10-31 16:19:38 | INFO | train_inner | epoch 004:   6988 / 11384 loss=0.096901, wps=1481.2, ups=0.77, wpb=1928.9, bsz=128, num_updates=40900, lr=5.45333e-05, gnorm=19.219, clip=100, loss_scale=8, train_wall=65, gb_free=16, wall=77209
2025-10-31 16:21:11 | INFO | train_inner | epoch 004:   7038 / 11384 loss=0.107077, wps=1044.9, ups=0.54, wpb=1948.3, bsz=128, num_updates=40950, lr=5.46e-05, gnorm=19.667, clip=100, loss_scale=8, train_wall=93, gb_free=14.8, wall=77303
2025-10-31 16:22:47 | INFO | train_inner | epoch 004:   7088 / 11384 loss=0.105781, wps=1027.2, ups=0.52, wpb=1973.7, bsz=128, num_updates=41000, lr=5.46667e-05, gnorm=24.489, clip=100, loss_scale=16, train_wall=96, gb_free=15.6, wall=77399
2025-10-31 16:24:16 | INFO | train_inner | epoch 004:   7138 / 11384 loss=0.100726, wps=1111.6, ups=0.56, wpb=1969, bsz=128, num_updates=41050, lr=5.47333e-05, gnorm=19.574, clip=100, loss_scale=16, train_wall=82, gb_free=12.1, wall=77487
2025-10-31 16:25:48 | INFO | train_inner | epoch 004:   7188 / 11384 loss=0.10415, wps=1082.5, ups=0.54, wpb=1987.3, bsz=128, num_updates=41100, lr=5.48e-05, gnorm=20.008, clip=100, loss_scale=16, train_wall=92, gb_free=16.9, wall=77579
2025-10-31 16:26:48 | INFO | train_inner | epoch 004:   7238 / 11384 loss=0.100976, wps=1656.1, ups=0.84, wpb=1978.4, bsz=128, num_updates=41150, lr=5.48667e-05, gnorm=18.706, clip=100, loss_scale=32, train_wall=59, gb_free=16, wall=77639
2025-10-31 16:28:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 16:28:19 | INFO | train_inner | epoch 004:   7289 / 11384 loss=0.098028, wps=1080.1, ups=0.55, wpb=1971.5, bsz=128, num_updates=41200, lr=5.49333e-05, gnorm=17.036, clip=100, loss_scale=16, train_wall=91, gb_free=15.6, wall=77730
2025-10-31 16:29:48 | INFO | train_inner | epoch 004:   7339 / 11384 loss=0.106752, wps=1116.4, ups=0.56, wpb=1980.9, bsz=128, num_updates=41250, lr=5.5e-05, gnorm=20.326, clip=100, loss_scale=16, train_wall=88, gb_free=14.5, wall=77819
2025-10-31 16:30:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 16:30:46 | INFO | train_inner | epoch 004:   7390 / 11384 loss=0.107467, wps=1724.6, ups=0.86, wpb=2001, bsz=128, num_updates=41300, lr=5.50667e-05, gnorm=17.757, clip=100, loss_scale=8, train_wall=58, gb_free=9.4, wall=77877
2025-10-31 16:32:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-10-31 16:32:07 | INFO | train_inner | epoch 004:   7441 / 11384 loss=0.095291, wps=1212.8, ups=0.62, wpb=1970.8, bsz=128, num_updates=41350, lr=5.51333e-05, gnorm=17.994, clip=100, loss_scale=4, train_wall=81, gb_free=7.2, wall=77958
2025-10-31 16:33:33 | INFO | train_inner | epoch 004:   7491 / 11384 loss=0.100686, wps=1125, ups=0.58, wpb=1932.9, bsz=128, num_updates=41400, lr=5.52e-05, gnorm=17.621, clip=100, loss_scale=4, train_wall=86, gb_free=16.4, wall=78044
2025-10-31 16:34:40 | INFO | train_inner | epoch 004:   7541 / 11384 loss=0.114963, wps=1450.5, ups=0.75, wpb=1946.7, bsz=128, num_updates=41450, lr=5.52667e-05, gnorm=21.831, clip=100, loss_scale=4, train_wall=67, gb_free=15.3, wall=78111
2025-10-31 16:36:01 | INFO | train_inner | epoch 004:   7591 / 11384 loss=0.096877, wps=1219.3, ups=0.62, wpb=1959.2, bsz=128, num_updates=41500, lr=5.53333e-05, gnorm=18.542, clip=100, loss_scale=8, train_wall=80, gb_free=14.7, wall=78192
2025-10-31 16:37:00 | INFO | train_inner | epoch 004:   7641 / 11384 loss=0.089178, wps=1628, ups=0.84, wpb=1935.8, bsz=128, num_updates=41550, lr=5.54e-05, gnorm=15.574, clip=100, loss_scale=8, train_wall=59, gb_free=13.4, wall=78251
2025-10-31 16:38:29 | INFO | train_inner | epoch 004:   7691 / 11384 loss=0.097355, wps=1095.4, ups=0.56, wpb=1946.1, bsz=128, num_updates=41600, lr=5.54667e-05, gnorm=18.074, clip=100, loss_scale=8, train_wall=88, gb_free=16.9, wall=78340
2025-10-31 16:39:56 | INFO | train_inner | epoch 004:   7741 / 11384 loss=0.109371, wps=1125, ups=0.57, wpb=1957.9, bsz=128, num_updates=41650, lr=5.55333e-05, gnorm=26.548, clip=100, loss_scale=16, train_wall=87, gb_free=16.5, wall=78427
2025-10-31 16:41:24 | INFO | train_inner | epoch 004:   7791 / 11384 loss=0.100924, wps=1109.4, ups=0.56, wpb=1964.6, bsz=128, num_updates=41700, lr=5.56e-05, gnorm=18.942, clip=100, loss_scale=16, train_wall=88, gb_free=6.6, wall=78516
2025-10-31 16:42:39 | INFO | train_inner | epoch 004:   7841 / 11384 loss=0.100376, wps=1356.7, ups=0.67, wpb=2015.1, bsz=128, num_updates=41750, lr=5.56667e-05, gnorm=17.376, clip=100, loss_scale=32, train_wall=74, gb_free=15.6, wall=78590
2025-10-31 16:44:09 | INFO | train_inner | epoch 004:   7891 / 11384 loss=0.094876, wps=1095.6, ups=0.56, wpb=1973.6, bsz=128, num_updates=41800, lr=5.57333e-05, gnorm=18.947, clip=100, loss_scale=32, train_wall=90, gb_free=14.7, wall=78680
2025-10-31 16:45:29 | INFO | train_inner | epoch 004:   7941 / 11384 loss=0.089521, wps=1218.2, ups=0.63, wpb=1942.9, bsz=128, num_updates=41850, lr=5.58e-05, gnorm=17.765, clip=100, loss_scale=32, train_wall=76, gb_free=16.1, wall=78760
2025-10-31 16:45:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 16:46:49 | INFO | train_inner | epoch 004:   7992 / 11384 loss=0.094091, wps=1201.5, ups=0.62, wpb=1933.9, bsz=128, num_updates=41900, lr=5.58667e-05, gnorm=17.614, clip=100, loss_scale=32, train_wall=80, gb_free=10.3, wall=78841
2025-10-31 16:48:13 | INFO | train_inner | epoch 004:   8042 / 11384 loss=0.099111, wps=1164.5, ups=0.6, wpb=1942.5, bsz=128, num_updates=41950, lr=5.59333e-05, gnorm=18.174, clip=100, loss_scale=32, train_wall=82, gb_free=15.5, wall=78924
2025-10-31 16:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 16:49:26 | INFO | train_inner | epoch 004:   8093 / 11384 loss=0.089583, wps=1339.9, ups=0.69, wpb=1947.6, bsz=128, num_updates=42000, lr=5.6e-05, gnorm=19.703, clip=100, loss_scale=32, train_wall=72, gb_free=16.1, wall=78997
2025-10-31 16:49:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 16:50:52 | INFO | train_inner | epoch 004:   8144 / 11384 loss=0.101279, wps=1162.4, ups=0.58, wpb=2007.1, bsz=128, num_updates=42050, lr=5.60667e-05, gnorm=20.323, clip=100, loss_scale=16, train_wall=86, gb_free=11.5, wall=79083
2025-10-31 16:52:03 | INFO | train_inner | epoch 004:   8194 / 11384 loss=0.093507, wps=1387.2, ups=0.71, wpb=1952.2, bsz=128, num_updates=42100, lr=5.61333e-05, gnorm=16.886, clip=100, loss_scale=16, train_wall=70, gb_free=15.2, wall=79154
2025-10-31 16:53:08 | INFO | train_inner | epoch 004:   8244 / 11384 loss=0.089288, wps=1480.7, ups=0.76, wpb=1948.9, bsz=128, num_updates=42150, lr=5.62e-05, gnorm=14.048, clip=100, loss_scale=32, train_wall=66, gb_free=12.9, wall=79220
2025-10-31 16:54:35 | INFO | train_inner | epoch 004:   8294 / 11384 loss=0.091092, wps=1112.1, ups=0.58, wpb=1933.2, bsz=128, num_updates=42200, lr=5.62667e-05, gnorm=16.657, clip=100, loss_scale=32, train_wall=87, gb_free=9.6, wall=79307
2025-10-31 16:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 16:55:54 | INFO | train_inner | epoch 004:   8345 / 11384 loss=0.092253, wps=1276.3, ups=0.64, wpb=1997.1, bsz=128, num_updates=42250, lr=5.63333e-05, gnorm=15.965, clip=100, loss_scale=16, train_wall=78, gb_free=13.9, wall=79385
2025-10-31 16:55:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 16:57:26 | INFO | train_inner | epoch 004:   8396 / 11384 loss=0.091676, wps=1057.2, ups=0.54, wpb=1944.9, bsz=127.9, num_updates=42300, lr=5.64e-05, gnorm=18.137, clip=100, loss_scale=8, train_wall=92, gb_free=15.6, wall=79477
2025-10-31 16:58:45 | INFO | train_inner | epoch 004:   8446 / 11384 loss=0.094119, wps=1239, ups=0.63, wpb=1951.3, bsz=128, num_updates=42350, lr=5.64667e-05, gnorm=14.306, clip=100, loss_scale=8, train_wall=78, gb_free=16.1, wall=79556
2025-10-31 17:00:22 | INFO | train_inner | epoch 004:   8496 / 11384 loss=0.085507, wps=1014, ups=0.51, wpb=1974.1, bsz=128, num_updates=42400, lr=5.65333e-05, gnorm=12.907, clip=100, loss_scale=16, train_wall=97, gb_free=15.6, wall=79653
2025-10-31 17:01:37 | INFO | train_inner | epoch 004:   8546 / 11384 loss=0.090224, wps=1319.5, ups=0.67, wpb=1967.7, bsz=128, num_updates=42450, lr=5.66e-05, gnorm=17.035, clip=100, loss_scale=16, train_wall=74, gb_free=15.4, wall=79728
2025-10-31 17:02:50 | INFO | train_inner | epoch 004:   8596 / 11384 loss=0.103384, wps=1339.5, ups=0.68, wpb=1959.1, bsz=128, num_updates=42500, lr=5.66667e-05, gnorm=17.678, clip=100, loss_scale=16, train_wall=73, gb_free=7.4, wall=79801
2025-10-31 17:04:37 | INFO | train_inner | epoch 004:   8646 / 11384 loss=0.093918, wps=911.7, ups=0.46, wpb=1962, bsz=128, num_updates=42550, lr=5.67333e-05, gnorm=18.756, clip=100, loss_scale=32, train_wall=107, gb_free=15.8, wall=79909
2025-10-31 17:04:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:06:02 | INFO | train_inner | epoch 004:   8697 / 11384 loss=0.10159, wps=1151.2, ups=0.59, wpb=1950.3, bsz=128, num_updates=42600, lr=5.68e-05, gnorm=16.168, clip=100, loss_scale=16, train_wall=84, gb_free=10, wall=79994
2025-10-31 17:07:31 | INFO | train_inner | epoch 004:   8747 / 11384 loss=0.107948, wps=1093.6, ups=0.57, wpb=1933.5, bsz=128, num_updates=42650, lr=5.68667e-05, gnorm=19.195, clip=100, loss_scale=16, train_wall=88, gb_free=16.9, wall=80082
2025-10-31 17:08:23 | INFO | train_inner | epoch 004:   8797 / 11384 loss=0.094548, wps=1855.1, ups=0.95, wpb=1953.8, bsz=128, num_updates=42700, lr=5.69333e-05, gnorm=17.924, clip=100, loss_scale=32, train_wall=52, gb_free=16.7, wall=80135
2025-10-31 17:09:47 | INFO | train_inner | epoch 004:   8847 / 11384 loss=0.097238, wps=1198.5, ups=0.6, wpb=1993.8, bsz=128, num_updates=42750, lr=5.7e-05, gnorm=17.619, clip=100, loss_scale=32, train_wall=83, gb_free=14.6, wall=80218
2025-10-31 17:10:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:10:56 | INFO | train_inner | epoch 004:   8898 / 11384 loss=0.094976, wps=1407.4, ups=0.72, wpb=1945, bsz=128, num_updates=42800, lr=5.70667e-05, gnorm=17.514, clip=100, loss_scale=16, train_wall=69, gb_free=16, wall=80287
2025-10-31 17:12:25 | INFO | train_inner | epoch 004:   8948 / 11384 loss=0.094936, wps=1114.2, ups=0.56, wpb=1979.2, bsz=128, num_updates=42850, lr=5.71333e-05, gnorm=15.728, clip=100, loss_scale=16, train_wall=89, gb_free=14.7, wall=80376
2025-10-31 17:13:31 | INFO | train_inner | epoch 004:   8998 / 11384 loss=0.098066, wps=1473.2, ups=0.76, wpb=1944.3, bsz=128, num_updates=42900, lr=5.72e-05, gnorm=18.919, clip=100, loss_scale=32, train_wall=66, gb_free=15.6, wall=80442
2025-10-31 17:14:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:14:57 | INFO | train_inner | epoch 004:   9049 / 11384 loss=0.10284, wps=1120.5, ups=0.58, wpb=1932.3, bsz=128, num_updates=42950, lr=5.72667e-05, gnorm=18.903, clip=100, loss_scale=16, train_wall=86, gb_free=15.1, wall=80528
2025-10-31 17:16:16 | INFO | train_inner | epoch 004:   9099 / 11384 loss=0.097849, wps=1227, ups=0.63, wpb=1946.8, bsz=128, num_updates=43000, lr=5.73333e-05, gnorm=18.476, clip=100, loss_scale=16, train_wall=79, gb_free=16.9, wall=80608
2025-10-31 17:17:47 | INFO | train_inner | epoch 004:   9149 / 11384 loss=0.100232, wps=1079.3, ups=0.55, wpb=1952.8, bsz=128, num_updates=43050, lr=5.74e-05, gnorm=16.675, clip=100, loss_scale=16, train_wall=90, gb_free=15.3, wall=80698
2025-10-31 17:18:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:19:06 | INFO | train_inner | epoch 004:   9200 / 11384 loss=0.09425, wps=1249, ups=0.63, wpb=1983.1, bsz=128, num_updates=43100, lr=5.74667e-05, gnorm=16.471, clip=100, loss_scale=16, train_wall=79, gb_free=12.7, wall=80778
2025-10-31 17:20:34 | INFO | train_inner | epoch 004:   9250 / 11384 loss=0.093845, wps=1117.8, ups=0.57, wpb=1960.9, bsz=128, num_updates=43150, lr=5.75333e-05, gnorm=20.527, clip=100, loss_scale=16, train_wall=87, gb_free=17, wall=80866
2025-10-31 17:22:05 | INFO | train_inner | epoch 004:   9300 / 11384 loss=0.105364, wps=1073.3, ups=0.55, wpb=1954.8, bsz=128, num_updates=43200, lr=5.76e-05, gnorm=18.351, clip=100, loss_scale=16, train_wall=91, gb_free=15.5, wall=80957
2025-10-31 17:22:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:23:08 | INFO | train_inner | epoch 004:   9351 / 11384 loss=0.097925, wps=1561.2, ups=0.8, wpb=1960.5, bsz=128, num_updates=43250, lr=5.76667e-05, gnorm=15.449, clip=100, loss_scale=16, train_wall=63, gb_free=15.9, wall=81019
2025-10-31 17:24:36 | INFO | train_inner | epoch 004:   9401 / 11384 loss=0.096404, wps=1125, ups=0.57, wpb=1970.5, bsz=128, num_updates=43300, lr=5.77333e-05, gnorm=17.47, clip=100, loss_scale=16, train_wall=87, gb_free=14.9, wall=81107
2025-10-31 17:25:43 | INFO | train_inner | epoch 004:   9451 / 11384 loss=0.099773, wps=1499.8, ups=0.74, wpb=2014.8, bsz=128, num_updates=43350, lr=5.78e-05, gnorm=18.705, clip=100, loss_scale=16, train_wall=67, gb_free=4.7, wall=81174
2025-10-31 17:27:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:27:16 | INFO | train_inner | epoch 004:   9502 / 11384 loss=0.08683, wps=1079.6, ups=0.54, wpb=2004.2, bsz=128, num_updates=43400, lr=5.78667e-05, gnorm=15.766, clip=100, loss_scale=16, train_wall=93, gb_free=16.6, wall=81267
2025-10-31 17:28:13 | INFO | train_inner | epoch 004:   9552 / 11384 loss=0.093207, wps=1706.6, ups=0.88, wpb=1948.4, bsz=128, num_updates=43450, lr=5.79333e-05, gnorm=16.491, clip=100, loss_scale=16, train_wall=57, gb_free=15.5, wall=81324
2025-10-31 17:29:47 | INFO | train_inner | epoch 004:   9602 / 11384 loss=0.088371, wps=1038.4, ups=0.53, wpb=1957.8, bsz=128, num_updates=43500, lr=5.8e-05, gnorm=16.114, clip=100, loss_scale=16, train_wall=89, gb_free=17.3, wall=81418
2025-10-31 17:30:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:31:15 | INFO | train_inner | epoch 004:   9653 / 11384 loss=0.09224, wps=1121.8, ups=0.57, wpb=1964.8, bsz=128, num_updates=43550, lr=5.80667e-05, gnorm=18.246, clip=100, loss_scale=16, train_wall=87, gb_free=16.7, wall=81506
2025-10-31 17:32:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 17:32:13 | INFO | train_inner | epoch 004:   9704 / 11384 loss=0.083502, wps=1684.9, ups=0.87, wpb=1944.5, bsz=128, num_updates=43600, lr=5.81333e-05, gnorm=15.551, clip=100, loss_scale=8, train_wall=57, gb_free=16.7, wall=81564
2025-10-31 17:33:52 | INFO | train_inner | epoch 004:   9754 / 11384 loss=0.090933, wps=969.9, ups=0.5, wpb=1925.1, bsz=128, num_updates=43650, lr=5.82e-05, gnorm=17.402, clip=100, loss_scale=8, train_wall=99, gb_free=13.3, wall=81663
2025-10-31 17:34:54 | INFO | train_inner | epoch 004:   9804 / 11384 loss=0.086685, wps=1588.8, ups=0.81, wpb=1969.6, bsz=128, num_updates=43700, lr=5.82667e-05, gnorm=24.363, clip=100, loss_scale=8, train_wall=62, gb_free=15.8, wall=81725
2025-10-31 17:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 17:36:18 | INFO | train_inner | epoch 004:   9855 / 11384 loss=0.089479, wps=1171.5, ups=0.6, wpb=1961.2, bsz=128, num_updates=43750, lr=5.83333e-05, gnorm=13.865, clip=100, loss_scale=8, train_wall=81, gb_free=15.3, wall=81810
2025-10-31 17:37:40 | INFO | train_inner | epoch 004:   9905 / 11384 loss=0.082439, wps=1217, ups=0.61, wpb=1992.7, bsz=128, num_updates=43800, lr=5.84e-05, gnorm=13.536, clip=100, loss_scale=8, train_wall=82, gb_free=13.4, wall=81892
2025-10-31 17:39:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2025-10-31 17:39:41 | INFO | train_inner | epoch 004:   9956 / 11384 loss=0.097265, wps=804.3, ups=0.42, wpb=1936.3, bsz=128, num_updates=43850, lr=5.84667e-05, gnorm=18.81, clip=100, loss_scale=4, train_wall=120, gb_free=11.8, wall=82012
2025-10-31 17:40:43 | INFO | train_inner | epoch 004:  10006 / 11384 loss=0.089385, wps=1571.8, ups=0.8, wpb=1962.2, bsz=128, num_updates=43900, lr=5.85333e-05, gnorm=21.273, clip=100, loss_scale=4, train_wall=62, gb_free=15.8, wall=82074
2025-10-31 17:42:22 | INFO | train_inner | epoch 004:  10056 / 11384 loss=0.087368, wps=982.1, ups=0.51, wpb=1941.2, bsz=128, num_updates=43950, lr=5.86e-05, gnorm=15.515, clip=100, loss_scale=4, train_wall=99, gb_free=12.8, wall=82173
2025-10-31 17:43:33 | INFO | train_inner | epoch 004:  10106 / 11384 loss=0.091871, wps=1365.6, ups=0.7, wpb=1942.4, bsz=128, num_updates=44000, lr=5.86667e-05, gnorm=16.365, clip=100, loss_scale=8, train_wall=71, gb_free=15.1, wall=82244
2025-10-31 17:44:53 | INFO | train_inner | epoch 004:  10156 / 11384 loss=0.098755, wps=1253.5, ups=0.63, wpb=2001.4, bsz=128, num_updates=44050, lr=5.87333e-05, gnorm=16.662, clip=100, loss_scale=8, train_wall=80, gb_free=15.2, wall=82324
2025-10-31 17:46:18 | INFO | train_inner | epoch 004:  10206 / 11384 loss=0.101179, wps=1138.3, ups=0.59, wpb=1923.3, bsz=128, num_updates=44100, lr=5.88e-05, gnorm=19.4, clip=100, loss_scale=16, train_wall=84, gb_free=16.5, wall=82409
2025-10-31 17:47:31 | INFO | train_inner | epoch 004:  10256 / 11384 loss=0.101832, wps=1315.1, ups=0.68, wpb=1935, bsz=128, num_updates=44150, lr=5.88667e-05, gnorm=19.484, clip=100, loss_scale=16, train_wall=73, gb_free=15.7, wall=82483
2025-10-31 17:48:52 | INFO | train_inner | epoch 004:  10306 / 11384 loss=0.096628, wps=1221.9, ups=0.62, wpb=1977.8, bsz=128, num_updates=44200, lr=5.89333e-05, gnorm=17.836, clip=100, loss_scale=16, train_wall=81, gb_free=16.4, wall=82564
2025-10-31 17:49:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 17:50:07 | INFO | train_inner | epoch 004:  10357 / 11384 loss=0.094391, wps=1309.1, ups=0.67, wpb=1961.1, bsz=128, num_updates=44250, lr=5.9e-05, gnorm=15.695, clip=100, loss_scale=16, train_wall=75, gb_free=12.8, wall=82638
2025-10-31 17:51:51 | INFO | train_inner | epoch 004:  10407 / 11384 loss=0.093666, wps=939.2, ups=0.48, wpb=1955.6, bsz=128, num_updates=44300, lr=5.90667e-05, gnorm=19.759, clip=100, loss_scale=16, train_wall=104, gb_free=14.2, wall=82743
2025-10-31 17:52:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 17:52:50 | INFO | train_inner | epoch 004:  10458 / 11384 loss=0.089487, wps=1690.6, ups=0.86, wpb=1971.6, bsz=128, num_updates=44350, lr=5.91333e-05, gnorm=23.98, clip=100, loss_scale=8, train_wall=58, gb_free=6.4, wall=82801
2025-10-31 17:54:36 | INFO | train_inner | epoch 004:  10508 / 11384 loss=0.08967, wps=905.1, ups=0.47, wpb=1918, bsz=128, num_updates=44400, lr=5.92e-05, gnorm=16.04, clip=100, loss_scale=8, train_wall=106, gb_free=15.5, wall=82907
2025-10-31 17:55:50 | INFO | train_inner | epoch 004:  10558 / 11384 loss=0.093096, wps=1339.3, ups=0.67, wpb=1989.2, bsz=128, num_updates=44450, lr=5.92667e-05, gnorm=21.757, clip=100, loss_scale=16, train_wall=74, gb_free=13.2, wall=82981
2025-10-31 17:57:15 | INFO | train_inner | epoch 004:  10608 / 11384 loss=0.097861, wps=1154.6, ups=0.59, wpb=1969.6, bsz=128, num_updates=44500, lr=5.93333e-05, gnorm=16.247, clip=100, loss_scale=16, train_wall=85, gb_free=16.5, wall=83066
2025-10-31 17:58:43 | INFO | train_inner | epoch 004:  10658 / 11384 loss=0.094848, wps=1129.3, ups=0.57, wpb=1975.3, bsz=128, num_updates=44550, lr=5.94e-05, gnorm=19.294, clip=100, loss_scale=16, train_wall=87, gb_free=17, wall=83154
2025-10-31 18:00:06 | INFO | train_inner | epoch 004:  10708 / 11384 loss=0.099721, wps=1157.2, ups=0.6, wpb=1928.1, bsz=128, num_updates=44600, lr=5.94667e-05, gnorm=20.167, clip=100, loss_scale=32, train_wall=83, gb_free=17, wall=83238
2025-10-31 18:01:34 | INFO | train_inner | epoch 004:  10758 / 11384 loss=0.10198, wps=1122.8, ups=0.57, wpb=1969.6, bsz=128, num_updates=44650, lr=5.95333e-05, gnorm=17.077, clip=100, loss_scale=32, train_wall=87, gb_free=11.6, wall=83325
2025-10-31 18:02:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 18:02:45 | INFO | train_inner | epoch 004:  10809 / 11384 loss=0.107233, wps=1351, ups=0.7, wpb=1917.9, bsz=128, num_updates=44700, lr=5.96e-05, gnorm=13.532, clip=100, loss_scale=16, train_wall=71, gb_free=15.2, wall=83396
2025-10-31 18:04:08 | INFO | train_inner | epoch 004:  10859 / 11384 loss=0.098131, wps=1187.1, ups=0.61, wpb=1960.4, bsz=128, num_updates=44750, lr=5.96667e-05, gnorm=16.683, clip=100, loss_scale=16, train_wall=82, gb_free=13.8, wall=83479
2025-10-31 18:05:33 | INFO | train_inner | epoch 004:  10909 / 11384 loss=0.098329, wps=1131.3, ups=0.59, wpb=1923.6, bsz=128, num_updates=44800, lr=5.97333e-05, gnorm=14.976, clip=100, loss_scale=16, train_wall=85, gb_free=4.8, wall=83564
2025-10-31 18:06:55 | INFO | train_inner | epoch 004:  10959 / 11384 loss=0.094583, wps=1157.5, ups=0.61, wpb=1910.1, bsz=128, num_updates=44850, lr=5.98e-05, gnorm=15.616, clip=100, loss_scale=32, train_wall=82, gb_free=15.9, wall=83646
2025-10-31 18:08:11 | INFO | train_inner | epoch 004:  11009 / 11384 loss=0.087165, wps=1315.6, ups=0.66, wpb=2000.3, bsz=128, num_updates=44900, lr=5.98667e-05, gnorm=16.695, clip=100, loss_scale=32, train_wall=76, gb_free=14.2, wall=83723
2025-10-31 18:09:34 | INFO | train_inner | epoch 004:  11059 / 11384 loss=0.088641, wps=1176.4, ups=0.6, wpb=1949.5, bsz=128, num_updates=44950, lr=5.99333e-05, gnorm=17.417, clip=100, loss_scale=64, train_wall=83, gb_free=16.7, wall=83806
2025-10-31 18:11:02 | INFO | train_inner | epoch 004:  11109 / 11384 loss=0.092715, wps=1090, ups=0.57, wpb=1918.9, bsz=128, num_updates=45000, lr=6e-05, gnorm=13.289, clip=100, loss_scale=64, train_wall=88, gb_free=9.5, wall=83894
2025-10-31 18:11:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 18:12:10 | INFO | train_inner | epoch 004:  11160 / 11384 loss=0.086147, wps=1465.2, ups=0.74, wpb=1976.6, bsz=128, num_updates=45050, lr=6.00667e-05, gnorm=13.517, clip=100, loss_scale=32, train_wall=67, gb_free=6, wall=83961
2025-10-31 18:13:33 | INFO | train_inner | epoch 004:  11210 / 11384 loss=0.085991, wps=1174.2, ups=0.6, wpb=1947.2, bsz=128, num_updates=45100, lr=6.01333e-05, gnorm=14.202, clip=100, loss_scale=32, train_wall=83, gb_free=16.7, wall=84044
2025-10-31 18:14:55 | INFO | train_inner | epoch 004:  11260 / 11384 loss=0.086177, wps=1192.7, ups=0.6, wpb=1972.5, bsz=128, num_updates=45150, lr=6.02e-05, gnorm=18.648, clip=100, loss_scale=32, train_wall=82, gb_free=16, wall=84127
2025-10-31 18:16:28 | INFO | train_inner | epoch 004:  11310 / 11384 loss=0.085711, wps=1057.2, ups=0.54, wpb=1955.4, bsz=128, num_updates=45200, lr=6.02667e-05, gnorm=13.965, clip=100, loss_scale=64, train_wall=92, gb_free=8.6, wall=84219
2025-10-31 18:16:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 18:17:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 18:17:58 | INFO | train_inner | epoch 004:  11362 / 11384 loss=0.084523, wps=1101.7, ups=0.56, wpb=1976.3, bsz=128, num_updates=45250, lr=6.03333e-05, gnorm=16.351, clip=100, loss_scale=16, train_wall=89, gb_free=16.5, wall=84309
2025-10-31 18:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-10-31 18:32:44 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.094903 | wps 1423.2 | wpb 1948.3 | bsz 127.9 | num_updates 45272 | best_loss 0.094903
2025-10-31 18:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 45272 updates
2025-10-31 18:32:44 | INFO | fairseq.trainer | Saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint4.pt
2025-10-31 18:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /data/run01/scw6f3q/zncao/affincraft-nn/affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint4.pt
2025-10-31 18:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./affincraft_pretrain_ckpts_lmdb_multi_gpu/checkpoint4.pt (epoch 4 @ 45272 updates, score 0.094903) (writing took 259.55536158697214 seconds)
2025-10-31 18:37:04 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2025-10-31 18:37:04 | INFO | train | epoch 004 | loss 0.102025 | wps 1005.8 | ups 0.51 | wpb 1959.3 | bsz 128 | num_updates 45272 | lr 6.03627e-05 | gnorm 19.191 | clip 100 | loss_scale 16 | train_wall 20154 | gb_free 16.2 | wall 85456
2025-10-31 18:37:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11384
2025-10-31 18:37:08 | INFO | fairseq.trainer | begin training epoch 5
2025-10-31 18:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2025-10-31 18:39:03 | INFO | train_inner | epoch 005:     28 / 11384 loss=0.099027, wps=76.9, ups=0.04, wpb=1946, bsz=127.7, num_updates=45300, lr=6.04e-05, gnorm=18.362, clip=100, loss_scale=16, train_wall=127, gb_free=17.3, wall=85574
2025-10-31 18:40:57 | INFO | train_inner | epoch 005:     78 / 11384 loss=0.095282, wps=858.2, ups=0.44, wpb=1954.1, bsz=128, num_updates=45350, lr=6.04667e-05, gnorm=17.402, clip=100, loss_scale=16, train_wall=114, gb_free=13.7, wall=85688
2025-10-31 18:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 18:41:49 | INFO | train_inner | epoch 005:    129 / 11384 loss=0.086309, wps=1861.5, ups=0.95, wpb=1957.7, bsz=128, num_updates=45400, lr=6.05333e-05, gnorm=13.388, clip=100, loss_scale=16, train_wall=52, gb_free=10.5, wall=85741
2025-10-31 18:43:13 | INFO | train_inner | epoch 005:    179 / 11384 loss=0.083256, wps=1141.2, ups=0.6, wpb=1912.7, bsz=128, num_updates=45450, lr=6.06e-05, gnorm=14.673, clip=100, loss_scale=16, train_wall=84, gb_free=10.7, wall=85824
2025-10-31 18:45:13 | INFO | train_inner | epoch 005:    229 / 11384 loss=0.079803, wps=819, ups=0.42, wpb=1963.6, bsz=128, num_updates=45500, lr=6.06667e-05, gnorm=13.865, clip=100, loss_scale=16, train_wall=120, gb_free=12.7, wall=85944
2025-10-31 18:46:02 | INFO | train_inner | epoch 005:    279 / 11384 loss=0.096966, wps=1987.3, ups=1.02, wpb=1950.5, bsz=128, num_updates=45550, lr=6.07333e-05, gnorm=16.779, clip=100, loss_scale=32, train_wall=49, gb_free=16.3, wall=85994
2025-10-31 18:46:55 | INFO | train_inner | epoch 005:    329 / 11384 loss=0.086673, wps=1869.9, ups=0.95, wpb=1975.5, bsz=128, num_updates=45600, lr=6.08e-05, gnorm=15.281, clip=100, loss_scale=32, train_wall=53, gb_free=17, wall=86046
2025-10-31 18:48:50 | INFO | train_inner | epoch 005:    379 / 11384 loss=0.092012, wps=855.9, ups=0.43, wpb=1970.5, bsz=128, num_updates=45650, lr=6.08667e-05, gnorm=17.847, clip=100, loss_scale=32, train_wall=115, gb_free=14.5, wall=86162
2025-10-31 18:50:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 18:50:46 | INFO | train_inner | epoch 005:    430 / 11384 loss=0.08686, wps=859.4, ups=0.43, wpb=1981.8, bsz=128, num_updates=45700, lr=6.09333e-05, gnorm=13.463, clip=100, loss_scale=32, train_wall=115, gb_free=13.2, wall=86277
2025-10-31 18:52:46 | INFO | train_inner | epoch 005:    480 / 11384 loss=0.080355, wps=807.7, ups=0.42, wpb=1945.3, bsz=128, num_updates=45750, lr=6.1e-05, gnorm=12.91, clip=100, loss_scale=32, train_wall=120, gb_free=15.4, wall=86397
2025-10-31 18:53:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 18:54:40 | INFO | train_inner | epoch 005:    531 / 11384 loss=0.09204, wps=868.1, ups=0.44, wpb=1981.4, bsz=128, num_updates=45800, lr=6.10667e-05, gnorm=25.034, clip=100, loss_scale=16, train_wall=62, gb_free=17.3, wall=86511
2025-10-31 18:57:01 | INFO | train_inner | epoch 005:    581 / 11384 loss=0.088813, wps=688.3, ups=0.35, wpb=1943.6, bsz=128, num_updates=45850, lr=6.11333e-05, gnorm=17.2, clip=100, loss_scale=16, train_wall=141, gb_free=16, wall=86653
2025-10-31 18:58:48 | INFO | train_inner | epoch 005:    631 / 11384 loss=0.094165, wps=923.3, ups=0.47, wpb=1966, bsz=128, num_updates=45900, lr=6.12e-05, gnorm=16.963, clip=100, loss_scale=16, train_wall=106, gb_free=16.2, wall=86759
2025-10-31 19:00:25 | INFO | train_inner | epoch 005:    681 / 11384 loss=0.086091, wps=1031.2, ups=0.52, wpb=2002.3, bsz=128, num_updates=45950, lr=6.12667e-05, gnorm=15.141, clip=100, loss_scale=32, train_wall=55, gb_free=15.6, wall=86856
2025-10-31 19:02:41 | INFO | train_inner | epoch 005:    731 / 11384 loss=0.080794, wps=725.7, ups=0.37, wpb=1975, bsz=128, num_updates=46000, lr=6.13333e-05, gnorm=15.016, clip=100, loss_scale=32, train_wall=136, gb_free=13.5, wall=86992
2025-10-31 19:04:28 | INFO | train_inner | epoch 005:    781 / 11384 loss=0.088224, wps=895.9, ups=0.46, wpb=1927.4, bsz=128, num_updates=46050, lr=6.14e-05, gnorm=13.321, clip=100, loss_scale=64, train_wall=107, gb_free=15.9, wall=87100
2025-10-31 19:05:19 | INFO | train_inner | epoch 005:    831 / 11384 loss=0.08741, wps=1901.1, ups=0.98, wpb=1934.3, bsz=128, num_updates=46100, lr=6.14667e-05, gnorm=11.886, clip=96, loss_scale=64, train_wall=51, gb_free=13.9, wall=87151
2025-10-31 19:06:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2025-10-31 19:07:34 | INFO | train_inner | epoch 005:    882 / 11384 loss=0.082721, wps=729.1, ups=0.37, wpb=1963.5, bsz=128, num_updates=46150, lr=6.15333e-05, gnorm=12.875, clip=100, loss_scale=32, train_wall=134, gb_free=16.5, wall=87285
2025-10-31 19:09:35 | INFO | train_inner | epoch 005:    932 / 11384 loss=0.08638, wps=809.3, ups=0.42, wpb=1946.3, bsz=128, num_updates=46200, lr=6.16e-05, gnorm=13.726, clip=98, loss_scale=32, train_wall=62, gb_free=17, wall=87406
2025-10-31 19:11:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 19:11:48 | INFO | train_inner | epoch 005:    983 / 11384 loss=0.089532, wps=729.2, ups=0.38, wpb=1940.1, bsz=128, num_updates=46250, lr=6.16667e-05, gnorm=15.47, clip=100, loss_scale=16, train_wall=119, gb_free=16.5, wall=87539
2025-10-31 19:13:28 | INFO | train_inner | epoch 005:   1033 / 11384 loss=0.08811, wps=976.9, ups=0.5, wpb=1962.3, bsz=128, num_updates=46300, lr=6.17333e-05, gnorm=15.555, clip=100, loss_scale=16, train_wall=70, gb_free=13.7, wall=87640
2025-10-31 19:16:02 | INFO | train_inner | epoch 005:   1083 / 11384 loss=0.088003, wps=629.1, ups=0.32, wpb=1938.4, bsz=128, num_updates=46350, lr=6.18e-05, gnorm=13.936, clip=100, loss_scale=32, train_wall=65, gb_free=15, wall=87794
2025-10-31 19:16:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2025-10-31 19:18:29 | INFO | train_inner | epoch 005:   1134 / 11384 loss=0.081436, wps=661.8, ups=0.34, wpb=1937.2, bsz=128, num_updates=46400, lr=6.18667e-05, gnorm=19.179, clip=100, loss_scale=16, train_wall=146, gb_free=16, wall=87940
2025-10-31 19:19:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2025-10-31 19:20:15 | INFO | train_inner | epoch 005:   1185 / 11384 loss=0.08219, wps=925.1, ups=0.47, wpb=1962.5, bsz=128, num_updates=46450, lr=6.19333e-05, gnorm=13.458, clip=100, loss_scale=8, train_wall=74, gb_free=13.8, wall=88046
2025-10-31 19:22:12 | INFO | train_inner | epoch 005:   1235 / 11384 loss=0.08179, wps=834, ups=0.43, wpb=1948.6, bsz=127.9, num_updates=46500, lr=6.2e-05, gnorm=13.196, clip=100, loss_scale=8, train_wall=117, gb_free=8.2, wall=88163
2025-10-31 19:24:26 | INFO | train_inner | epoch 005:   1285 / 11384 loss=0.094105, wps=724.8, ups=0.37, wpb=1940.7, bsz=128, num_updates=46550, lr=6.20667e-05, gnorm=14.075, clip=100, loss_scale=8, train_wall=85, gb_free=17.4, wall=88297
2025-10-31 19:26:08 | INFO | train_inner | epoch 005:   1335 / 11384 loss=0.085012, wps=949.7, ups=0.49, wpb=1954.2, bsz=128, num_updates=46600, lr=6.21333e-05, gnorm=18.625, clip=100, loss_scale=16, train_wall=103, gb_free=13.4, wall=88400
2025-10-31 19:27:42 | INFO | train_inner | epoch 005:   1385 / 11384 loss=0.083639, wps=1050, ups=0.54, wpb=1954.2, bsz=128, num_updates=46650, lr=6.22e-05, gnorm=13.17, clip=100, loss_scale=16, train_wall=93, gb_free=16.7, wall=88493
2025-10-31 19:30:25 | INFO | train_inner | epoch 005:   1435 / 11384 loss=0.085391, wps=604.5, ups=0.31, wpb=1977.4, bsz=128, num_updates=46700, lr=6.22667e-05, gnorm=13.689, clip=100, loss_scale=32, train_wall=163, gb_free=16, wall=88656
2025-10-31 19:31:17 | INFO | train_inner | epoch 005:   1485 / 11384 loss=0.088943, wps=1855.2, ups=0.96, wpb=1924, bsz=128, num_updates=46750, lr=6.23333e-05, gnorm=16.115, clip=98, loss_scale=32, train_wall=52, gb_free=10.9, wall=88708
2025-10-31 19:34:45 | INFO | train_inner | epoch 005:   1535 / 11384 loss=0.083704, wps=468.4, ups=0.24, wpb=1952.7, bsz=128, num_updates=46800, lr=6.24e-05, gnorm=14.689, clip=100, loss_scale=32, train_wall=59, gb_free=11.4, wall=88917
2025-10-31 19:36:48 | INFO | train_inner | epoch 005:   1585 / 11384 loss=0.083623, wps=797.8, ups=0.41, wpb=1954.5, bsz=128, num_updates=46850, lr=6.24667e-05, gnorm=13.862, clip=98, loss_scale=64, train_wall=89, gb_free=16.7, wall=89039
2025-10-31 19:36:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
==========================================
 ‚úÖ ‰ªªÂä°ÂÆåÊàê‰∫é: Fri Oct 31 19:41:48 CST 2025
==========================================
