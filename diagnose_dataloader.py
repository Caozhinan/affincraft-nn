#!/usr/bin/env python3  
"""  
DataLoader Â¥©Ê∫ÉËØäÊñ≠ËÑöÊú¨ - Áî®‰∫é AffinCraft LMDB Êï∞ÊçÆÈõÜ  
"""  
import os  
import sys  
import traceback  
import torch  
from torch.utils.data import DataLoader  
import psutil  
import pickle  
import lmdb  
  
# Ê≠£Á°ÆËÆæÁΩÆ Python Ë∑ØÂæÑ  
GRAPHORMER_PATH = "/data/run01/scw6f3q/zncao/affincraft-nn/graphormer"  
if GRAPHORMER_PATH not in sys.path:  
    sys.path.insert(0, GRAPHORMER_PATH)  
  
# Áõ¥Êé•ÂØºÂÖ•,‰∏çËß¶ÂèëÁõ∏ÂØπÂØºÂÖ•  
from data.affincraft_dataset import LMDBAffinCraftDataset  
  
def shm_status():  
    """ÊâìÂç∞ /dev/shm ‰∏éÁ≥ªÁªüÂÜÖÂ≠ò‰ΩøÁî®ÊÉÖÂÜµ"""  
    os.system("echo '\n[SHM STATUS]' && df -h /dev/shm 2>/dev/null || echo '/dev/shm not available'")  
    vmem = psutil.virtual_memory()  
    print(f"[Memory] total={vmem.total/1e9:.1f}GB used={vmem.used/1e9:.1f}GB avail={vmem.available/1e9:.1f}GB percent={vmem.percent}%")  
  
def tensor_stats(t):  
    """Ëé∑Âèñ tensor ÁªüËÆ°‰ø°ÊÅØ"""  
    if not torch.is_tensor(t):  
        return f"not tensor (type={type(t).__name__})"  
    try:  
        has_nan = torch.isnan(t).any().item() if t.dtype in [torch.float32, torch.float64, torch.float16] else False  
        has_inf = torch.isinf(t).any().item() if t.dtype in [torch.float32, torch.float64, torch.float16] else False  
        return (f"shape={tuple(t.shape)}, dtype={t.dtype}, "  
                f"min={float(t.min()):.4e}, max={float(t.max()):.4e}, "  
                f"mean={float(t.mean()):.4e}, NaN={has_nan}, Inf={has_inf}")  
    except Exception as e:  
        return f"shape={tuple(t.shape)}, dtype={t.dtype}, ERROR: {e}"  
  
def sample_summary(sample):  
    """ÁîüÊàêÊ†∑Êú¨ÊëòË¶Å"""  
    info = []  
    if isinstance(sample, dict):  
        for k, v in sample.items():  
            try:  
                if torch.is_tensor(v):  
                    info.append(f"  {k}: {tensor_stats(v)}")  
                else:  
                    info.append(f"  {k}: type={type(v).__name__}, len={len(v) if hasattr(v, '__len__') else 'N/A'}")  
            except Exception as e:  
                info.append(f"  {k}: ERROR - {e}")  
    elif isinstance(sample, (list, tuple)):  
        for i, v in enumerate(sample):  
            try:  
                info.append(f"  [{i}] {tensor_stats(v) if torch.is_tensor(v) else type(v).__name__}")  
            except Exception:  
                pass  
    else:  
        info.append(f"  type={type(sample).__name__}")  
    return "\n".join(info)  
  
def test_lmdb_integrity(lmdb_path, max_samples=100):  
    """ÊµãËØï LMDB Êï∞ÊçÆÂ∫ìÂÆåÊï¥ÊÄß"""  
    print(f"\n=== üîç Testing LMDB integrity: {lmdb_path} ===")  
    try:  
        env = lmdb.open(lmdb_path, readonly=True, lock=False, readahead=False, meminit=False)  
        with env.begin() as txn:  
            meta = txn.get(b'__metadata__')  
            if meta is None:  
                print("‚ùå Missing metadata in LMDB")  
                return False  
              
            meta_dict = pickle.loads(meta)  
            total_samples = meta_dict.get('num_samples', 0)  
            print(f"‚úÖ Metadata found: {total_samples} samples")  
              
            import random  
            test_indices = random.sample(range(total_samples), min(max_samples, total_samples))  
            corrupted = []  
              
            for idx in test_indices:  
                try:  
                    key = f'{idx}'.encode()  
                    data_bytes = txn.get(key)  
                    if data_bytes is None:  
                        corrupted.append((idx, "Missing key"))  
                        continue  
                    pkl_data = pickle.loads(data_bytes)  
                except Exception as e:  
                    corrupted.append((idx, str(e)))  
              
            if corrupted:  
                print(f"‚ùå Found {len(corrupted)} corrupted samples:")  
                for idx, err in corrupted[:10]:  
                    print(f"  Sample {idx}: {err}")  
                return False  
            else:  
                print(f"‚úÖ All {len(test_indices)} tested samples are valid")  
                return True  
                  
    except Exception as e:  
        print(f"‚ùå LMDB error: {e}")  
        traceback.print_exc()  
        return False  
  
def main():  
    print("=" * 60)  
    print("üß© AffinCraft DataLoader Â¥©Ê∫ÉËØäÊñ≠ËÑöÊú¨")  
    print("=" * 60)  
    shm_status()  
    print(f"PID: {os.getpid()}\n")  
  
    lmdb_path = "/ssd/home/scw6f3q/train_lmdb"  
      
    # 1Ô∏è‚É£ ÊµãËØï LMDB ÂÆåÊï¥ÊÄß  
    if not test_lmdb_integrity(lmdb_path):  
        print("\n‚ö†Ô∏è  LMDB Êï∞ÊçÆÂ∫ìÂ≠òÂú®ÈóÆÈ¢ò,ËØ∑ÂÖà‰øÆÂ§ç")  
        return  
  
    # 2Ô∏è‚É£ ÊûÑÈÄ† Dataset  
    print(f"\n=== üì¶ Loading dataset from {lmdb_path} ===")  
    try:  
        dataset = LMDBAffinCraftDataset(lmdb_path=lmdb_path)  
        print(f"‚úÖ Loaded dataset with {len(dataset)} samples")  
    except Exception as e:  
        print(f"‚ùå [ERROR dataset init] {e}")  
        traceback.print_exc()  
        return  
  
    # 3Ô∏è‚É£ ÊµãËØïÂçïÊ†∑Êú¨Âä†ËΩΩ  
    print("\n=== üî¨ Testing individual sample loading ===")  
    test_indices = [0, len(dataset)//2, len(dataset)-1]  
    for idx in test_indices:  
        try:  
            sample = dataset[idx]  
            print(f"‚úÖ Sample {idx} loaded successfully")  
            print(sample_summary(sample))  
        except Exception as e:  
            print(f"‚ùå Sample {idx} failed: {e}")  
            traceback.print_exc()  
  
    # 4Ô∏è‚É£ DataLoader ÊµãËØï - ‰ΩøÁî®ÁÆÄÂçïÁöÑ collate  
    print("\n=== üöÄ Testing DataLoader ===")  
      
    def simple_collate(batch):  
        """ÁÆÄÂçïÁöÑ collate ÂáΩÊï∞,ÈÅøÂÖçÂ§çÊùÇ‰æùËµñ"""  
        return batch  
      
    for num_workers in [0, 2, 4]:  
        print(f"\n--- Testing with num_workers={num_workers} ---")  
        loader = DataLoader(  
            dataset,  
            batch_size=4,  
            num_workers=num_workers,  
            collate_fn=simple_collate,  
            persistent_workers=False,  
            pin_memory=False,  
            shuffle=False,  
            timeout=30 if num_workers > 0 else 0,  
        )  
  
        try:  
            for i, batch in enumerate(loader):  
                if i % 50 == 0:  
                    shm_status()  
                    rss = psutil.Process(os.getpid()).memory_info().rss / 1e9  
                    print(f"[STEP {i}] RAM={rss:.2f} GB")  
                  
                # Ê£ÄÊü• batch ÂÜÖÂÆπ  
                for sample in batch:  
                    if isinstance(sample, dict):  
                        for k, v in sample.items():  
                            if torch.is_tensor(v):  
                                stats = tensor_stats(v)  
                                if "NaN=True" in stats or "Inf=True" in stats:  
                                    print(f"‚ö†Ô∏è  Batch {i} {k}: {stats}")  
                  
                if i >= 200:  
                    break  
                      
            print(f"‚úÖ Completed {i+1} batches with num_workers={num_workers}")  
              
        except Exception as e:  
            print(f"\n{'='*60}")  
            print(f"üí• CRASH DETECTED at batch {i} with num_workers={num_workers}")  
            print(f"{'='*60}")  
            print(f"Exception: {str(e)}")  
            traceback.print_exc()  
  
            print("\n--- üîç Single sample investigation ---")  
            start_idx = i * 4  
            for j in range(start_idx, min(start_idx + 4, len(dataset))):  
                try:  
                    s = dataset[j]  
                    print(f"‚úÖ [Sample {j}] OK")  
                    print(sample_summary(s))  
                except Exception as ee:  
                    print(f"‚ùå [Sample {j}] ERROR: {ee}")  
                    traceback.print_exc()  
            print("="*60)  
            break  
  
    print("\n=== ‚úÖ Diagnostic completed ===")  
  
if __name__ == "__main__":  
    main()